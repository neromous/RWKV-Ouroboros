{
  "proj_dir": "/home/neromous/RWKV-Ourobros/resources/weights",
  "port": 3000,
  "debug": false,
  "use_model": "rwkv",
  "db": {
    "host": "http://127.0.0.1:9001",
    "api_for_transact" : "",
    "api_for_query" : "",
    "api_for_remove" : ""
  },
  "jit_on": "",
  "add_init_prompt_after_train": true,
  "model": {
    "load_model": "/home/neromous/RWKV-Ourobros/resources/weights/RWKV-5-World-3B-v2-20231118-ctx16k.pth",
    "rwkv_version": "v5",
    "n_embd": -1,
    "n_layer": -1,
    "vocab_size": -1,
    "ctx_len": 2048,
    "dtype": "bf16",
    "head_size": 64,
    "head_size_a": 64,
    "head_size_divisor": 8
  },
  "trainer": {
    "train_type": "",
    "infctx_on": true,
    "warmup_steps": 0,
    "ctx_len": 4096,
    "grad_cp": 1,
    "dropout": 0,
    "window": 0,
    "min_loss": 0,
    "max_loss": 10,
    "min_loss_fix": 0.05,
    "max_loss_fix": 1,
    "ctx_parts": "0",
    "tokenizer": "/home/neromous/RWKV-Ourobros/resources/vocab/rwkv_vocab_v20230424.txt",
    "head_size": 64,
    "weight_decay": 0.01,
    "dim_att": 0,
    "dim_ffn": 0,
    "my_qa_mask": 0,
    "my_pos_emb": 0,
    "tiny_att_dim": 0,
    "pre_ffn": 0,
    "head_qk": 0,
    "layerwise_lr": 1,
    "lr_init": 1.0e-4,
    "beta1": 0.9,
    "beta2": 0.99,
    "adam_eps": 1.0e-8,
    "pre_ffn": 0,
    "optimzer_style":"",
    "adamw_mode": true,
    "my_pile_stage": 1
  },
  "inference": {
    "tokenizer": "/home/neromous/RWKV-Ourobros/resources/vocab/rwkv_vocab_v20230424.txt",
    "max_tokens": 300,
    "use_pos_cfg": false,
    "use_neg_cfg": false,
    "cfg_pos_alpha": 0.4,
    "cfg_neg_alpha": 0.2,
    "prompt_config": {
      "temperature": 1,
      "top_p": 0.85,
      "top_k": 0,
      "alpha_frequency": 0.2,
      "alpha_presence": 0.2,
      "alpha_decay": 1,
      "token_ban": [0],
      "token_stop": [65535],
      "chunk_len": 256,
      "token_count": 0,
      "over": true
    }
  }
}
