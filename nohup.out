[2023-09-30 14:43:29,895] [WARNING] [runner.py:190:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-09-30 14:43:29,915] [INFO] [runner.py:540:main] cmd = /home/neromous/.minicoda3/envs/blackfog/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None app.py --deepspeed
[2023-09-30 14:43:32,381] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [1]}
[2023-09-30 14:43:32,381] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=1, node_rank=0
[2023-09-30 14:43:32,381] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2023-09-30 14:43:32,381] [INFO] [launch.py:247:main] dist_world_size=1
[2023-09-30 14:43:32,381] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=1
RWKV_MY_TESTING 
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/wkv_512/build.ninja...
Building extension module wkv_512...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module wkv_512...
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 4.616151332855225 seconds
Adam Optimizer #0 is created with AVX2 arithmetic capability.
Config: alpha=0.000100, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=0
[2023-09-30 14:44:20,319] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.1, git-hash=unknown, git-branch=unknown
[2023-09-30 14:44:20,320] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-09-30 14:44:23,626] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-30 14:44:23,628] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-09-30 14:44:23,628] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-09-30 14:44:23,667] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2023-09-30 14:44:23,667] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2023-09-30 14:44:23,667] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 2 optimizer
[2023-09-30 14:44:23,667] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 2000000
[2023-09-30 14:44:23,667] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 2000000
[2023-09-30 14:44:23,668] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True
[2023-09-30 14:44:23,668] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.23317265510559082 seconds
Rank: 0 partition count [1, 1, 1] and sizes[(3062589440, False), (81920, False), (81920, False)] 
[2023-09-30 14:44:50,011] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-09-30 14:44:50,012] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 14:44:50,012] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 22.04 GB, percent = 17.5%
[2023-09-30 14:45:09,469] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-09-30 14:45:09,470] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 14:45:09,470] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.25 GB, percent = 48.7%
[2023-09-30 14:45:09,471] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized
[2023-09-30 14:45:11,081] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-09-30 14:45:11,082] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 14:45:11,082] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.27 GB, percent = 48.7%
[2023-09-30 14:45:11,106] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam
[2023-09-30 14:45:11,106] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-09-30 14:45:11,106] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7fb77d5f10d0>
[2023-09-30 14:45:11,106] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001, 0.0002, 0.00030000000000000003], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
[2023-09-30 14:45:11,107] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[2023-09-30 14:45:11,108] [INFO] [config.py:957:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-30 14:45:11,108] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-30 14:45:11,108] [INFO] [config.py:957:print]   amp_enabled .................. False
[2023-09-30 14:45:11,108] [INFO] [config.py:957:print]   amp_params ................... False
[2023-09-30 14:45:11,108] [INFO] [config.py:957:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-30 14:45:11,108] [INFO] [config.py:957:print]   bfloat16_enabled ............. False
[2023-09-30 14:45:11,108] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[2023-09-30 14:45:11,108] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fb77d5c80d0>
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   communication_data_type ...... None
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   disable_allgather ............ False
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   dump_state ................... False
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... None
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   fp16_auto_cast ............... None
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   fp16_enabled ................. False
[2023-09-30 14:45:11,109] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[2023-09-30 14:45:11,110] [INFO] [config.py:957:print]   global_rank .................. 0
[2023-09-30 14:45:11,110] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[2023-09-30 14:45:11,110] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 1
[2023-09-30 14:45:11,110] [INFO] [config.py:957:print]   gradient_clipping ............ 1
[2023-09-30 14:45:11,110] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[2023-09-30 14:45:11,110] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-30 14:45:11,110] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 65536
[2023-09-30 14:45:11,110] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[2023-09-30 14:45:11,110] [INFO] [config.py:957:print]   loss_scale ................... 0
[2023-09-30 14:45:11,110] [INFO] [config.py:957:print]   memory_breakdown ............. False
[2023-09-30 14:45:11,110] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-30 14:45:11,110] [INFO] [config.py:957:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-30 14:45:11,110] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[2023-09-30 14:45:11,110] [INFO] [config.py:957:print]   optimizer_name ............... None
[2023-09-30 14:45:11,110] [INFO] [config.py:957:print]   optimizer_params ............. None
[2023-09-30 14:45:11,110] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-30 14:45:11,110] [INFO] [config.py:957:print]   pld_enabled .................. False
[2023-09-30 14:45:11,110] [INFO] [config.py:957:print]   pld_params ................... False
[2023-09-30 14:45:11,110] [INFO] [config.py:957:print]   prescale_gradients ........... False
[2023-09-30 14:45:11,110] [INFO] [config.py:957:print]   scheduler_name ............... None
[2023-09-30 14:45:11,111] [INFO] [config.py:957:print]   scheduler_params ............. None
[2023-09-30 14:45:11,111] [INFO] [config.py:957:print]   sparse_attention ............. None
[2023-09-30 14:45:11,111] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[2023-09-30 14:45:11,111] [INFO] [config.py:957:print]   steps_per_print .............. 10
[2023-09-30 14:45:11,111] [INFO] [config.py:957:print]   train_batch_size ............. 1
[2023-09-30 14:45:11,111] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  1
[2023-09-30 14:45:11,111] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[2023-09-30 14:45:11,111] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[2023-09-30 14:45:11,111] [INFO] [config.py:957:print]   world_size ................... 1
[2023-09-30 14:45:11,111] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  False
[2023-09-30 14:45:11,111] [INFO] [config.py:957:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=2000000 allgather_partitions=True allgather_bucket_size=2000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[2023-09-30 14:45:11,111] [INFO] [config.py:957:print]   zero_enabled ................. True
[2023-09-30 14:45:11,111] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-30 14:45:11,111] [INFO] [config.py:957:print]   zero_optimization_stage ...... 2
[2023-09-30 14:45:11,111] [INFO] [config.py:943:print_user_config]   json = {
    "   fp16": {
        "enabled": false
    }, 
    "zero_optimization": {
        "stage": 2, 
        "offload_optimizer": {
            "device": "cpu", 
            "pin_memory": true
        }, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+06, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+06, 
        "contiguous_gradients": true
    }, 
    "gradient_accumulation_steps": 1, 
    "gradient_clipping": 1, 
    "train_micro_batch_size_per_gpu": 1, 
    "checkpoint": {
        "path": "/home/neromous/Documents/blackfog/resources/train-results/oneline/", 
        "keep_checkpoint_max": 3
    }
}
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.00045418739318847656 seconds
Bottle v0.12.25 server starting up (using WSGIRefServer())...
Listening on http://0.0.0.0:3000/
Hit Ctrl-C to quit.

[2023-09-30 16:38:02,153] [WARNING] [runner.py:190:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-09-30 16:38:02,173] [INFO] [runner.py:540:main] cmd = /home/neromous/.minicoda3/envs/blackfog/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None app.py --deepspeed
[2023-09-30 16:38:04,699] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [1]}
[2023-09-30 16:38:04,699] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=1, node_rank=0
[2023-09-30 16:38:04,699] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2023-09-30 16:38:04,699] [INFO] [launch.py:247:main] dist_world_size=1
[2023-09-30 16:38:04,699] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=1
RWKV_MY_TESTING 
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/wkv_512/build.ninja...
Building extension module wkv_512...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module wkv_512...
[2023-09-30 16:38:22,008] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 1207084
[2023-09-30 16:38:22,009] [ERROR] [launch.py:434:sigkill_handler] ['/home/neromous/.minicoda3/envs/blackfog/bin/python', '-u', 'app.py', '--local_rank=0', '--deepspeed'] exits with return code = -9
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 3.4222633838653564 seconds
Adam Optimizer #0 is created with AVX2 arithmetic capability.
Config: alpha=0.000100, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=0
[2023-09-30 16:38:27,349] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.1, git-hash=unknown, git-branch=unknown
[2023-09-30 16:38:27,350] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-09-30 16:38:27,999] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-30 16:38:28,001] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-09-30 16:38:28,001] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-09-30 16:38:28,025] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2023-09-30 16:38:28,025] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2023-09-30 16:38:28,025] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 2 optimizer
[2023-09-30 16:38:28,025] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 2000000
[2023-09-30 16:38:28,025] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 2000000
[2023-09-30 16:38:28,025] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True
[2023-09-30 16:38:28,025] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.22358965873718262 seconds
Rank: 0 partition count [1, 1, 1] and sizes[(461598720, False), (24576, False), (24576, False)] 
[2023-09-30 16:38:32,351] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-09-30 16:38:32,351] [INFO] [utils.py:786:see_memory_usage] MA 1.97 GB         Max_MA 1.97 GB         CA 1.97 GB         Max_CA 2 GB 
[2023-09-30 16:38:32,352] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 8.85 GB, percent = 7.0%
[2023-09-30 16:38:35,089] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-09-30 16:38:35,090] [INFO] [utils.py:786:see_memory_usage] MA 1.97 GB         Max_MA 1.97 GB         CA 1.97 GB         Max_CA 2 GB 
[2023-09-30 16:38:35,090] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 14.33 GB, percent = 11.4%
[2023-09-30 16:38:35,090] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized
[2023-09-30 16:38:35,750] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-09-30 16:38:35,751] [INFO] [utils.py:786:see_memory_usage] MA 1.97 GB         Max_MA 1.97 GB         CA 1.97 GB         Max_CA 2 GB 
[2023-09-30 16:38:35,751] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 14.33 GB, percent = 11.4%
[2023-09-30 16:38:35,766] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam
[2023-09-30 16:38:35,766] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-09-30 16:38:35,766] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7f9c5e773cd0>
[2023-09-30 16:38:35,766] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001, 0.0002, 0.00030000000000000003], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
[2023-09-30 16:38:35,767] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[2023-09-30 16:38:35,768] [INFO] [config.py:957:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-30 16:38:35,768] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-30 16:38:35,768] [INFO] [config.py:957:print]   amp_enabled .................. False
[2023-09-30 16:38:35,768] [INFO] [config.py:957:print]   amp_params ................... False
[2023-09-30 16:38:35,768] [INFO] [config.py:957:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-30 16:38:35,768] [INFO] [config.py:957:print]   bfloat16_enabled ............. False
[2023-09-30 16:38:35,768] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[2023-09-30 16:38:35,768] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[2023-09-30 16:38:35,768] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[2023-09-30 16:38:35,768] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f9c7ce4d040>
[2023-09-30 16:38:35,768] [INFO] [config.py:957:print]   communication_data_type ...... None
[2023-09-30 16:38:35,768] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-30 16:38:35,768] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[2023-09-30 16:38:35,768] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[2023-09-30 16:38:35,768] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-30 16:38:35,768] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[2023-09-30 16:38:35,768] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[2023-09-30 16:38:35,768] [INFO] [config.py:957:print]   disable_allgather ............ False
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   dump_state ................... False
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... None
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   fp16_auto_cast ............... None
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   fp16_enabled ................. False
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   global_rank .................. 0
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 1
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   gradient_clipping ............ 1
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 65536
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   loss_scale ................... 0
[2023-09-30 16:38:35,769] [INFO] [config.py:957:print]   memory_breakdown ............. False
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   optimizer_name ............... None
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   optimizer_params ............. None
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   pld_enabled .................. False
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   pld_params ................... False
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   prescale_gradients ........... False
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   scheduler_name ............... None
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   scheduler_params ............. None
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   sparse_attention ............. None
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   steps_per_print .............. 10
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   train_batch_size ............. 1
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  1
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   world_size ................... 1
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  False
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=2000000 allgather_partitions=True allgather_bucket_size=2000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   zero_enabled ................. True
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-30 16:38:35,770] [INFO] [config.py:957:print]   zero_optimization_stage ...... 2
[2023-09-30 16:38:35,771] [INFO] [config.py:943:print_user_config]   json = {
    "   fp16": {
        "enabled": false
    }, 
    "zero_optimization": {
        "stage": 2, 
        "offload_optimizer": {
            "device": "cpu", 
            "pin_memory": true
        }, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+06, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+06, 
        "contiguous_gradients": true
    }, 
    "gradient_accumulation_steps": 1, 
    "gradient_clipping": 1, 
    "train_micro_batch_size_per_gpu": 1, 
    "checkpoint": {
        "path": "/home/neromous/Documents/blackfog/resources/train-results/oneline/", 
        "keep_checkpoint_max": 3
    }
}
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0004134178161621094 seconds
Bottle v0.12.25 server starting up (using WSGIRefServer())...
Listening on http://0.0.0.0:3000/
Hit Ctrl-C to quit.

Traceback (most recent call last):
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 876, in _handle
    return route.call(**args)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 1759, in wrapper
    rv = callback(*a, **ka)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/app.py", line 155, in train
    for token in data_iter:
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/models/scene.py", line 76, in yield_tokens
    output = tokens[ctx:]
NameError: name 'ctx' is not defined
127.0.0.1 - - [30/Sep/2023 16:39:41] "POST /train/tx-data HTTP/1.1" 500 752
[2023-09-30 16:40:45,891] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 1239336
[2023-09-30 16:40:45,892] [ERROR] [launch.py:434:sigkill_handler] ['/home/neromous/.minicoda3/envs/blackfog/bin/python', '-u', 'app.py', '--local_rank=0', '--deepspeed'] exits with return code = -9
[2023-09-30 16:40:54,128] [WARNING] [runner.py:190:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-09-30 16:40:57,657] [INFO] [runner.py:540:main] cmd = /home/neromous/.minicoda3/envs/blackfog/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None app.py --deepspeed
[2023-09-30 16:41:00,151] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [1]}
[2023-09-30 16:41:00,151] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=1, node_rank=0
[2023-09-30 16:41:00,151] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2023-09-30 16:41:00,151] [INFO] [launch.py:247:main] dist_world_size=1
[2023-09-30 16:41:00,152] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=1
RWKV_MY_TESTING 
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/wkv_512/build.ninja...
Building extension module wkv_512...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module wkv_512...
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 3.167691230773926 seconds
Adam Optimizer #0 is created with AVX2 arithmetic capability.
Config: alpha=0.000100, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=0
[2023-09-30 16:41:21,608] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.1, git-hash=unknown, git-branch=unknown
[2023-09-30 16:41:21,609] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-09-30 16:41:22,237] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-30 16:41:22,238] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-09-30 16:41:22,238] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-09-30 16:41:22,262] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2023-09-30 16:41:22,262] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2023-09-30 16:41:22,262] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 2 optimizer
[2023-09-30 16:41:22,262] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 2000000
[2023-09-30 16:41:22,262] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 2000000
[2023-09-30 16:41:22,262] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True
[2023-09-30 16:41:22,262] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.24089789390563965 seconds
Rank: 0 partition count [1, 1, 1] and sizes[(461598720, False), (24576, False), (24576, False)] 
[2023-09-30 16:41:26,679] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-09-30 16:41:26,680] [INFO] [utils.py:786:see_memory_usage] MA 1.97 GB         Max_MA 1.97 GB         CA 1.97 GB         Max_CA 2 GB 
[2023-09-30 16:41:26,680] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 8.85 GB, percent = 7.0%
[2023-09-30 16:41:29,388] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-09-30 16:41:29,389] [INFO] [utils.py:786:see_memory_usage] MA 1.97 GB         Max_MA 1.97 GB         CA 1.97 GB         Max_CA 2 GB 
[2023-09-30 16:41:29,389] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 14.34 GB, percent = 11.4%
[2023-09-30 16:41:29,389] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized
[2023-09-30 16:41:30,060] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-09-30 16:41:30,061] [INFO] [utils.py:786:see_memory_usage] MA 1.97 GB         Max_MA 1.97 GB         CA 1.97 GB         Max_CA 2 GB 
[2023-09-30 16:41:30,061] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 14.34 GB, percent = 11.4%
[2023-09-30 16:41:30,083] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam
[2023-09-30 16:41:30,084] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-09-30 16:41:30,084] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7f0bf8a70220>
[2023-09-30 16:41:30,084] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001, 0.0002, 0.00030000000000000003], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
[2023-09-30 16:41:30,085] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[2023-09-30 16:41:30,085] [INFO] [config.py:957:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-30 16:41:30,085] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-30 16:41:30,085] [INFO] [config.py:957:print]   amp_enabled .................. False
[2023-09-30 16:41:30,085] [INFO] [config.py:957:print]   amp_params ................... False
[2023-09-30 16:41:30,085] [INFO] [config.py:957:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   bfloat16_enabled ............. False
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f0bf0d06b80>
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   communication_data_type ...... None
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   disable_allgather ............ False
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   dump_state ................... False
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... None
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[2023-09-30 16:41:30,086] [INFO] [config.py:957:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   fp16_auto_cast ............... None
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   fp16_enabled ................. False
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   global_rank .................. 0
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 1
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   gradient_clipping ............ 1
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 65536
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   loss_scale ................... 0
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   memory_breakdown ............. False
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   optimizer_name ............... None
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   optimizer_params ............. None
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   pld_enabled .................. False
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   pld_params ................... False
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   prescale_gradients ........... False
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   scheduler_name ............... None
[2023-09-30 16:41:30,087] [INFO] [config.py:957:print]   scheduler_params ............. None
[2023-09-30 16:41:30,088] [INFO] [config.py:957:print]   sparse_attention ............. None
[2023-09-30 16:41:30,088] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[2023-09-30 16:41:30,088] [INFO] [config.py:957:print]   steps_per_print .............. 10
[2023-09-30 16:41:30,088] [INFO] [config.py:957:print]   train_batch_size ............. 1
[2023-09-30 16:41:30,088] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  1
[2023-09-30 16:41:30,088] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[2023-09-30 16:41:30,088] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[2023-09-30 16:41:30,088] [INFO] [config.py:957:print]   world_size ................... 1
[2023-09-30 16:41:30,088] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  False
[2023-09-30 16:41:30,088] [INFO] [config.py:957:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=2000000 allgather_partitions=True allgather_bucket_size=2000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[2023-09-30 16:41:30,088] [INFO] [config.py:957:print]   zero_enabled ................. True
[2023-09-30 16:41:30,088] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-30 16:41:30,088] [INFO] [config.py:957:print]   zero_optimization_stage ...... 2
[2023-09-30 16:41:30,088] [INFO] [config.py:943:print_user_config]   json = {
    "   fp16": {
        "enabled": false
    }, 
    "zero_optimization": {
        "stage": 2, 
        "offload_optimizer": {
            "device": "cpu", 
            "pin_memory": true
        }, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+06, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+06, 
        "contiguous_gradients": true
    }, 
    "gradient_accumulation_steps": 1, 
    "gradient_clipping": 1, 
    "train_micro_batch_size_per_gpu": 1, 
    "checkpoint": {
        "path": "/home/neromous/Documents/blackfog/resources/train-results/oneline/", 
        "keep_checkpoint_max": 3
    }
}
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.00039887428283691406 seconds
Bottle v0.12.25 server starting up (using WSGIRefServer())...
Listening on http://0.0.0.0:3000/
Hit Ctrl-C to quit.

[2023-09-30 16:41:51,328] [INFO] [checkpointing.py:529:forward] Activation Checkpointing Information
[2023-09-30 16:41:51,328] [INFO] [checkpointing.py:530:forward] ----Partition Activations False, CPU CHECKPOINTING False
[2023-09-30 16:41:51,328] [INFO] [checkpointing.py:531:forward] ----contiguous Memory Checkpointing False with None total layers
[2023-09-30 16:41:51,328] [INFO] [checkpointing.py:533:forward] ----Synchronization False
[2023-09-30 16:41:51,328] [INFO] [checkpointing.py:534:forward] ----Profiling time in checkpointing False
Traceback (most recent call last):
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 876, in _handle
    return route.call(**args)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 1759, in wrapper
    rv = callback(*a, **ka)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/app.py", line 159, in train
    m = model_engine.training_step(batch, model_engine=model_engine)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/rwkv_model/model_lora.py", line 790, in training_step
    logits = self(idx)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/rwkv_model/model_lora.py", line 765, in forward
    x = deepspeed.checkpointing.checkpoint(block, x)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/deepspeed/runtime/activation_checkpointing/checkpointing.py", line 713, in checkpoint
    CheckpointFunction.apply(function, all_outputs, *args)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/torch/autograd/function.py", line 506, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/deepspeed/runtime/activation_checkpointing/checkpointing.py", line 555, in forward
    outputs = run_function(*inputs_cuda)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/rwkv_model/model_lora.py", line 518, in forward
    x = x + self.att(self.ln1(x))
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/rwkv_model/model_lora.py", line 422, in forward
    sr, k, v = self.jit_func(x)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/rwkv_model/model_lora.py", line 410, in jit_func
    @MyFunction
    def jit_func(self, x):
        xx = self.time_shift(x) # Mix x with the previous timestep to produce xk, xv, xr
             ~~~~~~~~~~~~~~~ <--- HERE
        xk = x * self.time_mix_k + xx * (1 - self.time_mix_k)
        xv = x * self.time_mix_v + xx * (1 - self.time_mix_v)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/torch/nn/modules/padding.py", line 25, in forward
    def forward(self, input: Tensor) -> Tensor:
        return F.pad(input, self.padding, 'constant', self.value)
               ~~~~~ <--- HERE
RuntimeError: narrow(): length must be non-negative.

127.0.0.1 - - [30/Sep/2023 16:41:51] "POST /train/tx-data HTTP/1.1" 500 752
[2023-09-30 16:42:56,292] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 1240743
[2023-09-30 16:42:56,293] [ERROR] [launch.py:434:sigkill_handler] ['/home/neromous/.minicoda3/envs/blackfog/bin/python', '-u', 'app.py', '--local_rank=0', '--deepspeed'] exits with return code = -9
[2023-09-30 16:43:00,215] [WARNING] [runner.py:190:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-09-30 16:43:00,235] [INFO] [runner.py:540:main] cmd = /home/neromous/.minicoda3/envs/blackfog/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None app.py --deepspeed
[2023-09-30 16:43:02,761] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [1]}
[2023-09-30 16:43:02,761] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=1, node_rank=0
[2023-09-30 16:43:02,761] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2023-09-30 16:43:02,761] [INFO] [launch.py:247:main] dist_world_size=1
[2023-09-30 16:43:02,761] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=1
RWKV_MY_TESTING 
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/wkv_512/build.ninja...
Building extension module wkv_512...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module wkv_512...
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 3.2136683464050293 seconds
Adam Optimizer #0 is created with AVX2 arithmetic capability.
Config: alpha=0.000100, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=0
[2023-09-30 16:43:24,447] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.1, git-hash=unknown, git-branch=unknown
[2023-09-30 16:43:24,447] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-09-30 16:43:25,064] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-30 16:43:25,065] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-09-30 16:43:25,065] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-09-30 16:43:25,089] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2023-09-30 16:43:25,089] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2023-09-30 16:43:25,089] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 2 optimizer
[2023-09-30 16:43:25,089] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 2000000
[2023-09-30 16:43:25,089] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 2000000
[2023-09-30 16:43:25,089] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True
[2023-09-30 16:43:25,089] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.2330338954925537 seconds
Rank: 0 partition count [1, 1, 1] and sizes[(461598720, False), (24576, False), (24576, False)] 
[2023-09-30 16:43:29,446] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-09-30 16:43:29,447] [INFO] [utils.py:786:see_memory_usage] MA 1.97 GB         Max_MA 1.97 GB         CA 1.97 GB         Max_CA 2 GB 
[2023-09-30 16:43:29,447] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 8.85 GB, percent = 7.0%
[2023-09-30 16:43:36,109] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-09-30 16:43:36,110] [INFO] [utils.py:786:see_memory_usage] MA 1.97 GB         Max_MA 1.97 GB         CA 1.97 GB         Max_CA 2 GB 
[2023-09-30 16:43:36,110] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 14.32 GB, percent = 11.4%
[2023-09-30 16:43:36,110] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized
[2023-09-30 16:43:36,763] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-09-30 16:43:36,763] [INFO] [utils.py:786:see_memory_usage] MA 1.97 GB         Max_MA 1.97 GB         CA 1.97 GB         Max_CA 2 GB 
[2023-09-30 16:43:36,764] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 14.33 GB, percent = 11.4%
[2023-09-30 16:43:36,779] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam
[2023-09-30 16:43:36,779] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-09-30 16:43:36,779] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7f8381a33c70>
[2023-09-30 16:43:36,779] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001, 0.0002, 0.00030000000000000003], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
[2023-09-30 16:43:36,780] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[2023-09-30 16:43:36,781] [INFO] [config.py:957:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-30 16:43:36,781] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-30 16:43:36,781] [INFO] [config.py:957:print]   amp_enabled .................. False
[2023-09-30 16:43:36,781] [INFO] [config.py:957:print]   amp_params ................... False
[2023-09-30 16:43:36,781] [INFO] [config.py:957:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-30 16:43:36,781] [INFO] [config.py:957:print]   bfloat16_enabled ............. False
[2023-09-30 16:43:36,781] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[2023-09-30 16:43:36,781] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[2023-09-30 16:43:36,781] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[2023-09-30 16:43:36,781] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f83940771f0>
[2023-09-30 16:43:36,781] [INFO] [config.py:957:print]   communication_data_type ...... None
[2023-09-30 16:43:36,781] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-30 16:43:36,781] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[2023-09-30 16:43:36,781] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[2023-09-30 16:43:36,781] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-30 16:43:36,781] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[2023-09-30 16:43:36,781] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[2023-09-30 16:43:36,781] [INFO] [config.py:957:print]   disable_allgather ............ False
[2023-09-30 16:43:36,781] [INFO] [config.py:957:print]   dump_state ................... False
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... None
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   fp16_auto_cast ............... None
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   fp16_enabled ................. False
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   global_rank .................. 0
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 1
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   gradient_clipping ............ 1
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 65536
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   loss_scale ................... 0
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   memory_breakdown ............. False
[2023-09-30 16:43:36,782] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   optimizer_name ............... None
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   optimizer_params ............. None
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   pld_enabled .................. False
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   pld_params ................... False
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   prescale_gradients ........... False
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   scheduler_name ............... None
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   scheduler_params ............. None
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   sparse_attention ............. None
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   steps_per_print .............. 10
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   train_batch_size ............. 1
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  1
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   world_size ................... 1
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  False
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=2000000 allgather_partitions=True allgather_bucket_size=2000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   zero_enabled ................. True
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-30 16:43:36,783] [INFO] [config.py:957:print]   zero_optimization_stage ...... 2
[2023-09-30 16:43:36,783] [INFO] [config.py:943:print_user_config]   json = {
    "   fp16": {
        "enabled": false
    }, 
    "zero_optimization": {
        "stage": 2, 
        "offload_optimizer": {
            "device": "cpu", 
            "pin_memory": true
        }, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+06, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+06, 
        "contiguous_gradients": true
    }, 
    "gradient_accumulation_steps": 1, 
    "gradient_clipping": 1, 
    "train_micro_batch_size_per_gpu": 1, 
    "checkpoint": {
        "path": "/home/neromous/Documents/blackfog/resources/train-results/oneline/", 
        "keep_checkpoint_max": 3
    }
}
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0003781318664550781 seconds
Bottle v0.12.25 server starting up (using WSGIRefServer())...
Listening on http://0.0.0.0:3000/
Hit Ctrl-C to quit.

{'input_ids': [], 'attention_mask': None}
[2023-09-30 16:43:53,902] [INFO] [checkpointing.py:529:forward] Activation Checkpointing Information
[2023-09-30 16:43:53,902] [INFO] [checkpointing.py:530:forward] ----Partition Activations False, CPU CHECKPOINTING False
[2023-09-30 16:43:53,902] [INFO] [checkpointing.py:531:forward] ----contiguous Memory Checkpointing False with None total layers
[2023-09-30 16:43:53,902] [INFO] [checkpointing.py:533:forward] ----Synchronization False
[2023-09-30 16:43:53,902] [INFO] [checkpointing.py:534:forward] ----Profiling time in checkpointing False
Traceback (most recent call last):
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 876, in _handle
    return route.call(**args)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 1759, in wrapper
    rv = callback(*a, **ka)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/app.py", line 160, in train
    m = model_engine.training_step(batch, model_engine=model_engine)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/rwkv_model/model_lora.py", line 790, in training_step
    logits = self(idx)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/rwkv_model/model_lora.py", line 765, in forward
    x = deepspeed.checkpointing.checkpoint(block, x)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/deepspeed/runtime/activation_checkpointing/checkpointing.py", line 713, in checkpoint
    CheckpointFunction.apply(function, all_outputs, *args)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/torch/autograd/function.py", line 506, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/deepspeed/runtime/activation_checkpointing/checkpointing.py", line 555, in forward
    outputs = run_function(*inputs_cuda)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/rwkv_model/model_lora.py", line 518, in forward
    x = x + self.att(self.ln1(x))
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/rwkv_model/model_lora.py", line 422, in forward
    sr, k, v = self.jit_func(x)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/rwkv_model/model_lora.py", line 410, in jit_func
    @MyFunction
    def jit_func(self, x):
        xx = self.time_shift(x) # Mix x with the previous timestep to produce xk, xv, xr
             ~~~~~~~~~~~~~~~ <--- HERE
        xk = x * self.time_mix_k + xx * (1 - self.time_mix_k)
        xv = x * self.time_mix_v + xx * (1 - self.time_mix_v)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/torch/nn/modules/padding.py", line 25, in forward
    def forward(self, input: Tensor) -> Tensor:
        return F.pad(input, self.padding, 'constant', self.value)
               ~~~~~ <--- HERE
RuntimeError: narrow(): length must be non-negative.

127.0.0.1 - - [30/Sep/2023 16:43:54] "POST /train/tx-data HTTP/1.1" 500 752
[2023-09-30 16:44:33,875] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 1241445
[2023-09-30 16:44:33,876] [ERROR] [launch.py:434:sigkill_handler] ['/home/neromous/.minicoda3/envs/blackfog/bin/python', '-u', 'app.py', '--local_rank=0', '--deepspeed'] exits with return code = -9
[2023-09-30 16:44:35,625] [WARNING] [runner.py:190:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-09-30 16:44:35,645] [INFO] [runner.py:540:main] cmd = /home/neromous/.minicoda3/envs/blackfog/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None app.py --deepspeed
[2023-09-30 16:44:38,155] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [1]}
[2023-09-30 16:44:38,155] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=1, node_rank=0
[2023-09-30 16:44:38,155] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2023-09-30 16:44:38,155] [INFO] [launch.py:247:main] dist_world_size=1
[2023-09-30 16:44:38,155] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=1
RWKV_MY_TESTING 
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/wkv_512/build.ninja...
Building extension module wkv_512...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module wkv_512...
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 3.2163853645324707 seconds
Adam Optimizer #0 is created with AVX2 arithmetic capability.
Config: alpha=0.000100, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=0
[2023-09-30 16:44:59,755] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.1, git-hash=unknown, git-branch=unknown
[2023-09-30 16:44:59,755] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-09-30 16:45:00,370] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-30 16:45:00,372] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-09-30 16:45:00,372] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-09-30 16:45:00,395] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2023-09-30 16:45:00,395] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2023-09-30 16:45:00,395] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 2 optimizer
[2023-09-30 16:45:00,395] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 2000000
[2023-09-30 16:45:00,395] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 2000000
[2023-09-30 16:45:00,395] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True
[2023-09-30 16:45:00,395] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.2518012523651123 seconds
Rank: 0 partition count [1, 1, 1] and sizes[(461598720, False), (24576, False), (24576, False)] 
[2023-09-30 16:45:04,773] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-09-30 16:45:04,774] [INFO] [utils.py:786:see_memory_usage] MA 1.97 GB         Max_MA 1.97 GB         CA 1.97 GB         Max_CA 2 GB 
[2023-09-30 16:45:04,774] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 8.85 GB, percent = 7.0%
[2023-09-30 16:45:07,478] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-09-30 16:45:07,479] [INFO] [utils.py:786:see_memory_usage] MA 1.97 GB         Max_MA 1.97 GB         CA 1.97 GB         Max_CA 2 GB 
[2023-09-30 16:45:07,479] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 14.33 GB, percent = 11.4%
[2023-09-30 16:45:07,479] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized
[2023-09-30 16:45:08,136] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-09-30 16:45:08,136] [INFO] [utils.py:786:see_memory_usage] MA 1.97 GB         Max_MA 1.97 GB         CA 1.97 GB         Max_CA 2 GB 
[2023-09-30 16:45:08,137] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 14.33 GB, percent = 11.4%
[2023-09-30 16:45:08,152] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam
[2023-09-30 16:45:08,152] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-09-30 16:45:08,152] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7f9b22e35b50>
[2023-09-30 16:45:08,152] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001, 0.0002, 0.00030000000000000003], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
[2023-09-30 16:45:08,153] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[2023-09-30 16:45:08,153] [INFO] [config.py:957:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-30 16:45:08,153] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-30 16:45:08,153] [INFO] [config.py:957:print]   amp_enabled .................. False
[2023-09-30 16:45:08,153] [INFO] [config.py:957:print]   amp_params ................... False
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   bfloat16_enabled ............. False
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f9b2d706d30>
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   communication_data_type ...... None
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   disable_allgather ............ False
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   dump_state ................... False
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... None
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[2023-09-30 16:45:08,154] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   fp16_auto_cast ............... None
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   fp16_enabled ................. False
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   global_rank .................. 0
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 1
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   gradient_clipping ............ 1
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 65536
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   loss_scale ................... 0
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   memory_breakdown ............. False
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   optimizer_name ............... None
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   optimizer_params ............. None
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   pld_enabled .................. False
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   pld_params ................... False
[2023-09-30 16:45:08,155] [INFO] [config.py:957:print]   prescale_gradients ........... False
[2023-09-30 16:45:08,156] [INFO] [config.py:957:print]   scheduler_name ............... None
[2023-09-30 16:45:08,156] [INFO] [config.py:957:print]   scheduler_params ............. None
[2023-09-30 16:45:08,156] [INFO] [config.py:957:print]   sparse_attention ............. None
[2023-09-30 16:45:08,156] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[2023-09-30 16:45:08,156] [INFO] [config.py:957:print]   steps_per_print .............. 10
[2023-09-30 16:45:08,156] [INFO] [config.py:957:print]   train_batch_size ............. 1
[2023-09-30 16:45:08,156] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  1
[2023-09-30 16:45:08,156] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[2023-09-30 16:45:08,156] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[2023-09-30 16:45:08,156] [INFO] [config.py:957:print]   world_size ................... 1
[2023-09-30 16:45:08,156] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  False
[2023-09-30 16:45:08,156] [INFO] [config.py:957:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=2000000 allgather_partitions=True allgather_bucket_size=2000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[2023-09-30 16:45:08,156] [INFO] [config.py:957:print]   zero_enabled ................. True
[2023-09-30 16:45:08,156] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-30 16:45:08,156] [INFO] [config.py:957:print]   zero_optimization_stage ...... 2
[2023-09-30 16:45:08,156] [INFO] [config.py:943:print_user_config]   json = {
    "   fp16": {
        "enabled": false
    }, 
    "zero_optimization": {
        "stage": 2, 
        "offload_optimizer": {
            "device": "cpu", 
            "pin_memory": true
        }, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+06, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+06, 
        "contiguous_gradients": true
    }, 
    "gradient_accumulation_steps": 1, 
    "gradient_clipping": 1, 
    "train_micro_batch_size_per_gpu": 1, 
    "checkpoint": {
        "path": "/home/neromous/Documents/blackfog/resources/train-results/oneline/", 
        "keep_checkpoint_max": 3
    }
}
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0003788471221923828 seconds
Bottle v0.12.25 server starting up (using WSGIRefServer())...
Listening on http://0.0.0.0:3000/
Hit Ctrl-C to quit.

{'input_ids': [65535, 10444, 65530, 65532, 11164, 11164, 6134, 2058, 59, 33, 11640, 17772, 13091, 15446, 15898, 14734, 19137, 11957, 10260, 11957, 19156, 12605, 12605, 12605, 65535, 261, 65530, 65534, 5585, 41693, 59, 33, 13091, 14734, 19137, 11640, 17772, 13091, 15446, 15898, 14734, 19137, 12605, 16503, 12848, 17363, 10464, 11640, 17772, 13191, 13064, 10560, 17147, 11086, 14446, 10250, 10349, 18431, 15898, 10080, 65535, 261, 11111, 11111, 65535], 'attention_mask': None}
[2023-09-30 16:45:46,789] [INFO] [checkpointing.py:529:forward] Activation Checkpointing Information
[2023-09-30 16:45:46,789] [INFO] [checkpointing.py:530:forward] ----Partition Activations False, CPU CHECKPOINTING False
[2023-09-30 16:45:46,789] [INFO] [checkpointing.py:531:forward] ----contiguous Memory Checkpointing False with None total layers
[2023-09-30 16:45:46,790] [INFO] [checkpointing.py:533:forward] ----Synchronization False
[2023-09-30 16:45:46,790] [INFO] [checkpointing.py:534:forward] ----Profiling time in checkpointing False
127.0.0.1 - - [30/Sep/2023 16:45:54] "POST /train/tx-data HTTP/1.1" 200 27
[2023-09-30 17:14:02,124] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 1242055
[2023-09-30 17:14:02,126] [ERROR] [launch.py:434:sigkill_handler] ['/home/neromous/.minicoda3/envs/blackfog/bin/python', '-u', 'app.py', '--local_rank=0', '--deepspeed'] exits with return code = -9
[2023-09-30 18:36:34,507] [WARNING] [runner.py:190:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-09-30 18:36:34,527] [INFO] [runner.py:540:main] cmd = /home/neromous/.minicoda3/envs/blackfog/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None app.py --deepspeed
[2023-09-30 18:36:37,056] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [1]}
[2023-09-30 18:36:37,056] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=1, node_rank=0
[2023-09-30 18:36:37,056] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2023-09-30 18:36:37,056] [INFO] [launch.py:247:main] dist_world_size=1
[2023-09-30 18:36:37,056] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=1
RWKV_MY_TESTING 
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/wkv_512/build.ninja...
Building extension module wkv_512...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module wkv_512...
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 4.662330150604248 seconds
Adam Optimizer #0 is created with AVX2 arithmetic capability.
Config: alpha=0.000100, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=0
[2023-09-30 18:37:32,089] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.1, git-hash=unknown, git-branch=unknown
[2023-09-30 18:37:32,089] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-09-30 18:37:35,898] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-30 18:37:35,901] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-09-30 18:37:35,901] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-09-30 18:37:35,940] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2023-09-30 18:37:35,940] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2023-09-30 18:37:35,940] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 2 optimizer
[2023-09-30 18:37:35,940] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 2000000
[2023-09-30 18:37:35,940] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 2000000
[2023-09-30 18:37:35,940] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True
[2023-09-30 18:37:35,940] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.2947425842285156 seconds
Rank: 0 partition count [1, 1, 1] and sizes[(3062589440, False), (81920, False), (81920, False)] 
[2023-09-30 18:38:03,297] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-09-30 18:38:03,298] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 18:38:03,299] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 22.43 GB, percent = 17.8%
[2023-09-30 18:38:24,130] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-09-30 18:38:24,131] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 18:38:24,131] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.6 GB, percent = 49.0%
[2023-09-30 18:38:24,131] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized
[2023-09-30 18:38:26,232] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-09-30 18:38:26,233] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 18:38:26,234] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.61 GB, percent = 49.0%
[2023-09-30 18:38:26,268] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam
[2023-09-30 18:38:26,268] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-09-30 18:38:26,268] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7f55adb2c640>
[2023-09-30 18:38:26,268] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001, 0.0002, 0.00030000000000000003], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
[2023-09-30 18:38:26,269] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[2023-09-30 18:38:26,270] [INFO] [config.py:957:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-30 18:38:26,270] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-30 18:38:26,270] [INFO] [config.py:957:print]   amp_enabled .................. False
[2023-09-30 18:38:26,270] [INFO] [config.py:957:print]   amp_params ................... False
[2023-09-30 18:38:26,270] [INFO] [config.py:957:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-30 18:38:26,270] [INFO] [config.py:957:print]   bfloat16_enabled ............. False
[2023-09-30 18:38:26,270] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[2023-09-30 18:38:26,270] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[2023-09-30 18:38:26,270] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f55adb1e970>
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   communication_data_type ...... None
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   disable_allgather ............ False
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   dump_state ................... False
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... None
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   fp16_auto_cast ............... None
[2023-09-30 18:38:26,271] [INFO] [config.py:957:print]   fp16_enabled ................. False
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   global_rank .................. 0
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 1
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   gradient_clipping ............ 1
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 65536
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   loss_scale ................... 0
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   memory_breakdown ............. False
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   optimizer_name ............... None
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   optimizer_params ............. None
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   pld_enabled .................. False
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   pld_params ................... False
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   prescale_gradients ........... False
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   scheduler_name ............... None
[2023-09-30 18:38:26,272] [INFO] [config.py:957:print]   scheduler_params ............. None
[2023-09-30 18:38:26,273] [INFO] [config.py:957:print]   sparse_attention ............. None
[2023-09-30 18:38:26,273] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[2023-09-30 18:38:26,273] [INFO] [config.py:957:print]   steps_per_print .............. 10
[2023-09-30 18:38:26,273] [INFO] [config.py:957:print]   train_batch_size ............. 1
[2023-09-30 18:38:26,273] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  1
[2023-09-30 18:38:26,273] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[2023-09-30 18:38:26,273] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[2023-09-30 18:38:26,273] [INFO] [config.py:957:print]   world_size ................... 1
[2023-09-30 18:38:26,273] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  False
[2023-09-30 18:38:26,273] [INFO] [config.py:957:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=2000000 allgather_partitions=True allgather_bucket_size=2000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[2023-09-30 18:38:26,273] [INFO] [config.py:957:print]   zero_enabled ................. True
[2023-09-30 18:38:26,273] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-30 18:38:26,273] [INFO] [config.py:957:print]   zero_optimization_stage ...... 2
[2023-09-30 18:38:26,273] [INFO] [config.py:943:print_user_config]   json = {
    "   fp16": {
        "enabled": false
    }, 
    "zero_optimization": {
        "stage": 2, 
        "offload_optimizer": {
            "device": "cpu", 
            "pin_memory": true
        }, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+06, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+06, 
        "contiguous_gradients": true
    }, 
    "gradient_accumulation_steps": 1, 
    "gradient_clipping": 1, 
    "train_micro_batch_size_per_gpu": 1, 
    "checkpoint": {
        "path": "/home/neromous/Documents/blackfog/resources/train-results/oneline/", 
        "keep_checkpoint_max": 3
    }
}
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0005602836608886719 seconds
Bottle v0.12.25 server starting up (using WSGIRefServer())...
Listening on http://0.0.0.0:3000/
Hit Ctrl-C to quit.

[2023-09-30 19:20:04,963] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 1276601
[2023-09-30 19:20:04,964] [ERROR] [launch.py:434:sigkill_handler] ['/home/neromous/.minicoda3/envs/blackfog/bin/python', '-u', 'app.py', '--local_rank=0', '--deepspeed'] exits with return code = -9
[2023-09-30 19:20:43,073] [WARNING] [runner.py:190:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-09-30 19:20:43,093] [INFO] [runner.py:540:main] cmd = /home/neromous/.minicoda3/envs/blackfog/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None app.py --deepspeed
[2023-09-30 19:20:45,640] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [1]}
[2023-09-30 19:20:45,640] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=1, node_rank=0
[2023-09-30 19:20:45,640] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2023-09-30 19:20:45,640] [INFO] [launch.py:247:main] dist_world_size=1
[2023-09-30 19:20:45,640] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=1
RWKV_MY_TESTING 
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/wkv_512/build.ninja...
Building extension module wkv_512...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module wkv_512...
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 4.627546072006226 seconds
Adam Optimizer #0 is created with AVX2 arithmetic capability.
Config: alpha=0.000100, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=0
[2023-09-30 19:21:36,486] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.1, git-hash=unknown, git-branch=unknown
[2023-09-30 19:21:36,486] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-09-30 19:21:40,429] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-30 19:21:40,431] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-09-30 19:21:40,431] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-09-30 19:21:40,470] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2023-09-30 19:21:40,471] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2023-09-30 19:21:40,471] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 2 optimizer
[2023-09-30 19:21:40,471] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 2000000
[2023-09-30 19:21:40,471] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 2000000
[2023-09-30 19:21:40,471] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True
[2023-09-30 19:21:40,471] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.29407310485839844 seconds
Rank: 0 partition count [1, 1, 1] and sizes[(3062589440, False), (81920, False), (81920, False)] 
[2023-09-30 19:22:15,587] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-09-30 19:22:15,588] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 19:22:15,588] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 22.37 GB, percent = 17.8%
[2023-09-30 19:22:36,301] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-09-30 19:22:36,302] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 19:22:36,303] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.59 GB, percent = 49.0%
[2023-09-30 19:22:36,303] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized
[2023-09-30 19:22:38,390] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-09-30 19:22:38,391] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 19:22:38,391] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.59 GB, percent = 49.0%
[2023-09-30 19:22:38,420] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam
[2023-09-30 19:22:38,421] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-09-30 19:22:38,421] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7fbd700ea460>
[2023-09-30 19:22:38,421] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001, 0.0002, 0.00030000000000000003], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
[2023-09-30 19:22:38,422] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[2023-09-30 19:22:38,422] [INFO] [config.py:957:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-30 19:22:38,422] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-30 19:22:38,423] [INFO] [config.py:957:print]   amp_enabled .................. False
[2023-09-30 19:22:38,423] [INFO] [config.py:957:print]   amp_params ................... False
[2023-09-30 19:22:38,423] [INFO] [config.py:957:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-30 19:22:38,423] [INFO] [config.py:957:print]   bfloat16_enabled ............. False
[2023-09-30 19:22:38,423] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[2023-09-30 19:22:38,423] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[2023-09-30 19:22:38,423] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[2023-09-30 19:22:38,423] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fbd6ff99460>
[2023-09-30 19:22:38,423] [INFO] [config.py:957:print]   communication_data_type ...... None
[2023-09-30 19:22:38,423] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-30 19:22:38,423] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[2023-09-30 19:22:38,423] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[2023-09-30 19:22:38,423] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-30 19:22:38,423] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[2023-09-30 19:22:38,423] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[2023-09-30 19:22:38,423] [INFO] [config.py:957:print]   disable_allgather ............ False
[2023-09-30 19:22:38,423] [INFO] [config.py:957:print]   dump_state ................... False
[2023-09-30 19:22:38,423] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... None
[2023-09-30 19:22:38,423] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[2023-09-30 19:22:38,423] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-30 19:22:38,423] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-30 19:22:38,424] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[2023-09-30 19:22:38,424] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[2023-09-30 19:22:38,424] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[2023-09-30 19:22:38,424] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[2023-09-30 19:22:38,424] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[2023-09-30 19:22:38,424] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[2023-09-30 19:22:38,424] [INFO] [config.py:957:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-30 19:22:38,424] [INFO] [config.py:957:print]   fp16_auto_cast ............... None
[2023-09-30 19:22:38,424] [INFO] [config.py:957:print]   fp16_enabled ................. False
[2023-09-30 19:22:38,424] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[2023-09-30 19:22:38,424] [INFO] [config.py:957:print]   global_rank .................. 0
[2023-09-30 19:22:38,424] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[2023-09-30 19:22:38,424] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 1
[2023-09-30 19:22:38,424] [INFO] [config.py:957:print]   gradient_clipping ............ 1
[2023-09-30 19:22:38,424] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[2023-09-30 19:22:38,424] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-30 19:22:38,424] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 65536
[2023-09-30 19:22:38,424] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[2023-09-30 19:22:38,424] [INFO] [config.py:957:print]   loss_scale ................... 0
[2023-09-30 19:22:38,424] [INFO] [config.py:957:print]   memory_breakdown ............. False
[2023-09-30 19:22:38,424] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   optimizer_name ............... None
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   optimizer_params ............. None
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   pld_enabled .................. False
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   pld_params ................... False
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   prescale_gradients ........... False
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   scheduler_name ............... None
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   scheduler_params ............. None
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   sparse_attention ............. None
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   steps_per_print .............. 10
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   train_batch_size ............. 1
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  1
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   world_size ................... 1
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  False
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=2000000 allgather_partitions=True allgather_bucket_size=2000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   zero_enabled ................. True
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-30 19:22:38,425] [INFO] [config.py:957:print]   zero_optimization_stage ...... 2
[2023-09-30 19:22:38,425] [INFO] [config.py:943:print_user_config]   json = {
    "   fp16": {
        "enabled": false
    }, 
    "zero_optimization": {
        "stage": 2, 
        "offload_optimizer": {
            "device": "cpu", 
            "pin_memory": true
        }, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+06, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+06, 
        "contiguous_gradients": true
    }, 
    "gradient_accumulation_steps": 1, 
    "gradient_clipping": 1, 
    "train_micro_batch_size_per_gpu": 1, 
    "checkpoint": {
        "path": "/home/neromous/Documents/blackfog/resources/train-results/oneline/", 
        "keep_checkpoint_max": 3
    }
}
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0005447864532470703 seconds
Bottle v0.12.25 server starting up (using WSGIRefServer())...
Listening on http://0.0.0.0:3000/
Hit Ctrl-C to quit.

192.168.0.103 - - [30/Sep/2023 19:23:50] "POST /inference/by-inf HTTP/1.1" 404 754
====== None



<|me|><|request|>
<|over|>

<|me|><|response|>
<|over|>

<|me|><|request|>
<|over|>

<|me|><|response|>
<|over|>

<|me|><|request|>
<|over|>

<|me|><|response|>
<|over|>

<|me|><|request|>
<|over|>

<|me|><|response|>
<|over|>

<|me|><|request|>
<|over|>


Traceback (most recent call last):
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 876, in _handle
    return route.call(**args)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 1759, in wrapper
    rv = callback(*a, **ka)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/app.py", line 162, in inference_by_org
    msg = inferencer.generate(rwkv_rnn,msg)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/models/inference_helper.py", line 125, in generate
    logits , self.state = model(token, self.state)
TypeError: 'NoneType' object is not callable
192.168.0.103 - - [30/Sep/2023 19:24:33] "POST /inference/by-org HTTP/1.1" 500 759
  0%|          | 0/582 [00:00<?, ?it/s]100%|| 582/582 [00:00<00:00, 12134.26it/s]
  0%|          | 0/582 [00:00<?, ?it/s]100%|| 582/582 [00:00<00:00, 325782.05it/s]
127.0.0.1 - - [30/Sep/2023 19:25:55] "POST /inference/load-model HTTP/1.1" 200 26
====== None



<|me|><|request|>
<|over|>

<|me|><|response|>
<|over|>

<|me|><|request|>
<|over|>

<|me|><|response|>
<|over|>

<|me|><|request|>
<|over|>

<|me|><|response|>
<|over|>

<|me|><|request|>
<|over|>

<|me|><|response|>
<|over|>

<|me|><|request|>
<|over|>


```python
def is_palindrome(string):
    """Check if a string is a palindrome."""
    return string == string[::-1]
```

## 


```console
True
```

## 

*   [Python Cookbook](https://docs.python.org/3/library/index.html)
*   [Learn Python the Hard Way](https://www. ZhaoxuQiu.com/Books/LearnPythonTheHardWay/)
*   [Automate the Boring Stuff with Python](https://automatetheboringstudio.withsm.com/)
*   [Automate the Boring Stuff with Python, Second Edition](https://automatetheboringstudio.withsm.com/)
*   [Automate the Boring Stuff with Python, Third Edition](https://automatetheboringstudio.withsm.com/)
*   [Automate the Boring Stuff with Python, Fourth Edition](https://automatetheboringstudio.withsm.com/)
*   [Automate the Boring Stuff with Python, FifthTraceback (most recent call last):
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 876, in _handle
    return route.call(**args)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 1765, in wrapper
    json_response = dumps(rv)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/json/__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/json/encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type Message is not JSON serializable
192.168.0.103 - - [30/Sep/2023 19:26:23] "POST /inference/by-org HTTP/1.1" 500 759
[2023-09-30 19:29:14,213] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 1289811
[2023-09-30 19:29:14,214] [ERROR] [launch.py:434:sigkill_handler] ['/home/neromous/.minicoda3/envs/blackfog/bin/python', '-u', 'app.py', '--local_rank=0', '--deepspeed'] exits with return code = -9
[2023-09-30 19:30:06,300] [WARNING] [runner.py:190:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-09-30 19:30:06,320] [INFO] [runner.py:540:main] cmd = /home/neromous/.minicoda3/envs/blackfog/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None app.py --deepspeed
[2023-09-30 19:30:08,816] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [1]}
[2023-09-30 19:30:08,816] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=1, node_rank=0
[2023-09-30 19:30:08,816] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2023-09-30 19:30:08,816] [INFO] [launch.py:247:main] dist_world_size=1
[2023-09-30 19:30:08,816] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=1
RWKV_MY_TESTING 
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/wkv_512/build.ninja...
Building extension module wkv_512...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module wkv_512...
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 4.694763660430908 seconds
Adam Optimizer #0 is created with AVX2 arithmetic capability.
Config: alpha=0.000100, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=0
[2023-09-30 19:30:59,515] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.1, git-hash=unknown, git-branch=unknown
[2023-09-30 19:30:59,515] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-09-30 19:31:06,311] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-30 19:31:06,313] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-09-30 19:31:06,313] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-09-30 19:31:06,352] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2023-09-30 19:31:06,352] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2023-09-30 19:31:06,352] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 2 optimizer
[2023-09-30 19:31:06,352] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 2000000
[2023-09-30 19:31:06,352] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 2000000
[2023-09-30 19:31:06,352] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True
[2023-09-30 19:31:06,352] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.29123592376708984 seconds
Rank: 0 partition count [1, 1, 1] and sizes[(3062589440, False), (81920, False), (81920, False)] 
[2023-09-30 19:31:30,257] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-09-30 19:31:30,258] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 19:31:30,258] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 22.4 GB, percent = 17.8%
[2023-09-30 19:31:50,752] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-09-30 19:31:50,753] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 19:31:50,753] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.59 GB, percent = 49.0%
[2023-09-30 19:31:50,753] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized
[2023-09-30 19:31:52,863] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-09-30 19:31:52,864] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 19:31:52,864] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.59 GB, percent = 49.0%
[2023-09-30 19:31:52,890] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam
[2023-09-30 19:31:52,891] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-09-30 19:31:52,891] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7f648cba3700>
[2023-09-30 19:31:52,891] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001, 0.0002, 0.00030000000000000003], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
[2023-09-30 19:31:52,892] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[2023-09-30 19:31:52,892] [INFO] [config.py:957:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-30 19:31:52,892] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-30 19:31:52,893] [INFO] [config.py:957:print]   amp_enabled .................. False
[2023-09-30 19:31:52,893] [INFO] [config.py:957:print]   amp_params ................... False
[2023-09-30 19:31:52,893] [INFO] [config.py:957:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-30 19:31:52,893] [INFO] [config.py:957:print]   bfloat16_enabled ............. False
[2023-09-30 19:31:52,893] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[2023-09-30 19:31:52,893] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[2023-09-30 19:31:52,893] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[2023-09-30 19:31:52,893] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f648ca081c0>
[2023-09-30 19:31:52,893] [INFO] [config.py:957:print]   communication_data_type ...... None
[2023-09-30 19:31:52,893] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-30 19:31:52,893] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[2023-09-30 19:31:52,893] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[2023-09-30 19:31:52,893] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-30 19:31:52,893] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[2023-09-30 19:31:52,893] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[2023-09-30 19:31:52,893] [INFO] [config.py:957:print]   disable_allgather ............ False
[2023-09-30 19:31:52,893] [INFO] [config.py:957:print]   dump_state ................... False
[2023-09-30 19:31:52,893] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... None
[2023-09-30 19:31:52,893] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[2023-09-30 19:31:52,893] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   fp16_auto_cast ............... None
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   fp16_enabled ................. False
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   global_rank .................. 0
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 1
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   gradient_clipping ............ 1
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 65536
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   loss_scale ................... 0
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   memory_breakdown ............. False
[2023-09-30 19:31:52,894] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   optimizer_name ............... None
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   optimizer_params ............. None
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   pld_enabled .................. False
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   pld_params ................... False
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   prescale_gradients ........... False
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   scheduler_name ............... None
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   scheduler_params ............. None
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   sparse_attention ............. None
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   steps_per_print .............. 10
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   train_batch_size ............. 1
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  1
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   world_size ................... 1
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  False
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=2000000 allgather_partitions=True allgather_bucket_size=2000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   zero_enabled ................. True
[2023-09-30 19:31:52,895] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-30 19:31:52,896] [INFO] [config.py:957:print]   zero_optimization_stage ...... 2
[2023-09-30 19:31:52,896] [INFO] [config.py:943:print_user_config]   json = {
    "   fp16": {
        "enabled": false
    }, 
    "zero_optimization": {
        "stage": 2, 
        "offload_optimizer": {
            "device": "cpu", 
            "pin_memory": true
        }, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+06, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+06, 
        "contiguous_gradients": true
    }, 
    "gradient_accumulation_steps": 1, 
    "gradient_clipping": 1, 
    "train_micro_batch_size_per_gpu": 1, 
    "checkpoint": {
        "path": "/home/neromous/Documents/blackfog/resources/train-results/oneline/", 
        "keep_checkpoint_max": 3
    }
}
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.00044608116149902344 seconds
Bottle v0.12.25 server starting up (using WSGIRefServer())...
Listening on http://0.0.0.0:3000/
Hit Ctrl-C to quit.

====== None
Traceback (most recent call last):
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 876, in _handle
    return route.call(**args)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 1759, in wrapper
    rv = callback(*a, **ka)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/app.py", line 161, in inference_by_org
    while token[-1] in [0,65535,261,11]:
NameError: name 'token' is not defined
192.168.0.103 - - [30/Sep/2023 19:32:08] "POST /inference/by-org HTTP/1.1" 500 759
[2023-09-30 19:32:54,013] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 1292675
[2023-09-30 19:32:54,014] [ERROR] [launch.py:434:sigkill_handler] ['/home/neromous/.minicoda3/envs/blackfog/bin/python', '-u', 'app.py', '--local_rank=0', '--deepspeed'] exits with return code = -9
[2023-09-30 19:33:36,996] [WARNING] [runner.py:190:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-09-30 19:33:37,016] [INFO] [runner.py:540:main] cmd = /home/neromous/.minicoda3/envs/blackfog/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None app.py --deepspeed
[2023-09-30 19:33:39,543] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [1]}
[2023-09-30 19:33:39,543] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=1, node_rank=0
[2023-09-30 19:33:39,543] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2023-09-30 19:33:39,543] [INFO] [launch.py:247:main] dist_world_size=1
[2023-09-30 19:33:39,543] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=1
RWKV_MY_TESTING 
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/wkv_512/build.ninja...
Building extension module wkv_512...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module wkv_512...
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 4.655505657196045 seconds
Adam Optimizer #0 is created with AVX2 arithmetic capability.
Config: alpha=0.000100, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=0
[2023-09-30 19:34:32,972] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.1, git-hash=unknown, git-branch=unknown
[2023-09-30 19:34:32,973] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-09-30 19:34:36,763] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-30 19:34:36,765] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-09-30 19:34:36,766] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-09-30 19:34:36,805] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2023-09-30 19:34:36,805] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2023-09-30 19:34:36,805] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 2 optimizer
[2023-09-30 19:34:36,805] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 2000000
[2023-09-30 19:34:36,805] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 2000000
[2023-09-30 19:34:36,805] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True
[2023-09-30 19:34:36,806] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.3257639408111572 seconds
Rank: 0 partition count [1, 1, 1] and sizes[(3062589440, False), (81920, False), (81920, False)] 
[2023-09-30 19:35:03,929] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-09-30 19:35:03,930] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 19:35:03,930] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 22.38 GB, percent = 17.8%
[2023-09-30 19:35:24,625] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-09-30 19:35:24,626] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 19:35:24,626] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.61 GB, percent = 49.0%
[2023-09-30 19:35:24,627] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized
[2023-09-30 19:35:25,506] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-09-30 19:35:25,507] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 19:35:25,507] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.61 GB, percent = 49.0%
[2023-09-30 19:35:25,541] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam
[2023-09-30 19:35:25,541] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-09-30 19:35:25,541] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7f03a8cfe6a0>
[2023-09-30 19:35:25,541] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001, 0.0002, 0.00030000000000000003], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
[2023-09-30 19:35:25,542] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[2023-09-30 19:35:25,543] [INFO] [config.py:957:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-30 19:35:25,543] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-30 19:35:25,543] [INFO] [config.py:957:print]   amp_enabled .................. False
[2023-09-30 19:35:25,543] [INFO] [config.py:957:print]   amp_params ................... False
[2023-09-30 19:35:25,543] [INFO] [config.py:957:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-30 19:35:25,543] [INFO] [config.py:957:print]   bfloat16_enabled ............. False
[2023-09-30 19:35:25,543] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[2023-09-30 19:35:25,543] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[2023-09-30 19:35:25,543] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[2023-09-30 19:35:25,543] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f03a8b83460>
[2023-09-30 19:35:25,543] [INFO] [config.py:957:print]   communication_data_type ...... None
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   disable_allgather ............ False
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   dump_state ................... False
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... None
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   fp16_auto_cast ............... None
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   fp16_enabled ................. False
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   global_rank .................. 0
[2023-09-30 19:35:25,544] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 1
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   gradient_clipping ............ 1
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 65536
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   loss_scale ................... 0
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   memory_breakdown ............. False
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   optimizer_name ............... None
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   optimizer_params ............. None
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   pld_enabled .................. False
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   pld_params ................... False
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   prescale_gradients ........... False
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   scheduler_name ............... None
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   scheduler_params ............. None
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   sparse_attention ............. None
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[2023-09-30 19:35:25,545] [INFO] [config.py:957:print]   steps_per_print .............. 10
[2023-09-30 19:35:25,546] [INFO] [config.py:957:print]   train_batch_size ............. 1
[2023-09-30 19:35:25,546] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  1
[2023-09-30 19:35:25,546] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[2023-09-30 19:35:25,546] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[2023-09-30 19:35:25,546] [INFO] [config.py:957:print]   world_size ................... 1
[2023-09-30 19:35:25,546] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  False
[2023-09-30 19:35:25,546] [INFO] [config.py:957:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=2000000 allgather_partitions=True allgather_bucket_size=2000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[2023-09-30 19:35:25,546] [INFO] [config.py:957:print]   zero_enabled ................. True
[2023-09-30 19:35:25,546] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-30 19:35:25,546] [INFO] [config.py:957:print]   zero_optimization_stage ...... 2
[2023-09-30 19:35:25,546] [INFO] [config.py:943:print_user_config]   json = {
    "   fp16": {
        "enabled": false
    }, 
    "zero_optimization": {
        "stage": 2, 
        "offload_optimizer": {
            "device": "cpu", 
            "pin_memory": true
        }, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+06, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+06, 
        "contiguous_gradients": true
    }, 
    "gradient_accumulation_steps": 1, 
    "gradient_clipping": 1, 
    "train_micro_batch_size_per_gpu": 1, 
    "checkpoint": {
        "path": "/home/neromous/Documents/blackfog/resources/train-results/oneline/", 
        "keep_checkpoint_max": 3
    }
}
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0004334449768066406 seconds
Bottle v0.12.25 server starting up (using WSGIRefServer())...
Listening on http://0.0.0.0:3000/
Hit Ctrl-C to quit.

====== None
Traceback (most recent call last):
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 876, in _handle
    return route.call(**args)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 1759, in wrapper
    rv = callback(*a, **ka)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/app.py", line 165, in inference_by_org
    msg = inferencer.generate(rwkv_rnn,msg)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/models/inference_helper.py", line 125, in generate
    logits , self.state = model(token, self.state)
TypeError: 'NoneType' object is not callable
192.168.0.103 - - [30/Sep/2023 19:36:30] "POST /inference/by-org HTTP/1.1" 500 759
  0%|          | 0/582 [00:00<?, ?it/s]  1%|         | 8/582 [00:02<02:24,  3.97it/s]100%|| 582/582 [00:02<00:00, 288.18it/s]
  0%|          | 0/582 [00:00<?, ?it/s]100%|| 582/582 [00:00<00:00, 567166.57it/s]
127.0.0.1 - - [30/Sep/2023 19:37:00] "POST /inference/load-model HTTP/1.1" 200 26
====== None
```python
def is_palindrome(string):
    """Check if a string is a palindrome."""
    return string == string[::-1]
```

## 


```console
True
```

## 

*   [PyCharm](https://www.jetbrains.com/pycharm/): Integrated Development Environment for Python, with syntax highlighting and debugging tools.
*   [PyCharm IDE](https://www.jetbrains.com/pycharm/): Integrated development environment for Python, with syntax highlighting and debugging tools, built on top of [JetBrains](https://www.jetbrains.com/)' IntelliJ IDEA productivity suite.
*   [PyCharm IDE tutorial](https://www.jetbrains.com/pycharm/tutorial/): Learn how to use PyCharm to write plugins for IntelliJ IDEA, including plugin architecture and plugin API reference documentation.
*   [PyCharm tutorial](https://www.jetbrains.com/pycharm/tutorial/): Learn how to use PyCharm to write plugins for IntelliJ IDEA,192.168.0.103 - - [30/Sep/2023 19:38:07] "POST /inference/by-org HTTP/1.1" 200 4068
====== None
## @ @

[@TimZhangLLL](https://github.com/TimZhangLLL)

[@TimZhangLLL](https://github.com/TimZhangLLL)

[@TimZhangLLL](https://github.com/TimZhangLLL)

[@TimZhangLLL](https://github.com/TimZhangLLL)

[@TimZhangLLL](https://github.com/TimZhangLLL)

[@TimZhangLLL](https://github.com/TimZhangLLL)192.168.0.103 - - [30/Sep/2023 19:38:38] "POST /inference/by-org HTTP/1.1" 200 4511
192.168.0.103 - - [30/Sep/2023 19:44:24] "POST /inference/by-org-no-state HTTP/1.1" 404 772
[2023-09-30 19:45:07,340] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 1293729
[2023-09-30 19:45:07,341] [ERROR] [launch.py:434:sigkill_handler] ['/home/neromous/.minicoda3/envs/blackfog/bin/python', '-u', 'app.py', '--local_rank=0', '--deepspeed'] exits with return code = -9
[2023-09-30 19:46:07,284] [WARNING] [runner.py:190:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-09-30 19:46:10,131] [INFO] [runner.py:540:main] cmd = /home/neromous/.minicoda3/envs/blackfog/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None app.py --deepspeed
[2023-09-30 19:46:12,598] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [1]}
[2023-09-30 19:46:12,598] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=1, node_rank=0
[2023-09-30 19:46:12,598] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2023-09-30 19:46:12,598] [INFO] [launch.py:247:main] dist_world_size=1
[2023-09-30 19:46:12,598] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=1
RWKV_MY_TESTING 
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/wkv_512/build.ninja...
Building extension module wkv_512...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module wkv_512...
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 4.585330009460449 seconds
Adam Optimizer #0 is created with AVX2 arithmetic capability.
Config: alpha=0.000100, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=0
[2023-09-30 19:47:03,163] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.1, git-hash=unknown, git-branch=unknown
[2023-09-30 19:47:03,164] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-09-30 19:47:09,893] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-30 19:47:09,895] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-09-30 19:47:09,895] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-09-30 19:47:09,934] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2023-09-30 19:47:09,934] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2023-09-30 19:47:09,934] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 2 optimizer
[2023-09-30 19:47:09,935] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 2000000
[2023-09-30 19:47:09,935] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 2000000
[2023-09-30 19:47:09,935] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True
[2023-09-30 19:47:09,935] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.2807796001434326 seconds
Rank: 0 partition count [1, 1, 1] and sizes[(3062589440, False), (81920, False), (81920, False)] 
[2023-09-30 19:47:33,836] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-09-30 19:47:33,837] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 19:47:33,837] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 22.39 GB, percent = 17.8%
[2023-09-30 19:47:54,737] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-09-30 19:47:54,738] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 19:47:54,738] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.61 GB, percent = 49.0%
[2023-09-30 19:47:54,738] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized
[2023-09-30 19:47:56,842] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-09-30 19:47:56,843] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 19:47:56,843] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.61 GB, percent = 49.0%
[2023-09-30 19:47:56,871] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam
[2023-09-30 19:47:56,871] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-09-30 19:47:56,871] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7fca0f8de8e0>
[2023-09-30 19:47:56,871] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001, 0.0002, 0.00030000000000000003], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
[2023-09-30 19:47:56,872] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[2023-09-30 19:47:56,873] [INFO] [config.py:957:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-30 19:47:56,873] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-30 19:47:56,873] [INFO] [config.py:957:print]   amp_enabled .................. False
[2023-09-30 19:47:56,873] [INFO] [config.py:957:print]   amp_params ................... False
[2023-09-30 19:47:56,873] [INFO] [config.py:957:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-30 19:47:56,873] [INFO] [config.py:957:print]   bfloat16_enabled ............. False
[2023-09-30 19:47:56,873] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[2023-09-30 19:47:56,873] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[2023-09-30 19:47:56,873] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[2023-09-30 19:47:56,873] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fca0f6da9d0>
[2023-09-30 19:47:56,873] [INFO] [config.py:957:print]   communication_data_type ...... None
[2023-09-30 19:47:56,873] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-30 19:47:56,873] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[2023-09-30 19:47:56,873] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   disable_allgather ............ False
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   dump_state ................... False
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... None
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   fp16_auto_cast ............... None
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   fp16_enabled ................. False
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   global_rank .................. 0
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 1
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   gradient_clipping ............ 1
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-30 19:47:56,874] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 65536
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   loss_scale ................... 0
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   memory_breakdown ............. False
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   optimizer_name ............... None
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   optimizer_params ............. None
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   pld_enabled .................. False
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   pld_params ................... False
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   prescale_gradients ........... False
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   scheduler_name ............... None
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   scheduler_params ............. None
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   sparse_attention ............. None
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   steps_per_print .............. 10
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   train_batch_size ............. 1
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  1
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   world_size ................... 1
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  False
[2023-09-30 19:47:56,875] [INFO] [config.py:957:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=2000000 allgather_partitions=True allgather_bucket_size=2000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[2023-09-30 19:47:56,876] [INFO] [config.py:957:print]   zero_enabled ................. True
[2023-09-30 19:47:56,876] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-30 19:47:56,876] [INFO] [config.py:957:print]   zero_optimization_stage ...... 2
[2023-09-30 19:47:56,876] [INFO] [config.py:943:print_user_config]   json = {
    "   fp16": {
        "enabled": false
    }, 
    "zero_optimization": {
        "stage": 2, 
        "offload_optimizer": {
            "device": "cpu", 
            "pin_memory": true
        }, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+06, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+06, 
        "contiguous_gradients": true
    }, 
    "gradient_accumulation_steps": 1, 
    "gradient_clipping": 1, 
    "train_micro_batch_size_per_gpu": 1, 
    "checkpoint": {
        "path": "/home/neromous/Documents/blackfog/resources/train-results/oneline/", 
        "keep_checkpoint_max": 3
    }
}
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0005488395690917969 seconds
Bottle v0.12.25 server starting up (using WSGIRefServer())...
Listening on http://0.0.0.0:3000/
Hit Ctrl-C to quit.

====== None
org-mode:
1.  org-mode , C-c C-x 
2.  Shift+C-x  org mode
3.  Ctrl+C (Windows)  Command+C (Mac OS X)  cmd window,  org mode :
``` elisp
   (printf "\\n\\nOrg mode: \\n%s\\n"\\org_mode)
 Ctrl+V (Windows)  Command+V (Mac OS X) 
192.168.0.103 - - [30/Sep/2023 19:49:21] "POST /inference/by-org-no-state HTTP/1.1" 200 4261
  0%|          | 0/582 [00:00<?, ?it/s]100%|| 582/582 [00:00<00:00, 32374.70it/s]
  0%|          | 0/582 [00:00<?, ?it/s]100%|| 582/582 [00:00<00:00, 553157.70it/s]
====== None
Traceback (most recent call last):
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 876, in _handle
    return route.call(**args)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 1759, in wrapper
    rv = callback(*a, **ka)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/app.py", line 171, in inference_by_org
    msg = inferencer.generate(rwkv_rnn,msg)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/models/inference_helper.py", line 128, in generate
    logits[n] = -float('inf')
IndexError: list assignment index out of range
192.168.0.103 - - [30/Sep/2023 19:49:38] "POST /inference/by-org HTTP/1.1" 500 759
  0%|          | 0/582 [00:00<?, ?it/s]100%|| 582/582 [00:00<00:00, 28787.74it/s]
  0%|          | 0/582 [00:00<?, ?it/s]100%|| 582/582 [00:00<00:00, 564282.23it/s]
127.0.0.1 - - [30/Sep/2023 19:51:31] "POST /inference/load-model HTTP/1.1" 200 26
====== None
Traceback (most recent call last):
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 876, in _handle
    return route.call(**args)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 1759, in wrapper
    rv = callback(*a, **ka)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/app.py", line 171, in inference_by_org
    msg = inferencer.generate(rwkv_rnn,msg)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/models/inference_helper.py", line 128, in generate
    logits[n] = -float('inf')
IndexError: list assignment index out of range
192.168.0.103 - - [30/Sep/2023 19:51:42] "POST /inference/by-org HTTP/1.1" 500 759
192.168.0.103 - - [30/Sep/2023 19:52:29] "POST /train/by-org HTTP/1.1" 404 746
[2023-09-30 19:55:49,257] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 1297923
[2023-09-30 19:55:49,258] [ERROR] [launch.py:434:sigkill_handler] ['/home/neromous/.minicoda3/envs/blackfog/bin/python', '-u', 'app.py', '--local_rank=0', '--deepspeed'] exits with return code = -9
[2023-09-30 19:56:03,785] [WARNING] [runner.py:190:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-09-30 19:56:03,805] [INFO] [runner.py:540:main] cmd = /home/neromous/.minicoda3/envs/blackfog/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None app.py --deepspeed
[2023-09-30 19:56:06,318] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [1]}
[2023-09-30 19:56:06,319] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=1, node_rank=0
[2023-09-30 19:56:06,319] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2023-09-30 19:56:06,319] [INFO] [launch.py:247:main] dist_world_size=1
[2023-09-30 19:56:06,319] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=1
RWKV_MY_TESTING 
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/wkv_512/build.ninja...
Building extension module wkv_512...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module wkv_512...
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 4.607452154159546 seconds
Adam Optimizer #0 is created with AVX2 arithmetic capability.
Config: alpha=0.000100, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=0
[2023-09-30 19:56:59,396] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.1, git-hash=unknown, git-branch=unknown
[2023-09-30 19:56:59,396] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-09-30 19:57:02,062] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-30 19:57:02,064] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-09-30 19:57:02,064] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-09-30 19:57:02,103] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2023-09-30 19:57:02,103] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2023-09-30 19:57:02,103] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 2 optimizer
[2023-09-30 19:57:02,103] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 2000000
[2023-09-30 19:57:02,103] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 2000000
[2023-09-30 19:57:02,103] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True
[2023-09-30 19:57:02,103] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.3096616268157959 seconds
Rank: 0 partition count [1, 1, 1] and sizes[(3062589440, False), (81920, False), (81920, False)] 
[2023-09-30 19:57:24,706] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-09-30 19:57:24,707] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 19:57:24,708] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 22.38 GB, percent = 17.8%
[2023-09-30 19:57:44,875] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-09-30 19:57:44,876] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 19:57:44,876] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.6 GB, percent = 49.0%
[2023-09-30 19:57:44,876] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized
[2023-09-30 19:57:45,743] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-09-30 19:57:45,744] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 19:57:45,744] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.6 GB, percent = 49.0%
[2023-09-30 19:57:45,765] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam
[2023-09-30 19:57:45,765] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-09-30 19:57:45,765] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7fa1fb839f40>
[2023-09-30 19:57:45,765] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001, 0.0002, 0.00030000000000000003], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
[2023-09-30 19:57:45,766] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[2023-09-30 19:57:45,766] [INFO] [config.py:957:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-30 19:57:45,766] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-30 19:57:45,767] [INFO] [config.py:957:print]   amp_enabled .................. False
[2023-09-30 19:57:45,767] [INFO] [config.py:957:print]   amp_params ................... False
[2023-09-30 19:57:45,767] [INFO] [config.py:957:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-30 19:57:45,767] [INFO] [config.py:957:print]   bfloat16_enabled ............. False
[2023-09-30 19:57:45,767] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[2023-09-30 19:57:45,767] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[2023-09-30 19:57:45,767] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[2023-09-30 19:57:45,767] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fa1fb839640>
[2023-09-30 19:57:45,767] [INFO] [config.py:957:print]   communication_data_type ...... None
[2023-09-30 19:57:45,767] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-30 19:57:45,767] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[2023-09-30 19:57:45,767] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[2023-09-30 19:57:45,767] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-30 19:57:45,767] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[2023-09-30 19:57:45,767] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[2023-09-30 19:57:45,767] [INFO] [config.py:957:print]   disable_allgather ............ False
[2023-09-30 19:57:45,767] [INFO] [config.py:957:print]   dump_state ................... False
[2023-09-30 19:57:45,767] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... None
[2023-09-30 19:57:45,767] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[2023-09-30 19:57:45,767] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-30 19:57:45,767] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   fp16_auto_cast ............... None
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   fp16_enabled ................. False
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   global_rank .................. 0
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 1
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   gradient_clipping ............ 1
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 65536
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   loss_scale ................... 0
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   memory_breakdown ............. False
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-30 19:57:45,768] [INFO] [config.py:957:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   optimizer_name ............... None
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   optimizer_params ............. None
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   pld_enabled .................. False
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   pld_params ................... False
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   prescale_gradients ........... False
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   scheduler_name ............... None
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   scheduler_params ............. None
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   sparse_attention ............. None
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   steps_per_print .............. 10
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   train_batch_size ............. 1
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  1
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   world_size ................... 1
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  False
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=2000000 allgather_partitions=True allgather_bucket_size=2000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   zero_enabled ................. True
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-30 19:57:45,769] [INFO] [config.py:957:print]   zero_optimization_stage ...... 2
[2023-09-30 19:57:45,769] [INFO] [config.py:943:print_user_config]   json = {
    "   fp16": {
        "enabled": false
    }, 
    "zero_optimization": {
        "stage": 2, 
        "offload_optimizer": {
            "device": "cpu", 
            "pin_memory": true
        }, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+06, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+06, 
        "contiguous_gradients": true
    }, 
    "gradient_accumulation_steps": 1, 
    "gradient_clipping": 1, 
    "train_micro_batch_size_per_gpu": 1, 
    "checkpoint": {
        "path": "/home/neromous/Documents/blackfog/resources/train-results/oneline/", 
        "keep_checkpoint_max": 3
    }
}
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.000385284423828125 seconds
Bottle v0.12.25 server starting up (using WSGIRefServer())...
Listening on http://0.0.0.0:3000/
Hit Ctrl-C to quit.

  0%|          | 0/582 [00:00<?, ?it/s]  1%|         | 8/582 [00:00<00:46, 12.41it/s]100%|| 582/582 [00:00<00:00, 899.80it/s]
  0%|          | 0/582 [00:00<?, ?it/s]100%|| 582/582 [00:00<00:00, 526663.41it/s]
====== None
=== [16503, 13685, 17097, 17688, 11124, 15478, 15850, 14734, 17109, 10760, 11, 65530, 65532, 12605, 17879, 16503, 10464, 10988, 15641, 14931, 12314, 10267, 14610, 19137, 12176, 12605, 10708, 10250, 17303, 11975, 16735, 11, 65535, 261, 65530, 65534, 11685, 14734, 19137, 12605, 10423, 11986, 16707, 10708, 10250, 17303, 11975, 16735, 10080, 10260, 17141, 19137, 12605, 17879, 16503, 13179, 11632, 14734, 10529, 12445, 13234, 12176, 10847, 12605, 13250, 12410, 28329, 65535, 261, 65530, 65532, 10464, 17879, 16503, 10373, 10303, 10529, 12445, 19156, 11, 65535, 261, 65530, 65534, 18117, 10658, 19137, 12605, 17879, 16503, 14862, 17222, 17148, 17303, 11975, 16735, 14734, 15261, 11496, 10080, 13091, 15034, 12206, 11975, 16735, 10079, 12472, 14638, 11975, 16735, 17147, 13091, 10687, 10390, 15261, 11496, 14734, 11975, 16735, 19156, 11, 65535, 261, 65530, 65532, 12605, 16667, 10292, 13091, 15034, 12206, 11975, 16735, 11, 65535, 261, 65530, 65534, 11685, 14734, 19137, 12605, 10423, 10292, 10464, 12848, 10494, 13179, 11632, 15478, 15907, 10080, 11454, 17148, 17303, 11975, 16735, 10285, 19137, 10293, 10370, 10678, 13091, 10250, 10447, 11043, 11017, 11889, 12363, 18295, 2453, 10788, 10348, 18005, 14734, 12201, 17093, 10460, 11920, 10080, 10390, 11454, 10708, 10460, 17141, 15052, 10285, 11002, 10792, 10333, 13279, 15033, 14987, 15036, 10838, 17387, 14734, 12325, 11168, 19137, 12266, 11726, 10588, 10250, 10349, 11656, 12418, 14734, 13370, 10080, 17148, 10349, 13370, 11574, 16672, 10390, 15752, 11634, 14791, 16519, 13203, 13234, 11124, 17141, 10985, 19137, 12202, 10265, 16056, 12348, 10333, 13279, 15033, 14987, 11656, 14734, 10838, 17387, 28329, 65535, 261, 65530, 65532, 15752, 12848, 10494, 16721, 10293, 10370, 10678, 14734, 11630, 16815, 14332, 12333, 11124, 15727, 13126, 10529, 12445, 11053, 19156, 11, 65535, 261, 65530, 65534, 11685, 14734, 19137, 12605, 10423, 10292, 10464, 12848, 10494, 16721, 10293, 10370, 10678, 14734, 14782, 10684, 10529, 12445, 10080, 18117, 10658, 19137, 17148, 10447, 10293, 10370, 10678, 11043, 11017, 11889, 12363, 14179, 2453, 12163, 14332, 11979, 19137, 10390, 13091, 10250, 10447, 12201, 17093, 13191, 10292, 14734, 10460, 11920, 10080, 10687, 13557, 19137, 10390, 13191, 10250, 11647, 13833, 11930, 14734, 18438, 10997, 11124, 13913, 17808, 14734, 14806, 14815, 19137, 15494, 10370, 14614, 10258, 13913, 10799, 14734, 10951, 16803, 10080, 13188, 11044, 19137, 10390, 12421, 13091, 15091, 14808, 12348, 10452, 10079, 10296, 13579, 12348, 10452, 19137, 15494, 10370, 14614, 10258, 15895, 11685, 14734, 15162, 10250, 10951, 16803, 28329, 65535, 261, 65530, 65532]
==== < Message
id: (1447)
role: (text)
text: ()
prefix: ()
postfix: ()
prefix_token: ([])
temperature: (0.1)
top_p: (0.1)
top_k: (0)
alpha_frequency: (0.45)
alpha_presence: (0.45)
alpha_decay: (0.996)
token_ban: ([0])
token_stop: ([65530, 65531, 65532, 65533, 65534, 65535])
chunk_len: (128)
token_count: (256)
over: (True)
scene_id: (507)
response: ()
generated: (False)
to_train: (True)
ctx: (2048)
ctx_fix: (256)
tokens: ([16503, 13685, 17097, 17688, 11124, 15478, 15850, 14734, 17109, 10760, 11, 65530, 65532, 12605, 17879, 16503, 10464, 10988, 15641, 14931, 12314, 10267, 14610, 19137, 12176, 12605, 10708, 10250, 17303, 11975, 16735, 11, 65535, 261, 65530, 65534, 11685, 14734, 19137, 12605, 10423, 11986, 16707, 10708, 10250, 17303, 11975, 16735, 10080, 10260, 17141, 19137, 12605, 17879, 16503, 13179, 11632, 14734, 10529, 12445, 13234, 12176, 10847, 12605, 13250, 12410, 28329, 65535, 261, 65530, 65532, 10464, 17879, 16503, 10373, 10303, 10529, 12445, 19156, 11, 65535, 261, 65530, 65534, 18117, 10658, 19137, 12605, 17879, 16503, 14862, 17222, 17148, 17303, 11975, 16735, 14734, 15261, 11496, 10080, 13091, 15034, 12206, 11975, 16735, 10079, 12472, 14638, 11975, 16735, 17147, 13091, 10687, 10390, 15261, 11496, 14734, 11975, 16735, 19156, 11, 65535, 261, 65530, 65532, 12605, 16667, 10292, 13091, 15034, 12206, 11975, 16735, 11, 65535, 261, 65530, 65534, 11685, 14734, 19137, 12605, 10423, 10292, 10464, 12848, 10494, 13179, 11632, 15478, 15907, 10080, 11454, 17148, 17303, 11975, 16735, 10285, 19137, 10293, 10370, 10678, 13091, 10250, 10447, 11043, 11017, 11889, 12363, 18295, 2453, 10788, 10348, 18005, 14734, 12201, 17093, 10460, 11920, 10080, 10390, 11454, 10708, 10460, 17141, 15052, 10285, 11002, 10792, 10333, 13279, 15033, 14987, 15036, 10838, 17387, 14734, 12325, 11168, 19137, 12266, 11726, 10588, 10250, 10349, 11656, 12418, 14734, 13370, 10080, 17148, 10349, 13370, 11574, 16672, 10390, 15752, 11634, 14791, 16519, 13203, 13234, 11124, 17141, 10985, 19137, 12202, 10265, 16056, 12348, 10333, 13279, 15033, 14987, 11656, 14734, 10838, 17387, 28329, 65535, 261, 65530, 65532, 15752, 12848, 10494, 16721, 10293, 10370, 10678, 14734, 11630, 16815, 14332, 12333, 11124, 15727, 13126, 10529, 12445, 11053, 19156, 11, 65535, 261, 65530, 65534, 11685, 14734, 19137, 12605, 10423, 10292, 10464, 12848, 10494, 16721, 10293, 10370, 10678, 14734, 14782, 10684, 10529, 12445, 10080, 18117, 10658, 19137, 17148, 10447, 10293, 10370, 10678, 11043, 11017, 11889, 12363, 14179, 2453, 12163, 14332, 11979, 19137, 10390, 13091, 10250, 10447, 12201, 17093, 13191, 10292, 14734, 10460, 11920, 10080, 10687, 13557, 19137, 10390, 13191, 10250, 11647, 13833, 11930, 14734, 18438, 10997, 11124, 13913, 17808, 14734, 14806, 14815, 19137, 15494, 10370, 14614, 10258, 13913, 10799, 14734, 10951, 16803, 10080, 13188, 11044, 19137, 10390, 12421, 13091, 15091, 14808, 12348, 10452, 10079, 10296, 13579, 12348, 10452, 19137, 15494, 10370, 14614, 10258, 15895, 11685, 14734, 15162, 10250, 10951, 16803, 28329, 65535, 261, 65530, 65532]) 
>

Traceback (most recent call last):
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 876, in _handle
    return route.call(**args)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 1759, in wrapper
    rv = callback(*a, **ka)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/app.py", line 173, in inference_by_org
    msg = inferencer.generate(rwkv_rnn,msg)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/models/inference_helper.py", line 128, in generate
    logits[n] = -float('inf')
IndexError: list assignment index out of range
192.168.0.103 - - [30/Sep/2023 19:58:19] "POST /inference/by-org HTTP/1.1" 500 759
====== None
====== None
====== None
==== [<models.org_text.DataNode object at 0x7fa16e4508b0>]
==== [11687, 10454, 16056, 11001, 7451, 1802, 267, 25028, 34043, 14734, 10285, 14734, 10696, 11922, 19156, 11, 5686, 1511, 70, 33, 10464, 11021, 10399, 10482, 14589, 10399, 10258, 4515, 7917, 33, 10397, 14875, 16056, 11001, 3784, 6908, 267, 25028, 34043, 33, 14734, 10696, 11922, 59, 11, 6884, 7441, 2191, 11, 41, 49026, 46, 26081, 283, 42, 11, 6884, 11, 97, 49026, 46, 26081, 97, 33, 10762, 13004, 13191, 10278, 10283, 10988, 13004, 59, 11, 46, 283, 33, 16417, 14966, 16056, 11001, 13188, 17145, 14734, 31213, 11, 46, 33, 13580, 13004, 16417, 14966, 16056, 11001, 13179, 13057, 14734, 31213, 11, 12631, 10399, 10292, 10333, 11016, 16056, 11001, 13188, 13034, 14734, 59300, 33, 10696, 11922, 45, 12605, 10402, 10427, 10673, 283, 33, 10953, 11021, 28329, 10487, 11687, 59, 11, 6884, 7441, 2191, 11, 41, 8079, 3421, 27139, 275, 49026, 46, 26081, 283, 5292, 11, 41, 49410, 269, 57956, 51308, 59, 272, 116, 35, 32224, 494, 11, 6884, 11, 17148, 13619, 10397, 14875, 10423, 16056, 11001, 59300, 33, 10696, 11922, 45, 12202, 13098, 14966, 11454, 13855, 12445, 13314, 10285, 28329, 10464, 10322, 11021, 10399, 12669, 59300, 33, 10696, 11922, 16914, 10577, 15494, 10250, 10283, 11003, 17387, 45, 14221, 11044, 17149, 16403, 14782, 10684, 14734, 11621, 14486, 28329, 12631, 10399, 45, 10482, 14589, 331, 49026, 46, 26081, 283, 97, 33, 11994, 11021, 10399, 11454, 3784, 6908, 20299, 113, 33, 10397, 14875, 10285, 16056, 11001, 3784, 6908, 33, 14734, 59300, 33, 10696, 11922, 28329, 10482, 14589, 10373, 10303, 7441, 2191, 10762, 13004, 15752, 11634, 11903, 14446, 11454, 7451, 1802, 10285, 14734, 8401, 46, 26267, 10258, 17177, 10285, 13279, 10283, 8760, 46, 27187, 19156, 520, 19589, 1511, 70, 33, 11021, 10399, 10482, 14589, 22236, 46, 34200, 33, 11117, 10398, 13234, 17177, 10285, 53048, 28329, 12750, 17644, 15487, 11899, 59, 11, 68, 46, 100, 332, 275, 8401, 46, 34200, 42, 11, 14589, 13764, 59, 11, 50, 47, 33, 10659, 13308, 12983, 11454, 8760, 27187, 14734, 13308, 18025, 10257, 11, 51, 47, 33, 12750, 302, 46, 100, 332, 11, 52, 47, 33, 17148, 11967, 17177, 10285, 16721, 8760, 27187, 10258, 14734, 12631, 13191, 10696, 11922, 11, 10464, 10322, 11021, 10399, 12748, 11899, 17879, 16503, 12357, 14445, 14734, 13557, 13004, 13234, 17177, 10285, 10260, 11042, 15451, 10790, 14734, 10696, 11922, 59, 11, 46, 302, 46, 100, 332, 284, 280, 33, 17177, 10285, 12307, 10808, 16403, 11, 46, 302, 46, 100, 332, 285, 280, 33, 17177, 10285, 12307, 10808, 15907, 14172, 41, 13308, 18025, 10992, 11855, 15907, 14172, 42, 11, 46, 302, 46, 100, 332, 286, 280, 33, 17177, 10285, 12307, 10808, 15907, 14172, 14734, 14302, 15907, 14172, 11, 46, 33, 15169, 15169, 11, 12631, 10399, 45, 11454, 22236, 46, 26267, 33, 10258, 17177, 10285, 13279, 10283, 53048, 45, 10464, 11021, 10399, 59, 11, 50, 47, 33, 10659, 13308, 12983, 11454, 16721, 53048, 33, 14734, 13308, 18025, 10257, 11, 51, 47, 33, 16749, 14589, 4398, 8401, 46, 34200, 313, 512, 10762, 13004, 45, 79, 33, 10292, 16503, 12357, 14445, 14734, 13557, 13004, 45, 10399, 17177, 10285, 16721, 11855, 13315, 11, 10487, 11687, 59, 11, 6884, 4515, 7917, 11, 41, 8401, 46, 34200, 285, 42, 267, 60, 33, 17177, 10285, 12307, 10808, 15907, 14172, 41, 11855, 13315, 42, 11, 6884, 11, 12159, 13197, 17148, 15752, 12176, 10847, 10464, 34, 24210, 11]
[2023-09-30 19:59:48,108] [INFO] [checkpointing.py:529:forward] Activation Checkpointing Information
[2023-09-30 19:59:48,108] [INFO] [checkpointing.py:530:forward] ----Partition Activations False, CPU CHECKPOINTING False
[2023-09-30 19:59:48,108] [INFO] [checkpointing.py:531:forward] ----contiguous Memory Checkpointing False with None total layers
[2023-09-30 19:59:48,109] [INFO] [checkpointing.py:533:forward] ----Synchronization False
[2023-09-30 19:59:48,109] [INFO] [checkpointing.py:534:forward] ----Profiling time in checkpointing False
-> item_loss 2.1173954010009766 batch_loss 2.1173954010009766
192.168.0.103 - - [30/Sep/2023 20:00:04] "POST /train/by-org HTTP/1.1" 200 28
  0%|          | 0/582 [00:00<?, ?it/s]100%|| 582/582 [00:00<00:00, 30457.22it/s]
  0%|          | 0/582 [00:00<?, ?it/s]100%|| 582/582 [00:00<00:00, 534622.19it/s]
127.0.0.1 - - [30/Sep/2023 20:03:43] "POST /inference/load-model HTTP/1.1" 200 26
None
None
127.0.0.1 - - [30/Sep/2023 20:03:43] "POST /state/reset HTTP/1.1" 200 21

<|over|>

<|me|><|request|>Question: 
<|over|>

<|me|><|response|>Answer: 
1. Ilica de la Reyna
2. Jazmin Harry Potter-Crabble-Kreacher
3. Fezco de la Reyna
4. Fernando de la Reyna
5. Fernando de la Reyna
6. Fernando de la Reyna
7. Fernando de la Reyna
8. 127.0.0.1 - - [30/Sep/2023 20:04:02] "POST /inference/generate HTTP/1.1" 200 3960
tensor([[ 1.1239e-01,  6.5617e-03,  1.8517e-01,  ...,  1.2466e-01,
          1.9486e-01,  1.4709e-01],
        [ 1.8481e-01,  1.7514e-02, -1.2661e-02,  ...,  8.3811e-01,
          1.9648e-01,  6.7376e-02],
        [-5.3432e+00, -4.5233e+00, -7.8453e-01,  ...,  1.3372e-01,
         -1.0569e-01, -6.6466e-01],
        ...,
        [-2.6437e-01, -3.1639e+01,  4.9620e+01,  ..., -4.7746e+00,
          2.7792e+00, -6.9258e+00],
        [ 1.0281e+00,  2.2015e+01,  1.6767e+01,  ...,  1.0229e+00,
          1.1468e+00,  1.2015e+00],
        [ 3.4083e+00,  7.3872e+00,  6.2586e+00,  ...,  1.7435e+01,
          1.3982e+00,  4.2004e+00]], device='cuda:0')
None
127.0.0.1 - - [30/Sep/2023 20:04:03] "POST /state/reset HTTP/1.1" 200 21

: 
1. 
2. 
3. 
4. 
5. : : 
: ?
: H.P.1923The Wonderful Works of God: 
: ?
: 127.0.0.1 - - [30/Sep/2023 20:05:57] "POST /inference/generate-no-state HTTP/1.1" 200 4281
[2023-09-30 20:07:32,097] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 1300887
[2023-09-30 20:07:32,098] [ERROR] [launch.py:434:sigkill_handler] ['/home/neromous/.minicoda3/envs/blackfog/bin/python', '-u', 'app.py', '--local_rank=0', '--deepspeed'] exits with return code = -9
[2023-09-30 20:11:05,456] [WARNING] [runner.py:190:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-09-30 20:11:06,619] [INFO] [runner.py:540:main] cmd = /home/neromous/.minicoda3/envs/blackfog/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None app.py --deepspeed
[2023-09-30 20:11:09,108] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [1]}
[2023-09-30 20:11:09,108] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=1, node_rank=0
[2023-09-30 20:11:09,108] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2023-09-30 20:11:09,109] [INFO] [launch.py:247:main] dist_world_size=1
[2023-09-30 20:11:09,109] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=1
RWKV_MY_TESTING 
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/wkv_512/build.ninja...
Building extension module wkv_512...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module wkv_512...
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 4.635452032089233 seconds
Adam Optimizer #0 is created with AVX2 arithmetic capability.
Config: alpha=0.000100, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=0
[2023-09-30 20:11:59,965] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.1, git-hash=unknown, git-branch=unknown
[2023-09-30 20:11:59,966] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-09-30 20:12:07,632] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-30 20:12:07,635] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-09-30 20:12:07,635] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-09-30 20:12:07,675] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2023-09-30 20:12:07,675] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2023-09-30 20:12:07,675] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 2 optimizer
[2023-09-30 20:12:07,675] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 2000000
[2023-09-30 20:12:07,675] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 2000000
[2023-09-30 20:12:07,675] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True
[2023-09-30 20:12:07,676] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.30291295051574707 seconds
Rank: 0 partition count [1, 1, 1] and sizes[(3062589440, False), (81920, False), (81920, False)] 
[2023-09-30 20:12:34,014] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-09-30 20:12:34,015] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 20:12:34,015] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 22.39 GB, percent = 17.8%
[2023-09-30 20:12:56,506] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-09-30 20:12:56,507] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 20:12:56,507] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.61 GB, percent = 49.0%
[2023-09-30 20:12:56,507] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized
[2023-09-30 20:12:57,491] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-09-30 20:12:57,492] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 20:12:57,492] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.61 GB, percent = 49.0%
[2023-09-30 20:12:57,517] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam
[2023-09-30 20:12:57,517] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-09-30 20:12:57,517] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7fb6c2f18040>
[2023-09-30 20:12:57,518] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001, 0.0002, 0.00030000000000000003], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
[2023-09-30 20:12:57,519] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[2023-09-30 20:12:57,519] [INFO] [config.py:957:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-30 20:12:57,519] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-30 20:12:57,519] [INFO] [config.py:957:print]   amp_enabled .................. False
[2023-09-30 20:12:57,519] [INFO] [config.py:957:print]   amp_params ................... False
[2023-09-30 20:12:57,519] [INFO] [config.py:957:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-30 20:12:57,519] [INFO] [config.py:957:print]   bfloat16_enabled ............. False
[2023-09-30 20:12:57,519] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fb6c2d27040>
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   communication_data_type ...... None
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   disable_allgather ............ False
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   dump_state ................... False
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... None
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   fp16_auto_cast ............... None
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   fp16_enabled ................. False
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   global_rank .................. 0
[2023-09-30 20:12:57,520] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 1
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   gradient_clipping ............ 1
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 65536
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   loss_scale ................... 0
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   memory_breakdown ............. False
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   optimizer_name ............... None
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   optimizer_params ............. None
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   pld_enabled .................. False
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   pld_params ................... False
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   prescale_gradients ........... False
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   scheduler_name ............... None
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   scheduler_params ............. None
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   sparse_attention ............. None
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[2023-09-30 20:12:57,521] [INFO] [config.py:957:print]   steps_per_print .............. 10
[2023-09-30 20:12:57,522] [INFO] [config.py:957:print]   train_batch_size ............. 1
[2023-09-30 20:12:57,522] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  1
[2023-09-30 20:12:57,522] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[2023-09-30 20:12:57,522] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[2023-09-30 20:12:57,522] [INFO] [config.py:957:print]   world_size ................... 1
[2023-09-30 20:12:57,522] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  False
[2023-09-30 20:12:57,522] [INFO] [config.py:957:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=2000000 allgather_partitions=True allgather_bucket_size=2000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[2023-09-30 20:12:57,522] [INFO] [config.py:957:print]   zero_enabled ................. True
[2023-09-30 20:12:57,522] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-30 20:12:57,522] [INFO] [config.py:957:print]   zero_optimization_stage ...... 2
[2023-09-30 20:12:57,522] [INFO] [config.py:943:print_user_config]   json = {
    "   fp16": {
        "enabled": false
    }, 
    "zero_optimization": {
        "stage": 2, 
        "offload_optimizer": {
            "device": "cpu", 
            "pin_memory": true
        }, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+06, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+06, 
        "contiguous_gradients": true
    }, 
    "gradient_accumulation_steps": 1, 
    "gradient_clipping": 1, 
    "train_micro_batch_size_per_gpu": 1, 
    "checkpoint": {
        "path": "/home/neromous/Documents/blackfog/resources/train-results/oneline/", 
        "keep_checkpoint_max": 3
    }
}
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.00042128562927246094 seconds
Bottle v0.12.25 server starting up (using WSGIRefServer())...
Listening on http://0.0.0.0:3000/
Hit Ctrl-C to quit.

  0%|          | 0/582 [00:00<?, ?it/s]100%|| 582/582 [00:00<00:00, 20772.19it/s]
  0%|          | 0/582 [00:00<?, ?it/s]100%|| 582/582 [00:00<00:00, 575184.95it/s]
==== [65530, 65531, 12656, 14035, 10250, 10283, 15847, 11805, 10452, 15543, 17108, 19137, 13326, 12797, 27370, 14734, 17109, 10673, 15494, 10760, 15543, 17108, 11044, 14734, 13012, 13205, 11, 65535, 261, 65530, 65532, 12605, 17879, 16503, 10464, 12927, 10708, 10684, 10339, 13631, 11795, 12678, 10691, 14782, 10684, 14734, 14862, 16696, 14734, 13012, 15131, 11, 65535, 261, 65530, 65534, 10399, 10258, 13091, 10250, 10283, 10487, 11855, 59, 267, 11454, 17141, 10985, 14734, 10745, 10917, 12201, 17384, 45, 33, 13631, 11795, 10684, 15304, 10250, 14781, 11622, 11002, 10370, 10402, 14734, 10684, 13773, 10080, 17148, 10293, 16503, 13091, 11416, 10292, 45, 33, 13631, 10366, 11454, 12395, 11858, 11124, 10358, 11044, 14734, 17268, 10745, 10283, 13190, 17384, 12665, 12701, 10333, 12140, 11638, 14734, 14583, 10358, 10838, 10409, 10843, 45, 33, 11042, 13064, 10322, 12665, 11002, 10333, 12140, 11638, 14734, 15287, 14987, 10966, 10838, 10080, 11684, 17879, 16503, 14240, 18004, 11795, 10650, 45, 33, 11042, 13064, 17147, 16503, 10692, 18004, 12137, 10460, 11124, 11871, 10323, 28329, 11454, 17148, 15033, 12484, 10724, 10258, 45, 33, 13631, 10366, 14734, 17177, 12731, 10293, 16503, 13191, 10278, 15033, 59, 33, 10250, 15033, 13091, 17177, 12731, 11454, 11920, 10285, 15847, 15494, 15847, 16956, 45, 33, 11013, 10250, 15033, 10779, 13091, 17177, 12731, 11454, 10913, 17796, 12824, 11002, 12686, 14486, 28329, 13051, 16686, 17177, 12731, 11187, 15033, 13036, 13764, 45, 33, 13631, 10366, 17311, 17919, 10288, 14808, 12140, 11638, 14734, 10966, 10838, 10080, 11684, 17879, 16503, 14240, 18004, 11795, 10650, 45, 33, 11042, 13064, 17147, 16503, 10692, 18004, 12137, 10460, 11124, 11871, 10323, 10080, 11684, 12368, 18001, 10260, 13032, 11459, 11871, 10323, 13034, 14862, 16696, 11124, 12666, 15752, 45, 33, 11042, 13064, 10322, 12159, 13197, 15752, 11634, 12348, 10792, 14970, 10423, 14734, 16667, 11021, 10080, 11454, 17148, 10283, 17141, 15052, 10285, 45, 33, 11684, 17919, 10288, 14808, 12140, 11638, 14734, 10966, 10838, 28329, 11687, 13258, 17177, 12731, 11454, 11920, 10285, 15847, 15494, 15847, 16956, 45, 65535, 261, 65530, 65534, 10399, 10258, 13091, 10250, 10283, 15486, 17141, 15543, 17108, 11044, 14734, 14314, 13205, 59, 11, 13631, 11795, 17734, 37881, 33, 13091, 12445, 12445, 14782, 10684, 14734, 10080, 17145, 10745, 10917, 12201, 45, 13631, 10366, 10402, 14734, 16530, 15898, 11622, 11002, 10684, 13773, 28329, 12395, 11858, 10992, 10780, 14583, 10358, 11044, 10745, 10283, 13190, 45, 13631, 10366, 15710, 16875, 13722, 17385, 14734, 11920, 12234, 16879, 10409, 45, 11042, 13064, 12665, 11002, 10966, 10838, 10080, 11684, 16503, 14240, 18004, 11795, 10650, 10079, 12137, 10460, 11124, 11871, 10323, 45, 17879, 16503, 11454, 17148, 10285, 17734, 11001, 12348, 12200, 16412, 28329, 13191, 10278, 15033, 13036, 12276, 11021, 10494, 17177, 12731, 59, 11, 10250, 13091, 45, 11454, 11920, 15847, 10293, 14240, 18004, 11795, 10650, 10080, 17148, 15033, 13036, 12276, 14782, 11957, 10511, 11901, 10444, 17879, 16503, 13631, 10366, 15931, 16899, 13179, 11632, 13064, 17734, 10261, 13773, 12522, 10838, 28329, 10337, 13091, 45, 11967, 11795, 10650, 10355, 15494, 10913, 17796, 14791, 12686, 10080, 13631, 10366, 11021, 10264, 13773, 12137, 10460, 11871, 10323, 45, 10444, 15931, 16899, 13179, 11632, 28329, 10260, 15202, 13631, 10366, 17177, 12731, 11187, 15033, 13036, 12276, 45, 10966, 10838, 17311, 12337, 11638, 28329, 11684, 17879, 16503, 10260, 13032, 11871, 10323, 13034, 12666, 15752, 10079, 11584, 17688, 14862, 16696, 45, 11042, 13064, 10335, 11001, 14970, 10423, 16667, 11042, 28329, 11687, 13258, 17177, 12731, 11454, 11920, 14240, 18004, 45, 13631, 10366, 17879, 16503, 59, 11, 9828, 33, 10333, 16533, 11795, 10650, 16099, 10691, 10079, 11889, 12678, 10261, 10997, 12022, 17879, 16503, 11, 9828, 33, 11871, 10323, 14660, 14662, 18009, 17771, 10261, 11533, 13205, 12686, 14486, 14862, 16696, 11, 9828, 33, 10261, 11795, 10650, 13250, 12261, 39332, 7939, 102, 33, 10342, 10846, 11, 9828, 28377, 585, 11, 11687, 13581, 12638, 15752, 16672, 13631, 11795, 37881, 33, 11454, 11795, 10650, 12604, 17688, 17141, 15052, 10285, 12746, 15511, 12299, 10901, 28329, 12421, 14734, 13234, 16735, 45, 13191, 12986, 14734, 13631, 11795, 12678, 10691, 11001, 10722, 10339, 13631, 10366, 14734, 12986, 14426, 15202, 14486, 11124, 10260, 13032, 11871, 10323, 28329, 10399, 10257, 13091, 10250, 10283, 13179, 15190, 15475, 13923, 13127, 14734, 14314, 13205, 10080, 16738, 10538, 12981, 17631, 16730, 10305, 11621, 45, 11088, 14862, 10684, 17644, 10529, 12445, 17225, 14033, 10080, 65535, 261, 65530, 65534]
:
 
 
 
,,192.168.0.103 - - [30/Sep/2023 20:14:48] "POST /inference/by-org HTTP/1.1" 200 5688
,,
192.168.0.103 - - [30/Sep/2023 20:33:26] "POST /inference/generate HTTP/1.1" 200 1230
,
USER 
ROBOT 
 USER 
 ROBOT 
USER 
192.168.0.103 - - [30/Sep/2023 20:34:19] "POST /inference/generate HTTP/1.1" 200 2114
,
192.168.0.103 - - [30/Sep/2023 20:37:40] "POST /inference/generate HTTP/1.1" 200 1265
,
192.168.0.103 - - [30/Sep/2023 20:38:31] "POST /inference/generate HTTP/1.1" 200 1265
,
192.168.0.103 - - [30/Sep/2023 20:38:59] "POST /inference/generate HTTP/1.1" 200 1265
,
192.168.0.103 - - [30/Sep/2023 20:39:15] "POST /inference/generate HTTP/1.1" 200 1265
192.168.0.103 - - [30/Sep/2023 20:41:41] "POST /inference/generate HTTP/1.1" 200 10176
192.168.0.103 - - [30/Sep/2023 20:44:24] "POST /inference/generate HTTP/1.1" 200 10175
,user
192.168.0.103 - - [30/Sep/2023 20:46:24] "POST /inference/generate HTTP/1.1" 200 5661
,user
192.168.0.103 - - [30/Sep/2023 20:46:59] "POST /inference/generate HTTP/1.1" 200 11223
:
:
,,,
, 192.168.0.103 - - [30/Sep/2023 20:48:20] "POST /inference/generate HTTP/1.1" 200 12208
AI
192.168.0.103 - - [30/Sep/2023 20:52:44] "POST /inference/generate HTTP/1.1" 200 1280
:
,,,, 
192.168.0.103 - - [30/Sep/2023 20:52:57] "POST /inference/generate HTTP/1.1" 200 2596
192.168.0.103 - - [30/Sep/2023 20:53:14] "POST /inference/generate HTTP/1.1" 200 3939
  0%|          | 0/582 [00:00<?, ?it/s]100%|| 582/582 [00:00<00:00, 34985.60it/s]
  0%|          | 0/582 [00:00<?, ?it/s]100%|| 582/582 [00:00<00:00, 501146.57it/s]
127.0.0.1 - - [30/Sep/2023 20:54:51] "POST /inference/load-model HTTP/1.1" 200 26
AI192.168.0.103 - - [30/Sep/2023 20:55:10] "POST /inference/generate HTTP/1.1" 200 1242
:
,,,
192.168.0.103 - - [30/Sep/2023 20:55:20] "POST /inference/generate HTTP/1.1" 200 2516
192.168.0.103 - - [30/Sep/2023 20:55:35] "POST /inference/generate HTTP/1.1" 200 3749
:
,,,
192.168.0.103 - - [30/Sep/2023 20:55:50] "POST /inference/generate HTTP/1.1" 200 4899
[2023-09-30 21:23:07,882] [WARNING] [runner.py:190:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-09-30 21:23:08,888] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 1305551
[2023-09-30 21:23:08,890] [ERROR] [launch.py:434:sigkill_handler] ['/home/neromous/.minicoda3/envs/blackfog/bin/python', '-u', 'app.py', '--local_rank=0', '--deepspeed'] exits with return code = -9
[2023-09-30 21:23:12,077] [INFO] [runner.py:540:main] cmd = /home/neromous/.minicoda3/envs/blackfog/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None app.py --deepspeed
[2023-09-30 21:23:14,549] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [1]}
[2023-09-30 21:23:14,549] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=1, node_rank=0
[2023-09-30 21:23:14,549] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2023-09-30 21:23:14,549] [INFO] [launch.py:247:main] dist_world_size=1
[2023-09-30 21:23:14,549] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=1
RWKV_MY_TESTING 
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/wkv_512/build.ninja...
Building extension module wkv_512...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module wkv_512...
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 4.703971862792969 seconds
Adam Optimizer #0 is created with AVX2 arithmetic capability.
Config: alpha=0.000100, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=0
[2023-09-30 21:24:05,396] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.1, git-hash=unknown, git-branch=unknown
[2023-09-30 21:24:05,396] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-09-30 21:24:12,948] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-30 21:24:12,950] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-09-30 21:24:12,950] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-09-30 21:24:12,989] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2023-09-30 21:24:12,989] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2023-09-30 21:24:12,989] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 2 optimizer
[2023-09-30 21:24:12,989] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 2000000
[2023-09-30 21:24:12,989] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 2000000
[2023-09-30 21:24:12,989] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True
[2023-09-30 21:24:12,989] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.2928633689880371 seconds
Rank: 0 partition count [1, 1, 1] and sizes[(3062589440, False), (81920, False), (81920, False)] 
[2023-09-30 21:24:37,127] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-09-30 21:24:37,128] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 21:24:37,129] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 22.38 GB, percent = 17.8%
[2023-09-30 21:24:57,717] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-09-30 21:24:57,718] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 21:24:57,718] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.61 GB, percent = 49.0%
[2023-09-30 21:24:57,718] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized
[2023-09-30 21:24:59,841] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-09-30 21:24:59,842] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 21:24:59,842] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.61 GB, percent = 49.0%
[2023-09-30 21:24:59,869] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam
[2023-09-30 21:24:59,869] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-09-30 21:24:59,869] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7f9e70b39160>
[2023-09-30 21:24:59,869] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001, 0.0002, 0.00030000000000000003], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
[2023-09-30 21:24:59,871] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[2023-09-30 21:24:59,871] [INFO] [config.py:957:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-30 21:24:59,871] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-30 21:24:59,871] [INFO] [config.py:957:print]   amp_enabled .................. False
[2023-09-30 21:24:59,871] [INFO] [config.py:957:print]   amp_params ................... False
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   bfloat16_enabled ............. False
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f9e70b26160>
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   communication_data_type ...... None
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   disable_allgather ............ False
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   dump_state ................... False
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... None
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[2023-09-30 21:24:59,872] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[2023-09-30 21:24:59,873] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[2023-09-30 21:24:59,873] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[2023-09-30 21:24:59,873] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[2023-09-30 21:24:59,873] [INFO] [config.py:957:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-30 21:24:59,873] [INFO] [config.py:957:print]   fp16_auto_cast ............... None
[2023-09-30 21:24:59,873] [INFO] [config.py:957:print]   fp16_enabled ................. False
[2023-09-30 21:24:59,873] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[2023-09-30 21:24:59,873] [INFO] [config.py:957:print]   global_rank .................. 0
[2023-09-30 21:24:59,873] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[2023-09-30 21:24:59,873] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 1
[2023-09-30 21:24:59,873] [INFO] [config.py:957:print]   gradient_clipping ............ 1
[2023-09-30 21:24:59,873] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[2023-09-30 21:24:59,873] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-30 21:24:59,873] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 65536
[2023-09-30 21:24:59,873] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[2023-09-30 21:24:59,873] [INFO] [config.py:957:print]   loss_scale ................... 0
[2023-09-30 21:24:59,873] [INFO] [config.py:957:print]   memory_breakdown ............. False
[2023-09-30 21:24:59,873] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-30 21:24:59,873] [INFO] [config.py:957:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-30 21:24:59,873] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[2023-09-30 21:24:59,874] [INFO] [config.py:957:print]   optimizer_name ............... None
[2023-09-30 21:24:59,874] [INFO] [config.py:957:print]   optimizer_params ............. None
[2023-09-30 21:24:59,874] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-30 21:24:59,874] [INFO] [config.py:957:print]   pld_enabled .................. False
[2023-09-30 21:24:59,874] [INFO] [config.py:957:print]   pld_params ................... False
[2023-09-30 21:24:59,874] [INFO] [config.py:957:print]   prescale_gradients ........... False
[2023-09-30 21:24:59,874] [INFO] [config.py:957:print]   scheduler_name ............... None
[2023-09-30 21:24:59,874] [INFO] [config.py:957:print]   scheduler_params ............. None
[2023-09-30 21:24:59,874] [INFO] [config.py:957:print]   sparse_attention ............. None
[2023-09-30 21:24:59,874] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[2023-09-30 21:24:59,874] [INFO] [config.py:957:print]   steps_per_print .............. 10
[2023-09-30 21:24:59,874] [INFO] [config.py:957:print]   train_batch_size ............. 1
[2023-09-30 21:24:59,874] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  1
[2023-09-30 21:24:59,874] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[2023-09-30 21:24:59,874] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[2023-09-30 21:24:59,874] [INFO] [config.py:957:print]   world_size ................... 1
[2023-09-30 21:24:59,874] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  False
[2023-09-30 21:24:59,874] [INFO] [config.py:957:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=2000000 allgather_partitions=True allgather_bucket_size=2000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[2023-09-30 21:24:59,874] [INFO] [config.py:957:print]   zero_enabled ................. True
[2023-09-30 21:24:59,874] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-30 21:24:59,874] [INFO] [config.py:957:print]   zero_optimization_stage ...... 2
[2023-09-30 21:24:59,874] [INFO] [config.py:943:print_user_config]   json = {
    "   fp16": {
        "enabled": false
    }, 
    "zero_optimization": {
        "stage": 2, 
        "offload_optimizer": {
            "device": "cpu", 
            "pin_memory": true
        }, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+06, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+06, 
        "contiguous_gradients": true
    }, 
    "gradient_accumulation_steps": 1, 
    "gradient_clipping": 1, 
    "train_micro_batch_size_per_gpu": 1, 
    "checkpoint": {
        "path": "/home/neromous/Documents/blackfog/resources/train-results/oneline/", 
        "keep_checkpoint_max": 3
    }
}
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0006890296936035156 seconds
Bottle v0.12.25 server starting up (using WSGIRefServer())...
Listening on http://0.0.0.0:3000/
Hit Ctrl-C to quit.

  0%|          | 0/582 [00:00<?, ?it/s]  1%|         | 8/582 [00:01<02:23,  4.00it/s]100%|| 582/582 [00:02<00:00, 290.95it/s]
  0%|          | 0/582 [00:00<?, ?it/s]100%|| 582/582 [00:00<00:00, 419574.58it/s]
bot: 
192.168.0.103 - - [30/Sep/2023 21:26:11] "POST /inference/generate HTTP/1.1" 200 1127
bot: 
192.168.0.103 - - [30/Sep/2023 21:26:34] "POST /inference/generate HTTP/1.1" 200 2369
bot: SCP-1000SCP-1000SCP-1000SCP-1000330SCP-1000SCP-1000SCP-1000192.168.0.103 - - [30/Sep/2023 21:27:15] "POST /inference/generate HTTP/1.1" 200 5304
bot: SCP-1000SCP-1000SCP-1000SCP-1000192.168.0.103 - - [30/Sep/2023 21:28:59] "POST /inference/generate HTTP/1.1" 200 1821
None
None
192.168.0.103 - - [30/Sep/2023 21:29:35] "POST /state/reset HTTP/1.1" 200 21
bot: SCP-1000
192.168.0.103 - - [30/Sep/2023 21:29:42] "POST /inference/generate HTTP/1.1" 200 3279
None
None
192.168.0.103 - - [30/Sep/2023 21:29:52] "POST /state/reset HTTP/1.1" 200 21
scp682AIscp682
192.168.0.103 - - [30/Sep/2023 21:29:55] "POST /inference/generate HTTP/1.1" 200 1518
None
None
192.168.0.103 - - [30/Sep/2023 21:37:15] "POST /state/reset HTTP/1.1" 200 21
[2023-09-30 21:37:17,537] [INFO] [checkpointing.py:529:forward] Activation Checkpointing Information
[2023-09-30 21:37:17,537] [INFO] [checkpointing.py:530:forward] ----Partition Activations False, CPU CHECKPOINTING False
[2023-09-30 21:37:17,537] [INFO] [checkpointing.py:531:forward] ----contiguous Memory Checkpointing False with None total layers
[2023-09-30 21:37:17,537] [INFO] [checkpointing.py:533:forward] ----Synchronization False
[2023-09-30 21:37:17,537] [INFO] [checkpointing.py:534:forward] ----Profiling time in checkpointing False
192.168.0.103 - - [30/Sep/2023 21:37:36] "POST /train/tx-data HTTP/1.1" 200 28
None
None
192.168.0.103 - - [30/Sep/2023 21:39:34] "POST /state/reset HTTP/1.1" 200 21
192.168.0.103 - - [30/Sep/2023 21:39:51] "POST /train/tx-data HTTP/1.1" 200 28
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
==== [15847, 12605, 12522, 16696, 12261, 13250, 11, 65530, 65531, 17148, 13091, 65530, 14734, 15847, 14787, 19137, 17148, 17384, 14734, 65530, 11454, 17149, 16403, 10390, 15847, 12605, 16667, 14862, 13036, 17919, 14734, 13250, 12261, 28329, 65535, 261, 65530, 65534, 12605, 11043, 11017, 65530, 19137, 15669, 10270, 13091, 10250, 11043, 15036, 10325, 19137, 10270, 10457, 14299, 11685, 13091, 16530, 15898, 12656, 14035, 15643, 19137, 12605, 17147, 13191, 14488, 14543, 10079, 11889, 13849, 12705, 15169, 10790, 11043, 19137, 33, 17189, 17141, 17749, 16742, 65532, 10285, 14734, 16503, 13685, 19137, 33, 12605, 14256, 12459, 15202, 14486, 15643, 11957, 12605, 14734, 16503, 13685, 19137, 12605, 11454, 65534, 10305, 11044, 15494, 10760, 12605, 14734, 11168, 12220, 10080, 12605, 10423, 11454, 65533, 10285, 17149, 16403, 13913, 12231, 12410, 15641, 19137, 33, 10985, 16671, 16686, 28329, 65535, 261, 65530, 65531, 13191, 10370, 10423, 17728, 16944, 10464, 13091, 11060, 13091, 28316, 74, 9823, 19137, 10464, 16525, 12348, 12220, 16721, 12401, 10303, 11414, 15178, 19156, 11, 65535, 261, 65530, 65533, 12605, 16667, 10292, 14914, 11899, 65530, 13091, 11060, 13091, 10370, 12137, 13133, 15752, 19133, 820, 19134, 13091, 13644, 13051, 12522, 10304, 14734, 10080, 10460, 10292, 10250, 10283, 13133, 15752, 10452, 19137, 10684, 13773, 14734, 13091, 13133, 15752, 10452, 14734, 11159, 13327, 11124, 10370, 13327, 14734, 10590, 10675, 19137, 15646, 10260, 13091, 10399, 10339, 11885, 14734, 15033, 13046, 13234, 10784, 13032, 28329, 65535, 261, 65530, 65534, 12605, 16667, 10292, 13637, 17097, 11038, 17172, 14734, 11414, 15178, 13091, 19151, 11, 11957, 10370, 12137, 13133, 15752, 13234, 16735, 45, 17385, 16503, 14734, 13091, 10655, 10768, 10997, 12764, 10841, 15752, 11124, 10408, 10577, 45, 15646, 10260, 11454, 10339, 16443, 10775, 10768, 10292, 35, 10370, 15261, 35, 17147, 13091, 35, 13212, 11369, 35, 10080, 12605, 10402, 12220, 15674, 14216, 10339, 13133, 15752, 10452, 13205, 17038, 14734, 16403, 10292, 11124, 15752, 10838, 45, 15646, 10260, 13091, 10687, 12666, 13208, 13205, 13981, 28329, 11042, 13064, 45, 17385, 16523, 10431, 14486, 10733, 10779, 11124, 10408, 10577, 16520, 10079, 11971, 17385, 10370, 12415, 10322, 13091, 13133, 15752, 15304, 15500, 12220, 10688, 11622, 14734, 28329, 12421, 14734, 13234, 16735, 45, 10399, 10258, 10745, 14172, 13179, 17385, 16503, 59, 11, 50, 42, 33, 14015, 16956, 14589, 12626, 17879, 13685, 10079, 12848, 10494, 10408, 10577, 28329, 51, 42, 33, 17241, 11888, 13580, 12307, 12415, 11124, 17181, 13078, 12415, 10974, 10779, 28329, 52, 42, 33, 11971, 17385, 10370, 13216, 10079, 17248, 10662, 13584, 16523, 28329, 53, 42, 33, 11021, 10399, 12824, 11002, 14762, 14819, 11124, 16749, 13006, 28329, 15646, 10260, 12220, 10377, 15674, 14216, 10339, 13091, 11060, 16443, 11899, 12415, 10292, 35, 820, 35, 10080, 11016, 16503, 12605, 10402, 14734, 13133, 15752, 15304, 15500, 15752, 10452, 14446, 10399, 10257, 11159, 16884, 45, 11885, 12220, 16721, 16443, 15494, 10334, 14782, 12220, 14734, 11971, 17385, 28329, 11687, 10454, 11414, 11626, 11687, 13258, 16443, 17728, 10992, 35, 10464, 13091, 820, 11053, 799, 17148, 15261, 17728, 18025, 45, 12605, 16667, 10292, 11021, 10399, 11687, 13581, 11414, 15178, 59, 11, 35, 12605, 13091, 10250, 10283, 16689, 16664, 14589, 10339, 12848, 10494, 12176, 10847, 11124, 10529, 12445, 14734, 13133, 15752, 15304, 15500, 10080, 12605, 14734, 10293, 16503, 14778, 13308, 13091, 14015, 16956, 14589, 12626, 17879, 13685, 45, 12605, 10423, 10260, 13032, 11871, 10323, 11124, 12848, 18216, 10399, 11903, 14446, 17148, 10283, 14778, 13308, 10080, 35, 11, 11967, 17385, 14172, 12983, 11454, 10841, 15752, 11124, 14778, 13308, 10257, 45, 15646, 10260, 13091, 12666, 13208, 10768, 15261, 45, 17148, 13324, 14734, 11414, 12220, 10423, 13179, 10842, 10285, 15713, 12266, 12983, 10080, 65535, 261, 65530, 65531, 12824, 10258, 13234, 19137, 17148, 13091, 10464, 14734, 15847, 17162, 28329, 65535, 261, 65530, 65532, 10464, 13091, 16747, 19156, 10382, 15484, 10464, 15847, 12144, 28329, 65535, 261, 65530, 65534, 12605, 11017, 65530, 33, 12605, 13091, 10250, 10283, 13125, 13125, 17189, 17189, 14734, 10370, 10080, 12605, 14583, 13815, 11454, 11459, 14484, 10257, 19137, 12010, 10449, 11454, 10285, 11435, 10080, 33, 12605, 13191, 10250, 17734, 12630, 11855, 11124, 10250, 17100, 13713, 17079, 19137, 33, 17147, 13191, 10250, 10283, 11021, 14299, 14734, 11679, 10650, 10080, 33, 12605, 14734, 14583, 13815, 10655, 11903, 15646, 10265, 15597, 14015, 10080, 33, 12605, 14583, 13815, 10285, 13191, 10250, 10283, 11210, 10250, 14734, 15568, 12577, 19137, 17268, 11994, 13091, 11454, 12605, 10344, 12039, 17268, 12201, 19137, 12605, 14734, 14302, 10366, 11645, 17001, 10333, 10080, 10390, 14734, 15023, 10985, 16672, 12605, 12337, 12476, 10429, 10080, 33, 10444, 13091, 12605, 14446, 11454, 12768, 10460, 10333, 16944, 13234, 19137, 10655, 14015, 10310, 16520, 11124, 12159, 13197, 14734, 14583, 13815, 14808, 28329, 65535, 261, 65530, 65532, 12631, 10399, 10464, 10848, 10838, 14734, 11659, 13020, 10792, 14446, 11454, 19137, 11124, 10464, 14734, 15133, 12201, 10781, 10429, 13191, 10684, 11053, 19156, 11, 65535, 261, 65530, 65534, 12605, 16667, 10292, 11021, 15752, 13091, 14734, 11, 65535, 261, 65530, 65532, 11315, 45, 12605, 14486, 16533, 10460, 10292, 10250, 10283, 13191, 15133, 12201, 10781, 10429, 14734, 10370, 45, 12469, 10696, 12366, 11021, 15752, 15043, 15330, 10333, 16684, 11632, 12484, 12527, 17879, 16503, 17382, 12983, 10080, 10460, 10292, 12469, 14734, 12366, 14486, 10913, 14583, 45, 12605, 10423, 10399, 12266, 12983, 10079, 17916, 16694, 10784, 14734, 12396, 12231, 10578, 11065, 12469, 14734, 12985, 10336, 45, 12202, 15494, 10334, 12368, 16503, 14734, 12978, 12746, 11124, 12261, 16676, 10080, 18117, 10658, 45, 12469, 12537, 12522, 16753, 16753, 15133, 12201, 13064, 17237, 17213, 10333, 10373, 10303, 13324, 14734, 10781, 10429, 11053, 64, 16738, 12002, 11021, 15752, 16722, 15478, 11459, 12847, 17162, 12469, 14734, 12527, 11002, 11124, 10452, 18183, 10080, 12605, 10423, 15648, 12366, 11459, 10578, 11065, 45, 10260, 10423, 12662, 10784, 13032, 12469, 10080, 12605, 10402, 11021, 10399, 10250, 13582, 13582, 14486, 13923, 17148, 10349, 13057, 13199, 15486, 10964, 11687, 10454, 12325, 11168, 10333, 12469, 14446, 11454, 14734, 14583, 13815, 11124, 12484, 15509, 10080, 11454, 17148, 10283, 17141, 15052, 10285, 45, 12605, 12159, 13197, 15752, 12176, 10847, 12469, 12261, 15123, 15847, 10529, 45, 17919, 11957, 12202, 12824, 15462, 15847, 12144, 14734, 17141, 10985, 10080, 16738, 12983, 12366, 10578, 16698, 12469, 14734, 12985, 10336, 45, 12605, 10402, 10423, 10250, 16944, 12509, 10840, 13764, 12176, 12469, 16939, 10760, 10781, 10429, 14734, 17773, 12325, 28329, 65535, 261, 65530, 65534, 12605, 11017, 65530, 33, 12605, 13091, 10250, 10283, 13125, 13125, 17189, 17189, 14734, 10370, 10080, 12605, 14583, 13815, 11454, 11459, 14484, 10257, 19137, 12010, 10449, 11454, 10285, 11435, 10080, 33, 12605, 13191, 10250, 17734, 12630, 11855, 11124, 10250, 17100, 13713, 17079, 19137, 33, 17147, 13191, 10250, 10283, 11021, 14299, 14734, 11679, 10650, 10080, 33, 12605, 14734, 14583, 13815, 10655, 11903, 15646, 10265, 15597, 14015, 10080, 33, 12605, 14583, 13815, 10285, 13191, 10250, 10283, 11210, 10250, 14734, 15568, 12577, 19137, 17268, 11994, 13091, 11454, 12605, 10344, 12039, 17268, 12201, 19137, 12605, 14734, 14302, 10366, 11645, 17001, 10333, 10080, 10390, 14734, 15023, 10985, 16672, 12605, 12337, 12476, 10429, 10080, 33, 10444, 13091, 12605, 14446, 11454, 12768, 10460, 10333, 16944, 13234, 19137, 10655, 14015, 10310, 16520, 11124, 12159, 13197, 14734, 14583, 13815, 14808, 28329, 65535, 261, 65530, 65532, 16774, 16774, 10464, 12537, 12522, 10768, 10361, 10464, 14734, 12985, 10336, 45, 65530, 10080, 12605, 15752, 14486, 16533, 10460, 10292, 10250, 10283, 54, 12039, 11872, 11855, 45, 14302, 10366, 14734, 15023, 10985, 11957, 10464, 17194, 12604, 10333, 12140, 11638, 14734, 10781, 10429, 45, 17148, 15033, 10429, 14673, 10250, 11899, 17819, 14808, 10464, 14734, 12604, 17688, 10437, 17819, 10333, 12337, 17688, 13064, 17734, 28329, 10250, 10283, 11872, 11855, 17879, 16503, 14302, 10366, 14734, 17802, 10437, 11124, 10684, 14299, 45, 10390, 14734, 15023, 10985, 10260, 11021, 17248, 10662, 11459, 10423, 16672, 10464, 12527, 10792, 16443, 12679, 12269, 10080, 17148, 10283, 10781, 10429, 11021, 15752, 12325, 11168, 10333, 10464, 11957, 10684, 15304, 14734, 10529, 10409, 45, 10322, 16672, 10464, 11454, 12604, 17688, 17141, 15052, 10285, 15568, 10309, 14302, 17102, 14734, 12748, 11960, 10080, 17148, 10250, 10769, 17311, 11021, 15752, 11960, 15850, 10464, 14734, 12484, 12527, 17879, 13685, 12348, 10260, 10792, 14015, 16956, 28329, 14221, 15646, 45, 12605, 12337, 18216, 10685, 14791, 10792, 10464, 14446, 11454, 15752, 15043, 13249, 11459, 14791, 12335, 14583, 13815, 45, 13191, 15847, 12144, 14734, 11920, 12234, 11124, 10336, 10270, 10080, 17148, 16417, 13078, 10464, 13091, 10250, 10283, 13249, 10688, 17945, 12415, 11124, 14583, 11861, 10838, 14734, 10370, 10080, 10464, 13734, 13191, 16443, 17141, 10985, 14734, 10781, 10429, 12642, 16881, 45, 15646, 13091, 10848, 10838, 16939, 10760, 17773, 12325, 45, 13815, 10760, 15847, 12144, 12509, 16503, 14734, 14583, 13815, 28329, 11687, 13258, 10464, 10383, 14221, 11957, 14302, 10366, 14734, 15023, 10985, 12527, 10792, 11426, 12658, 12609, 14673, 15958, 45, 12605, 10402, 11021, 10399, 17149, 10250, 13582, 12822, 16671, 10464, 10696, 12366, 14734, 12527, 11002, 45, 13637, 11687, 16443, 17225, 12269, 14734, 12430, 12499, 45, 11957, 14302, 31337, 33, 14734, 13952, 13197, 15169, 15169, 10080, 10464, 11021, 10399, 10578, 16698, 10409, 10454, 10464, 12509, 16735, 14734, 45, 12605, 10423, 10578, 11065, 12202, 15494, 10334, 12978, 12746, 10080, 12605, 10402, 10423, 10250, 16944, 12664, 10792, 12176, 10847, 10464, 11891, 10675, 16939, 10760, 17148, 13619, 10781, 10429, 14734, 13036, 13764, 10080, 16738, 14782, 10529, 15847, 12144, 14734, 10838, 17387, 45, 10464, 10260, 13091, 11870, 14370, 10250, 10370, 10080, 65535, 261, 65530, 65534, 12605, 11454, 10257, 11871, 14734, 13064, 10560, 19137, 33, 11042, 11871, 10402, 12421, 13091, 11348, 15149, 12605, 10080, 33, 11454, 17213, 10792, 13320, 11423, 17901, 10737, 10336, 10407, 14734, 13064, 10560, 19137, 12605, 16678, 12348, 17268, 10283, 10370, 11017, 13221, 13109, 13078, 19137, 33, 10390, 12421, 13091, 12642, 12605, 19137, 12202, 10265, 10423, 12172, 10257, 10745, 10283, 10370, 10250, 16944, 10080, 33, 10390, 10402, 12421, 11017, 12605, 17386, 11872, 11855, 28329, 65535, 261, 65530, 65532, 12605, 14486, 16533, 11454, 13320, 11423, 17384, 17237, 17213, 17901, 10737, 13091, 17916, 12182, 14673, 15958, 14734, 15486, 10964, 10080, 16443, 13221, 13109, 13078, 11124, 10687, 10390, 10370, 17129, 18175, 10079, 13618, 12642, 11957, 10464, 17194, 12604, 10333, 13913, 10799, 14734, 10781, 10429, 28329, 10460, 10292, 10250, 10283, 11872, 11855, 45, 11002, 10792, 11042, 10437, 14734, 12711, 15498, 11124, 10429, 11917, 13091, 13249, 10687, 11426, 17843, 14734, 10080, 10390, 10402, 14734, 16403, 10292, 16672, 10464, 12527, 10792, 15847, 12144, 10260, 16443, 12824, 11002, 10079, 10260, 16443, 11971, 17385, 10080, 9822, 17386, 11872, 11855, 9823, 17148, 13324, 14734, 15044, 11116, 13179, 13091, 11454, 10464, 14734, 15847, 11971, 12366, 10257, 12266, 10764, 45, 16672, 10464, 16667, 10292, 15847, 12144, 13091, 10250, 10283, 10260, 16443, 14970, 10423, 17879, 16503, 14734, 10370, 28329, 12605, 15752, 12527, 11002, 10792, 13320, 11423, 13156, 10838, 15494, 10464, 12172, 13234, 14734, 15600, 17129, 12527, 11124, 10696, 14643, 12527, 10080, 10444, 12605, 12509, 16672, 10464, 14862, 17222, 45, 17148, 15498, 10260, 13091, 10464, 14734, 17631, 10080, 10464, 10260, 16721, 10292, 10390, 10370, 14734, 13156, 10838, 16403, 10292, 16875, 16879, 10409, 10080, 12605, 12159, 13197, 12605, 10402, 11021, 10399, 12822, 16671, 10464, 11957, 17148, 13619, 15486, 10964, 14734, 14794, 11903, 12527, 11002, 45, 10482, 10464, 10957, 10258, 10696, 12366, 14734, 17385, 12701, 28329, 10464, 13091, 10250, 10283, 12337, 13191, 10408, 10577, 14734, 10370, 10080, 17148, 10283, 10267, 14610, 17879, 16503, 10464, 45, 17879, 16503, 10464, 14734, 14370, 14332, 10305, 11621, 10080, 12605, 10423, 12176, 10847, 10464, 17385, 12261, 15847, 10529, 45, 16667, 16696, 10792, 17901, 10737, 15643, 14734, 17631, 16730, 16403, 10292, 10261, 10464, 13051, 10684, 10080, 12605, 10402, 10423, 10250, 16944, 12664, 10792, 13036, 13764, 45, 16672, 10464, 14734, 14583, 13815, 10260, 10703, 16443, 17141, 10985, 14734, 17773, 12325, 12631, 12138, 11025, 10080, 16738, 14782, 10529, 10464, 14734, 10838, 17387, 45, 12605, 10402, 10250, 11899, 15752, 16939, 10760, 17148, 13557, 14734, 10781, 10429, 10080, 65535, 261, 65530, 65534, 11454, 12824, 11002, 17148, 10349, 10370, 14734, 13565, 16875, 10305, 11044, 19137, 12605, 11994, 10258, 11899, 10722, 12366, 16503, 10848, 10838, 14734, 11871, 10323, 14862, 16696, 19137, 15641, 10283, 11685, 11871, 13320, 16056, 12348, 13179, 18216, 14734, 14970, 10423, 11459, 10447, 28329, 65535, 261, 65530, 65532, 12605, 12337, 13559, 16917, 10464, 10293, 10846, 10384, 16443, 10846, 14734, 11621, 11574, 10285, 11959, 12664, 15043, 13249, 14734, 10760, 16981, 10080, 10722, 12366, 17189, 17141, 10848, 10838, 11871, 10323, 13234, 12981, 11003, 15847, 12144, 14734, 11117, 17144, 45, 17148, 13098, 14966, 10760, 10464, 13249, 12299, 14734, 12522, 12377, 10838, 11124, 12676, 10966, 15752, 10838, 28329, 12307, 17237, 17213, 13320, 11423, 13565, 10737, 13064, 45, 10464, 13734, 13191, 17177, 12731, 12687, 11626, 12609, 15847, 13156, 15847, 12269, 45, 15646, 13091, 11967, 17148, 13619, 14673, 15958, 15486, 10964, 10460, 10292, 10846, 10838, 45, 10292, 15847, 12144, 16689, 11899, 10333, 13179, 18216, 14734, 14778, 13308, 10080, 17148, 10410, 10863, 13655, 11124, 10722, 12366, 10398, 10370, 17551, 10470, 28329, 17189, 17141, 10848, 10838, 11871, 10323, 13234, 12848, 10920, 15847, 12144, 45, 16056, 12348, 14862, 16696, 11124, 12666, 15752, 45, 14734, 14914, 11021, 10399, 12176, 10847, 10464, 16056, 11001, 13179, 11632, 13212, 10423, 11124, 11021, 15752, 12415, 10080, 12605, 14782, 10529, 10399, 10464, 14734, 13628, 10838, 45, 11891, 10675, 13191, 15752, 10838, 17136, 12604, 15847, 12144, 14734, 14778, 13308, 28329, 16678, 10449, 16503, 14240, 18004, 11685, 15847, 12144, 45, 10260, 16503, 10292, 10333, 14778, 13308, 15646, 12392, 16523, 10333, 17038, 12366, 10590, 12237, 10080, 10464, 12631, 17237, 11002, 14734, 10781, 10429, 11021, 15752, 17147, 17879, 16503, 13064, 17734, 13234, 12435, 11626, 10080, 12605, 10423, 10675, 15052, 12978, 12746, 10464, 45, 10464, 10260, 13091, 10250, 10283, 10370, 11454, 12610, 13020, 10080, 16672, 12605, 10402, 10250, 16944, 16671, 16686, 11687, 10454, 10588, 10792, 10848, 10838, 11047, 10257, 45, 11042, 13064, 10322, 10684, 12366, 15847, 12144, 14734, 17879, 16503, 10080, 10464, 14734, 13203, 13234, 10655, 14015, 12159, 13197, 45, 16738, 10525, 12746, 10529, 12366, 34, 65535, 261, 65530, 65534, 11021, 15752, 12605, 11640, 14589, 10838, 10333, 10080, 33, 10441, 10308, 11454, 12604, 12201, 14734, 17141, 15052, 12307, 10285, 12392, 16523, 10333, 12337, 11632, 10272, 16501, 28329, 65535, 261, 65530, 65532, 12469, 12848, 10792, 11454, 10848, 10838, 11903, 14446, 14778, 13308, 14734, 17141, 15052, 10285, 45, 11021, 15752, 12392, 16523, 10333, 10250, 10349, 10687, 10390, 17385, 16503, 14734, 10336, 12484, 45, 17148, 16672, 12605, 13179, 10842, 13559, 16917, 12469, 14734, 15847, 14787, 10261, 10995, 12410, 10080, 12604, 12201, 12604, 17688, 14734, 17222, 16981, 10257, 45, 12605, 10402, 17311, 10423, 10250, 10975, 12484, 12537, 45, 10399, 15849, 10339, 11003, 12348, 14313, 17919, 28329, 10848, 10838, 12981, 11003, 11117, 17144, 10079, 11001, 12348, 17149, 13582, 13205, 17038, 13091, 17916, 12182, 13580, 17919, 14734, 10336, 12484, 10080, 10444, 11454, 13581, 17141, 15052, 10285, 45, 12605, 10402, 10322, 13191, 11021, 15752, 12392, 16523, 10370, 14583, 10285, 10687, 10390, 17385, 16503, 14734, 12007, 17919, 45, 13637, 11687, 11920, 10370, 10079, 10993, 12484, 10079, 14299, 12484, 10079, 10283, 10370, 10685, 16954, 14299, 11685, 10079, 12366, 14141, 11124, 12484, 12527, 14734, 17879, 13685, 15169, 10080, 17148, 10349, 17311, 13091, 13250, 12604, 10286, 11932, 11632, 12319, 10370, 14583, 14734, 16503, 15323, 28329, 12631, 10399, 12605, 12261, 16676, 12469, 11021, 10399, 17379, 11001, 10399, 10258, 12828, 13038, 59, 15162, 10250, 45, 10452, 16751, 12202, 12527, 16774, 17141, 10985, 10848, 10838, 11659, 13020, 14734, 15847, 12144, 60, 15162, 10337, 45, 10589, 10258, 13234, 10995, 12410, 16443, 12392, 16523, 14734, 18011, 11524, 45, 16694, 10435, 15847, 12144, 17147, 17879, 16503, 10373, 10303, 60, 15162, 10256, 45, 10794, 11899, 16403, 10846, 16664, 10775, 45, 17182, 13582, 10692, 18004, 16443, 12392, 16523, 14734, 17879, 13685, 60, 15162, 11412, 45, 10261, 12978, 12746, 12469, 14734, 10366, 10993, 10355, 13819, 45, 16056, 11001, 10390, 10402, 14734, 10995, 18108, 28329, 16678, 10449, 45, 14583, 13815, 10285, 12337, 11977, 13191, 11891, 15597, 13051, 15568, 10305, 10336, 10080, 12469, 12145, 15486, 16939, 10333, 12337, 17688, 14734, 16981, 45, 14446, 11454, 11021, 10399, 16749, 13006, 13036, 11047, 45, 11903, 14446, 13179, 10675, 17919, 12200, 16412, 14734, 12604, 17688, 10080, 12605, 14782, 10529, 45, 15486, 17141, 12469, 14734, 10848, 10838, 45, 10250, 11899, 15752, 12664, 10792, 16672, 15847, 12144, 12527, 10792, 13179, 14015, 16956, 11124, 12203, 15009, 14734, 14583, 13815, 14349, 12396, 10080, 11687, 13258, 12527, 10792, 17165, 15987, 45, 17819, 13064, 13558, 17143, 10261, 12605, 10355, 13819, 10080, 65535, 261, 65530, 65534, 11044, 13234, 12605, 16667, 16696, 10333, 10250, 10283, 11435, 17781, 10355, 12791, 14583, 13209, 16037, 19137, 33, 12605, 10402, 12330, 13581, 17916, 12182, 13559, 16917, 19137, 33, 13186, 15486, 10997, 14583, 17141, 10250, 10349, 13844, 14042, 14734, 10336, 12484, 10080, 33, 10790, 16730, 10423, 12605, 13734, 13191, 11124, 11684, 10588, 11903, 17781, 14734, 12415, 12824, 16535, 10080, 33, 10444, 13091, 12605, 10402, 12330, 13581, 12570, 12573, 10080, 33, 10444, 13091, 17268, 10283, 13064, 17734, 13619, 12605, 11903, 11454, 13091, 11640, 10585, 14091, 10333, 19137, 33, 12669, 17169, 13685, 14970, 10423, 11459, 10447, 12307, 10588, 11210, 10250, 14734, 10336, 12484, 28329, 65535, 261, 65530, 65532, 12605, 14486, 16533, 11454, 17169, 13685, 14778, 13308, 14734, 17141, 15052, 10285, 45, 12469, 17213, 10792, 10333, 13209, 16037, 17148, 13324, 10250, 10283, 17385, 16503, 14734, 10370, 45, 12330, 13581, 17734, 10322, 10358, 14583, 10333, 15597, 11685, 14734, 12484, 12527, 15671, 15489, 10080, 14221, 15646, 12307, 13064, 17141, 10339, 12650, 14808, 10339, 10336, 10270, 45, 13203, 15752, 15494, 10334, 17148, 13619, 12527, 12484, 12220, 13191, 14734, 17385, 16523, 11124, 11414, 12220, 10080, 17148, 11021, 15752, 16672, 12469, 11454, 10399, 11044, 11414, 12509, 16944, 13234, 13064, 12527, 10792, 17225, 12577, 28329, 14299, 12484, 11124, 10993, 12484, 17311, 13091, 14583, 13815, 10285, 17916, 12182, 11902, 16896, 14734, 15486, 10964, 10080, 12307, 12605, 10402, 10675, 12366, 12674, 10673, 13279, 10250, 10283, 18011, 11524, 13064, 45, 12337, 11922, 13080, 12392, 16523, 10370, 10261, 10370, 10305, 17734, 12359, 11701, 15646, 15597, 11685, 14734, 12484, 12527, 10355, 13819, 28329, 12605, 12261, 16676, 12469, 10260, 16503, 11416, 13581, 15847, 16879, 10080, 17268, 10283, 17775, 13619, 14734, 12469, 13326, 12797, 12307, 13064, 14734, 14349, 12396, 10588, 10760, 10333, 17177, 12731, 10080, 14446, 11454, 12469, 12145, 15486, 12522, 16696, 10792, 45, 10370, 14583, 10285, 17879, 16503, 13179, 10675, 17919, 11459, 10692, 18004, 10260, 11042, 14734, 17879, 13685, 28329, 11687, 13258, 13209, 16037, 11957, 12469, 10383, 12522, 10304, 17916, 10746, 45, 12469, 10260, 11709, 16707, 14808, 17385, 13034, 15671, 15304, 11684, 45, 16417, 17136, 12469, 14734, 13571, 12522, 11124, 15847, 12605, 12604, 17688, 14734, 12527, 12465, 10080, 11994, 15200, 12145, 17631, 17141, 17148, 13619, 12527, 12484, 45, 11885, 10322, 12604, 10292, 12469, 10370, 14583, 11902, 16896, 14734, 10250, 17996, 10080, 16678, 10449, 12266, 12983, 12366, 15750, 45, 14460, 12493, 14806, 10808, 10370, 10080, 12469, 10423, 12979, 16056, 13179, 11632, 13203, 13234, 14734, 13212, 10423, 10080, 65535, 261, 65530, 65531, 16738, 13326, 12797, 12605, 10402, 10305, 10808, 14734, 10355, 13819, 19137, 33, 16667, 14794, 14734, 13377, 14486, 10250, 10258, 65530, 14734, 12415, 13327, 14332, 14172, 19137, 12176, 10847, 12605, 10588, 10250, 10258, 15287, 14987, 10768, 13254, 13234, 16672, 12605, 13179, 10842, 10333, 16533, 65530, 15847, 12144, 28329, 65535, 261, 65530, 65532, 11685, 14734, 45, 16672, 12605, 11986, 16707, 13326, 12797, 12605, 10402, 10305, 10808, 14734, 16671, 16686, 45, 40635, 6105, 1216, 10768, 13254, 12469, 14734, 12415, 13327, 14332, 14172, 59, 11, 12469, 13191, 14808, 12299, 11638, 14734, 12522, 12377, 10838, 11124, 11474, 12746, 10260, 12580, 14734, 15287, 14987, 10080, 10384, 11975, 17237, 17213, 14302, 10366, 15023, 10267, 14734, 10781, 10429, 45, 12469, 13734, 13191, 16443, 12642, 16881, 45, 15646, 13091, 10848, 10838, 14583, 13815, 10080, 17919, 11957, 13320, 11423, 13156, 10838, 45, 12469, 17177, 12731, 14589, 16742, 10325, 12981, 11003, 11117, 17144, 10080, 17148, 13098, 14966, 10760, 12469, 17919, 11957, 17176, 11574, 14734, 17945, 12415, 28329, 12469, 13191, 12337, 12299, 14734, 10257, 17149, 12366, 11124, 17149, 11001, 15287, 14987, 10080, 10292, 10333, 16947, 16948, 17141, 10985, 14734, 10781, 10429, 45, 12469, 10392, 10760, 12140, 11638, 10848, 10838, 13685, 11871, 11124, 12137, 10460, 45, 13098, 14966, 10760, 12299, 14179, 14734, 12604, 11994, 10846, 13212, 28329, 12469, 13637, 17097, 13773, 17385, 10336, 10270, 11124, 14486, 12509, 45, 13186, 10250, 12231, 12392, 16523, 10283, 10370, 12484, 12527, 17879, 16503, 11124, 14583, 13815, 14734, 12200, 16412, 10080, 10444, 12469, 12145, 15486, 12522, 16696, 10792, 17148, 10250, 17728, 18025, 45, 16417, 14446, 10760, 12604, 14256, 14734, 15847, 14787, 15752, 10838, 28329, 12469, 11957, 10390, 10370, 12484, 12527, 15671, 15304, 11124, 10366, 11930, 10684, 15304, 17147, 13191, 10250, 11899, 14734, 18004, 16253, 45, 11021, 15752, 10261, 13057, 13199, 14734, 10781, 10429, 15486, 10964, 13191, 10684, 10080, 17148, 10322, 13091, 13203, 13234, 11021, 10399, 15507, 15511, 12822, 15325, 14734, 10250, 13036, 17919, 28329, 12469, 12604, 14256, 10696, 12997, 15646, 11474, 17945, 45, 13191, 17919, 11957, 10370, 14583, 11426, 11574, 10261, 15847, 12144, 10696, 12366, 14734, 10863, 13655, 45, 10322, 12537, 12522, 10578, 11065, 10390, 10370, 12261, 16676, 10080, 17148, 13098, 14966, 10760, 13133, 12551, 10261, 11042, 12484, 12366, 14734, 15489, 11038, 28329, 12605, 12261, 16676, 12469, 13052, 16667, 16696, 10792, 15847, 12144, 14734, 10421, 14172, 45, 10322, 13773, 12522, 17268, 17384, 10383, 17879, 12604, 17688, 10080, 13633, 10250, 10283, 10370, 17311, 13091, 11454, 11003, 10901, 10285, 12604, 17688, 14734, 45, 17385, 16503, 14734, 13091, 10525, 12746, 11957, 14583, 13815, 14734, 14195, 12484, 45, 10261, 15713, 11899, 15847, 12144, 14734, 12522, 12537, 10080, 16738, 15507, 15511, 11474, 12746, 45, 12605, 10423, 10250, 14781, 11454, 17148, 17384, 12978, 12746, 12469, 34, 65535, 261, 65530, 65534, 15752, 11634, 12176, 12605, 10588, 10250, 13557, 15287, 14987, 10768, 13254, 11053, 19156, 11, 65535, 261, 65530, 65532, 11685, 14734, 45, 12605, 11021, 10399, 11986, 16707, 14589, 10459, 13799, 10414, 12363, 15287, 14987, 10768, 13254, 11871, 13818, 14734, 16523, 16530, 13234, 14486, 16533, 12469, 14734, 12415, 13327, 10261, 15486, 10964, 59, 11, 10384, 15287, 14987, 15489, 13250, 13234, 14791, 45, 12469, 14734, 15847, 12605, 10441, 10308, 13637, 17097, 10997, 17136, 45, 16417, 14446, 10292, 12299, 14179, 14734, 10257, 17149, 12366, 11124, 12604, 11994, 10846, 13212, 10080, 10444, 12469, 14734, 15847, 12605, 11021, 15752, 10322, 12665, 11002, 10333, 10250, 11899, 14734, 10781, 10429, 45, 13637, 11687, 14302, 10366, 14734, 15023, 10985, 11124, 13320, 11423, 13156, 10838, 10336, 10407, 45, 17148, 12325, 11168, 10333, 12469, 14734, 10370, 13327, 10997, 12022, 28329, 11, 13326, 12797, 10459, 13799, 10414, 12363, 14734, 16520, 14172, 45, 12469, 14734, 13205, 12605, 16417, 14446, 10760, 12299, 11638, 14734, 14583, 11861, 13205, 15752, 45, 11454, 14445, 11574, 10966, 10838, 10258, 10383, 14221, 11474, 12746, 15847, 12605, 10080, 10444, 11021, 15752, 12469, 14734, 16947, 12605, 13637, 17097, 10279, 15951, 45, 16503, 13685, 12469, 17241, 12357, 17097, 18216, 14734, 13308, 10733, 45, 12392, 16523, 12484, 12527, 17879, 13685, 10080, 17148, 17194, 12604, 10333, 13205, 12605, 11124, 16947, 12605, 10305, 17734, 14734, 14858, 14785, 28329, 11, 10384, 15287, 14987, 10846, 10838, 13234, 14791, 45, 12469, 10441, 10308, 13191, 17097, 12299, 14734, 10397, 10598, 12366, 14486, 45, 17189, 17141, 10264, 13773, 10336, 10270, 11124, 14778, 13308, 13234, 29334, 2241, 33, 13057, 13199, 10781, 10429, 15486, 10964, 12172, 13234, 14734, 36831, 7876, 33, 12527, 10080, 12469, 10322, 16417, 14446, 10760, 17097, 18216, 14734, 13074, 10925, 15752, 10838, 45, 10953, 12669, 15287, 10838, 12674, 10673, 10792, 14970, 10423, 12665, 16667, 14734, 12604, 11994, 10285, 28329, 11, 14059, 12522, 16696, 13036, 17919, 45, 12605, 12826, 13827, 12469, 11021, 15752, 11861, 11454, 16443, 17225, 12269, 14734, 12484, 15489, 45, 13952, 13197, 12348, 10792, 16667, 11021, 11124, 11889, 10675, 12527, 10080, 17148, 11021, 15752, 12325, 11168, 12469, 11957, 10366, 11930, 10684, 15304, 14734, 10495, 16922, 12415, 10080, 12605, 10402, 11021, 15752, 17879, 16503, 17149, 10250, 13582, 12822, 16671, 12469, 10696, 12366, 14734, 14216, 16253, 10261, 17771, 12354, 13212, 10794, 28329, 11, 11687, 13258, 12605, 14734, 10768, 13254, 13191, 10409, 10454, 17631, 16730, 45, 16738, 12469, 12748, 13580, 10080, 12605, 10402, 11021, 10399, 15507, 15511, 12822, 16671, 45, 10399, 12176, 10847, 12469, 16056, 12348, 11957, 15847, 12605, 14734, 13913, 10799, 14486, 16533, 10080, 17148, 17879, 16503, 17688, 13199, 14734, 12137, 10460, 45, 10444, 12605, 10423, 10675, 15052, 12978, 12746, 12469, 10080, 65535, 261, 65530, 65534, 13191, 13064, 10560, 12605, 10423, 16525, 12348, 10696, 12366, 15090, 16256, 19137, 10260, 14862, 12631, 12828, 28329, 65535, 261, 65530, 65532, 11685, 14734, 45, 12605, 10423, 11986, 16707, 10384, 10650, 15133, 12366, 14486, 11871, 11124, 10370, 13205, 10293, 10304, 12366, 14486, 11871, 14734, 16523, 16530, 45, 10768, 13254, 12469, 10696, 12366, 15090, 16256, 10079, 17165, 15987, 14734, 11021, 15752, 10974, 11416, 59, 11, 10384, 10650, 15133, 12366, 14486, 11871, 14791, 45, 14302, 10366, 11454, 54, 12039, 13064, 14734, 15023, 10985, 11021, 15752, 16672, 12469, 14734, 10495, 12428, 17879, 13685, 12348, 10260, 10792, 14015, 16956, 10080, 13326, 12797, 14299, 10788, 10660, 13396, 14734, 15287, 14987, 14970, 10423, 10997, 12022, 14486, 16686, 45, 17148, 10250, 13064, 13199, 11957, 14302, 13631, 14734, 10495, 16922, 11124, 10529, 10409, 11957, 10250, 10283, 11872, 11855, 14734, 12604, 17688, 15849, 10684, 17385, 16503, 10080, 14302, 14299, 14734, 15568, 11645, 11021, 15752, 11960, 15850, 12469, 14734, 11533, 13205, 10529, 10409, 11002, 10792, 10846, 12894, 45, 17149, 15646, 17194, 12604, 12484, 12527, 10257, 14734, 10260, 11889, 10675, 12527, 28329, 11454, 10370, 13205, 10293, 10304, 12366, 14486, 11871, 10285, 45, 15577, 13240, 13033, 12299, 16749, 13633, 10283, 10370, 17311, 13191, 11903, 14446, 15847, 12605, 45098, 34932, 33, 14734, 10696, 11454, 17879, 13685, 10080, 11021, 15752, 11454, 17169, 13685, 11630, 11454, 12604, 11994, 14734, 17141, 15052, 10285, 45, 12469, 12392, 16523, 10333, 10696, 11454, 15847, 12605, 14734, 17879, 16503, 45, 11960, 15850, 14446, 11454, 12527, 10792, 15090, 16256, 28329, 10292, 10333, 16056, 12348, 10390, 10370, 16667, 11021, 45, 12469, 11021, 15752, 17141, 10768, 12299, 16749, 10588, 10250, 10283, 9822, 11957, 14734, 10370, 28319, 15646, 12392, 16523, 10333, 10460, 10292, 10250, 10283, 9822, 14794, 11903, 14734, 10370, 9823, 14734, 17879, 13685, 10080, 13326, 12797, 18157, 13033, 13799, 14734, 17879, 13685, 12007, 13557, 14486, 16686, 45, 11016, 13191, 18216, 12007, 13557, 14734, 15847, 12605, 11903, 14446, 17879, 13685, 16443, 14015, 16956, 45, 10250, 10283, 10370, 12638, 15752, 12664, 10792, 14794, 13580, 14734, 14015, 16956, 12527, 28329, 12605, 12261, 16676, 12469, 11414, 12306, 10696, 12366, 45, 10578, 11065, 10696, 11454, 14734, 11610, 17952, 45, 12822, 15325, 15847, 12144, 16443, 17225, 12378, 12609, 12670, 10794, 14734, 12484, 12527, 17879, 13685, 10080, 17385, 13034, 12261, 15123, 11957, 15847, 12144, 14734, 10529, 10409, 45, 13815, 10760, 10250, 10283, 13179, 14794, 11903, 13179, 10286, 11932, 14734, 15847, 12605, 10080, 17148, 17879, 16503, 13064, 17734, 45, 10444, 12605, 14782, 10529, 10399, 12469, 14734, 10863, 13655, 45, 10250, 11899, 15752, 11634, 10588, 10792, 10080, 12605, 11454, 17148, 17384, 10675, 12366, 12978, 12746, 12469, 10080, 65535, 261, 65530, 65534, 11957, 10339, 17148, 15033, 12484, 12527, 11124, 12484, 15509, 14734, 10370, 19137, 33, 15752, 12826, 16007, 10325, 15252, 10079, 11975, 16735, 11124, 12603, 10821, 13234, 12176, 10847, 12200, 11626, 11124, 17149, 16403, 12484, 15509, 14864, 13580, 11053, 19156, 11, 65535, 261, 65530, 65532, 11685, 14734, 45, 12605, 11986, 16707, 12826, 16007, 10250, 10349, 10325, 15252, 10079, 11975, 16735, 11124, 12603, 10821, 45, 17148, 10349, 10460, 11159, 11021, 15752, 12176, 10847, 12469, 12200, 11626, 12484, 15509, 45, 17149, 16403, 12484, 12527, 14734, 13751, 14641, 59, 11, 50, 47, 33, 10325, 15252, 59, 10086, 12727, 12691, 10696, 11454, 14734, 11872, 11855, 10087, 45, 12176, 10847, 17919, 11957, 10696, 12366, 10781, 10429, 60, 10086, 10370, 14583, 14734, 17169, 13685, 10087, 45, 11959, 12664, 14583, 11117, 12522, 10304, 60, 10086, 12366, 14486, 11871, 10261, 14583, 13815, 10087, 45, 16667, 16696, 15847, 12605, 60, 10086, 10846, 13212, 10261, 10370, 13327, 10087, 45, 12664, 10792, 10696, 11454, 10846, 10838, 28329, 51, 47, 33, 11975, 16735, 59, 10086, 12766, 11753, 14734, 13396, 13256, 10087, 45, 13751, 12518, 17141, 15052, 60, 10086, 12605, 10402, 10400, 10087, 45, 11920, 12234, 10684, 15304, 60, 10086, 18052, 18361, 17848, 10087, 45, 10283, 10452, 12604, 17688, 60, 10086, 12366, 13091, 11870, 14370, 14734, 14384, 12636, 10087, 45, 12822, 15325, 10370, 12415, 28329, 52, 47, 33, 12603, 10821, 59, 10086, 13849, 18366, 10087, 45, 11920, 12234, 15593, 15482, 60, 10086, 13594, 10353, 17613, 11209, 11098, 10087, 45, 10283, 10370, 11659, 13020, 60, 10086, 15169, 12335, 12598, 11632, 10087, 45, 14583, 11117, 12522, 10304, 60, 10086, 11633, 13953, 14987, 10087, 45, 12366, 14141, 12991, 16916, 28329, 12605, 12261, 16676, 12469, 11021, 10399, 10384, 10285, 12664, 10792, 10682, 18365, 45, 11967, 10325, 10285, 10370, 14328, 14734, 15486, 10964, 10261, 15847, 12144, 14734, 61604, 45, 16056, 12348, 12484, 12527, 14734, 13800, 16519, 10080, 10421, 15597, 14734, 16728, 16537, 10322, 11021, 10399, 13751, 12518, 12366, 14141, 10781, 10429, 45, 17385, 12261, 15043, 13249, 12366, 12396, 10080, 12159, 13197, 17148, 10349, 10460, 11159, 11021, 10399, 17802, 10437, 12469, 14734, 15847, 12605, 12822, 15325, 10305, 13042, 10080, 11687, 13258, 13191, 10687, 10390, 12826, 16007, 17879, 16503, 45, 16738, 11088, 16698, 12605, 10080, 65535, 261]
-> item_loss 1.9321231842041016 batch_loss 1.9321231842041016
==== [10272, 18043, 46, 647, 11960, 12298, 10529, 12445, 11, 65530, 65532, 15494, 10760, 10272, 18043, 647, 14734, 13012, 13205, 10529, 12445, 45, 11454, 13012, 13205, 13188, 11044, 19137, 12605, 17879, 16503, 13006, 14486, 12604, 1843, 111, 13327, 12276, 19137, 13036, 10511, 14589, 10339, 11, 65535, 261, 65530, 65534, 10272, 18043, 46, 647, 10285, 11960, 12298, 13091, 10285, 11435, 14880, 10794, 14734, 10285, 17150, 15052, 12298, 17222, 11960, 12298, 10080, 33, 13326, 12797, 10678, 12266, 16909, 13021, 45, 10687, 10293, 16503, 12666, 13208, 10988, 13004, 11687, 10258, 59, 11, 9828, 33, 11965, 15052, 59, 640, 620, 46, 650, 620, 10918, 15260, 11, 9828, 33, 11960, 12298, 17688, 12231, 59, 637, 15260, 265, 9828, 33, 10997, 11965, 17385, 17387, 59, 638, 47, 55, 33, 11062, 3339, 9828, 33, 12610, 13020, 17303, 17385, 17387, 59, 50, 11062, 11, 9828, 33, 10482, 14589, 13882, 10452, 14267, 13021, 11, 10272, 18043, 46, 647, 11960, 12298, 10292, 10278, 10283, 15451, 10790, 59, 10272, 18043, 46, 647, 11124, 10272, 18043, 46, 647, 66, 45, 10293, 16503, 10912, 10790, 11454, 11965, 15052, 10257, 28329, 10272, 18043, 46, 647, 59, 11, 9828, 33, 11965, 15052, 59, 640, 620, 10918, 15260, 11, 9828, 33, 12610, 13020, 17303, 17385, 17387, 59, 695, 49, 10918, 10660, 11, 10272, 18043, 46, 647, 66, 59, 11, 9828, 11965, 15052, 59, 645, 620, 127, 650, 620, 10918, 15260, 3339, 9828, 33, 12610, 13020, 17303, 17385, 17387, 59, 50, 11062, 11, 10272, 18043, 46, 647, 11960, 12298, 16443, 12266, 10997, 14589, 10339, 15092, 14894, 10912, 11524, 17771, 15090, 15304, 15500, 45, 15752, 11634, 10495, 17917, 12298, 17222, 13177, 15471, 11124, 13212, 10846, 17248, 12987, 45, 13091, 10285, 11435, 17782, 11533, 13325, 10838, 17387, 14734, 10293, 10838, 10305, 10250, 28329, 10272, 18043, 46, 647, 11960, 12298, 12025, 10339, 10285, 10079, 14866, 11168, 12220, 13064, 17734, 12298, 17222, 11960, 12298, 45, 15752, 11634, 11454, 12728, 12617, 10808, 12387, 17193, 15092, 14894, 17771, 15090, 10452, 15304, 28329, 10272, 18043, 10337, 10917, 10253, 14734, 14332, 14172, 10894, 12732, 11, 50, 47, 33, 17379, 14589, 10994, 13882, 12396, 14136, 15208, 10997, 10846, 13212, 28331, 51, 47, 33, 17332, 15586, 10333, 11626, 13215, 14734, 10794, 11960, 15304, 15500, 19137, 10399, 10992, 10688, 11622, 12101, 13034, 14734, 10846, 10838, 15304, 15500, 28329, 10399, 10257, 13091, 10684, 10339, 10272, 18043, 46, 647, 11960, 12298, 14734, 11533, 13205, 13445, 17162, 45, 12159, 13197, 15752, 10292, 12469, 12848, 10494, 10988, 15641, 10080, 11687, 13258, 13191, 10409, 10454, 14638, 17728, 45, 13558, 17143, 11047, 12605, 12848, 17728, 28329, 10384, 10257, 17162, 13004, 12797, 10285, 19137, 33, 13006, 14486, 15489, 13250, 10901, 10529, 12445, 11687, 10258, 11, 6884, 1843, 111, 11, 2370, 26290, 269, 10272, 18043, 46, 647, 35, 11, 59, 8148, 58475, 269, 10285, 11435, 35, 11, 59, 42519, 269, 638, 47, 55, 33, 11062, 35, 11, 59, 41775, 267, 35, 637, 33, 15260, 35, 11, 59, 9059, 25566, 267, 35, 630, 620, 10918, 10660, 35, 11, 59, 35494, 269, 640, 620, 46, 650, 620, 10918, 15260, 35, 11, 59, 41330, 269, 10994, 13882, 12396, 14136, 15208, 10997, 10846, 13212, 35, 11, 59, 53988, 4363, 13191, 12986, 17095, 16032, 11021, 16749, 395, 11, 59, 63053, 269, 10272, 18043, 46, 647, 10285, 15052, 12298, 17222, 11960, 12298, 45, 17332, 11622, 11626, 13215, 14734, 10794, 11960, 11124, 12101, 13034, 14734, 10846, 10838, 15304, 15500, 10080, 399, 11, 6884, 65535, 261]
-> item_loss 1.6350220441818237 batch_loss 1.7835726141929626
==== [12366, 14486, 16690, 16753, 12308, 11, 65530, 65531, 10399, 10258, 11957, 16713, 13091, 12366, 14486, 10913, 14583, 11124, 13234, 16690, 15643, 10305, 17734, 14734, 11957, 16713, 19137, 6608, 54116, 1937, 13091, 10250, 10447, 15287, 14987, 10768, 16449, 14663, 12467, 15643, 10080, 10390, 16667, 10292, 15847, 12144, 13091, 10250, 10283, 820, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 10464, 11685, 844, 2194, 41693, 45, 267, 13234, 14734, 12771, 13057, 14734, 47, 11, 65535, 261, 65530, 65534, 5585, 41693, 41, 6608, 54116, 1937, 501, 33, 13091, 14734, 45, 12605, 13199, 12335, 17148, 13557, 14734, 10355, 13819, 47, 33, 15847, 10384, 10257, 13557, 16519, 17141, 10464, 10305, 11044, 12605, 11685, 11632, 10333, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 17268, 10303, 12605, 10402, 14446, 11454, 12266, 11726, 47, 267, 14446, 11454, 12605, 17728, 10464, 10250, 10283, 17728, 18025, 45, 33, 10464, 13091, 11060, 17147, 12395, 14638, 15847, 12144, 13091, 10250, 10283, 820, 10370, 12137, 13133, 15752, 64, 11, 65535, 261, 65530, 65534, 5585, 41693, 41, 6608, 54116, 1937, 501, 33, 12605, 10260, 14862, 17222, 47, 33, 12605, 11016, 13091, 10250, 10283, 15052, 12217, 47, 33, 12605, 13734, 13191, 12527, 16525, 11124, 12522, 16696, 47, 33, 12605, 11016, 13091, 10250, 10283, 15052, 12217, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 12631, 10399, 10464, 13091, 10250, 10283, 15052, 12217, 64, 33, 10464, 13191, 10373, 10303, 13234, 16692, 13078, 15847, 12144, 13091, 10250, 10283, 15052, 12217, 17268, 64, 11, 65535, 261, 65530, 65534, 5585, 41693, 41, 6608, 54116, 1937, 501, 33, 12605, 13091, 10250, 10283, 15052, 12217, 47, 33, 12605, 13734, 13191, 12527, 16525, 11124, 12522, 16696, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 14589, 12636, 12623, 10333, 10250, 10258, 5585, 41693, 14734, 15804, 17303, 47, 58683, 12527, 16525, 10792, 10250, 17774, 17355, 14673, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 10464, 14446, 11454, 13091, 11060, 12527, 16525, 10792, 10373, 10303, 64, 11, 65535, 261, 65530, 65534, 5585, 41693, 41, 6608, 54116, 1937, 501, 33, 12605, 12527, 16525, 10792, 10333, 47, 33, 10464, 12623, 10333, 12605, 10250, 10258, 47, 33, 10444, 13091, 17148, 10260, 15752, 16692, 13078, 10373, 10303, 47, 33, 12605, 17147, 13091, 820, 10370, 12137, 13133, 15752, 47, 11, 65535, 261, 65530, 65531, 33365, 49461, 12745, 10760, 10333, 10250, 12287, 14240, 14313, 45, 33, 10257, 17919, 13091, 5585, 41693, 11124, 10390, 14734, 11920, 10370, 10402, 45, 58683, 12691, 14808, 10390, 14734, 11679, 10650, 17900, 16501, 45, 33, 10390, 10402, 15149, 14734, 17311, 12337, 12266, 12366, 47, 17900, 16501, 12636, 10285, 12745, 14808, 10250, 10283, 13778, 17159, 11975, 14249, 45, 11994, 13091, 16407, 10257, 12182, 16519, 14734, 17268, 15033, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 17148, 12287, 14240, 14313, 10464, 16667, 16696, 11053, 64, 11, 65535, 261, 65530, 65534, 5585, 41693, 41, 6608, 54116, 1937, 501, 33, 17148, 13091, 12605, 14734, 11679, 10650, 17900, 16501, 47, 33, 11684, 12337, 11021, 14299, 47, 33, 12605, 12337, 11268, 13558, 11684, 47, 33, 12605, 10402, 10250, 11920, 10370, 17311, 12337, 11268, 13558, 11684, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 10370, 12137, 13133, 15752, 12401, 10303, 10423, 13191, 11679, 10650, 14734, 64, 11, 65535, 261, 65530, 65534, 5585, 41693, 41, 6608, 54116, 1937, 501, 33, 12605, 10260, 14862, 17222, 47, 33, 10444, 13091, 17148, 11994, 13091, 12605, 14734, 11679, 10650, 47, 33, 11684, 12337, 11021, 14299, 47, 33, 12605, 12337, 11268, 13558, 11684, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 12605, 16535, 14935, 10464, 14734, 13064, 10560, 45, 33, 10464, 10423, 12527, 16525, 10792, 14658, 14673, 47, 33, 10464, 10322, 13191, 14658, 14299, 14734, 11679, 10650, 47, 267, 12631, 10399, 10464, 17147, 11474, 12746, 10464, 13091, 10370, 12137, 13133, 15752, 11053, 64, 11, 65535, 261, 65530, 65531, 33365, 49461, 14589, 12748, 11981, 12813, 10449, 5585, 41693, 14734, 12636, 15833, 45, 58683, 12527, 16525, 10792, 14658, 14673, 47, 11, 65535, 261, 65530, 65534, 5585, 41693, 41, 6608, 54116, 1937, 501, 33, 12266, 11726, 13722, 18441, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 10464, 17147, 11474, 12746, 10464, 13091, 10370, 12137, 13133, 15752, 11053, 64, 11, 65535, 261, 65530, 65534, 5585, 41693, 59, 33, 12605, 10260, 14862, 17222, 47, 33, 12605, 11016, 13091, 10250, 10283, 15052, 12217, 47, 33, 12605, 13734, 13191, 12527, 16525, 11124, 12522, 16696, 47, 33, 12605, 11016, 13091, 10250, 10283, 15052, 12217, 579, 10390, 14734, 15287, 14987, 17771, 15471, 12266, 11726, 12100, 13977, 42, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 12605, 14782, 10529, 10464, 13091, 10250, 10283, 14794, 13580, 14734, 10370, 47, 33, 10464, 14734, 12366, 14486, 14660, 14662, 11016, 13091, 16417, 14446, 10292, 10250, 10283, 820, 10370, 12137, 13133, 15752, 47, 33, 10464, 10260, 10423, 16443, 14794, 13580, 14734, 15287, 14987, 14662, 12631, 12325, 11168, 47, 33, 14446, 11454, 10464, 14862, 17222, 15847, 12144, 13091, 10373, 10303, 10333, 11053, 64, 11, 65535, 261, 65530, 65534, 5585, 41693, 59, 33, 12605, 16678, 16944, 13234, 10333, 47, 33, 12605, 13091, 10250, 10283, 14794, 13580, 14734, 10370, 47, 33, 12605, 10260, 13091, 820, 10370, 12137, 13133, 15752, 47, 33, 12605, 13091, 10250, 10283, 10370, 15261, 45, 33, 10250, 10283, 13191, 16399, 13191, 15694, 14734, 10370, 15261, 47, 33, 16774, 16774, 10464, 10913, 14583, 45, 33, 12605, 14862, 17222, 15847, 12144, 13091, 10373, 10303, 10333, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 14446, 11454, 45, 33, 12307, 10464, 12848, 10792, 97, 12605, 97, 17148, 10283, 16702, 14734, 13064, 10560, 45, 10464, 14734, 10423, 15671, 12509, 10792, 64, 11, 65535, 261, 65530, 65534, 5585, 41693, 59, 33, 12605, 12509, 10792, 14734, 13091, 12605, 15847, 12144, 47, 33, 12605, 13091, 10250, 10283, 14794, 13580, 14734, 10370, 15261, 45, 33, 13191, 16399, 13191, 15694, 14734, 10370, 15261, 47, 33, 12605, 10260, 13091, 820, 10370, 12137, 13133, 15752, 47, 33, 12605, 10260, 10423, 16443, 14794, 13580, 14734, 15287, 14987, 14662, 12631, 12325, 11168, 47, 33, 12605, 10260, 13091, 13091, 10250, 10283, 10632, 10901, 13594, 13248, 14734, 15052, 12217, 45, 33, 12605, 11021, 10399, 10588, 10760, 12337, 11632, 10336, 12484, 10985, 12981, 11003, 17148, 10283, 10267, 14610, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 17268, 10303, 10464, 15752, 11634, 10588, 10792, 11053, 64, 33, 10464, 15752, 11634, 12509, 16803, 10760, 15847, 12144, 14734, 14302, 13631, 11053, 64, 33, 12609, 15643, 10464, 14734, 13192, 10993, 64, 33, 10464, 15752, 11634, 11414, 12369, 16944, 17141, 10985, 14734, 10336, 12484, 11053, 64, 11, 65535, 261, 65530, 65534, 5585, 41693, 59, 33, 12605, 15752, 11634, 11414, 12369, 16944, 17141, 10985, 14734, 10336, 12484, 47, 33, 12605, 11021, 10399, 12509, 16803, 10760, 15847, 12144, 14734, 14302, 13631, 45, 33, 12605, 11021, 10399, 12509, 16803, 10760, 13192, 10993, 10402, 47, 33, 10444, 13091, 12605, 10260, 15752, 12509, 16803, 10760, 15847, 12144, 14734, 15287, 14987, 14662, 13091, 10373, 10303, 13064, 10560, 10997, 14583, 14734, 47, 33, 12605, 17268, 13064, 10560, 16730, 10399, 10292, 15847, 12144, 13091, 10250, 10283, 820, 10370, 12137, 13133, 15752, 15646, 10260, 13091, 14794, 13580, 14734, 10370, 15261, 47, 267, 10260, 14862, 17222, 10373, 10303, 13064, 10560, 17148, 15033, 10632, 10901, 13594, 13248, 14734, 17207, 17108, 12527, 13282, 10333, 12605, 45, 16672, 12605, 12378, 16678, 10333, 15847, 12144, 13091, 10250, 10283, 10688, 13191, 14583, 10846, 45, 13815, 10838, 45, 13815, 13786, 14734, 10370, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 12337, 11685, 47, 33, 12605, 10402, 10381, 11639, 14734, 13751, 14641, 11994, 10792, 17148, 17384, 10333, 47, 33, 10464, 11021, 10399, 11414, 10985, 12410, 15641, 10250, 10258, 45, 33, 14221, 11044, 12605, 10402, 10703, 13234, 10588, 10258, 10250, 13557, 14734, 13751, 14641, 47, 33, 12159, 13197, 10464, 15752, 11634, 11685, 16944, 13234, 47, 33, 12605, 10402, 11454, 10258, 13557, 16519, 17919, 14734, 13064, 10560, 10703, 12261, 47, 33, 10703, 16519, 34, 11, 65535, 261]
-> item_loss 1.1061184406280518 batch_loss 1.5577545563379924
==== [25106, 11, 65530, 65531, 24869, 13091, 10250, 10283, 10370, 12137, 13133, 15752, 10847, 12636, 19137, 11021, 10399, 12176, 10847, 10370, 15261, 10588, 11036, 15033, 10336, 12484, 10080, 24869, 12337, 15678, 13078, 19137, 15752, 10384, 10370, 15261, 14734, 16728, 16537, 10285, 14486, 16533, 10370, 15261, 14734, 17879, 13685, 28329, 65535, 261, 65530, 65532, 27370, 59, 30274, 19156, 11, 65535, 261, 65530, 65534, 24869, 59, 33, 12605, 11454, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 11021, 10399, 14589, 15963, 13012, 11124, 12605, 16735, 16713, 10303, 19156, 11, 65535, 261, 65530, 65534, 24869, 59, 4089, 45604, 34, 308, 21413, 63354, 32487, 22799, 4596, 50199, 47, 20063, 21413, 308, 45221, 22799, 45, 4677, 46526, 64, 11, 65535, 261, 65530, 65532, 27370, 59, 33, 17268, 11021, 10399, 14589, 13053, 13012, 10303, 19156, 11, 65535, 261, 65530, 65534, 24869, 59, 33, 10139, 10103, 10079, 13053, 13205, 16592, 43385, 11961, 12380, 43380, 43421, 10080, 10454, 10107, 10106, 12636, 10424, 43312, 58530, 10107, 10080, 10134, 10104, 3022, 159, 10106, 13657, 17055, 10136, 10079, 10116, 10293, 10370, 13476, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 11685, 11061, 19137, 10780, 12638, 11016, 13091, 13827, 16707, 19137, 17147, 13091, 14589, 10285, 13012, 11061, 11, 65535, 261, 65530, 65534, 24869, 59, 33, 13734, 17728, 18025, 19137, 10293, 10370, 19137, 12605, 11021, 10399, 14589, 11036, 15033, 16728, 16537, 12176, 12469, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 10464, 14862, 17222, 10296, 10250, 10995, 10256, 10303, 19156, 11, 65535, 261, 65530, 65534, 24869, 59, 33, 14862, 17222, 19137, 10296, 10250, 10995, 10256, 13091, 12748, 11871, 10423, 10333, 10250, 15261, 14862, 16696, 12609, 13036, 13764, 11044, 19137, 15752, 11634, 11967, 10687, 13325, 12366, 12410, 12509, 12220, 14589, 10339, 11042, 15261, 11496, 12609, 14782, 10441, 14734, 12484, 13126, 12609, 10409, 10843, 10285, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 11638, 10452, 10257, 13734, 13191, 17728, 18025, 28329, 65535, 261, 65530, 65534, 24869, 59, 33, 11315, 19137, 11685, 14734, 19137, 10293, 10370, 17147, 13191, 10687, 10390, 10336, 12484, 10303, 19156, 11, 65535, 261, 65530, 65532, 27370, 59, 33, 12605, 12509, 16735, 14734, 13091, 19137, 14589, 13234, 16675, 15475, 10464, 14734, 16728, 13021, 12337, 17843, 17136, 10792, 11891, 11622, 43282, 28329, 65535, 261, 65530, 65534, 24869, 59, 33, 12631, 10399, 10293, 10370, 14734, 12522, 12410, 13091, 19137, 12605, 11454, 17213, 10792, 10250, 10349, 13734, 13191, 16519, 17141, 14734, 17728, 18025, 13064, 19137, 17879, 16503, 10296, 10250, 10995, 10256, 19137, 15641, 16253, 15847, 12144, 17213, 10792, 17141, 14734, 11042, 15261, 17728, 18025, 19137, 12202, 11986, 16707, 14589, 10687, 10285, 14734, 12410, 12509, 10985, 16533, 10722, 19156, 11, 65535, 261, 65530, 65532, 27370, 59, 33, 11957, 19137, 15678, 13078, 19126, 11, 65535, 261, 65530, 65534, 24869, 59, 33, 16774, 16774, 10293, 10370, 11649, 11665, 19137, 12605, 10423, 11986, 16707, 11047, 17148, 10283, 13036, 11047, 10848, 10838, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 11315, 19137, 12605, 10703, 15494, 10464, 10296, 10283, 10487, 11855, 11061, 10080, 13637, 11687, 15494, 10464, 10250, 10283, 10409, 10843, 19137, 10464, 17879, 16503, 10384, 35, 33839, 5178, 24364, 98, 35, 11124, 35, 684, 35, 10285, 17177, 12731, 10250, 10283, 17109, 10760, 10080, 17148, 13324, 19137, 10464, 10658, 11088, 16698, 12605, 17148, 13557, 10464, 17109, 10760, 10333, 10373, 10303, 19137, 14781, 12824, 12669, 10464, 14734, 17177, 12731, 17109, 10760, 10760, 13234, 28329, 65535, 261, 65530, 65534, 24869, 59, 3537, 11, 65535, 261, 65530, 65532, 27370, 59, 33, 13734, 17631, 19137, 11454, 17148, 15261, 10409, 10843, 10285, 10464, 17879, 16503, 12750, 14240, 12748, 11899, 13327, 12276, 10733, 14914, 11459, 17109, 10760, 10696, 11922, 19137, 17268, 12605, 10703, 15494, 10464, 12791, 10250, 10283, 17728, 18025, 28329, 65535, 261, 65530, 65534, 24869, 59, 33, 11685, 14734, 10293, 10370, 19137, 12605, 15169, 12335, 10464, 14734, 17728, 18025, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 17148, 13557, 10384, 92, 6885, 94, 10079, 92, 1751, 101, 94, 10079, 92, 114, 94, 10285, 17177, 12731, 10250, 10283, 17109, 10760, 11, 65535, 261, 65530, 65534, 24869, 59, 348, 11, 65535, 261, 65530, 65532, 27370, 59, 33, 10464, 10384, 17148, 10278, 10283, 17728, 18025, 10285, 10997, 14446, 10333, 10373, 10303, 11053, 19156, 11, 65535, 261, 65530, 65534, 24869, 59, 33, 10293, 10370, 19137, 15489, 11038, 11124, 10464, 14734, 15667, 11639, 10964, 11024, 19137, 12605, 10997, 14446, 17148, 10278, 10283, 10409, 10843, 12025, 10339, 11042, 15261, 10409, 10843, 19137, 17311, 13091, 17879, 16503, 12605, 12750, 14240, 13327, 12276, 15287, 10733, 14734, 17109, 10760, 10696, 11922, 10080, 10444, 13091, 10278, 15643, 10912, 10790, 11454, 10339, 19137, 10808, 15643, 14734, 10696, 11922, 13091, 14597, 12282, 11028, 10894, 16468, 10079, 14597, 17187, 11028, 17734, 17821, 14734, 19137, 15646, 11044, 15643, 10779, 13091, 14597, 13036, 12732, 11028, 10894, 16468, 10079, 14597, 18005, 11028, 17734, 17821, 19137, 10560, 17177, 14734, 10696, 11922, 10322, 13191, 12631, 10260, 11042, 10080, 12605, 12826, 13827, 10250, 10258, 19137, 10293, 10370, 14734, 12522, 12410, 13091, 12509, 11088, 16698, 12605, 17148, 10278, 10283, 10409, 10843, 13091, 11042, 10250, 15033, 15261, 19137, 12631, 10399, 12307, 12605, 11871, 10423, 10333, 10250, 10283, 10305, 11044, 19137, 12220, 12307, 13078, 14731, 11042, 15261, 14734, 10409, 10843, 16721, 12401, 13324, 10985, 11891, 12604, 19137, 13091, 17148, 13324, 10303, 19156, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 13734, 17631, 10080, 12605, 10402, 17147, 11021, 10399, 10588, 13179, 11632, 14734, 13827, 16707, 10303, 19156, 11, 65535, 261, 65530, 65534, 24869, 59, 33, 11021, 10399, 14734, 19137, 12605, 15169, 12335, 12469, 14734, 13034, 13827, 16707, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11986, 16707, 17109, 10760, 10250, 10283, 15963, 13012, 10923, 16530, 17187, 11028, 19137, 17147, 13091, 10260, 17879, 16503, 17109, 10760, 10687, 10390, 13012, 11860, 28329, 65535, 261, 65530, 65534, 24869, 59, 279, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11986, 16707, 17109, 10760, 10250, 10283, 10285, 13012, 17187, 11028, 19137, 12202, 17819, 10511, 16735, 14172, 10373, 10303, 11, 65535, 261, 65530, 65534, 24869, 59, 23245, 10293, 10370, 19137, 12605, 12750, 14240, 12469, 14734, 12522, 12410, 17109, 10760, 10333, 10250, 10283, 10285, 13012, 17187, 11028, 19137, 11885, 10447, 10339, 12605, 17148, 11012, 16713, 14734, 10808, 17919, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 10588, 12348, 11685, 10080, 1751, 7321, 7321, 1817, 7051, 1832, 1751, 11, 65535, 261, 65530, 65534, 24869, 59, 33, 16774, 16774, 11649, 11665, 19137, 10444, 13091, 12605, 14791, 10260, 12578, 11454, 10293, 10370, 12469, 14734, 11044, 10250, 11012, 16713, 19137, 11885, 13091, 10373, 10303, 12522, 12410, 19156, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 10260, 11975, 12366, 12642, 10333, 10250, 10349, 10328, 14875, 19137, 10260, 16503, 11454, 12522, 28329, 65535, 261, 65530, 65534, 24869, 59, 33, 13078, 14731, 10333, 28329, 65535, 261]
-> item_loss 0.9601616263389587 batch_loss 1.408356323838234
==== [12366, 14486, 16690, 16753, 12308, 11, 65530, 65531, 10399, 10258, 11957, 16713, 13091, 12366, 14486, 10913, 14583, 11124, 13234, 16690, 15643, 10305, 17734, 14734, 11957, 16713, 19137, 33914, 8778, 117, 41, 13341, 12001, 42, 13091, 10250, 10447, 10337, 10917, 12039, 14734, 11977, 11679, 45, 11684, 11474, 12746, 16667, 10292, 15847, 12144, 11016, 13091, 10250, 10283, 820, 10370, 12137, 13133, 15752, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 10464, 11685, 13341, 12001, 47, 11, 65535, 261, 65530, 65534, 5585, 41693, 41, 13341, 12001, 501, 33, 10464, 11685, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 10464, 13188, 17145, 13191, 10373, 10303, 14189, 12454, 11053, 64, 11, 65535, 261, 65530, 65534, 5585, 41693, 41, 13341, 12001, 501, 33, 12605, 13188, 17145, 12421, 13091, 12527, 16525, 12337, 15330, 19137, 15646, 10265, 12605, 10322, 10260, 14862, 17222, 10292, 10373, 10303, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 10464, 17147, 16667, 10292, 15847, 12144, 13091, 10250, 10283, 820, 10370, 12137, 13133, 15752, 45, 11016, 13091, 10250, 10283, 15052, 12217, 45, 13734, 13191, 12527, 12484, 11124, 12410, 12509, 11053, 64, 11, 65535, 261, 65530, 65534, 5585, 41693, 41, 13341, 12001, 501, 33, 12605, 10260, 14862, 17222, 47, 12605, 11016, 13091, 10250, 10283, 15052, 12217, 45, 13734, 13191, 12527, 12484, 11124, 12410, 12509, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 17268, 10303, 10464, 10292, 10373, 10303, 10423, 12527, 10792, 14654, 12502, 11102, 64, 11, 65535, 261, 65530, 65534, 5585, 41693, 41, 13341, 12001, 501, 33, 12605, 10260, 14862, 17222, 47, 12605, 11016, 13091, 12527, 16525, 12337, 15330, 45, 15646, 10265, 12605, 10322, 10260, 14862, 17222, 10292, 10373, 10303, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 10464, 13191, 13734, 13191, 12509, 17141, 45, 10322, 16684, 10464, 13091, 10250, 10283, 14794, 13580, 14734, 10370, 15261, 11102, 64, 11, 65535, 261, 65530, 65534, 5585, 41693, 41, 13341, 12001, 501, 33, 12609, 16684, 13091, 11061, 47, 10444, 13091, 12605, 10260, 14862, 17222, 15847, 12144, 13091, 16747, 45, 10322, 10260, 14862, 17222, 15847, 12144, 10292, 10373, 10303, 10423, 13234, 10792, 17148, 17384, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 10464, 11692, 11692, 12266, 17079, 17171, 10464, 13234, 14734, 11, 65535, 261, 65530, 65534, 5585, 41693, 41, 13341, 12001, 501, 33, 12605, 10260, 14862, 17222, 47, 12605, 11016, 16678, 12348, 12605, 13091, 11454, 10250, 10283, 12337, 11638, 14734, 12630, 17734, 17384, 17919, 45, 14221, 11044, 13191, 10250, 10283, 10370, 11088, 16698, 12605, 45, 10390, 13091, 12605, 14734, 14304, 14304, 47, 10444, 13091, 12605, 10260, 14862, 17222, 10390, 13091, 16747, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 17148, 10303, 16735, 10464, 10260, 16678, 12348, 10464, 14734, 14302, 10366, 10333, 64, 11, 65535, 261, 65530, 65534, 5585, 41693, 41, 13341, 12001, 501, 33, 10260, 16678, 12348, 10333, 47, 12605, 11016, 16678, 12348, 12605, 13091, 10250, 10283, 820, 10370, 12137, 13133, 15752, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 13091, 10260, 13091, 12337, 11632, 10370, 17311, 11088, 16698, 10464, 45, 10464, 13091, 10283, 820, 10370, 12137, 13133, 15752, 64, 11, 65535, 261, 65530, 65534, 5585, 41693, 41, 13341, 12001, 501, 33, 13091, 14734, 47, 12605, 10260, 14862, 17222, 10390, 10402, 10292, 10373, 10303, 16503, 17148, 10303, 16735, 45, 10444, 13091, 12605, 12527, 16525, 10390, 10402, 11685, 10621, 12337, 11917, 12405, 12605, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 10292, 10373, 10303, 64, 11, 65535, 261, 65530, 65534, 5585, 41693, 41, 13341, 12001, 501, 33, 12605, 10260, 14862, 17222, 47, 10444, 13091, 10390, 10402, 12421, 13091, 12337, 11917, 12405, 12605, 45, 11685, 10621, 12605, 10423, 10429, 11917, 10390, 10402, 10250, 13324, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 10444, 13091, 10464, 10260, 10423, 10429, 11917, 10390, 10402, 11957, 10260, 11957, 47, 11, 65535, 261, 65530, 65534, 5585, 41693, 41, 13341, 12001, 501, 33, 10260, 10423, 47, 12605, 10260, 10423, 10429, 11917, 10390, 10402, 14734, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 45913, 32232, 31123, 22799, 11, 65535, 261, 65530, 65534, 5585, 41693, 41, 13341, 12001, 501, 33, 10260, 10423, 47, 12605, 10260, 10423, 10429, 11917, 10390, 10402, 14734, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 13341, 12001, 45, 15847, 12605, 10525, 12686, 13091, 10250, 15033, 10370, 15261, 14734, 13205, 15752, 45, 33, 10464, 10260, 12220, 16721, 12676, 12711, 11885, 47, 11, 65535, 261, 65530, 65534, 5585, 41693, 41, 13341, 12001, 501, 33, 12605, 10260, 14862, 17222, 47, 12605, 11016, 13091, 12527, 16525, 12337, 11917, 12405, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 10464, 10260, 14589, 11917, 12405, 47, 10464, 11016, 13091, 10250, 10283, 11021, 14299, 14734, 11975, 11679, 11872, 45, 33, 11975, 11679, 11872, 15752, 13191, 10373, 10303, 17631, 17268, 64, 33, 12509, 10250, 12509, 45, 12605, 10402, 13186, 15486, 10250, 16944, 12610, 15735, 17141, 12140, 18488, 45, 17268, 15033, 12418, 14328, 12605, 10402, 17311, 11021, 10399, 12610, 15735, 11, 65535, 261, 65530, 65534, 5585, 41693, 41, 13341, 12001, 501, 33, 12605, 10260, 14862, 17222, 47, 12605, 11016, 13091, 12527, 16525, 12337, 11917, 12405, 47, 11, 65535, 261, 65530, 65532, 33365, 49461, 59, 33, 10464, 11021, 10399, 11088, 16698, 12605, 10997, 14583, 10333, 10373, 10303, 10336, 11053, 64, 33, 12605, 10402, 10250, 16944, 13234, 16533, 10722, 11885, 11685, 11053, 64, 11, 65535, 261, 65530, 65532, 5585, 41693, 59, 33, 11957, 16713, 12145, 15489, 13229, 19137, 13051, 13764, 17149, 16403, 10258, 10250, 13582, 14734, 10409, 10843, 11621, 14486, 10080, 11687, 13258, 12469, 13191, 10687, 10390, 17728, 18025, 17879, 16503, 12176, 10847, 19137, 16738, 17819, 13064, 12848, 10760, 28329, 65535, 261]
-> item_loss 0.8733910918235779 batch_loss 1.3013632774353028
==== [25106, 11, 65530, 65531, 10464, 13091, 10250, 10283, 16728, 16537, 13499, 11496, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 11454, 10303, 19156, 11, 65535, 261, 65530, 65534, 33914, 8778, 117, 59, 33, 11454, 14734, 19137, 13191, 10373, 10303, 10336, 12484, 12605, 11021, 10399, 12176, 12469, 10303, 19156, 11, 65535, 261, 65530, 65532, 27370, 59, 33, 12605, 12509, 16503, 11454, 10370, 15261, 14734, 15123, 11461, 10257, 11124, 10464, 16671, 16686, 10250, 10258, 10464, 16503, 11687, 10454, 11124, 10370, 15261, 15667, 11639, 19137, 10423, 16672, 10370, 15261, 12527, 16525, 13179, 10842, 15867, 17172, 28329, 65535, 261, 65530, 65534, 33914, 8778, 117, 59, 33, 11021, 10399, 14734, 19137, 16738, 17728, 12605, 17879, 16503, 11047, 12469, 12848, 10494, 16520, 14172, 10303, 19156, 11, 65535, 261, 65530, 65532, 27370, 59, 33, 12605, 13234, 12848, 10494, 16520, 14172, 11061, 10080, 18117, 10658, 19137, 12605, 16667, 10292, 19137, 820, 11021, 10399, 10985, 10293, 10846, 11047, 10370, 15261, 12848, 17728, 19137, 10444, 13091, 10260, 12220, 16721, 17141, 12231, 18020, 15414, 10080, 15646, 10265, 12307, 10464, 10784, 13032, 10370, 15261, 17879, 16503, 11957, 16713, 14734, 10293, 10846, 13216, 13064, 19137, 12220, 16721, 15494, 10370, 15261, 13179, 11632, 14734, 13212, 10423, 13234, 10997, 16537, 28329, 65535, 261, 65530, 65534, 33914, 8778, 117, 59, 33, 12605, 10333, 16533, 10333, 19137, 16738, 17728, 17148, 13324, 10588, 14734, 10974, 11416, 13091, 10373, 10303, 19156, 11, 65535, 261, 65530, 65532, 27370, 59, 33, 10464, 16707, 14808, 12410, 15641, 10250, 10258, 19137, 11687, 13258, 10464, 10250, 14781, 11454, 12848, 17728, 19137, 10423, 10997, 14583, 10373, 10303, 19156, 11, 65535, 261, 65530, 65534, 33914, 8778, 117, 59, 33, 11685, 14734, 10293, 10370, 19137, 12605, 16707, 14808, 12410, 15641, 10250, 10258, 10080, 11687, 13258, 12605, 10250, 14781, 11454, 12848, 17728, 19137, 17268, 10303, 10370, 15261, 11994, 17879, 16503, 10260, 13032, 14734, 11414, 15178, 12605, 14734, 17728, 18025, 10080, 11687, 13258, 10370, 15261, 10260, 13032, 14734, 11414, 15178, 12605, 14734, 17728, 18025, 19137, 17268, 10303, 12337, 13191, 11021, 15752, 13734, 13191, 13064, 17734, 13234, 11047, 12605, 12848, 17728, 10080, 12605, 11994, 13734, 13191, 10840, 13764, 12176, 10792, 10370, 15261, 10080, 12631, 10399, 19137, 10293, 10370, 14734, 12522, 12410, 13091, 16672, 12605, 16707, 14808, 11967, 13179, 11632, 14734, 11957, 16713, 10293, 10846, 13216, 10355, 15494, 10370, 15261, 19137, 10384, 15646, 13179, 11685, 14734, 12176, 10847, 10370, 15261, 10080, 13091, 17148, 13324, 10303, 19156, 11, 65535, 261, 65530, 65532, 27370, 59, 33, 13734, 17631, 19137, 17148, 13324, 10370, 15261, 10423, 12527, 10792, 12337, 15867, 17172, 10080, 10260, 17141, 10260, 16503, 11416, 13581, 10985, 12983, 12269, 15847, 12144, 14734, 11685, 11656, 12366, 19137, 12605, 12337, 18458, 10851, 10464, 10293, 10846, 10985, 11047, 10370, 15261, 12848, 17728, 28329, 65535, 261, 65530, 65534, 33914, 8778, 117, 59, 33, 11685, 14734, 19137, 16774, 16774, 10293, 10370, 14734, 14486, 16533, 19126, 12605, 10399, 11044, 10423, 11986, 16707, 11454, 10293, 10846, 12848, 17728, 14015, 16956, 15847, 12144, 11685, 11656, 12366, 14734, 11042, 13064, 19137, 10421, 10658, 15641, 16253, 10370, 15261, 17728, 12605, 14734, 17728, 18025, 19137, 12202, 10265, 11454, 11957, 16713, 10285, 15494, 10370, 15261, 13179, 11632, 14734, 10293, 10846, 13216, 19137, 16672, 10370, 15261, 12527, 10792, 15867, 17172, 28329, 65535, 261]
-> item_loss 1.0084446668624878 batch_loss 1.2525435090065002
==== [25106, 11, 65530, 65531, 16201, 16201, 13091, 10250, 10283, 820, 10080, 11454, 11957, 16713, 13064, 19137, 16201, 16201, 10423, 11967, 12366, 14486, 10261, 10846, 10460, 12847, 10708, 12983, 11454, 9822, 19133, 19134, 9823, 10285, 10080, 93, 2078, 8704, 59, 33, 16201, 16201, 19137, 13115, 10257, 11685, 28329, 65535, 261, 65530, 65534, 16201, 16201, 59, 275, 13947, 13283, 10250, 15149, 42, 33, 13115, 10257, 11685, 45, 33, 10293, 10370, 10464, 13234, 12664, 12605, 11235, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 16728, 16537, 13499, 11496, 14734, 12206, 16525, 13091, 10373, 10303, 12522, 12410, 11102, 19156, 11, 65535, 261, 65530, 65534, 16201, 16201, 59, 275, 14638, 12489, 42, 33, 12605, 10402, 14734, 12206, 16525, 10303, 19156, 10399, 10808, 13734, 11065, 17141, 11102, 19137, 10293, 10370, 13091, 16503, 16735, 11124, 10370, 15261, 14734, 12206, 16525, 10250, 13324, 10303, 19156, 11, 65535, 261, 65530, 65532, 27370, 59, 33, 12202, 10260, 13091, 19137, 16728, 16537, 13499, 11496, 14734, 12206, 16525, 41, 6113, 35927, 42, 13091, 10250, 10283, 11871, 13208, 13445, 12389, 19137, 11885, 13091, 12748, 16728, 16537, 13499, 11496, 13191, 13064, 10423, 17109, 10760, 10250, 10349, 11124, 10336, 11903, 13078, 13098, 10260, 15158, 14734, 10272, 16501, 10080, 93, 111, 10487, 11687, 19137, 12307, 12605, 17728, 10464, 13580, 11454, 12199, 10373, 10303, 14734, 13064, 10560, 10080, 10464, 11414, 15178, 10333, 12605, 19137, 15847, 12144, 13580, 11454, 13042, 13953, 10080, 10444, 13091, 12605, 10402, 14862, 17222, 19137, 10464, 11454, 10261, 12605, 11957, 16713, 19137, 15646, 10260, 13091, 13042, 13953, 10080, 12631, 10399, 17148, 10423, 16443, 11638, 17303, 10768, 10370, 16667, 10292, 13499, 11496, 10621, 10370, 15261, 10250, 13324, 10358, 14583, 10333, 12206, 16525, 19137, 10339, 13091, 19137, 10511, 12669, 17148, 15033, 14446, 16803, 11117, 11043, 10292, 16728, 16537, 13499, 11496, 14734, 9822, 12206, 16525, 9823, 10080, 10260, 17141, 19137, 10322, 13191, 10370, 16667, 10292, 12605, 10780, 12638, 12631, 16735, 14734, 17268, 15033, 12484, 10724, 13091, 11416, 10292, 11454, 17109, 10673, 11044, 19137, 16728, 16537, 13499, 11496, 15671, 12509, 10792, 10333, 15847, 12144, 11454, 13042, 13953, 14734, 13324, 11855, 19137, 12631, 10399, 12638, 10423, 16735, 15847, 12144, 11454, 13042, 13953, 28329, 65535, 261, 65530, 65534, 16201, 16201, 59, 275, 14172, 11647, 42, 33, 11183, 19137, 12605, 13078, 14731, 10333, 10080, 16728, 16537, 13499, 11496, 14734, 12206, 16525, 41, 6113, 35927, 42, 13091, 12748, 12307, 16728, 16537, 13499, 11496, 12824, 11002, 17109, 10673, 13064, 19137, 17109, 10760, 10261, 14446, 11903, 10260, 15158, 14734, 10336, 12484, 14734, 14446, 16803, 10080, 12206, 16525, 14734, 13234, 13981, 13191, 11021, 15752, 13091, 16728, 16537, 13499, 11496, 11967, 15847, 12144, 15671, 12509, 10792, 14734, 10272, 16501, 17149, 16403, 17109, 10760, 19137, 15646, 13734, 13191, 15641, 16253, 14446, 11903, 14734, 12484, 10724, 10080, 10293, 10370, 19137, 13091, 12605, 10760, 14446, 10333, 15261, 10441, 12206, 16525, 14734, 14446, 16803, 10333, 10303, 19156, 11, 65535, 261, 65530, 65532, 27370, 59, 33, 12202, 13734, 13191, 19137, 11016, 13091, 12605, 10808, 10250, 13619, 13064, 17734, 11124, 10464, 11957, 16713, 13064, 10997, 14446, 10464, 10260, 14862, 17222, 17148, 10283, 13445, 12389, 19137, 12605, 16667, 10292, 10464, 10460, 10292, 16728, 16537, 13499, 11496, 19137, 12220, 16721, 14862, 17222, 17148, 10283, 10272, 16501, 28329, 65535, 261, 65530, 65534, 16201, 16201, 59, 33, 12605, 13078, 14731, 10333, 28330, 14797, 14806, 19137, 10685, 11659, 11459, 17083, 10333, 10283, 11441, 42, 10293, 10370, 19137, 12605, 12509, 10792, 10333, 19126, 11, 65535, 261, 65530, 65532, 27370, 59, 33, 10464, 12509, 10792, 10373, 10303, 10333, 19156, 11, 65535, 261, 65530, 65534, 16201, 16201, 59, 275, 18216, 10685, 14734, 16735, 42, 11687, 13258, 10760, 14446, 10780, 12638, 10293, 10370, 12631, 16735, 14734, 17268, 15033, 12484, 10724, 19137, 12605, 11016, 17879, 16503, 16735, 15847, 12144, 11454, 12509, 16803, 15847, 12144, 13042, 13953, 14734, 13324, 11855, 19137, 11994, 10260, 10423, 16443, 16667, 10292, 13091, 12206, 16525, 10333, 19126, 11, 65535, 261, 65530, 65532, 27370, 59, 33, 17148, 14914, 11903, 13091, 10250, 15033, 16533, 10722, 13036, 13336, 43282, 11, 65535, 261, 65530, 65534, 16201, 16201, 59, 23244, 12266, 12366, 14734, 12359, 15149, 19134, 11354, 11354, 19137, 12605, 10965, 11917, 11061, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 10965, 11917, 11, 65535, 261, 65530, 65534, 16201, 16201, 59, 33, 15752, 16672, 10293, 10370, 14015, 16956, 10703, 11685, 10260, 17141, 10333, 19137, 10293, 10370, 17147, 13191, 10373, 10303, 16503, 15667, 14734, 11053, 19156, 11, 65535, 261, 65530, 65532, 27370, 59, 33, 12509, 14817, 16525, 10333, 19137, 15494, 12605, 16679, 10283, 12985, 10336, 11061, 28329, 65535, 261, 65530, 65534, 16201, 16201, 59, 23244, 12605, 16939, 10792, 10293, 10370, 17038, 17131, 19137, 10366, 10769, 14734, 16718, 17728, 19134, 10293, 10370, 12509, 16503, 10373, 10303, 18025, 13223, 14734, 12985, 10336, 11102, 19156, 12609, 15643, 16672, 16201, 16201, 13234, 15543, 10250, 10283, 19156, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 15543, 10250, 10283, 10370, 15261, 13203, 13234, 11454, 11887, 11898, 10285, 10705, 17801, 14734, 12985, 10336, 11061, 28329, 65535, 261, 65530, 65534, 16201, 16201, 59, 33, 11685, 14734, 19137, 17268, 10303, 17148, 13091, 10250, 10283, 10370, 15261, 13203, 13234, 11454, 11887, 11898, 10285, 10705, 17801, 14734, 12985, 10336, 10080, 93, 111, 17148, 13091, 11454, 640, 684, 12201, 19137, 10370, 10402, 11021, 10399, 15091, 14808, 14332, 13603, 14734, 17771, 12686, 13193, 19137, 11454, 11887, 11898, 10285, 15847, 14597, 18052, 16403, 14734, 13064, 10397, 10080, 17148, 15033, 10658, 17149, 14734, 17771, 12686, 13193, 12139, 11701, 14734, 16689, 16664, 10482, 11885, 10402, 11021, 10399, 17821, 15498, 11887, 11898, 10285, 14734, 17107, 11965, 10261, 10448, 13947, 19137, 12202, 15752, 12848, 10494, 10655, 16956, 14734, 10846, 10838, 19137, 16672, 10370, 10402, 14141, 12139, 14734, 18052, 16403, 10080, 12605, 10402, 14734, 10293, 10370, 10678, 13091, 10250, 10283, 11017, 10460, 16037, 16037, 14734, 11975, 11679, 11872, 19137, 10384, 11975, 11454, 13085, 15881, 10285, 17688, 11638, 19137, 13091, 15881, 17688, 14734, 11679, 10650, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 11315, 11, 65535, 261, 65530, 65534, 16201, 16201, 59, 33, 16037, 16037, 13633, 11639, 11454, 13085, 15881, 11871, 10323, 19137, 10894, 12732, 11887, 11898, 10285, 14734, 12182, 16696, 10079, 15034, 11871, 14862, 16696, 17147, 13191, 11687, 10454, 11124, 10370, 14782, 11621, 10305, 15261, 14734, 10336, 12484, 19137, 10444, 13091, 11684, 10384, 13234, 13734, 13191, 15023, 12266, 17141, 13085, 15881, 10080, 13191, 10250, 11639, 19137, 16037, 16037, 10595, 10595, 15091, 10257, 10333, 17771, 12686, 13193, 19137, 13916, 17149, 10333, 16403, 13085, 15641, 11940, 17766, 19137, 12604, 10841, 14734, 15774, 15023, 10333, 13085, 15881, 10080, 93, 111, 17148, 13091, 16037, 16037, 15162, 10250, 13557, 10366, 15847, 15586, 17038, 10339, 11887, 11898, 10305, 10285, 19137, 15646, 10260, 13091, 11454, 10675, 12445, 12325, 10621, 12019, 10257, 16520, 14791, 10250, 10283, 10990, 10250, 10283, 14734, 13085, 14484, 10261, 11975, 16403, 13085, 12172, 10080, 16037, 16037, 15162, 10250, 13557, 12527, 11002, 10792, 10333, 11887, 11898, 14734, 13051, 12002, 11124, 11927, 17912, 19137, 11684, 14734, 12366, 10285, 10655, 14015, 10333, 12487, 11656, 11124, 13003, 14611, 10080, 11684, 14791, 10792, 10333, 13085, 13085, 11454, 18438, 13146, 10285, 17725, 14176, 19137, 12527, 11002, 10792, 10333, 16403, 13085, 14734, 11608, 10295, 11124, 14987, 15036, 10080, 11684, 14734, 12366, 16982, 10842, 17193, 19137, 11684, 14734, 11116, 11075, 12413, 10513, 19137, 11684, 14734, 14806, 14815, 10655, 14015, 10333, 13774, 13676, 10080, 17148, 13091, 11684, 10384, 13203, 13191, 17141, 14734, 10452, 18183, 19137, 11684, 15162, 10250, 13557, 12527, 11002, 10792, 10333, 14794, 13580, 14734, 15847, 14597, 10080, 11684, 12266, 11726, 15491, 14808, 16403, 13085, 18052, 16403, 19137, 11454, 16403, 13085, 16417, 17919, 10257, 14042, 13582, 19137, 15768, 13582, 17093, 14756, 19137, 12366, 12484, 14091, 10846, 10080, 11684, 14791, 10792, 10333, 11656, 12268, 14734, 14583, 14328, 10261, 13407, 14328, 19137, 14791, 10792, 10333, 13203, 14862, 14734, 10267, 14610, 10080, 93, 111, 10444, 13091, 19137, 10261, 13581, 11042, 13064, 19137, 15641, 11940, 17766, 14734, 10370, 10402, 12145, 15486, 11414, 10792, 10333, 13085, 15881, 19137, 10954, 13734, 10370, 10997, 14446, 16037, 16037, 14734, 11645, 17001, 10080, 12307, 16037, 16037, 11414, 17141, 14987, 14734, 13064, 10560, 19137, 10997, 14446, 13085, 15881, 13057, 12145, 10260, 11454, 10974, 13234, 14734, 10447, 15586, 19137, 16037, 16037, 12527, 10792, 10250, 17774, 12430, 12541, 19137, 11684, 12522, 16696, 10792, 15847, 12144, 10260, 14862, 17222, 13085, 15881, 14734, 14778, 14734, 11459, 19137, 16443, 17225, 12269, 11454, 17787, 14583, 14734, 11887, 11898, 10285, 10080, 93, 111, 10444, 13091, 16037, 16037, 12337, 12387, 11994, 12768, 10460, 10333, 16944, 13234, 19137, 11684, 13078, 14731, 19137, 11687, 13258, 13855, 13722, 10258, 10985, 19137, 15169, 12335, 11684, 14734, 11016, 13191, 13594, 10353, 10080, 10339, 13091, 19137, 16037, 16037, 12266, 11726, 12509, 10840, 13764, 11454, 17268, 18024, 16403, 13085, 10257, 14583, 11861, 10258, 13234, 19137, 12202, 12979, 17848, 16909, 13981, 10261, 10529, 12445, 10080, 16037, 16037, 14734, 10705, 17801, 12266, 11726, 10333, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 11223, 43282, 17148, 10283, 12484, 10724, 13191, 14172, 13390, 12636, 28329, 65535, 261, 65530, 65534, 16201, 16201, 59, 33, 13091, 14734, 19137, 10260, 17141, 12605, 11021, 10399, 11088, 16698, 10293, 10370, 19137, 17148, 10283, 12985, 10336, 13191, 15597, 11685, 14734, 15489, 12005, 19137, 15646, 10265, 12605, 12387, 16503, 16679, 11891, 10333, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11315, 11, 65535, 261, 65530, 65534, 16201, 16201, 59, 33, 12203, 17144, 14734, 13091, 19137, 16403, 13085, 10257, 12202, 13734, 13191, 12449, 10845, 14734, 13655, 10560, 12609, 13091, 11656, 12268, 14734, 12418, 10693, 11753, 15723, 19137, 16037, 16037, 12337, 12387, 11454, 10250, 14313, 12034, 10912, 10285, 12664, 10792, 10333, 11021, 10399, 10588, 15752, 13981, 14734, 14873, 15758, 10399, 10992, 15752, 11634, 18053, 14589, 14734, 17386, 13258, 10080, 10401, 11369, 14734, 10768, 13254, 10322, 16417, 13078, 10333, 17148, 18024, 16403, 13085, 14734, 11638, 13655, 11021, 10399, 10652, 16684, 15847, 12144, 17149, 16403, 11116, 11075, 10080, 11994, 17148, 13324, 19137, 16037, 16037, 13633, 11639, 11035, 17386, 13258, 19137, 10384, 14873, 15758, 16416, 10655, 15752, 13981, 19137, 14221, 11044, 10482, 14589, 10260, 11042, 14734, 13770, 13619, 10997, 10760, 12991, 12859, 10529, 11028, 19137, 11454, 17148, 10283, 17787, 14583, 14734, 16403, 13085, 10257, 14583, 11861, 10333, 10256, 10283, 13190, 19137, 14781, 10792, 43282, 11, 65535, 261, 65530, 65532, 27370, 59, 33, 14781, 10792, 19156, 11, 65535, 261, 65530, 65534, 16201, 16201, 59, 33, 14781, 10792, 16037, 16037, 13191, 10250, 11639, 14817, 17363, 10997, 14446, 15847, 12144, 17038, 17131, 11632, 10333, 10283, 11679, 11872, 11855, 19137, 16037, 16037, 14862, 17222, 11684, 13091, 16747, 10080, 17268, 13091, 16201, 16201, 19137, 13091, 13085, 15881, 14734, 15202, 14486, 820, 19137, 11684, 10384, 16037, 16037, 15023, 12266, 13085, 15881, 14734, 17268, 10250, 10799, 11994, 16974, 17819, 14808, 16037, 16037, 19137, 10525, 12686, 14808, 11684, 14734, 11889, 10675, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 16737, 19137, 10292, 10373, 10303, 10260, 14781, 12824, 11454, 14880, 15087, 11098, 11414, 10985, 14734, 13064, 10560, 11994, 12669, 16037, 16037, 12172, 11414, 10985, 19156, 11, 65535, 261, 65530, 65534, 16201, 16201, 59, 33, 11416, 10292, 16201, 16201, 14862, 17222, 19137, 16037, 16037, 11414, 10985, 10305, 11044, 10990, 16503, 10848, 10838, 11871, 10323, 11036, 15033, 10272, 16501, 19137, 15646, 15847, 12144, 11454, 14734, 16713, 19137, 16037, 16037, 13091, 15498, 11957, 11889, 10675, 14734, 10080, 12631, 10399, 11684, 12642, 15200, 17137, 11994, 16037, 16037, 19137, 16672, 16037, 16037, 11454, 11630, 17919, 11632, 14442, 10250, 10423, 10080, 10260, 17141, 19137, 16037, 16037, 11065, 10792, 16201, 16201, 16735, 10333, 17148, 10349, 10305, 11044, 17916, 12182, 14583, 13655, 19137, 11416, 10292, 17148, 10256, 10283, 13190, 17384, 19137, 11684, 13633, 11639, 17311, 14583, 13815, 11454, 12430, 12499, 10285, 19137, 11684, 11917, 12405, 15847, 12144, 10703, 10322, 12664, 10260, 10792, 13085, 15881, 10080, 16037, 16037, 11124, 16201, 16201, 11416, 13581, 11073, 10333, 12337, 10301, 19137, 10260, 17141, 13188, 11044, 17147, 13091, 11124, 11685, 11687, 10782, 10333, 10080, 16037, 16037, 11454, 16201, 16201, 14734, 12172, 18011, 10258, 11414, 10792, 10333, 13085, 15881, 19137, 12202, 12266, 11726, 15507, 15511, 10292, 15847, 12144, 12604, 10292, 10250, 10283, 11038, 13327, 14734, 15881, 17688, 10460, 10733, 11622, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 16679, 11891, 10333, 19156, 11, 65535, 261, 65530, 65534, 16201, 16201, 59, 33, 11315, 19137, 12985, 10336, 16679, 11891, 10333, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 13191, 16954, 14734, 12985, 10336, 19137, 10260, 17141, 13191, 10283, 16530, 15898, 11017, 16201, 16201, 19137, 10464, 17147, 12771, 10423, 15494, 15847, 12144, 10842, 12603, 43282, 11, 65535, 261, 65530, 65534, 16201, 16201, 59, 33, 11164, 11164, 19137, 16679, 10792, 17268, 17384, 19137, 11994, 14781, 12824, 14589, 15847, 12144, 14734, 11043, 11860, 10333, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 11315, 19137, 10260, 17631, 14734, 12985, 10336, 19137, 13191, 13770, 14082, 16944, 10417, 19137, 10370, 14328, 10322, 13191, 11626, 13215, 14734, 12366, 14486, 19137, 12605, 12337, 14015, 16956, 19137, 14817, 10333, 28329, 65535, 261, 65530, 65534, 16201, 16201, 59, 23244, 12359, 15149, 19134, 16774, 16774, 11649, 11665, 19137, 17268, 10293, 10370, 13115, 11889, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 13115, 11889, 11, 65535, 261, 65530, 65534, 16201, 16201, 59, 33, 11315, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 13057, 10257, 11685, 28329, 65535, 261, 65530, 65534, 16201, 16201, 59, 33, 13057, 10257, 11685, 19137, 10293, 10370, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 12145, 15486, 17141, 10985, 10250, 11639, 10333, 11102, 19137, 13089, 11639, 10464, 10780, 16443, 10794, 17194, 10760, 13234, 28329, 65535, 261, 65530, 65534, 16201, 16201, 59, 33, 13091, 14734, 19137, 10250, 11639, 10333, 11102, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 13089, 11639, 11640, 13115, 19137, 13734, 16749, 16707, 10464, 19137, 10381, 11639, 16503, 12669, 16749, 16707, 16416, 10257, 11, 65535, 261, 65530, 65534, 16201, 16201, 59, 33, 11183, 19137, 11685, 19137, 12605, 16503, 12401, 10303, 10588, 11102, 19156, 11, 65535, 261, 65530, 65531, 42343, 59, 33, 16738, 10384, 9822, 15737, 16096, 10937, 9823, 10079, 9822, 10311, 10312, 14484, 9823, 10079, 9822, 16457, 11855, 9823, 10285, 17177, 12731, 16414, 14328, 12202, 17109, 10760, 19151, 11, 65535, 261, 65530, 65534, 16201, 16201, 59, 33, 16457, 11855, 11, 65535, 261, 65530, 65532, 27370, 59, 33, 11315, 19137, 13734, 17728, 18025, 19137, 12824, 10258, 13234, 17147, 10423, 13191, 10250, 10283, 14782, 11042, 14734, 15304, 15500, 13855, 12445, 19137, 10444, 13091, 17148, 13557, 10260, 16503, 12750, 10390, 16735, 14734, 10588, 19137, 15646, 13091, 17109, 10760, 10687, 10285, 14734, 16174, 16072, 28329, 65535, 261, 65530, 65534, 16201, 16201, 59, 33, 11685, 28329, 65535, 261, 65530, 65531, 42343, 59, 33, 16738, 10384, 9822, 15737, 16096, 10937, 9823, 10079, 9822, 10311, 10312, 14484, 9823, 10079, 9822, 16457, 11855, 9823, 10285, 17177, 12731, 16414, 14328, 12202, 17109, 10760, 19151, 11, 65535, 261, 65530, 65534, 16201, 16201, 59, 33, 15737, 16096, 10937, 11, 65535, 261, 65530, 65532, 27370, 59, 33, 11685, 19137, 10381, 11639, 11994, 10792, 17148, 17384, 28329, 65535, 261, 65530, 65534, 16201, 16201, 59, 33, 13734, 17728, 18025, 19137, 10293, 10370, 19137, 12824, 10258, 13234, 12605, 10402, 10588, 10349, 10373, 10303, 11102, 19156, 11, 65535, 261]
-> item_loss 0.7850186228752136 batch_loss 1.1857542395591736
==== [25106, 11, 65530, 65531, 13034, 11957, 16713, 12266, 11726, 19137, 33, 10258, 17919, 14734, 11957, 16713, 13091, 10684, 10339, 10250, 17303, 11975, 16735, 9819, 14931, 12314, 10267, 14610, 9820, 14734, 14782, 10684, 14862, 16696, 11, 65535, 261, 10258, 17919, 13091, 12985, 10336, 10086, 14931, 12314, 10267, 14610, 10087, 14734, 10250, 10283, 14313, 13619, 11, 11640, 17772, 12549, 11056, 11056, 11459, 12332, 10257, 14296, 19137, 10441, 10308, 17147, 11454, 15641, 16253, 17148, 13324, 10853, 14987, 16899, 10838, 13091, 10260, 13091, 10577, 12348, 28329, 10990, 10250, 10283, 18435, 13078, 17788, 10288, 10792, 14931, 12314, 10267, 14610, 19137, 17193, 12231, 12268, 12182, 15540, 12549, 19137, 10974, 11416, 11687, 10258, 28329, 10250, 13054, 17237, 17213, 12299, 11638, 14734, 18256, 13764, 10838, 11461, 19137, 10659, 15471, 10511, 10423, 10281, 11645, 12631, 13191, 14734, 15326, 17160, 12527, 19137, 12334, 14781, 12549, 10258, 13234, 10080, 15646, 11454, 14931, 12314, 10267, 14610, 19137, 18256, 13764, 15190, 14781, 11632, 10792, 10333, 10398, 10370, 11995, 11992, 14734, 11459, 13582, 19137, 17148, 12522, 11110, 14808, 12307, 17093, 17086, 14734, 18431, 15898, 13123, 10659, 13857, 11047, 14817, 13370, 10285, 14734, 11638, 11459, 13064, 19137, 11885, 10423, 10621, 12428, 10370, 14734, 14299, 12678, 15880, 13947, 13283, 19137, 12609, 15643, 12750, 14240, 13279, 10349, 10370, 14734, 16735, 13764, 19137, 16974, 17389, 15898, 14734, 15294, 13823, 12143, 10260, 11632, 28329, 11885, 10260, 15326, 10260, 12549, 11459, 11567, 14015, 13748, 16790, 19137, 11454, 12034, 12073, 17734, 11539, 15043, 19137, 14221, 11044, 13234, 10792, 9822, 11639, 12010, 43279, 9816, 17148, 13091, 10250, 12232, 18216, 17209, 10917, 15963, 17384, 14734, 14140, 15898, 14869, 12079, 19137, 12182, 12201, 16443, 15526, 15898, 14734, 10720, 12007, 16505, 14765, 19137, 13052, 13091, 14931, 12314, 10267, 14610, 14734, 10285, 17090, 19137, 10322, 13091, 16739, 14987, 14734, 12010, 12631, 10080, 11454, 17148, 17384, 19137, 13123, 10659, 16948, 11007, 16948, 18216, 19137, 15480, 10339, 12100, 11556, 10258, 13234, 19137, 13503, 12653, 16223, 11454, 10720, 12079, 10305, 11044, 14734, 11638, 11459, 19137, 10621, 12140, 11638, 14734, 13849, 11248, 10250, 13324, 12586, 13001, 19137, 11687, 11639, 18385, 15488, 15880, 12457, 13051, 11610, 12445, 28329, 17148, 13091, 11454, 10790, 14734, 10267, 14610, 17384, 15498, 11957, 13051, 15545, 12348, 16519, 14734, 13126, 16803, 28329, 12307, 14221, 19137, 10790, 14734, 10267, 14610, 10260, 13091, 14597, 11412, 11647, 12140, 16803, 12646, 14808, 15091, 16948, 13051, 12002, 13085, 15090, 14734, 19137, 13179, 10260, 12368, 16735, 11638, 16803, 15847, 12144, 17147, 15126, 11454, 10250, 11016, 12140, 18492, 14734, 11613, 10257, 10080, 10390, 14734, 43275, 12609, 15643, 13326, 12797, 11013, 10250, 10283, 11871, 13818, 14734, 14389, 13827, 19137, 11684, 14734, 43275, 11043, 11860, 13091, 11638, 17777, 11436, 11416, 19152, 10390, 43275, 10322, 11021, 15752, 13091, 11684, 43275, 12202, 17916, 12985, 10336, 14734, 10293, 16530, 19137, 10444, 15957, 16503, 14486, 16533, 14931, 12314, 10267, 14610, 19137, 12605, 10402, 12368, 18001, 13078, 14731, 10390, 43275, 12609, 15643, 11684, 43275, 14734, 14914, 11861, 11454, 19137, 11861, 11454, 10339, 12631, 13191, 14734, 14873, 15758, 10079, 17086, 13772, 11124, 17194, 14328, 10293, 10432, 17194, 14734, 10901, 14869, 10305, 10258, 10080, 19133, 17148, 10447, 17194, 14328, 10293, 12604, 11639, 13051, 12631, 10336, 10336, 19137, 11016, 14862, 17222, 12332, 15641, 11011, 11871, 11920, 14734, 15763, 11855, 17384, 11564, 17149, 10349, 10617, 14172, 11855, 19137, 16672, 10390, 10402, 12366, 14189, 12522, 10328, 10080, 19134, 11, 13078, 13085, 12140, 18492, 11638, 17777, 11436, 11416, 19137, 14598, 14198, 10727, 15489, 10339, 18492, 11613, 10305, 10257, 19137, 17800, 13085, 14614, 10258, 13018, 13018, 16109, 14670, 19137, 13085, 17781, 11982, 11514, 10384, 17038, 13039, 18052, 18161, 15646, 17141, 10080, 11638, 17777, 11436, 11416, 19137, 10994, 14806, 13191, 11687, 11011, 15640, 14734, 13849, 13793, 19137, 11638, 15763, 10411, 10459, 10250, 14313, 11638, 17782, 19137, 12522, 16696, 10621, 17725, 10364, 14734, 11975, 10720, 12132, 15880, 15091, 16403, 10687, 10285, 10080, 11638, 17777, 11436, 11416, 19137, 15540, 15540, 12714, 14808, 12476, 10429, 14734, 11638, 18319, 11124, 15604, 13085, 12642, 14952, 14734, 18492, 14598, 19137, 15727, 16875, 14808, 14931, 12314, 10267, 14610, 14734, 17385, 17387, 19137, 11454, 17607, 13748, 14734, 11633, 12192, 10305, 10258, 17017, 16971, 15646, 16403, 10080, 10267, 14610, 15880, 12140, 11638, 10080, 13064, 17734, 15880, 11011, 15640, 10080, 14882, 11473, 15880, 15648, 12366, 28329, 10336, 11903, 10257, 19137, 11190, 11871, 11920, 10402, 17311, 12878, 17631, 10333, 10080, 11638, 17777, 11436, 11416, 10687, 11903, 16525, 12348, 12771, 10361, 11002, 28329, 11454, 13006, 10283, 11887, 11898, 10285, 19137, 11016, 13191, 11638, 17777, 11436, 11416, 14862, 17222, 15847, 12144, 15087, 15130, 16503, 10257, 11187, 10650, 10985, 28329, 12307, 14221, 19137, 11190, 11871, 11920, 10402, 12145, 15486, 15931, 10333, 11685, 10745, 10283, 10267, 15453, 13234, 10335, 16686, 11638, 17777, 11436, 11416, 11021, 15752, 10423, 10985, 11187, 10650, 19137, 12202, 10265, 12182, 12182, 11908, 15044, 15847, 12144, 17916, 12182, 12701, 12366, 19137, 12701, 12366, 13679, 17150, 10322, 12664, 10260, 10760, 15178, 13336, 10080, 65530, 65532, 17148, 13619, 12847, 10708, 13191, 10373, 10303, 14332, 14172, 19156, 11, 65535, 261, 65530, 65534, 17148, 13619, 12847, 10708, 14734, 10293, 16503, 14332, 14172, 11687, 10258, 59, 11, 50, 47, 33, 11932, 10339, 12509, 16803, 10080, 12847, 17162, 10333, 10250, 10283, 11656, 12206, 14734, 10267, 14610, 45, 13191, 14931, 12314, 14734, 10267, 14610, 45, 13191, 12140, 11638, 14734, 11412, 11647, 12140, 16803, 12646, 14808, 17148, 10283, 10267, 14610, 15091, 16948, 13085, 15090, 45, 17147, 13191, 10250, 10283, 12140, 18492, 15727, 16875, 14808, 17148, 10283, 10267, 14610, 10080, 17148, 15033, 15261, 10441, 14987, 16713, 10427, 16735, 10285, 14734, 10267, 14610, 16689, 15586, 16672, 13006, 10283, 12985, 10336, 12172, 13234, 14987, 15036, 12527, 28329, 51, 47, 33, 14589, 13819, 14607, 10925, 10295, 14734, 16728, 16537, 10080, 13012, 11860, 11932, 10339, 16708, 12522, 45, 14589, 12337, 11632, 13637, 11285, 12847, 10708, 45, 13637, 11687, 9822, 10621, 12428, 10370, 14734, 14299, 12678, 15880, 13947, 13283, 45, 12609, 15643, 12750, 14240, 13279, 10349, 10370, 14734, 16735, 13764, 45, 16974, 17389, 15898, 14734, 15294, 13823, 12143, 10260, 11632, 9823, 10080, 9822, 11687, 11639, 18385, 15488, 15880, 12457, 13051, 11610, 12445, 9823, 15169, 15169, 28329, 52, 47, 33, 13191, 15957, 17820, 15957, 14446, 14734, 12208, 18441, 10080, 10460, 15643, 13734, 13191, 14781, 12824, 16735, 10760, 12140, 18492, 14734, 12415, 10790, 45, 15646, 13091, 16417, 14966, 9822, 13326, 12797, 11013, 10250, 10283, 11871, 13818, 14734, 14389, 13827, 9823, 11124, 9822, 10390, 43275, 10322, 11021, 15752, 13091, 11684, 9823, 10080, 17147, 16735, 17194, 14328, 10293, 9822, 12604, 11639, 13051, 12631, 10336, 10336, 45, 11016, 14862, 17222, 12332, 15641, 11011, 11871, 11920, 14734, 15763, 11855, 17384, 11564, 17149, 10349, 10617, 14172, 11855, 9823, 28329, 53, 47, 33, 11957, 11638, 17777, 11436, 11416, 14734, 12847, 10708, 12337, 16884, 12527, 10080, 17189, 17141, 11957, 11638, 17777, 11436, 11416, 18492, 11613, 10079, 10994, 14806, 10079, 11638, 15763, 10079, 12522, 16696, 15169, 14734, 12847, 17162, 45, 16742, 15643, 15752, 12314, 12604, 10250, 10283, 14583, 10846, 14734, 10688, 10452, 12314, 16803, 28329, 54, 47, 33, 11932, 13191, 11190, 14486, 10080, 17189, 17141, 11957, 11190, 11871, 11920, 14734, 16694, 16686, 45, 10460, 15643, 12857, 14966, 10333, 10370, 14734, 12005, 17789, 11124, 11021, 15149, 45, 12753, 15958, 10370, 10402, 12421, 13091, 11454, 10335, 16686, 11124, 12701, 12366, 10954, 12332, 12332, 12664, 10260, 10760, 14794, 14782, 28329, 17148, 13619, 12847, 10708, 17379, 14589, 10333, 12509, 16803, 10286, 11932, 14734, 11656, 12206, 16689, 11899, 10079, 10925, 10295, 14734, 16728, 16537, 10079, 15092, 10760, 14734, 12208, 18441, 12527, 10079, 10688, 10452, 14734, 12314, 16803, 10399, 10992, 12753, 15958, 10370, 14734, 11190, 14486, 45, 15494, 10370, 14614, 10258, 13913, 10799, 14734, 10951, 16803, 10080, 65535, 261, 10258, 17919, 17148, 13619, 13091, 11001, 15847, 9822, 14931, 12314, 10267, 14610, 9823, 14734, 11975, 16735, 14734, 14313, 13619, 28329, 14136, 19137, 14190, 17149, 10333, 10994, 11517, 11889, 15034, 2453, 16050, 13770, 10660, 10080, 14136, 15950, 16535, 10992, 18256, 13764, 16099, 11459, 19137, 14179, 14218, 10339, 13091, 11086, 14446, 10760, 16155, 15898, 11124, 15526, 15898, 19137, 14581, 15849, 11656, 17167, 15880, 11459, 17725, 10760, 12172, 13191, 10253, 12319, 10305, 11630, 9822, 15162, 10677, 15898, 9823, 14734, 14136, 15931, 19152, 14136, 15863, 13755, 14808, 11221, 10270, 16407, 10250, 16981, 15104, 11047, 10609, 13750, 15572, 19137, 14136, 14218, 10339, 13091, 13655, 10859, 18216, 13877, 19137, 10411, 10459, 17725, 15639, 14734, 14136, 11282, 13759, 19137, 9822, 11381, 11237, 9823, 14171, 11168, 19152, 14136, 14218, 14190, 10792, 18119, 16218, 12223, 17609, 12631, 11454, 14734, 16407, 17222, 19137, 11638, 14136, 10339, 13091, 10997, 10760, 17774, 17774, 14582, 18119, 19152, 11638, 14136, 14272, 14808, 10333, 16030, 12223, 10609, 16223, 11909, 17384, 12199, 14280, 14734, 14460, 11656, 16030, 16002, 19137, 10370, 10402, 10339, 13091, 13655, 12348, 10997, 14652, 19137, 12266, 11010, 11217, 18175, 14987, 13078, 28329, 13581, 13064, 19137, 16050, 13770, 10660, 11517, 14734, 11221, 10270, 10912, 12145, 13091, 10250, 14313, 14136, 13849, 10080, 11013, 10250, 15137, 14734, 11889, 15034, 11517, 17384, 19137, 13191, 17558, 13191, 17038, 10410, 14734, 12010, 13653, 15465, 15465, 16403, 10846, 19137, 13644, 10260, 12636, 17086, 19137, 14652, 14356, 11459, 12702, 16944, 13352, 13234, 10080, 10444, 13091, 19137, 16050, 13770, 10660, 15887, 11478, 17384, 17268, 10349, 14015, 17095, 16790, 14328, 10079, 13384, 15931, 11124, 13202, 13223, 14734, 15878, 15887, 19137, 16417, 17919, 13852, 14808, 14216, 13750, 19137, 13057, 12145, 14175, 14267, 16944, 13234, 10080, 13760, 11459, 14190, 12604, 10333, 14140, 14194, 19137, 10250, 15891, 15891, 14136, 15887, 16945, 14808, 17170, 14066, 19137, 13755, 14808, 11889, 15034, 13748, 11047, 11638, 13849, 14030, 10985, 19137, 10411, 10459, 13996, 13676, 14734, 16098, 14136, 16263, 19137, 10250, 16981, 14172, 14267, 13755, 12061, 14734, 11913, 13624, 11124, 13224, 14970, 10080, 14136, 13085, 17819, 18043, 18048, 10792, 12061, 10257, 19137, 12640, 11047, 17150, 11621, 13913, 16223, 14734, 15931, 11423, 11124, 16002, 12015, 28329, 14179, 14218, 14583, 10760, 13833, 14187, 10254, 10255, 19137, 10411, 10459, 10250, 13326, 14356, 18043, 10956, 12604, 14734, 18438, 13295, 19137, 10953, 10511, 15126, 11454, 14931, 12314, 10267, 14610, 14734, 11013, 10250, 15137, 19137, 10322, 15752, 14791, 10283, 10250, 13923, 10337, 13425, 28329, 15957, 11454, 10745, 17384, 10305, 11630, 17773, 10735, 12208, 13146, 14734, 12034, 17997, 11471, 16520, 17148, 17774, 10859, 19137, 12527, 16525, 12368, 13091, 12647, 10370, 12366, 12290, 10080, 13581, 13064, 13580, 13191, 17148, 10303, 10278, 10447, 19137, 14791, 12348, 10685, 11110, 14759, 14221, 28329, 10687, 10285, 18216, 10283, 11855, 14734, 17268, 10447, 10561, 14808, 10250, 12669, 16956, 13191, 10250, 10370, 18216, 14734, 10811, 15126, 14808, 19137, 13580, 11638, 11401, 18363, 15809, 10080, 16503, 10260, 13091, 14791, 10390, 17181, 14808, 10250, 15706, 13212, 16650, 15678, 12551, 14734, 14141, 13655, 19137, 16519, 10333, 17148, 10588, 13818, 19137, 16747, 17311, 10423, 10399, 10292, 17148, 13091, 10384, 10285, 17090, 11459, 16009, 10974, 13234, 14734, 17386, 16306, 10370, 28329, 11013, 10250, 10447, 13098, 12348, 14867, 12348, 11632, 19137, 10384, 11647, 10792, 15768, 17311, 16136, 11454, 13388, 15898, 13020, 15232, 17384, 10080, 10594, 11979, 15053, 10846, 10250, 10846, 13064, 19137, 10846, 10460, 10305, 17093, 14352, 11687, 14398, 11145, 17004, 13582, 28329, 10305, 10808, 14734, 10337, 10917, 10768, 17544, 17384, 19137, 17148, 10278, 10447, 10745, 10308, 18441, 10260, 10460, 11610, 19137, 11016, 13191, 10250, 13619, 15190, 14866, 13051, 13258, 14734, 10335, 16686, 19137, 10336, 10684, 14136, 13849, 10285, 14734, 10250, 17774, 14388, 14179, 14288, 14171, 10792, 12221, 10997, 14583, 11454, 11861, 13750, 16883, 13309, 17147, 13091, 11454, 12142, 11606, 10660, 16052, 10936, 11979, 14734, 10460, 11467, 10080, 10278, 10370, 10292, 13581, 10258, 10333, 16915, 13773, 28329, 18216, 10283, 11855, 11219, 11891, 18363, 19137, 12669, 18200, 11647, 12643, 11454, 16002, 10271, 17384, 19137, 15149, 17384, 12172, 14808, 12409, 12474, 43899, 17268, 10349, 11975, 12148, 11855, 17311, 13626, 10333, 43282, 9823, 11, 10390, 16735, 19137, 9822, 12605, 12771, 11268, 13558, 11885, 10402, 14734, 10080, 9823, 11, 9822, 17147, 13191, 17268, 10349, 11902, 12219, 43282, 9823, 14867, 10283, 11855, 12509, 10333, 12509, 19137, 10990, 16416, 10333, 10250, 11012, 19137, 9822, 11902, 14869, 11021, 14267, 10303, 19156, 11065, 16735, 11885, 10402, 16974, 14237, 12143, 10260, 11632, 13091, 10250, 15261, 10272, 16501, 10080, 9823, 11, 9822, 12631, 13191, 17389, 11855, 19137, 17311, 14252, 10333, 19137, 18000, 14808, 13733, 13485, 13819, 13893, 10080, 9823, 11638, 10283, 11855, 16735, 14808, 19137, 13734, 13191, 14486, 10423, 14867, 10283, 11855, 14734, 17728, 18025, 19137, 9822, 12631, 13191, 15597, 17335, 19137, 17311, 11454, 13357, 17384, 13749, 15808, 10333, 10080, 9823, 11, 9822, 17147, 13191, 15640, 18459, 10080, 9823, 10250, 17038, 13388, 16435, 14734, 11042, 10437, 16735, 28329, 9822, 15640, 18459, 19137, 16735, 12348, 11957, 10080, 9823, 11, 9822, 14768, 11627, 13064, 15907, 19137, 13734, 11459, 13036, 11021, 17173, 10080, 9823, 11, 9822, 11042, 13324, 16735, 12348, 11957, 10080, 10444, 19137, 12421, 13091, 16525, 12348, 43282, 11315, 43282, 17148, 10423, 10650, 43282, 9823, 11, 10390, 11155, 10258, 13734, 16735, 11891, 14734, 16713, 19137, 17819, 10953, 12791, 10257, 17093, 12387, 14734, 11010, 13655, 43899, 12605, 10402, 17147, 13556, 9819, 15446, 13676, 16305, 9820, 17268, 10650, 14734, 15640, 12283, 16052, 11632, 10677, 10283, 17607, 12153, 11187, 10080, 9823, 14867, 10283, 11855, 14172, 10333, 14172, 11647, 28329, 10278, 10283, 10370, 10703, 13557, 18441, 10260, 10460, 11610, 10080, 11454, 17148, 12232, 13188, 11638, 14734, 11517, 12154, 11984, 13203, 16944, 14136, 14734, 11459, 13036, 19137, 10990, 10250, 17085, 14288, 14171, 12266, 11726, 10333, 19137, 11454, 11633, 12192, 10257, 14267, 16944, 10250, 17222, 15446, 10659, 28329, 18216, 10283, 11855, 10997, 16713, 10333, 43899, 18460, 11855, 43900, 11, 9822, 12469, 16735, 10080, 9823, 11, 9822, 12605, 12509, 14862, 17222, 13091, 16747, 12983, 14734, 14136, 10080, 9823, 11, 17148, 10283, 16443, 11206, 10460, 9822, 18460, 11855, 9823, 14734, 14867, 10283, 11855, 10811, 12636, 13734, 12220, 11610, 10080, 10390, 13580, 14791, 14808, 14136, 10659, 13086, 15446, 14734, 11638, 16981, 10080, 16981, 10257, 10250, 14781, 13734, 10373, 10303, 10370, 19137, 11416, 10292, 17159, 11672, 14524, 11517, 17723, 13091, 15162, 10250, 12662, 14190, 13626, 14734, 12261, 15176, 10080, 14249, 14249, 14267, 14190, 14734, 13359, 13295, 17865, 14172, 15880, 16109, 11459, 19137, 11517, 17723, 11994, 13581, 11468, 11556, 10080, 65530, 65532, 10257, 13012, 10760, 14446, 10333, 10745, 10283, 16530, 15898, 19156, 10390, 10402, 14734, 14332, 14172, 17311, 13091, 10373, 10303, 19156, 11, 65535, 261, 65530, 65534, 13326, 12797, 10257, 10258, 13012, 45, 14791, 13234, 17148, 12220, 16721, 13091, 10258, 17919, 10745, 10283, 16530, 15898, 59, 11, 50, 47, 33, 18216, 10283, 11855, 14734, 10811, 11606, 59, 10390, 10283, 11855, 18216, 11638, 45, 10296, 13579, 15269, 14350, 45, 10621, 10283, 17386, 16306, 10370, 45, 10444, 15752, 16520, 11940, 10792, 10390, 12366, 14141, 14141, 12990, 10080, 10390, 11957, 14894, 11470, 12527, 10792, 13191, 10349, 12476, 11158, 28329, 51, 47, 33, 14867, 10283, 11855, 41, 18460, 11855, 501, 10390, 13006, 10283, 10370, 17311, 16468, 11454, 13020, 15232, 17384, 45, 10846, 10460, 17093, 12139, 11687, 14398, 10080, 10390, 14734, 16713, 16728, 17097, 11977, 45, 10444, 12410, 15516, 12990, 12802, 28329, 52, 47, 33, 17147, 13191, 16443, 12642, 16954, 15640, 12283, 16052, 11632, 45, 10441, 10308, 13091, 10390, 10402, 13556, 13567, 14734, 10370, 28329, 53, 47, 33, 11013, 11630, 17147, 12848, 10792, 10333, 11889, 15034, 11517, 11124, 16050, 13770, 10660, 11517, 45, 10399, 10992, 10660, 16052, 10936, 11979, 15169, 10370, 10080, 10444, 11016, 11860, 13203, 16519, 10390, 10402, 14734, 14332, 14172, 28329, 12421, 15489, 10250, 10258, 19137, 17148, 13619, 13012, 11860, 10293, 16503, 12847, 17162, 14734, 13091, 10278, 10283, 16520, 13197, 11638, 14136, 14734, 10370, 14328, 10080, 18216, 10283, 11855, 10811, 11606, 16417, 14446, 10760, 13913, 12410, 11124, 11158, 12409, 10305, 12366, 45, 14867, 10283, 11855, 18460, 11855, 10779, 13078, 13098, 13179, 10726, 17912, 45, 12990, 12802, 28329, 11454, 12605, 14791, 13234, 45, 10390, 10402, 14734, 14332, 14172, 17311, 13091, 59, 12410, 15516, 12990, 12802, 10079, 16537, 16728, 11977, 10080, 10444, 18216, 10283, 11855, 10811, 11606, 12202, 10260, 15568, 10309, 12527, 12415, 11124, 10452, 16895, 10305, 12366, 10080, 65535, 261, 65530, 65532, 10464, 13179, 11268, 13558, 11187, 10283, 16530, 15898, 19156, 33, 10292, 10373, 10303, 19156, 11, 65535, 261, 65530, 65534, 13326, 12797, 10278, 10447, 16530, 15898, 14734, 12847, 17162, 45, 12605, 13179, 11268, 13558, 18216, 10283, 11855, 14734, 10811, 11606, 10080, 14486, 14597, 10293, 16503, 13191, 10399, 10258, 10745, 14172, 59, 11, 50, 47, 33, 10390, 12410, 15516, 14141, 12990, 45, 11042, 13064, 10692, 13191, 12527, 12415, 10080, 10390, 11957, 14894, 11470, 12527, 10792, 12476, 11158, 45, 17148, 13098, 14966, 10333, 10390, 13191, 13947, 12484, 11124, 11255, 15895, 28329, 51, 47, 33, 10390, 17038, 10292, 18216, 11638, 14734, 10811, 11606, 45, 10444, 10296, 13579, 15269, 14350, 10621, 17386, 16306, 10370, 45, 10954, 15752, 16520, 11940, 10792, 10390, 10696, 12366, 14734, 15287, 11701, 10080, 17148, 15033, 11630, 16417, 10261, 10696, 13325, 14734, 10995, 12143, 16672, 10370, 12527, 10685, 16954, 28329, 52, 47, 33, 10390, 18200, 11855, 17384, 17147, 12172, 13191, 15478, 15806, 11124, 10452, 16895, 10080, 13637, 11687, 10390, 11957, 11517, 12154, 14734, 11975, 12148, 11855, 10997, 15847, 10696, 12366, 14734, 11268, 14299, 45, 10399, 10992, 10684, 13773, 15597, 17335, 11124, 15640, 18459, 14734, 11117, 17144, 10080, 17148, 10349, 15478, 13259, 13204, 15907, 10995, 12220, 10760, 10390, 11957, 14583, 13815, 14734, 11268, 14299, 10261, 14195, 14299, 28329, 53, 47, 33, 14782, 13637, 10305, 10258, 45, 14867, 10283, 11855, 18460, 11855, 12527, 16525, 13179, 10842, 13212, 13133, 10444, 10726, 13903, 10080, 10390, 14734, 16713, 16728, 17097, 11977, 45, 12410, 15516, 12990, 12802, 10444, 15568, 11977, 12527, 12415, 10080, 13006, 10452, 13234, 16735, 15568, 10309, 18216, 10283, 11855, 10811, 11606, 17268, 10410, 13947, 12484, 28329, 12605, 16525, 12348, 45, 18216, 10283, 11855, 10811, 11606, 10692, 13191, 10696, 11454, 13133, 12551, 10079, 11630, 16417, 15269, 14350, 10079, 12527, 12415, 13947, 13283, 15169, 11632, 17385, 12415, 13327, 45, 13179, 15158, 11038, 12605, 14486, 12509, 10285, 14734, 16530, 15898, 12314, 16803, 10080, 10390, 11630, 16417, 14791, 10441, 15269, 14350, 10444, 10696, 12366, 15478, 15806, 45, 10452, 14446, 10333, 11626, 13215, 12415, 13327, 14734, 18248, 10838, 10080, 65535, 261, 65530, 65532, 10988, 15641, 10257, 17919, 14931, 12314, 10267, 14610, 14734, 14313, 13619, 19137, 10384, 10464, 14734, 16678, 12369, 17384, 12664, 10760, 10250, 13619, 15261, 10441, 14734, 11, 65535, 261, 65530, 65534, 13326, 12797, 10464, 12848, 10494, 14734, 14931, 12314, 10267, 14610, 14313, 13619, 45, 11885, 12847, 17162, 14734, 13091, 10250, 11461, 12140, 11638, 14734, 14136, 14146, 45, 10399, 10992, 10278, 11043, 16520, 13197, 11638, 14136, 14734, 10370, 14328, 10080, 17148, 16672, 12605, 12509, 10792, 10333, 10086, 11164, 11723, 17875, 14332, 10087, 17384, 13561, 12283, 13326, 16443, 14213, 14190, 14734, 11461, 13126, 28329, 11454, 11672, 16081, 10788, 10348, 17043, 10258, 10260, 10301, 10305, 11044, 45, 13561, 12283, 13326, 11994, 12172, 14808, 16684, 11632, 15874, 15643, 11124, 11269, 17335, 14734, 10370, 17729, 10673, 15874, 11022, 45, 17343, 14607, 11459, 14442, 10310, 16114, 10080, 11164, 11723, 17875, 14332, 12669, 10390, 11206, 10760, 13234, 45, 12857, 17900, 10390, 10260, 10768, 11461, 11038, 11459, 15463, 12484, 11610, 15898, 45, 10339, 13091, 11164, 11723, 17875, 14332, 14190, 10333, 10390, 14734, 15874, 11022, 28329, 13581, 13064, 45, 15874, 11022, 14213, 14190, 14734, 14136, 14218, 11454, 18438, 13146, 10285, 12719, 12894, 15639, 14806, 45, 12719, 13234, 16520, 10420, 14734, 11685, 11656, 59, 11, 9822, 14791, 11223, 45, 10442, 14434, 15658, 14508, 14267, 14190, 14734, 14152, 14142, 45, 10390, 17268, 12359, 15149, 14734, 11872, 11855, 45, 13561, 12283, 13326, 16443, 14179, 14136, 14144, 14190, 60, 14791, 14267, 14190, 14734, 14136, 14218, 10721, 10257, 11639, 15090, 45, 10621, 14141, 18245, 14975, 13685, 11885, 13034, 14734, 12010, 12631, 10080, 9823, 11, 15874, 11022, 10257, 14734, 14136, 10659, 11124, 13561, 12283, 13326, 14734, 17237, 17213, 45, 16672, 11164, 11723, 17875, 14332, 11105, 11430, 14734, 10370, 10260, 15002, 16676, 16686, 15465, 15465, 45, 10687, 10285, 18216, 10283, 14734, 12283, 13196, 16501, 13033, 15034, 11994, 16694, 16686, 17222, 23334, 11885, 10364, 12348, 11632, 10303, 15639, 14806, 11223, 23251, 11, 12421, 14734, 13234, 16735, 45, 17148, 10278, 13619, 13012, 11860, 14735, 10399, 11649, 12287, 14734, 14136, 10659, 10460, 10292, 13655, 13660, 14734, 10781, 17194, 45, 17181, 17141, 10370, 10402, 14734, 16520, 12527, 11124, 11957, 10687, 10260, 11042, 12527, 11002, 45, 12847, 15493, 10760, 10260, 11042, 12484, 12527, 28329, 10260, 11042, 11454, 10339, 10086, 14931, 12314, 10267, 14610, 10087, 13179, 10684, 13773, 14637, 15023, 16520, 13197, 14734, 12366, 12396, 45, 15646, 10086, 11164, 11723, 17875, 14332, 10087, 10779, 13179, 10688, 12603, 10821, 12986, 13258, 45, 12299, 16749, 14136, 14218, 11454, 15874, 11022, 10257, 14734, 12522, 10304, 10080, 10278, 10283, 12985, 10336, 14734, 14216, 14172, 10322, 10260, 12002, 14782, 11042, 28329, 10444, 10460, 10292, 10278, 13619, 12847, 17162, 14136, 14218, 10261, 10370, 12527, 11002, 12202, 11861, 14734, 13012, 11860, 45, 12421, 10452, 17147, 13091, 13191, 14782, 17189, 10305, 11621, 14734, 10080, 65535, 261, 65530, 65532, 12631, 10399, 10464, 10684, 13773, 14734, 13179, 11632, 14734, 13091, 14136, 14218, 11957, 10260, 11957, 19156, 11, 65535, 261, 65530, 65534, 12469, 12748, 10760, 12605, 10441, 10308, 13179, 10684, 13773, 17148, 10278, 13619, 13012, 11860, 10285, 14136, 14218, 14734, 12847, 17162, 45, 17148, 10441, 10308, 11021, 10399, 10995, 13086, 10760, 12605, 11957, 13012, 11860, 14734, 10250, 10349, 10585, 18012, 10080, 11042, 12522, 12469, 14734, 16520, 11940, 45, 12605, 14734, 14914, 11957, 14136, 14218, 14734, 12847, 10708, 13637, 17097, 13191, 10685, 16954, 10080, 10444, 12605, 12509, 12299, 16749, 14734, 13091, 59, 11, 50, 47, 33, 14136, 14218, 11016, 13091, 17148, 10278, 13619, 13012, 11860, 10799, 14604, 13660, 11430, 11124, 12484, 12527, 14734, 10250, 10283, 16803, 12333, 12636, 13619, 45, 15646, 10260, 13091, 12605, 10684, 13773, 14734, 14216, 14172, 10080, 12605, 13179, 10578, 11047, 10339, 10684, 13773, 14136, 14218, 15727, 11044, 10758, 13098, 10760, 14734, 10370, 14328, 12527, 11002, 11124, 10460, 15643, 12522, 11436, 28329, 51, 47, 33, 13637, 17097, 10278, 13619, 13012, 11860, 14734, 10260, 11042, 10482, 14589, 14136, 10659, 12636, 13764, 45, 13179, 15752, 10758, 13098, 10278, 10447, 10460, 15643, 10260, 11042, 14734, 12847, 10708, 18043, 13327, 11124, 12985, 10336, 10283, 12415, 10080, 17148, 13091, 12605, 13637, 17097, 13191, 10685, 16954, 10768, 13254, 14734, 28329, 52, 47, 33, 10370, 14328, 12527, 11002, 11124, 12484, 12527, 12220, 16721, 10260, 10348, 10339, 14136, 14218, 13205, 17038, 10080, 14136, 14218, 12847, 10708, 13179, 11632, 13091, 10292, 10333, 17363, 14778, 11459, 16698, 16735, 10370, 14328, 10696, 12366, 11124, 16417, 17136, 10460, 15643, 12509, 13764, 28329, 12421, 14734, 13234, 16735, 45, 10460, 10292, 10250, 10283, 12985, 10336, 16503, 15323, 45, 14136, 14218, 14914, 11903, 12348, 10792, 10333, 12605, 13637, 17097, 11632, 14734, 10684, 13773, 10080, 10444, 12605, 13179, 17385, 16523, 14734, 13091, 11885, 15727, 11044, 12631, 10758, 13098, 14734, 10370, 13012, 12522, 10304, 28329, 14136, 14218, 11016, 10260, 17141, 13091, 10250, 10283, 11805, 10382, 45, 15752, 17189, 17141, 11885, 12847, 15493, 10760, 13179, 10292, 18302, 13815, 14734, 10370, 14328, 12366, 14141, 10261, 10267, 14610, 16520, 28329, 12605, 14734, 10684, 13773, 14172, 17848, 10285, 11454, 10278, 10283, 13036, 17919, 59, 11, 10250, 13091, 10370, 14328, 12527, 11002, 17148, 10250, 12007, 17919, 45, 14136, 10659, 15727, 11044, 10758, 13098, 14734, 13091, 10260, 11042, 10370, 11957, 13581, 14734, 12527, 11002, 11124, 10995, 12220, 28329, 10337, 13091, 10460, 15643, 12636, 13764, 10261, 10283, 12415, 45, 10460, 15643, 17189, 17141, 10260, 11042, 13036, 12276, 10482, 14589, 14136, 10659, 45, 12022, 14446, 10760, 10283, 10370, 14734, 16728, 16537, 18043, 13327, 28329, 17148, 10278, 13036, 17919, 13179, 15752, 10452, 14446, 10460, 15643, 15904, 13208, 14589, 12522, 45, 13091, 12605, 13179, 12527, 10685, 16954, 10768, 13254, 10261, 13559, 16917, 14734, 10080, 65535, 261, 65530, 65532, 11957, 13637, 10086, 15597, 11435, 10420, 14987, 10087, 17148, 17303, 11975, 16735, 12848, 10494, 14734, 14987, 11871, 16803, 12333, 19137, 33, 12605, 10402, 15752, 10384, 10086, 14931, 12314, 10267, 14610, 10087, 17148, 17303, 11975, 16735, 17384, 17919, 12848, 11001, 10792, 17268, 10349, 16803, 12333, 12522, 10304, 14734, 10272, 16501, 19156, 11, 65535, 261, 65530, 65534, 11454, 11414, 15178, 17148, 10283, 17728, 18025, 10305, 10808, 45, 12605, 12509, 12299, 16749, 14734, 13091, 10260, 11042, 10460, 11159, 14734, 16803, 12333, 11064, 10304, 13091, 11036, 10260, 14782, 11042, 14734, 45, 10399, 10258, 13091, 12605, 11957, 10086, 14931, 12314, 10267, 14610, 10087, 17148, 17303, 11975, 16735, 14734, 10250, 10349, 16803, 12333, 16533, 16742, 59, 11, 50, 47, 33, 14931, 12314, 10267, 14610, 13205, 17038, 11994, 13091, 10250, 10283, 12299, 11638, 14734, 16803, 12333, 10080, 11885, 10397, 16417, 10460, 15643, 12509, 16803, 10838, 14734, 13051, 17789, 45, 16982, 10760, 14371, 11975, 14734, 14446, 11903, 13499, 11496, 28329, 51, 47, 33, 11888, 11633, 10370, 11124, 11888, 11633, 11691, 10370, 16803, 12333, 14808, 15516, 12746, 15042, 12217, 14734, 10838, 17387, 45, 10397, 16417, 14486, 12415, 11124, 13133, 12551, 28329, 52, 47, 33, 14320, 11647, 10370, 16803, 12333, 14808, 10974, 11726, 14734, 17386, 16306, 10838, 17387, 45, 17820, 11285, 10370, 12415, 10285, 11626, 13215, 14734, 10278, 17919, 12415, 28329, 53, 47, 33, 18256, 12996, 16803, 12333, 14808, 17271, 12449, 11124, 16009, 16783, 45, 10444, 10322, 12848, 17363, 12605, 10402, 12200, 16412, 13091, 17385, 16503, 14734, 28329, 54, 47, 33, 13042, 15052, 13205, 17038, 11994, 13091, 10250, 10283, 16803, 12333, 45, 10397, 16417, 10370, 14734, 12604, 17688, 11124, 16525, 17363, 28329, 55, 47, 33, 10260, 11042, 15033, 13046, 16803, 12333, 14808, 10370, 12415, 10285, 14734, 11036, 10283, 17919, 11047, 45, 12605, 10402, 17879, 16503, 13006, 11038, 11885, 10402, 12638, 15752, 16056, 12348, 12200, 16412, 28329, 12421, 14734, 13234, 16735, 45, 10086, 14931, 12314, 10267, 14610, 10087, 12848, 10494, 14734, 16803, 12333, 12522, 10304, 13179, 11632, 11459, 12299, 16749, 10370, 12415, 14734, 11626, 13215, 11632, 13324, 45, 12200, 16412, 10838, 17387, 10305, 17734, 14734, 17385, 16503, 12415, 10080, 11885, 13191, 12522, 16696, 11459, 12822, 16671, 10370, 12415, 14734, 11632, 17919, 12415, 45, 18458, 10851, 12605, 10402, 16947, 16948, 14371, 17824, 14734, 12410, 15516, 13499, 12276, 28329, 10261, 10086, 15597, 11435, 10420, 14987, 10087, 10285, 14734, 14987, 11871, 16803, 12333, 14782, 13637, 45, 10086, 14931, 12314, 10267, 14610, 10087, 12848, 10494, 14734, 16803, 12333, 12522, 10304, 13179, 13773, 17385, 10696, 11454, 15287, 14987, 12007, 17919, 14734, 12822, 15325, 10080, 11885, 12299, 16749, 10452, 18183, 11124, 12509, 16803, 45, 16947, 15774, 10333, 10688, 10452, 14734, 14987, 16713, 11887, 11898, 10080, 65535, 261, 65530, 65532, 12848, 10494, 9822, 14931, 12314, 10267, 14610, 9823, 17148, 17303, 11975, 16735, 14734, 14782, 10684, 10529, 12445, 19137, 10894, 12732, 10460, 15643, 19137, 10926, 10460, 18043, 13327, 19137, 10384, 10250, 10283, 17189, 10522, 11975, 16735, 10460, 11920, 14734, 16530, 12231, 12664, 10760, 11885, 14734, 17725, 10659, 14172, 11124, 10260, 16956, 11, 65535, 261, 65530, 65534, 10086, 14931, 12314, 10267, 14610, 10087, 17148, 17303, 11975, 16735, 10688, 13191, 12337, 18216, 14734, 10781, 10460, 10408, 10577, 45, 10384, 17189, 10522, 11975, 16735, 14734, 16530, 12231, 13234, 10768, 13254, 59, 11, 9828, 10460, 15643, 59, 14332, 17384, 2453, 13125, 12705, 10769, 14332, 28329, 9828, 10926, 10460, 18043, 13327, 59, 12208, 18441, 18043, 16954, 45, 11268, 10821, 10653, 15323, 10286, 11932, 45, 12172, 13191, 15034, 12206, 11124, 11656, 12206, 15898, 12319, 28329, 9828, 17725, 10659, 14172, 59, 11, 50, 42, 10286, 11932, 14734, 12509, 16803, 10838, 45, 16689, 16664, 10333, 14370, 14332, 14734, 14931, 12314, 10267, 14610, 52865, 45, 10894, 12732, 11412, 10283, 11869, 15907, 11435, 12231, 10079, 17997, 15137, 14734, 13961, 13819, 10079, 10452, 17385, 11003, 17093, 14734, 14328, 14486, 11899, 12340, 15169, 28329, 51, 42, 10286, 11932, 13191, 16954, 14734, 10370, 14328, 12314, 16803, 45, 11687, 13594, 14987, 10079, 18256, 13764, 12158, 10079, 12142, 12158, 11871, 12345, 10079, 12632, 12200, 11459, 14484, 11871, 10423, 10293, 12175, 15169, 28329, 52, 42, 14442, 11110, 14734, 12208, 18441, 18043, 16954, 45, 16688, 10798, 14970, 10423, 14446, 11903, 28329, 9828, 10260, 16956, 59, 11, 50, 42, 11638, 17387, 14734, 10328, 12657, 14486, 16686, 11124, 11043, 16702, 45, 11021, 15752, 15568, 10309, 15326, 10740, 12527, 28329, 51, 42, 15092, 14894, 12182, 14486, 14734, 15034, 12206, 16689, 11899, 45, 11957, 10250, 15880, 16742, 15643, 11021, 15752, 17843, 10399, 12824, 11002, 28329, 9828, 12421, 10452, 13234, 16735, 59, 11, 16269, 14221, 13191, 10250, 10349, 15568, 14172, 45, 10444, 10086, 14931, 12314, 10267, 14610, 10087, 10954, 10752, 10563, 14370, 10781, 14734, 12509, 16803, 10079, 12208, 18441, 16710, 16760, 14734, 11639, 18157, 16403, 15090, 14734, 12484, 15907, 45, 10399, 10992, 14370, 14332, 14734, 10267, 14610, 16520, 45, 16056, 12348, 10333, 12210, 13766, 14734, 16742, 15643, 16667, 11021, 10080, 17148, 13580, 13091, 10250, 17303, 17189, 10522, 11975, 16735, 12631, 17879, 16503, 10692, 11622, 14734, 10653, 15323, 10080, 65535, 261, 65530, 65532, 12848, 10494, 9822, 14931, 12314, 10267, 14610, 9823, 15304, 10777, 14734, 10460, 15643, 11043, 15044, 11124, 10529, 12445, 10080, 33, 17147, 13191, 16721, 10460, 15643, 14734, 14782, 10684, 10460, 11159, 17848, 11, 65535, 261, 65530, 65534, 10086, 14931, 12314, 10267, 14610, 10087, 15304, 10777, 14734, 10460, 15643, 13091, 15963, 11435, 10460, 11920, 13778, 14523, 2453, 13125, 12705, 10769, 14332, 41, 6696, 2174, 20670, 2204, 7686, 117, 497, 10390, 10322, 13191, 10687, 10390, 16114, 11043, 14734, 15304, 10777, 10427, 11656, 10460, 11159, 28329, 10293, 16503, 10529, 12445, 59, 11, 9828, 33, 10460, 15643, 59, 13778, 14523, 2453, 13125, 12705, 10769, 14332, 41, 6696, 2174, 20670, 2204, 7686, 117, 497, 639, 668, 12201, 53, 13190, 648, 13053, 10760, 14583, 45, 640, 635, 12201, 52, 13190, 632, 13053, 10985, 10267, 28329, 9828, 33, 11435, 15252, 59, 15963, 11435, 10460, 11920, 11, 9828, 33, 10397, 16417, 10460, 59, 10086, 14931, 12314, 10267, 14610, 10087, 15304, 10777, 41, 23570, 36017, 42, 11975, 16735, 17848, 11, 9828, 33, 10687, 10390, 10460, 11159, 59, 10086, 6699, 28608, 1859, 44696, 10087, 15304, 10777, 10079, 10086, 6699, 49955, 50425, 21265, 21823, 28821, 24738, 20762, 25291, 10087, 15304, 10777, 15169, 11, 10086, 14931, 12314, 10267, 14610, 10087, 15304, 10777, 10384, 639, 703, 12201, 12266, 11726, 14734, 45, 10682, 660, 11632, 13205, 10080, 10293, 16503, 12847, 17162, 10333, 14931, 12314, 10267, 14610, 10257, 14734, 10370, 10261, 14583, 10540, 13234, 14734, 18256, 13764, 10838, 17387, 10399, 10992, 11036, 15033, 11698, 12418, 14583, 14328, 10080, 16891, 15091, 11726, 15480, 14734, 10293, 18025, 13091, 11117, 17144, 10261, 15847, 14597, 12522, 12377, 10399, 10992, 13133, 12551, 10261, 12525, 16393, 14734, 11957, 15123, 28329, 13778, 14523, 2453, 13125, 12705, 10769, 14332, 14734, 16684, 11632, 10460, 11159, 17311, 10688, 13191, 13833, 17285, 14734, 15963, 11435, 12208, 18441, 18043, 13327, 45, 16728, 16537, 14583, 10846, 16710, 16760, 45, 10370, 14328, 18302, 13815, 16982, 15774, 45, 10399, 13249, 10687, 12208, 18441, 14734, 13036, 12276, 12847, 10708, 11626, 13215, 14734, 11190, 14486, 16520, 10080, 10390, 16443, 11971, 10292, 9822, 15963, 16728, 11268, 10821, 10305, 14302, 9823, 10080, 65535, 261, 65530, 65532, 10460, 10292, 10250, 11043, 15847, 11805, 10452, 15543, 17108, 19137, 33, 12848, 10494, 9822, 18256, 13764, 14734, 18029, 15898, 9823, 17148, 17303, 11975, 16735, 19133, 6696, 2174, 20670, 2204, 7686, 117, 16114, 19134, 14734, 12898, 16503, 10529, 12445, 19137, 33, 10894, 12732, 10821, 12484, 11124, 10684, 17644, 10370, 14328, 11, 65535, 261, 65530, 65534, 12605, 14446, 11454, 15494, 10760, 12605, 14734, 15162, 10250, 10283, 15178, 13336, 19137, 33, 17148, 13091, 12605, 16667, 10292, 13188, 11685, 14734, 19151, 11, 18256, 13764, 14734, 18029, 15898, 41, 6699, 44135, 4706, 36976, 42, 13091, 13778, 14523, 2453, 13125, 12705, 10769, 14332, 41, 6696, 2174, 20670, 2204, 7686, 117, 42, 14734, 18117, 17303, 16130, 15917, 12001, 11975, 16735, 41, 23570, 36017, 47234, 42, 28329, 10293, 16503, 10370, 14328, 59, 11, 9828, 1419, 8218, 27487, 59, 33, 10250, 10283, 15299, 15293, 14734, 18256, 13764, 12158, 10080, 10390, 10260, 11975, 12366, 17149, 10792, 10333, 18488, 33640, 12034, 10257, 45, 11454, 17268, 17384, 10390, 17213, 10792, 10333, 10278, 10283, 11630, 13234, 15643, 10080, 10390, 11994, 12604, 10333, 10390, 10402, 11024, 12645, 13799, 14057, 11638, 17782, 10305, 16403, 14734, 11047, 11960, 28329, 9828, 6720, 41426, 59, 33, 10250, 10283, 20683, 2162, 41, 23570, 36017, 10257, 14734, 10250, 10283, 11435, 11920, 42, 11932, 16455, 14734, 13042, 16403, 11221, 10370, 10080, 10390, 13234, 10792, 11024, 12645, 13799, 14057, 11638, 17782, 17149, 16403, 12231, 10580, 10080, 14597, 10339, 10260, 10333, 16533, 18256, 13764, 14734, 10267, 14610, 45, 10390, 12182, 12182, 17808, 10673, 10952, 17801, 10305, 10285, 28329, 9828, 6699, 20320, 25476, 59, 21042, 41426, 14734, 16403, 13221, 15209, 10080, 11885, 13191, 15847, 12144, 14734, 12410, 12527, 12484, 45, 13191, 13064, 10423, 10525, 12686, 11885, 14734, 10293, 10370, 28329, 10821, 12484, 59, 11, 10997, 14583, 11454, 18256, 13764, 10655, 13027, 14734, 11024, 12645, 13799, 14057, 11638, 17782, 10080, 6720, 41426, 13234, 10792, 17148, 17384, 13042, 16403, 45, 1419, 8218, 27487, 12604, 10292, 10390, 14734, 11047, 11960, 10080, 10390, 10402, 10339, 13091, 12022, 12266, 10250, 15304, 10777, 14734, 10705, 17801, 17149, 16403, 11024, 12645, 13799, 14057, 14734, 15091, 13373, 10305, 13042, 28329, 10390, 10402, 17213, 10792, 11036, 15033, 18256, 13764, 14583, 14328, 45, 13637, 11687, 18488, 10079, 15287, 14141, 10079, 18256, 13764, 12158, 15169, 10080, 10390, 10402, 10322, 17919, 10288, 18256, 13764, 12172, 13234, 14734, 11036, 15033, 10952, 17801, 11124, 12752, 12610, 10080, 65535, 261, 65530, 65534, 12605, 14446, 11454, 12791, 10283, 16530, 12231, 13234, 12410, 15641, 17148, 10283, 17728, 18025, 19137, 15494, 10760, 11013, 11630, 10250, 10283, 15178, 13336, 19151, 11, 11454, 17148, 17303, 11975, 16735, 10285, 45, 20754, 1788, 27487, 11124, 6720, 41426, 16443, 10956, 10673, 16684, 11632, 11426, 11574, 10305, 10285, 45, 13191, 13064, 13091, 11416, 10292, 15847, 12144, 14734, 13051, 14862, 11124, 10260, 16780, 12542, 45, 13191, 13064, 13091, 11416, 10292, 11013, 10250, 10283, 10722, 11899, 10390, 10402, 14734, 11630, 11454, 10838, 17387, 10080, 10390, 10402, 17919, 11957, 14808, 16739, 11687, 14136, 12034, 10079, 13849, 17843, 10399, 10992, 11024, 12645, 13799, 14057, 11638, 17782, 10285, 13188, 12299, 11638, 14734, 18256, 13764, 12158, 10402, 14734, 11753, 15723, 28329, 12002, 15202, 1419, 8218, 27487, 13091, 10250, 10283, 15299, 15293, 14734, 18256, 13764, 12158, 19137, 10444, 10390, 10250, 14781, 11454, 15136, 12002, 10675, 10838, 10525, 12686, 6720, 41426, 19137, 15646, 6720, 41426, 10779, 12172, 13234, 10333, 11957, 17148, 10283, 11656, 11701, 14734, 18256, 13764, 10267, 14610, 14734, 14195, 12484, 11124, 11685, 11656, 12366, 28329, 11454, 17148, 10283, 10655, 14015, 18256, 13764, 14734, 10267, 14610, 17384, 19137, 11210, 10250, 11474, 11687, 14947, 14869, 14734, 11957, 16803, 13091, 6720, 41426, 14734, 16403, 13221, 15209, 19137, 11885, 13091, 10250, 10283, 13815, 14583, 14583, 14734, 10079, 16399, 15446, 15898, 14734, 16403, 13221, 15209, 19137, 11021, 10399, 12669, 11885, 14734, 10293, 10370, 10525, 12686, 11454, 10409, 10454, 10952, 17801, 14445, 11574, 10285, 28329, 17148, 17303, 11975, 16735, 13091, 10250, 17303, 11701, 16954, 13503, 14583, 14734, 11656, 12206, 10705, 17801, 11975, 16735, 19137, 16672, 16742, 15643, 10452, 18183, 10792, 10333, 9822, 17169, 13685, 14862, 16696, 11124, 12822, 15325, 9823, 14734, 10310, 16954, 19137, 11042, 13064, 10322, 16672, 10370, 12509, 16944, 10333, 14583, 11117, 10285, 14734, 13947, 18121, 11124, 10993, 16754, 10080, 65535, 261]
[2023-09-30 21:43:15,223] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=0, lr=[0.0001, 0.0001, 0.0001], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
-> item_loss 0.7131894826889038 batch_loss 1.1266836449503899
==== [12645, 13799, 14057, 11638, 17782, 17149, 16403, 12231, 10580, 10080, 14597, 10339, 10260, 10333, 16533, 18256, 13764, 14734, 10267, 14610, 45, 10390, 12182, 12182, 17808, 10673, 10952, 17801, 10305, 10285, 28329, 9828, 6699, 20320, 25476, 59, 21042, 41426, 14734, 16403, 13221, 15209, 10080, 11885, 13191, 15847, 12144, 14734, 12410, 12527, 12484, 45, 13191, 13064, 10423, 10525, 12686, 11885, 14734, 10293, 10370, 28329, 10821, 12484, 59, 11, 10997, 14583, 11454, 18256, 13764, 10655, 13027, 14734, 11024, 12645, 13799, 14057, 11638, 17782, 10080, 6720, 41426, 13234, 10792, 17148, 17384, 13042, 16403, 45, 1419, 8218, 27487, 12604, 10292, 10390, 14734, 11047, 11960, 10080, 10390, 10402, 10339, 13091, 12022, 12266, 10250, 15304, 10777, 14734, 10705, 17801, 17149, 16403, 11024, 12645, 13799, 14057, 14734, 15091, 13373, 10305, 13042, 28329, 10390, 10402, 17213, 10792, 11036, 15033, 18256, 13764, 14583, 14328, 45, 13637, 11687, 18488, 10079, 15287, 14141, 10079, 18256, 13764, 12158, 15169, 10080, 10390, 10402, 10322, 17919, 10288, 18256, 13764, 12172, 13234, 14734, 11036, 15033, 10952, 17801, 11124, 12752, 12610, 10080, 65535, 261, 65530, 65534, 12605, 14446, 11454, 12791, 10283, 16530, 12231, 13234, 12410, 15641, 17148, 10283, 17728, 18025, 19137, 15494, 10760, 11013, 11630, 10250, 10283, 15178, 13336, 19151, 11, 11454, 17148, 17303, 11975, 16735, 10285, 45, 20754, 1788, 27487, 11124, 6720, 41426, 16443, 10956, 10673, 16684, 11632, 11426, 11574, 10305, 10285, 45, 13191, 13064, 13091, 11416, 10292, 15847, 12144, 14734, 13051, 14862, 11124, 10260, 16780, 12542, 45, 13191, 13064, 13091, 11416, 10292, 11013, 10250, 10283, 10722, 11899, 10390, 10402, 14734, 11630, 11454, 10838, 17387, 10080, 10390, 10402, 17919, 11957, 14808, 16739, 11687, 14136, 12034, 10079, 13849, 17843, 10399, 10992, 11024, 12645, 13799, 14057, 11638, 17782, 10285, 13188, 12299, 11638, 14734, 18256, 13764, 12158, 10402, 14734, 11753, 15723, 28329, 12002, 15202, 1419, 8218, 27487, 13091, 10250, 10283, 15299, 15293, 14734, 18256, 13764, 12158, 19137, 10444, 10390, 10250, 14781, 11454, 15136, 12002, 10675, 10838, 10525, 12686, 6720, 41426, 19137, 15646, 6720, 41426, 10779, 12172, 13234, 10333, 11957, 17148, 10283, 11656, 11701, 14734, 18256, 13764, 10267, 14610, 14734, 14195, 12484, 11124, 11685, 11656, 12366, 28329, 11454, 17148, 10283, 10655, 14015, 18256, 13764, 14734, 10267, 14610, 17384, 19137, 11210, 10250, 11474, 11687, 14947, 14869, 14734, 11957, 16803, 13091, 6720, 41426, 14734, 16403, 13221, 15209, 19137, 11885, 13091, 10250, 10283, 13815, 14583, 14583, 14734, 10079, 16399, 15446, 15898, 14734, 16403, 13221, 15209, 19137, 11021, 10399, 12669, 11885, 14734, 10293, 10370, 10525, 12686, 11454, 10409, 10454, 10952, 17801, 14445, 11574, 10285, 28329, 17148, 17303, 11975, 16735, 13091, 10250, 17303, 11701, 16954, 13503, 14583, 14734, 11656, 12206, 10705, 17801, 11975, 16735, 19137, 16672, 16742, 15643, 10452, 18183, 10792, 10333, 9822, 17169, 13685, 14862, 16696, 11124, 12822, 15325, 9823, 14734, 10310, 16954, 19137, 11042, 13064, 10322, 16672, 10370, 12509, 16944, 10333, 14583, 11117, 10285, 14734, 13947, 18121, 11124, 10993, 16754, 10080, 65535, 261]
-> item_loss 1.085699200630188 batch_loss 1.1221298178037007
==== [25106, 11, 65530, 65531, 10464, 13091, 10250, 10283, 13637, 17097, 14332, 13603, 14734, 820, 19137, 11017, 10460, 1139, 1955, 10080, 10464, 16443, 16689, 16664, 10760, 13234, 12202, 10260, 13091, 10292, 10333, 10292, 10370, 15261, 12848, 10494, 13193, 10843, 19137, 15646, 13091, 13827, 16707, 820, 10792, 12221, 15752, 11003, 12348, 13191, 11632, 15678, 13078, 10080, 10464, 10423, 10621, 10250, 10283, 10370, 15261, 10250, 13324, 11124, 10687, 10390, 10370, 10355, 16753, 19137, 10464, 16735, 10760, 13234, 14734, 10696, 11922, 13091, 11891, 10675, 15847, 10293, 10722, 11899, 14734, 19137, 12202, 10265, 11001, 10722, 10339, 10464, 14734, 12509, 13764, 11124, 13499, 12722, 12366, 12484, 28329, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 11454, 10303, 11, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 10464, 11685, 19156, 11, 65535, 261, 65530, 65534, 1139, 1955, 59, 33, 10464, 11685, 19137, 12605, 13091, 1139, 1955, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 10464, 13191, 10373, 10303, 10841, 15752, 19156, 11, 65535, 261, 65530, 65534, 1139, 1955, 59, 33, 10460, 10292, 10250, 10283, 820, 19137, 12605, 14734, 10841, 15752, 13191, 12337, 11632, 19137, 13637, 11687, 10621, 14446, 11454, 17148, 13324, 11124, 10464, 15667, 11639, 19137, 10444, 13091, 12605, 12202, 10260, 13091, 10292, 10333, 13193, 10843, 10370, 15261, 15646, 16443, 10781, 17194, 10760, 13234, 14734, 19137, 12631, 10399, 11021, 15752, 16503, 16672, 10464, 11645, 13197, 10333, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 18030, 19137, 10260, 13091, 10292, 10333, 12176, 10847, 10370, 15261, 19137, 17268, 10464, 10292, 10373, 10303, 10423, 16443, 17194, 10760, 13234, 19156, 11, 65535, 261, 65530, 65534, 1139, 1955, 59, 33, 11111, 11111, 19137, 17268, 12605, 11994, 10260, 14862, 17222, 10333, 19137, 12609, 16684, 10464, 11021, 10399, 17728, 10258, 12605, 14734, 10794, 17194, 15643, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 10464, 17148, 10283, 12396, 12231, 43282, 11, 65535, 261, 65530, 65534, 1139, 1955, 59, 33, 12605, 16525, 12348, 12605, 14734, 12396, 12231, 13734, 10373, 10303, 17728, 18025, 19137, 11416, 10292, 10464, 17728, 17148, 10349, 17728, 18025, 13064, 10441, 10308, 13734, 13191, 15641, 16253, 12605, 10423, 12401, 10303, 12509, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 11685, 11061, 11957, 10260, 16944, 19137, 11021, 15752, 13091, 12605, 11124, 10687, 10390, 820, 15667, 11639, 11640, 11632, 10333, 19137, 10464, 10322, 16684, 13191, 10349, 10260, 10250, 13324, 28329, 65535, 261, 65530, 65534, 1139, 1955, 59, 33, 16774, 16774, 10464, 14734, 14486, 16533, 19137, 12605, 10322, 10292, 12605, 14734, 12396, 12231, 17222, 13571, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 12605, 16525, 12348, 10464, 13091, 10283, 13191, 16954, 14734, 820, 19137, 10260, 17141, 10780, 12638, 12605, 16707, 12822, 10464, 12202, 17916, 13091, 10760, 10339, 12449, 12522, 19137, 12605, 11016, 13091, 12509, 11957, 10464, 13191, 10250, 10283, 16722, 15478, 14734, 10333, 16533, 28329, 65535, 261, 65530, 65534, 1139, 1955, 59, 33, 11315, 19137, 12631, 10399, 10464, 12509, 10333, 16533, 10349, 10373, 10303, 19156, 12605, 10460, 10292, 10250, 10283, 13212, 11369, 13734, 10373, 10303, 15036, 11930, 19137, 11021, 10399, 11124, 10464, 16679, 16679, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 10464, 14734, 12221, 12007, 13499, 11496, 13091, 10373, 10303, 28329, 65535, 261, 65530, 65534, 1139, 1955, 59, 33, 18030, 19137, 17148, 10283, 12605, 11021, 15752, 13734, 13764, 11414, 15178, 10464, 19137, 12202, 10260, 13091, 11416, 10292, 17148, 13091, 13212, 11930, 19137, 15646, 13091, 11416, 10292, 12605, 11871, 10323, 14734, 16728, 13021, 11640, 11632, 10333, 19137, 10687, 10285, 10894, 12732, 11036, 15033, 10687, 10390, 16728, 16537, 13499, 11496, 14589, 17141, 14734, 16728, 13021, 19137, 12631, 10399, 12605, 10260, 11640, 10768, 12348, 13923, 43282, 11, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 10464, 10292, 10373, 10303, 16735, 16713, 10423, 17148, 10303, 15847, 14221, 19156, 13091, 11416, 10292, 10464, 16443, 16689, 11899, 12604, 17148, 13324, 10303, 19156, 11, 65535, 261, 65530, 65534, 1139, 1955, 59, 33, 13091, 17148, 13324, 14734, 19137, 10464, 10402, 10370, 15261, 12631, 16735, 14734, 16689, 11899, 10441, 10308, 13091, 12748, 11454, 12605, 14734, 17109, 10673, 12266, 11647, 17303, 10768, 14734, 13012, 13205, 10080, 35, 10464, 13091, 10250, 10283, 13637, 17097, 14332, 13603, 14734, 820, 19137, 11017, 10460, 1139, 1955, 10080, 10464, 16443, 16689, 16664, 10760, 13234, 12202, 10260, 13091, 10292, 10333, 10292, 10370, 15261, 12848, 10494, 13193, 10843, 19137, 15646, 13091, 13827, 16707, 820, 10792, 12221, 15752, 11003, 12348, 13191, 11632, 15678, 13078, 10080, 35, 11885, 10441, 10308, 13091, 17148, 13324, 10708, 14734, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 12631, 10399, 10464, 10377, 10377, 13091, 10250, 10283, 13212, 11369, 19137, 13734, 13191, 15847, 12605, 19156, 11, 65535, 261, 65530, 65534, 1139, 1955, 59, 33, 10464, 16525, 12348, 12605, 10621, 13091, 13734, 13191, 10303, 19156, 11685, 11061, 19137, 14791, 16944, 13234, 14914, 11903, 12337, 10621, 10080, 10444, 13091, 19137, 12605, 16269, 14221, 10423, 10279, 13327, 12750, 14240, 16689, 11899, 12314, 12276, 19137, 10444, 13091, 12605, 10322, 10423, 13326, 12797, 13499, 11496, 14734, 14862, 16696, 10261, 14332, 12415, 13234, 17109, 10760, 10696, 11922, 10080, 13637, 11687, 19137, 11454, 17148, 10283, 16689, 11899, 10258, 12605, 11021, 10399, 17177, 12731, 13091, 11060, 10261, 10464, 15507, 15511, 15667, 11639, 10080, 10464, 11021, 10399, 16667, 10292, 19137, 12605, 16269, 14221, 13091, 10283, 13212, 11369, 19137, 10444, 13091, 12727, 13191, 10250, 17303, 10768, 10370, 15261, 14734, 14332, 12415, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 11164, 11164, 19137, 10687, 11903, 12605, 17311, 14862, 17222, 19137, 12605, 13091, 10464, 14734, 10794, 17194, 15643, 19137, 1139, 1955, 28329, 65535, 261, 65530, 65534, 1139, 1955, 59, 33, 10322, 11994, 13091, 16735, 10464, 13091, 12605, 14734, 10293, 10370, 19156, 10293, 10370, 10464, 17148, 10260, 13091, 11454, 13565, 16875, 12605, 10303, 43282, 13078, 13078, 14862, 17222, 17147, 16503, 11124, 12605, 16679, 17148, 10349, 19137, 11100, 11100, 11100, 43282, 11, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 10790, 11188, 10333, 19137, 10687, 11903, 12605, 10402, 14734, 17148, 13619, 11957, 16713, 13091, 12605, 15543, 10708, 14734, 16728, 13021, 19137, 12202, 10260, 13091, 10464, 14794, 13580, 14734, 15486, 10964, 10080, 11454, 13203, 13234, 19137, 10464, 12609, 16684, 10423, 16443, 11017, 10460, 10687, 11885, 14734, 11043, 11860, 19137, 13637, 11687, 35, 32890, 35, 12609, 35, 994, 26405, 35, 10079, 14581, 15849, 13091, 15190, 10932, 14734, 12642, 10257, 35, 820, 5178, 33394, 35, 15169, 13308, 15189, 19137, 10444, 13091, 12605, 12159, 13197, 10464, 15752, 10384, 17148, 13619, 16728, 13021, 10285, 11871, 10323, 10792, 10250, 10349, 10272, 16501, 10080, 11685, 10333, 19137, 14446, 11454, 10589, 13579, 13499, 12722, 10370, 15261, 11061, 19137, 12605, 13179, 12981, 13188, 10782, 14734, 16689, 11899, 19137, 14446, 11454, 10464, 11003, 11414, 17268, 10283, 12176, 10847, 10370, 15261, 14734, 13212, 11369, 10370, 28329, 65535, 261, 65530, 65534, 1139, 1955, 59, 33, 11685, 14734, 19137, 12605, 14446, 11454, 11003, 12604, 12176, 10847, 10370, 15261, 14734, 13212, 11369, 10370, 10080, 10687, 11903, 19137, 10293, 10370, 10464, 14734, 11117, 10398, 10261, 9822, 16443, 16689, 16664, 10760, 13234, 10292, 10370, 15261, 13193, 10843, 14734, 16689, 11899, 9823, 14782, 12463, 19137, 10444, 13091, 12605, 12537, 12522, 11065, 12469, 14734, 11117, 10398, 10080, 12605, 10423, 16678, 10449, 17148, 13619, 16728, 13021, 19137, 10384, 10285, 11871, 10323, 14734, 10080, 16738, 17728, 10293, 10370, 17147, 13191, 10373, 10303, 17879, 16503, 12605, 12176, 10847, 14734, 11053, 19156, 11, 65535, 261]
-> item_loss 0.9231598973274231 batch_loss 1.102232825756073
==== [25106, 11, 65530, 65534, 17148, 13619, 13012, 11860, 13091, 9822, 14931, 12314, 10267, 14610, 9823, 14734, 10250, 10283, 14313, 13619, 19137, 12847, 17162, 10333, 10250, 10283, 10278, 10283, 10370, 11454, 11957, 16713, 14734, 11461, 13126, 19137, 33, 12605, 12509, 11454, 10258, 17919, 14734, 17749, 16742, 10285, 10333, 16533, 16721, 13012, 13205, 14734, 16530, 15898, 11124, 10370, 14328, 10529, 12445, 11, 14136, 19137, 14190, 17149, 10333, 10994, 11517, 11889, 15034, 2453, 16050, 13770, 10660, 10080, 14136, 15950, 16535, 10992, 18256, 13764, 16099, 11459, 19137, 14179, 14218, 10339, 13091, 11086, 14446, 10760, 16155, 15898, 11124, 15526, 15898, 19137, 14581, 15849, 11656, 17167, 15880, 11459, 17725, 10760, 12172, 13191, 10253, 12319, 10305, 11630, 9822, 15162, 10677, 15898, 9823, 14734, 14136, 15931, 19152, 14136, 15863, 13755, 14808, 11221, 10270, 16407, 10250, 16981, 15104, 11047, 10609, 13750, 15572, 19137, 14136, 14218, 10339, 13091, 13655, 10859, 18216, 13877, 19137, 10411, 10459, 17725, 15639, 14734, 14136, 11282, 13759, 19137, 9822, 11381, 11237, 9823, 14171, 11168, 19152, 14136, 14218, 14190, 10792, 18119, 16218, 12223, 17609, 12631, 11454, 14734, 16407, 17222, 19137, 11638, 14136, 10339, 13091, 10997, 10760, 17774, 17774, 14582, 18119, 19152, 11638, 14136, 14272, 14808, 10333, 16030, 12223, 10609, 16223, 11909, 17384, 12199, 14280, 14734, 14460, 11656, 16030, 16002, 19137, 10370, 10402, 10339, 13091, 13655, 12348, 10997, 14652, 19137, 12266, 11010, 11217, 18175, 14987, 13078, 28329, 13581, 13064, 19137, 16050, 13770, 10660, 11517, 14734, 11221, 10270, 10912, 12145, 13091, 10250, 14313, 14136, 13849, 10080, 11013, 10250, 15137, 14734, 11889, 15034, 11517, 17384, 19137, 13191, 17558, 13191, 17038, 10410, 14734, 12010, 13653, 15465, 15465, 16403, 10846, 19137, 13644, 10260, 12636, 17086, 19137, 14652, 14356, 11459, 12702, 16944, 13352, 13234, 10080, 10444, 13091, 19137, 16050, 13770, 10660, 15887, 11478, 17384, 17268, 10349, 14015, 17095, 16790, 14328, 10079, 13384, 15931, 11124, 13202, 13223, 14734, 15878, 15887, 19137, 16417, 17919, 13852, 14808, 14216, 13750, 19137, 13057, 12145, 14175, 14267, 16944, 13234, 10080, 13760, 11459, 14190, 12604, 10333, 14140, 14194, 19137, 10250, 15891, 15891, 14136, 15887, 16945, 14808, 17170, 14066, 19137, 13755, 14808, 11889, 15034, 13748, 11047, 11638, 13849, 14030, 10985, 19137, 10411, 10459, 13996, 13676, 14734, 16098, 14136, 16263, 19137, 10250, 16981, 14172, 14267, 13755, 12061, 14734, 11913, 13624, 11124, 13224, 14970, 10080, 14136, 13085, 17819, 18043, 18048, 10792, 12061, 10257, 19137, 12640, 11047, 17150, 11621, 13913, 16223, 14734, 15931, 11423, 11124, 16002, 12015, 28329, 14179, 14218, 14583, 10760, 13833, 14187, 10254, 10255, 19137, 10411, 10459, 10250, 13326, 14356, 18043, 10956, 12604, 14734, 18438, 13295, 19137, 10953, 10511, 15126, 11454, 14931, 12314, 10267, 14610, 14734, 11013, 10250, 15137, 19137, 10322, 15752, 14791, 10283, 10250, 13923, 10337, 13425, 28329, 15957, 11454, 10745, 17384, 10305, 11630, 17773, 10735, 12208, 13146, 14734, 12034, 17997, 11471, 16520, 17148, 17774, 10859, 19137, 12527, 16525, 12368, 13091, 12647, 10370, 12366, 12290, 10080, 13581, 13064, 13580, 13191, 17148, 10303, 10278, 10447, 19137, 14791, 12348, 10685, 11110, 14759, 14221, 28329, 10687, 10285, 18216, 10283, 11855, 14734, 17268, 10447, 10561, 14808, 10250, 12669, 16956, 13191, 10250, 10370, 18216, 14734, 10811, 15126, 14808, 19137, 13580, 11638, 11401, 18363, 15809, 10080, 16503, 10260, 13091, 14791, 10390, 17181, 14808, 10250, 15706, 13212, 16650, 15678, 12551, 14734, 14141, 13655, 19137, 16519, 10333, 17148, 10588, 13818, 19137, 16747, 17311, 10423, 10399, 10292, 17148, 13091, 10384, 10285, 17090, 11459, 16009, 10974, 13234, 14734, 17386, 16306, 10370, 28329, 11013, 10250, 10447, 13098, 12348, 14867, 12348, 11632, 19137, 10384, 11647, 10792, 15768, 17311, 16136, 11454, 13388, 15898, 13020, 15232, 17384, 10080, 10594, 11979, 15053, 10846, 10250, 10846, 13064, 19137, 10846, 10460, 10305, 17093, 14352, 11687, 14398, 11145, 17004, 13582, 28329, 10305, 10808, 14734, 10337, 10917, 10768, 17544, 17384, 19137, 17148, 10278, 10447, 10745, 10308, 18441, 10260, 10460, 11610, 19137, 11016, 13191, 10250, 13619, 15190, 14866, 13051, 13258, 14734, 10335, 16686, 19137, 10336, 10684, 14136, 13849, 10285, 14734, 10250, 17774, 14388, 14179, 14288, 14171, 10792, 12221, 10997, 14583, 11454, 11861, 13750, 16883, 13309, 17147, 13091, 11454, 12142, 11606, 10660, 16052, 10936, 11979, 14734, 10460, 11467, 10080, 10278, 10370, 10292, 13581, 10258, 10333, 16915, 13773, 28329, 18216, 10283, 11855, 11219, 11891, 18363, 19137, 12669, 18200, 11647, 12643, 11454, 16002, 10271, 17384, 19137, 15149, 17384, 12172, 14808, 12409, 12474, 43899, 17268, 10349, 11975, 12148, 11855, 17311, 13626, 10333, 43282, 9823, 11, 10390, 16735, 19137, 9822, 12605, 12771, 11268, 13558, 11885, 10402, 14734, 10080, 9823, 11, 9822, 17147, 13191, 17268, 10349, 11902, 12219, 43282, 9823, 14867, 10283, 11855, 12509, 10333, 12509, 19137, 10990, 16416, 10333, 10250, 11012, 19137, 9822, 11902, 14869, 11021, 14267, 10303, 19156, 11065, 16735, 11885, 10402, 16974, 14237, 12143, 10260, 11632, 13091, 10250, 15261, 10272, 16501, 10080, 9823, 11, 9822, 12631, 13191, 17389, 11855, 19137, 17311, 14252, 10333, 19137, 18000, 14808, 13733, 13485, 13819, 13893, 10080, 9823, 11638, 10283, 11855, 16735, 14808, 19137, 13734, 13191, 14486, 10423, 14867, 10283, 11855, 14734, 17728, 18025, 19137, 9822, 12631, 13191, 15597, 17335, 19137, 17311, 11454, 13357, 17384, 13749, 15808, 10333, 10080, 9823, 11, 9822, 17147, 13191, 15640, 18459, 10080, 9823, 10250, 17038, 13388, 16435, 14734, 11042, 10437, 16735, 28329, 9822, 15640, 18459, 19137, 16735, 12348, 11957, 10080, 9823, 11, 9822, 14768, 11627, 13064, 15907, 19137, 13734, 11459, 13036, 11021, 17173, 10080, 9823, 11, 9822, 11042, 13324, 16735, 12348, 11957, 10080, 10444, 19137, 12421, 13091, 16525, 12348, 43282, 11315, 43282, 17148, 10423, 10650, 43282, 9823, 11, 10390, 11155, 10258, 13734, 16735, 11891, 14734, 16713, 19137, 17819, 10953, 12791, 10257, 17093, 12387, 14734, 11010, 13655, 43899, 12605, 10402, 17147, 13556, 9819, 15446, 13676, 16305, 9820, 17268, 10650, 14734, 15640, 12283, 16052, 11632, 10677, 10283, 17607, 12153, 11187, 10080, 9823, 14867, 10283, 11855, 14172, 10333, 14172, 11647, 28329, 10278, 10283, 10370, 10703, 13557, 18441, 10260, 10460, 11610, 10080, 11454, 17148, 12232, 13188, 11638, 14734, 11517, 12154, 11984, 13203, 16944, 14136, 14734, 11459, 13036, 19137, 10990, 10250, 17085, 14288, 14171, 12266, 11726, 10333, 19137, 11454, 11633, 12192, 10257, 14267, 16944, 10250, 17222, 15446, 10659, 28329, 18216, 10283, 11855, 10997, 16713, 10333, 43899, 18460, 11855, 43900, 11, 9822, 12469, 16735, 10080, 9823, 11, 9822, 12605, 12509, 14862, 17222, 13091, 16747, 12983, 14734, 14136, 10080, 9823, 11, 17148, 10283, 16443, 11206, 10460, 9822, 18460, 11855, 9823, 14734, 14867, 10283, 11855, 10811, 12636, 13734, 12220, 11610, 10080, 10390, 13580, 14791, 14808, 14136, 10659, 13086, 15446, 14734, 11638, 16981, 10080, 16981, 10257, 10250, 14781, 13734, 10373, 10303, 10370, 19137, 11416, 10292, 17159, 11672, 14524, 11517, 17723, 13091, 15162, 10250, 12662, 14190, 13626, 14734, 12261, 15176, 10080, 14249, 14249, 14267, 14190, 14734, 13359, 13295, 17865, 14172, 15880, 16109, 11459, 19137, 11517, 17723, 11994, 13581, 11468, 11556, 10080, 65535, 261, 65530, 65532, 10460, 10292, 10250, 11043, 15287, 17189, 16530, 15898, 12656, 14035, 14734, 14442, 11920, 19137, 10399, 14867, 10283, 11855, 14734, 16523, 16530, 19137, 12847, 17162, 14867, 10283, 11855, 11454, 17148, 10283, 11461, 13126, 10285, 14734, 16403, 10292, 11124, 12366, 14486, 14349, 12396, 28329, 13773, 13078, 19151, 14867, 10283, 11855, 11957, 18216, 10283, 11855, 11861, 11454, 10250, 10349, 15847, 10928, 12484, 15509, 10080, 65535, 261, 65530, 65534, 14867, 10283, 11855, 14734, 16523, 16530, 19151, 11, 12605, 14791, 14808, 14249, 14249, 14267, 14190, 14734, 11517, 12154, 19137, 12366, 10285, 10655, 14015, 10333, 12476, 11158, 10080, 17148, 12232, 11517, 12154, 13091, 12605, 14734, 11920, 11423, 19137, 10444, 14446, 11454, 11885, 12604, 10333, 10250, 14313, 12228, 11585, 19137, 12605, 12631, 14256, 12459, 14734, 10250, 10769, 17311, 10392, 10305, 10250, 14165, 10080, 14136, 14218, 11454, 11633, 15090, 10285, 16982, 16962, 19137, 10411, 10459, 10278, 10447, 11679, 11606, 11454, 10335, 18043, 11035, 17359, 19137, 10260, 10768, 10434, 10405, 28329, 12605, 12509, 16944, 10333, 15640, 18459, 16735, 17141, 14734, 16713, 43899, 17148, 10303, 11638, 14734, 14136, 10859, 19137, 13734, 10370, 11098, 10429, 10353, 14794, 13091, 10254, 12203, 10333, 10080, 9823, 10390, 16735, 17148, 16713, 14734, 13064, 10560, 19137, 16728, 13655, 17384, 12172, 14808, 10250, 10273, 17093, 13247, 10080, 12609, 16684, 10390, 16525, 12348, 15847, 12144, 12145, 15486, 10323, 12506, 10333, 17148, 13324, 14734, 14146, 17843, 28329, 15646, 12605, 14862, 17222, 19137, 17148, 11016, 13091, 13156, 10838, 14734, 10720, 12034, 10250, 16530, 10080, 13006, 10283, 11517, 12154, 17311, 11021, 15752, 11454, 14179, 14218, 10285, 18034, 12675, 10079, 11115, 11057, 10079, 13188, 15480, 10901, 10292, 10306, 13191, 28329, 12605, 14791, 11047, 18216, 10283, 11855, 19137, 10390, 13580, 12379, 14808, 12669, 14188, 14256, 14734, 18293, 10384, 18293, 18200, 11647, 10257, 12831, 10258, 13234, 19137, 10277, 17149, 11349, 17384, 10080, 10390, 10441, 10308, 11891, 10675, 13734, 12669, 17148, 11461, 14146, 17843, 12307, 10250, 11414, 10336, 10080, 12609, 16684, 11454, 10390, 14791, 13234, 19137, 17148, 11016, 13091, 10250, 11461, 12522, 11630, 10080, 65535, 261, 65530, 65534, 14867, 10283, 11855, 14734, 16523, 16530, 19151, 11, 12605, 14791, 14808, 14249, 14249, 14267, 14190, 14734, 11517, 12154, 19137, 12366, 10285, 10655, 14015, 10333, 12476, 11158, 10080, 17148, 12232, 11517, 12154, 13091, 12605, 14734, 11920, 11423, 19137, 10444, 14446, 11454, 11885, 12604, 10333, 10250, 14313, 12228, 11585, 19137, 12605, 12631, 14460, 16523, 14734, 10272, 16501, 10392, 10305, 10250, 14165, 28329, 12605, 14791, 10792, 13191, 10349, 10370, 12604, 15604, 15489, 17766, 11459, 10384, 11638, 16981, 10257, 16939, 17141, 19137, 10411, 10459, 13734, 10336, 10370, 17268, 13324, 16676, 16686, 14808, 17148, 11461, 14146, 17843, 10080, 10390, 10402, 12609, 16684, 10423, 18169, 16956, 16520, 13197, 10250, 10258, 14249, 14249, 14267, 14190, 14734, 18216, 11559, 19137, 10444, 13179, 11021, 15752, 14734, 13091, 17177, 12731, 13051, 16523, 28329, 15646, 12307, 10390, 10402, 14778, 10659, 14782, 17213, 13064, 19137, 12605, 15752, 14791, 10792, 12476, 10429, 10079, 12409, 12474, 11124, 11042, 12484, 10080, 17148, 16672, 12605, 12527, 10792, 10250, 10273, 11889, 12556, 28329, 10444, 12337, 12387, 17148, 10349, 12484, 15509, 11994, 13855, 11645, 12348, 13051, 12325, 13051, 17001, 10080, 11416, 10292, 12605, 14862, 17222, 19137, 10390, 10402, 11016, 13091, 12669, 12476, 10429, 11124, 12409, 12474, 16223, 11454, 12366, 17384, 19137, 10260, 12509, 16672, 15847, 12144, 10322, 11003, 12348, 10448, 16893, 28329, 17148, 16672, 12605, 12509, 16944, 10333, 10399, 10808, 11454, 10324, 10258, 16519, 17141, 14734, 10250, 15033, 16273, 16272, 10080, 16273, 16272, 17213, 10792, 10952, 17801, 13064, 10423, 11967, 17038, 10452, 16335, 12604, 10250, 10283, 15326, 10740, 14734, 14484, 14349, 19137, 10399, 13581, 13234, 10739, 11977, 11957, 11630, 14610, 14734, 12824, 16535, 10080, 65535, 261, 65530, 65534, 14867, 10283, 11855, 14734, 16523, 16530, 59, 11, 12605, 18441, 10260, 10460, 11610, 11459, 14779, 14808, 14249, 14249, 14267, 14190, 14734, 14136, 10659, 45, 12366, 10285, 10655, 14015, 10333, 11626, 13215, 14734, 12484, 15509, 28329, 17148, 11461, 11638, 14136, 13091, 12605, 10402, 12457, 12457, 16664, 10775, 10333, 12337, 10301, 14734, 12687, 11626, 45, 11021, 10250, 14791, 10792, 11687, 13581, 12500, 14179, 14734, 13126, 16803, 45, 12605, 10383, 13191, 10349, 12430, 12499, 11124, 11044, 12462, 10305, 12522, 28329, 10444, 12605, 13179, 11632, 14734, 13091, 10966, 12670, 14808, 14734, 12348, 12522, 10080, 12605, 11124, 18216, 10283, 11855, 14734, 16664, 10775, 15480, 10339, 12348, 17192, 45, 17268, 10349, 13565, 10966, 12605, 10402, 16684, 10301, 14734, 15500, 13751, 15643, 11124, 13216, 16896, 10953, 11967, 10392, 10760, 10397, 10408, 10080, 17148, 10283, 13064, 10560, 12220, 12307, 12527, 10792, 13559, 11268, 12638, 13091, 28329, 14221, 15646, 45, 18216, 10283, 11855, 17268, 13324, 17093, 13247, 14734, 16728, 13655, 11124, 15149, 11922, 45, 17147, 13191, 10390, 11957, 14136, 14146, 11044, 14734, 10250, 10769, 12789, 11645, 13644, 10260, 11454, 10308, 14734, 13324, 11855, 45, 12421, 13091, 16672, 12605, 12527, 10792, 15847, 10928, 11124, 11645, 16109, 28329, 12605, 12202, 17916, 13734, 13191, 12509, 13764, 45, 10322, 15752, 16735, 10760, 10687, 10390, 16520, 14172, 45, 10444, 10390, 14734, 16713, 16728, 12421, 13091, 13187, 12605, 10460, 10293, 45, 15646, 12605, 10322, 11016, 13191, 18441, 18441, 14172, 11647, 28329, 12605, 12145, 15486, 10323, 12506, 10333, 10292, 10390, 17802, 16420, 11124, 10460, 17802, 10080, 11016, 13191, 11454, 17148, 13324, 13626, 14138, 10250, 10769, 14734, 13064, 10560, 45, 12605, 12638, 12527, 10792, 12605, 10402, 13091, 12200, 15169, 14734, 28329, 10444, 12605, 12145, 12509, 13078, 14731, 45, 12605, 11124, 10390, 15480, 15087, 10260, 11042, 10080, 10390, 13091, 10250, 10283, 15584, 14347, 45, 15646, 12605, 10383, 13191, 18004, 12370, 10261, 11255, 15895, 10080, 65535, 261, 65530, 65534, 18216, 10283, 11855, 14734, 12847, 17162, 16530, 12231, 11687, 10258, 59, 11, 12605, 41, 18216, 10283, 11855, 42, 11124, 12605, 14734, 11042, 10437, 18460, 11855, 41, 14867, 10283, 11855, 13020, 15217, 10285, 14734, 10370, 42, 13580, 11454, 17150, 11621, 14734, 12034, 17997, 16520, 14791, 10258, 13036, 10994, 11517, 11889, 15034, 11124, 16050, 13770, 10660, 11638, 14136, 14267, 14190, 14734, 13126, 16803, 10080, 12605, 10402, 10534, 18441, 10260, 10460, 11610, 14791, 10333, 10337, 10917, 11632, 10768, 17544, 45, 11016, 13191, 10250, 13557, 10335, 12650, 13091, 11060, 13091, 13279, 11621, 10387, 12219, 14288, 14171, 10358, 14583, 14734, 28329, 18460, 11855, 16269, 14221, 14867, 45, 10444, 14791, 10441, 12990, 12802, 10079, 13212, 12990, 10080, 10390, 14734, 13633, 10250, 10283, 10846, 10460, 17311, 12337, 17093, 12139, 28329, 12605, 11035, 11891, 18363, 15809, 11044, 16694, 10408, 17311, 12154, 17384, 14734, 11975, 12148, 11124, 11011, 11902, 16443, 14190, 13626, 45, 18460, 11855, 10779, 16718, 17728, 11902, 14869, 13091, 11060, 15752, 14267, 14190, 10080, 10444, 12605, 13734, 13191, 13580, 17919, 11414, 15178, 10390, 14734, 17728, 18025, 28329, 12605, 10402, 15507, 15511, 16520, 14136, 45, 18460, 11855, 12748, 10760, 14136, 14146, 10285, 15640, 18459, 14734, 10258, 11461, 45, 12605, 16417, 14966, 16928, 11042, 28329, 13006, 10452, 13234, 16735, 45, 12605, 11957, 18460, 11855, 13191, 15895, 11685, 14734, 16694, 10408, 10080, 10390, 13212, 12990, 15678, 12551, 45, 13633, 10250, 11012, 16713, 17311, 12663, 16503, 13191, 10838, 10080, 10390, 14734, 17728, 18025, 12609, 16694, 16686, 10322, 17311, 12337, 15287, 10733, 12202, 13191, 12261, 16689, 12415, 10080, 65535, 261, 65530, 65532, 10399, 15162, 10250, 10370, 15044, 19133, 18216, 10283, 11855, 43898, 12847, 17162, 18216, 10283, 11855, 11124, 14867, 10283, 11855, 14734, 10355, 13819, 19137, 16417, 14446, 18216, 10283, 11855, 14734, 12366, 14486, 13815, 10846, 11124, 10390, 11957, 14867, 10283, 11855, 14734, 16694, 10408, 28329, 65535, 261, 65530, 65534, 18216, 10283, 11855, 14734, 12847, 17162, 16530, 12231, 11687, 10258, 59, 11, 12605, 41, 18216, 10283, 11855, 42, 11124, 12605, 14734, 11042, 10437, 18460, 11855, 41, 14867, 10283, 11855, 13020, 15217, 10285, 14734, 10370, 42, 13580, 11454, 17150, 11621, 14734, 12034, 17997, 16520, 14791, 10258, 13036, 10994, 11517, 11889, 15034, 11124, 16050, 13770, 10660, 11638, 14136, 14267, 14190, 14734, 13126, 16803, 10080, 12605, 10402, 10534, 18441, 10260, 10460, 11610, 14791, 10333, 10337, 10917, 11632, 10768, 17544, 45, 11016, 13191, 10250, 13557, 10335, 12650, 13091, 11060, 13091, 13279, 11621, 10387, 12219, 14288, 14171, 10358, 14583, 14734, 28329, 18460, 11855, 16269, 14221, 14867, 45, 10444, 14791, 10441, 12990, 12802, 10079, 13212, 12990, 10080, 10390, 14734, 13633, 10250, 10283, 10846, 10460, 17311, 12337, 17093, 12139, 28329, 12605, 11035, 11891, 18363, 15809, 11044, 16694, 10408, 17311, 12154, 17384, 14734, 11975, 12148, 11124, 11011, 11902, 16443, 14190, 13626, 45, 18460, 11855, 10779, 16718, 17728, 11902, 14869, 13091, 11060, 15752, 14267, 14190, 10080, 10444, 12605, 13734, 13191, 13580, 17919, 11414, 15178, 10390, 14734, 17728, 18025, 28329, 12605, 10402, 15507, 15511, 16520, 14136, 45, 18460, 11855, 12748, 10760, 14136, 14146, 10285, 15640, 18459, 14734, 10258, 11461, 45, 12605, 16417, 14966, 16928, 11042, 28329, 13006, 10452, 13234, 16735, 45, 12605, 11957, 18460, 11855, 13191, 15895, 11685, 14734, 16694, 10408, 10080, 10390, 13212, 12990, 15678, 12551, 45, 13633, 10250, 11012, 16713, 17311, 12663, 16503, 13191, 10838, 10080, 10390, 14734, 17728, 18025, 12609, 16694, 16686, 10322, 17311, 12337, 15287, 10733, 12202, 13191, 12261, 16689, 12415, 10080, 65535, 261, 65530, 65532, 14313, 13619, 10285, 13191, 10745, 10447, 16530, 15898, 10760, 11461, 19156, 11, 65535, 261, 65530, 65534, 10377, 10384, 12631, 12848, 10494, 14734, 14313, 13619, 13234, 14791, 45, 14313, 13619, 10285, 10760, 11461, 14734, 10293, 16503, 16530, 15898, 10441, 10308, 11016, 13191, 10278, 10283, 59, 11, 50, 47, 33, 10250, 10283, 18216, 10283, 11855, 14734, 10811, 12636, 10080, 14313, 10285, 11967, 10390, 12847, 17162, 10292, 35, 18216, 10283, 11855, 384, 10390, 10561, 14808, 10250, 12669, 17688, 10811, 12202, 11638, 11401, 18363, 15809, 28329, 51, 47, 33, 10250, 10283, 14867, 10283, 11855, 14734, 11042, 10437, 45, 10675, 17038, 10894, 16468, 11454, 13020, 15217, 17384, 45, 15046, 10846, 13064, 10621, 14398, 10250, 13324, 17093, 14756, 28329, 14313, 13619, 10285, 13734, 13191, 17181, 17900, 17148, 10278, 10370, 14734, 10688, 10452, 17038, 10410, 12609, 15669, 10270, 45, 11016, 12847, 17162, 10390, 10402, 17912, 17912, 11459, 16520, 16917, 14808, 17150, 11621, 14179, 14218, 14249, 14249, 14734, 11517, 12154, 28329, 17148, 10278, 10370, 14734, 10342, 10846, 16417, 13078, 10390, 10402, 13091, 14782, 16696, 12145, 10301, 14734, 10422, 10437, 45, 10305, 17734, 11861, 11454, 10250, 11899, 14734, 18441, 11662, 28329, 12631, 10399, 11994, 14313, 13619, 13205, 17038, 12848, 10494, 14734, 10529, 12445, 13234, 14791, 45, 14313, 10285, 10760, 11461, 14734, 16530, 15898, 10293, 16503, 11016, 13191, 17148, 10278, 10447, 45, 10265, 13051, 13764, 12826, 13032, 10390, 10402, 14734, 10688, 10452, 15669, 10270, 28329, 12159, 13197, 10399, 10257, 10529, 12445, 15752, 12176, 10847, 10792, 12469, 10080, 15957, 13191, 10260, 16956, 10305, 11621, 17147, 16738, 12748, 13580, 10080, 65535, 261, 65530, 65532, 12847, 17162, 18216, 10283, 11855, 14734, 11630, 16815, 14332, 12333, 11124, 12415, 13327, 14332, 14172, 11, 65535, 261, 65530, 65534, 18216, 10283, 11855, 14734, 17385, 16503, 14332, 12333, 11124, 12415, 13327, 14332, 14172, 11687, 10258, 59, 11, 50, 47, 33, 11630, 16815, 18216, 11638, 10080, 14313, 13619, 10285, 11967, 10390, 12847, 17162, 10292, 9822, 18216, 10283, 11855, 28319, 13637, 10390, 14734, 11042, 10437, 14867, 10283, 11855, 13098, 16114, 18216, 11638, 28329, 51, 47, 33, 15752, 12199, 10843, 11903, 10080, 14313, 10285, 12848, 10792, 10390, 9822, 17181, 14808, 10250, 15706, 13212, 16650, 15678, 12551, 14734, 14141, 13655, 28319, 10261, 10390, 9822, 11638, 11401, 18363, 15809, 9823, 14734, 10588, 13818, 12314, 12604, 11957, 13637, 45, 16735, 13078, 10390, 12415, 13327, 11903, 17781, 15752, 12199, 28329, 52, 47, 33, 16792, 17136, 11638, 12231, 10080, 10390, 14791, 16944, 13234, 11957, 11638, 14136, 14190, 13626, 14734, 9822, 11975, 12148, 11855, 9823, 12202, 10260, 10382, 12522, 45, 10995, 15646, 16417, 14966, 9822, 12771, 11268, 13558, 11885, 10402, 14734, 9823, 28329, 53, 47, 33, 12560, 12552, 12503, 12522, 10080, 10390, 14331, 13856, 10792, 13556, 10258, 9822, 15446, 13676, 16305, 9823, 17335, 18107, 14734, 10576, 10843, 45, 13098, 14966, 10390, 14583, 13815, 17311, 14782, 12307, 11671, 10486, 28329, 54, 47, 33, 11957, 11042, 10437, 13191, 14862, 12144, 10305, 11685, 10080, 10390, 14589, 9822, 18460, 11855, 9823, 15044, 11116, 14867, 10283, 11855, 11042, 10437, 45, 13098, 14966, 10390, 10402, 12145, 13191, 13913, 10972, 10355, 12484, 28329, 55, 47, 33, 17819, 11124, 12208, 18441, 10080, 10390, 11016, 17819, 12522, 11414, 12220, 11042, 10437, 14734, 12848, 17728, 45, 12202, 12266, 14442, 15149, 16735, 9822, 12631, 13191, 15640, 18459, 9823, 17311, 13594, 11454, 11638, 14136, 10285, 28329, 56, 47, 33, 11957, 10336, 10407, 14794, 14782, 12337, 11454, 12522, 10080, 10390, 17728, 14867, 10283, 11855, 11042, 10437, 9822, 12605, 12509, 14862, 17222, 13091, 16747, 12983, 14734, 14136, 9823, 28329, 10399, 10257, 10293, 16503, 11533, 10339, 18216, 10283, 11855, 14734, 11630, 16815, 12847, 17162, 10079, 15707, 10452, 16728, 16537, 10399, 10992, 10261, 14867, 10283, 11855, 11042, 10437, 14734, 10342, 10846, 13234, 12826, 13032, 10390, 14734, 12415, 13327, 14332, 14172, 10080, 12159, 13197, 15752, 11634, 10733, 14914, 11414, 15178, 12469, 14734, 17728, 18025, 10080, 65535, 261, 65530, 65532, 12605, 17879, 16503, 14589, 8683, 24381, 59517, 15493, 10794, 14867, 10283, 11855, 14734, 11630, 16815, 19137, 33, 16738, 15494, 12605, 11957, 12220, 14734, 12848, 14966, 16702, 11, 65535, 261, 65530, 65534, 10399, 10258, 13091, 12722, 12261, 16676, 14734, 14867, 10283, 11855, 14734, 11630, 16815, 12847, 17162, 16702, 59, 11, 9828, 37347, 280, 33, 18216, 10283, 11855, 11967, 10390, 15044, 10292, 14867, 10283, 11855, 45, 16735, 13078, 10390, 17038, 13223, 12337, 14866, 11975, 28329, 9828, 29087, 1843, 280, 33, 10390, 10675, 17038, 17311, 10894, 16468, 11454, 13388, 15898, 14734, 13020, 15232, 17384, 45, 12848, 14966, 10390, 12182, 15091, 13191, 10671, 12184, 14734, 13020, 15232, 28329, 9828, 3630, 7834, 280, 33, 16269, 14221, 14867, 11975, 10444, 16403, 10846, 10621, 14398, 10250, 13324, 12990, 12802, 17140, 17193, 28329, 9828, 50469, 280, 33, 10390, 12337, 11977, 16735, 16713, 45, 15494, 10370, 14987, 15036, 14734, 12527, 16525, 28329, 9828, 36406, 38056, 280, 33, 10390, 15091, 14808, 13388, 15898, 13020, 15232, 45, 11021, 13091, 10250, 10283, 65129, 51725, 28329, 9828, 44656, 7015, 280, 33, 10390, 18441, 18441, 11459, 16520, 11940, 14808, 11638, 14136, 45, 16735, 13078, 10390, 12337, 14614, 12522, 11105, 11430, 14734, 15478, 15907, 28329, 9828, 28478, 101, 280, 33, 12002, 15202, 10260, 14914, 11899, 45, 10444, 14597, 10339, 10390, 14734, 14987, 15036, 11124, 17122, 16696, 12231, 45, 12337, 13191, 11021, 15752, 13191, 10250, 12669, 15737, 11855, 28329, 9828, 36838, 8091, 7473, 30806, 280, 33, 12002, 15202, 13734, 13191, 12847, 17162, 10390, 14734, 14806, 14815, 45, 10444, 15641, 16253, 10792, 10390, 14734, 15678, 13078, 11124, 16520, 11940, 10838, 45, 10390, 11021, 15752, 13191, 10250, 10994, 13133, 12551, 14734, 14806, 14815, 28329, 9828, 29087, 47249, 280, 33, 14597, 10339, 10390, 10675, 17038, 17311, 16468, 11454, 13020, 15232, 17384, 45, 10671, 12184, 14734, 17773, 12325, 11021, 15752, 17238, 12761, 17303, 10768, 10390, 14734, 17919, 17303, 14332, 12333, 28329, 9828, 29438, 7493, 8439, 39725, 280, 33, 12307, 18216, 10283, 11855, 12848, 10792, 35, 12631, 13191, 15640, 18459, 35, 13064, 45, 10390, 13191, 11021, 15752, 15149, 10333, 10250, 10258, 45, 10444, 15149, 11922, 17820, 16223, 11454, 13020, 15232, 10258, 45, 14987, 15036, 15646, 13191, 18248, 10838, 28329, 12159, 13197, 10399, 10257, 14734, 12847, 17162, 16702, 15752, 10847, 12469, 14583, 12604, 15158, 11038, 12985, 10336, 15478, 15907, 14734, 14867, 10283, 11855, 11630, 16815, 12314, 16803, 10080, 15957, 13191, 10260, 11038, 17172, 10305, 11621, 45, 13558, 17143, 12748, 13580, 28329, 36, 44, 24217, 59, 29945, 4164, 5608, 44816, 29850, 3662, 1313, 19589, 1511, 70, 359, 19566, 5675, 969, 65535, 261]
-> item_loss 1.3474713563919067 batch_loss 1.1245272376320579
==== [25106, 11, 65530, 65532, 13499, 11496, 17384, 13191, 10370, 11454, 10303, 19156, 11, 65535, 261, 65530, 65534, 12469, 11685, 19137, 12605, 13091, 13499, 11496, 10696, 14734, 11168, 12220, 10293, 10452, 10080, 12605, 11021, 10399, 14781, 12824, 11957, 12469, 17149, 16403, 11414, 11626, 19137, 10444, 13091, 12159, 13197, 12469, 15752, 12848, 10494, 13179, 10842, 11891, 11255, 14734, 42100, 19137, 17148, 13324, 15752, 10482, 12605, 13179, 11922, 13080, 10912, 10768, 10997, 16537, 10370, 12202, 12848, 18216, 12605, 14734, 17207, 17108, 28329, 65535, 261, 65530, 65532, 18030, 19137, 11685, 11061, 19137, 17148, 13557, 11016, 13091, 13827, 16707, 10250, 10258, 10080, 12605, 10985, 10708, 10250, 10258, 42100, 11, 65535, 261, 65530, 65534, 11685, 14734, 19137, 12605, 12337, 10310, 12522, 12824, 11002, 12469, 14734, 13827, 16707, 28329, 65535, 261, 65530, 65532, 16713, 16735, 19137, 10464, 13191, 10373, 10303, 12261, 16676, 10303, 19156, 11, 65535, 261, 65530, 65534, 12469, 10322, 16684, 11021, 10399, 11986, 16707, 10250, 10258, 11454, 15667, 11639, 10696, 11922, 10808, 10842, 10673, 10464, 15847, 12144, 14734, 16530, 15898, 19137, 13637, 11687, 35, 24281, 59, 358, 10997, 16537, 10696, 11922, 126, 33, 12609, 15643, 13091, 10293, 10370, 19151, 124, 10997, 16537, 10696, 11922, 2383, 19137, 12609, 15643, 11454, 15667, 11639, 10305, 10808, 10842, 10673, 10250, 10349, 12484, 13126, 12847, 17162, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 13091, 17148, 13324, 10303, 19156, 11, 65535, 261, 65530, 65534, 11168, 12220, 10293, 10452, 19151, 13734, 17631, 19137, 11584, 10842, 10997, 16537, 10370, 13308, 16696, 15158, 15752, 11634, 12176, 10847, 12605, 10402, 13179, 11685, 11459, 10912, 10768, 10997, 16537, 11957, 16803, 19137, 10384, 15646, 12848, 18216, 12605, 10402, 14734, 15667, 11639, 16884, 17387, 28329, 65535, 261, 65530, 65531, 40812, 59, 33, 13205, 13499, 11496, 12727, 13191, 15752, 11634, 14486, 16533, 13064, 17734, 14734, 15752, 10838, 10080, 12307, 13191, 13064, 17734, 17109, 10673, 13064, 19137, 12605, 11021, 10399, 14141, 13815, 14734, 10788, 14589, 11885, 10402, 13179, 11685, 11459, 13193, 10843, 14589, 12626, 28329, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 51, 3486, 59, 622, 59, 643, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11454, 10303, 19156, 11, 65535, 261, 65530, 65534, 5645, 59, 33, 10293, 10370, 19137, 10258, 10921, 11685, 19137, 12605, 10250, 14781, 17311, 11454, 14734, 10080, 12469, 12664, 12605, 13191, 10373, 10303, 10336, 10303, 19156, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 51, 3486, 59, 623, 59, 621, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11315, 19137, 12605, 12159, 13197, 10464, 15752, 11454, 10305, 11044, 14734, 11957, 16713, 10285, 12656, 14035, 10250, 10283, 14398, 11764, 10080, 14398, 11764, 13091, 13191, 14808, 14398, 14332, 12333, 10261, 17303, 10768, 10323, 12415, 14734, 10370, 12314, 14583, 14328, 19137, 11684, 10402, 11454, 16735, 16713, 14734, 13064, 10560, 11268, 13558, 11454, 11012, 12003, 10842, 10250, 10283, 35, 11280, 127, 35, 11860, 28329, 65535, 261, 65530, 65534, 5645, 59, 33, 13078, 14731, 10333, 10293, 10370, 19137, 14446, 11454, 12605, 13091, 10250, 10283, 14398, 11764, 10333, 11280, 127, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 51, 3486, 59, 623, 59, 635, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 10464, 12509, 16503, 10921, 14817, 10303, 19156, 11, 65535, 261, 65530, 65534, 5645, 59, 33, 12605, 13091, 10283, 10653, 13655, 14015, 14015, 14734, 14398, 11764, 11280, 127, 14446, 11454, 17147, 10260, 12509, 10921, 14817, 19137, 11416, 10292, 12605, 12509, 12176, 10257, 10293, 10370, 14734, 12379, 11280, 127, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 51, 3486, 59, 624, 59, 620, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 18030, 19137, 13091, 11416, 10292, 10464, 13091, 13212, 11369, 10370, 10260, 17879, 16503, 14817, 16525, 19137, 12631, 10399, 12638, 17148, 10303, 16735, 14734, 10303, 19156, 11, 65535, 261, 65530, 65534, 5645, 59, 33, 10260, 14862, 17222, 10293, 10370, 11454, 16735, 10373, 10303, 11102, 11280, 127, 11687, 13258, 12605, 13091, 12656, 12604, 14398, 11764, 14734, 13212, 11369, 10370, 14734, 16713, 19137, 15713, 11899, 13091, 10260, 14589, 14817, 16525, 14734, 11280, 2411, 10444, 13091, 12605, 13091, 10250, 10283, 14398, 11764, 19137, 12509, 16503, 14817, 16525, 14734, 13064, 10560, 10423, 10985, 14817, 14734, 11280, 127, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 51, 3486, 59, 624, 59, 637, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11164, 11164, 19137, 12605, 14862, 17222, 10333, 28329, 65535, 261, 65530, 65534, 5645, 59, 33, 11280, 11354, 11354, 127, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 51, 3489, 59, 622, 59, 674, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11315, 43282, 11685, 10621, 17147, 13734, 15494, 10464, 16944, 11043, 11860, 19137, 10464, 11994, 11017, 8227, 112, 10333, 19137, 8227, 112, 19137, 11454, 10303, 19156, 11, 65535, 261, 65530, 65534, 5645, 59, 33, 11454, 14734, 11280, 127, 11685, 10621, 12145, 15486, 13091, 10258, 10921, 10333, 11102, 10080, 8227, 112, 10780, 10780, 14817, 11891, 10250, 16525, 19137, 17819, 13064, 11021, 10399, 15494, 10293, 10370, 12176, 12379, 11280, 127, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 51, 3489, 59, 623, 59, 636, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 10589, 13579, 12656, 14035, 14398, 11764, 11061, 19137, 8227, 112, 14734, 11043, 11860, 10525, 14614, 28329, 65535, 261, 65530, 65534, 5645, 59, 33, 11685, 14734, 10293, 10370, 19137, 12605, 14446, 11454, 10589, 13579, 12656, 14035, 19137, 13191, 10373, 10303, 10336, 12484, 10303, 19156, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 51, 3489, 59, 624, 59, 621, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 4682, 1997, 11, 65535, 261, 65530, 65534, 5645, 59, 33, 10293, 10370, 19137, 12605, 11454, 28329, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 51, 3489, 59, 624, 59, 632, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 10464, 16525, 12348, 12605, 13091, 10283, 12401, 13324, 14734, 10370, 19156, 11, 65535, 261, 65530, 65534, 5645, 59, 33, 10293, 10370, 11994, 13091, 10293, 10370, 19137, 13091, 12605, 13193, 10843, 14734, 11957, 16803, 10080, 12605, 12202, 10260, 12727, 13191, 10293, 16520, 12522, 16696, 19137, 12631, 10399, 12202, 10260, 10423, 11957, 10358, 14583, 18030, 11630, 14734, 16694, 10408, 10261, 14791, 13764, 10080, 11687, 13258, 10293, 10370, 17879, 16503, 12605, 16417, 14446, 10760, 17148, 13036, 17919, 14734, 14332, 12415, 19137, 11021, 10399, 10538, 12981, 12605, 14734, 16689, 11899, 12609, 13091, 11047, 12605, 12848, 10760, 16503, 13685, 28329, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 51, 3490, 59, 620, 59, 621, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11315, 19137, 12605, 14486, 16533, 10333, 19137, 17268, 12605, 17879, 16503, 10464, 14446, 11454, 11003, 12348, 10370, 12415, 10901, 10250, 14172, 10080, 10688, 10452, 10792, 10373, 10303, 15052, 12231, 10464, 15847, 12144, 12669, 12853, 28329, 65535, 261, 65530, 65534, 5645, 59, 33, 12605, 13078, 14731, 10333, 19137, 10293, 10370, 10080, 10460, 10292, 8227, 112, 19137, 10293, 10370, 11957, 10339, 12605, 13234, 16735, 11994, 10621, 10366, 11930, 14734, 13192, 10993, 10250, 13324, 19137, 12605, 12337, 11268, 13558, 10293, 10370, 10080, 17147, 13191, 10293, 10370, 10464, 10780, 10780, 16672, 12605, 12656, 14035, 10250, 10283, 14398, 11764, 19137, 17148, 16672, 12605, 15053, 12359, 13191, 10250, 14172, 14172, 11917, 15600, 19137, 10260, 17141, 12605, 12337, 12537, 12522, 10292, 10293, 10370, 12656, 14398, 11764, 10080, 10293, 10370, 19137, 17148, 13324, 14734, 15052, 12231, 11021, 10399, 11053, 19156, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 51, 3490, 59, 620, 59, 641, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 12771, 10260, 17631, 14734, 28329, 65535, 261, 65530, 65534, 5645, 59, 33, 11685, 19137, 17268, 12605, 11994, 10525, 12746, 17148, 10283, 14349, 12396, 11235, 28329, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 52, 291, 59, 630, 59, 621, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 13057, 10257, 11685, 28329, 65535, 261, 65530, 65534, 5645, 59, 33, 13057, 10257, 11685, 19137, 10293, 10370, 10080, 13089, 13115, 10293, 10370, 13734, 13191, 12664, 12605, 16735, 16713, 13191, 10250, 14172, 11975, 11927, 11939, 11102, 19137, 17879, 16503, 12605, 10292, 12469, 12848, 10494, 10250, 10349, 13057, 18069, 14734, 12261, 16676, 10303, 19156, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 52, 291, 59, 630, 59, 636, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11223, 12691, 13571, 12691, 13571, 19137, 13089, 13115, 13191, 14172, 10336, 10080, 58, 14172, 13191, 10283, 10423, 19137, 13057, 18069, 12605, 12387, 18069, 10384, 15190, 10333, 19137, 14778, 10808, 13734, 13191, 17879, 16503, 10464, 12176, 12379, 14734, 28329, 65535, 261, 65530, 65534, 5645, 59, 33, 11957, 10260, 16944, 19137, 10293, 10370, 19137, 10441, 10308, 12605, 13499, 12722, 14734, 12527, 12484, 16672, 12469, 11426, 12658, 10333, 10080, 10687, 11903, 12605, 13734, 13191, 13064, 17734, 13819, 17191, 14734, 13445, 12389, 19137, 12631, 10399, 12202, 10260, 10423, 11927, 11939, 19137, 10293, 10370, 10260, 12368, 10292, 13581, 10696, 14643, 10080, 12605, 10305, 11044, 10423, 16417, 14446, 12348, 13179, 11685, 14734, 28329, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 52, 291, 59, 630, 59, 675, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 12605, 14486, 16533, 10333, 19137, 11957, 10339, 14446, 11454, 14734, 10464, 12605, 12771, 14015, 12522, 14734, 10080, 11957, 10333, 8227, 112, 19137, 10464, 14794, 14734, 16667, 10292, 10464, 13734, 13191, 12484, 12527, 11124, 10370, 13327, 10303, 19156, 11, 65535, 261, 65530, 65534, 5645, 59, 33, 11907, 16520, 13234, 16679, 13091, 17148, 13324, 14734, 19137, 12605, 14734, 16728, 16537, 13091, 13326, 12797, 12469, 14734, 17879, 13685, 10495, 13445, 14426, 17109, 10760, 14734, 19137, 12605, 14734, 16403, 10292, 13499, 12276, 13205, 16884, 10257, 13091, 13499, 10411, 10261, 12656, 14035, 28329, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 52, 291, 59, 633, 59, 636, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 17268, 10580, 16689, 10464, 10250, 14781, 15516, 12746, 12307, 10808, 17148, 10283, 16403, 10292, 13499, 12276, 19137, 12202, 10265, 10409, 10454, 10370, 17311, 10260, 14862, 17222, 10464, 13091, 11454, 13499, 10411, 10261, 12656, 14035, 11102, 19156, 11, 65535, 261, 65530, 65534, 5645, 59, 33, 17148, 13324, 13234, 16679, 19137, 12605, 11021, 15752, 10423, 16443, 10390, 10370, 16667, 10292, 13091, 10250, 10283, 12727, 13191, 12484, 12527, 12609, 10370, 13327, 14734, 10283, 10452, 10080, 10444, 13091, 19137, 10384, 12605, 14734, 14862, 16696, 10760, 10997, 19137, 12605, 12202, 10260, 15752, 12527, 11002, 10792, 15847, 12605, 28329, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 52, 291, 59, 634, 59, 667, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 17268, 12605, 11687, 13258, 16735, 10464, 10780, 12638, 17148, 13619, 17109, 10760, 13091, 10384, 11685, 10745, 13557, 17109, 10760, 10285, 12752, 17177, 10760, 13234, 14734, 10250, 10283, 19137, 15646, 11454, 10687, 10390, 14734, 17109, 10760, 10285, 19137, 10464, 13191, 12665, 16667, 15752, 12527, 11002, 10792, 15847, 12605, 14734, 11903, 10487, 11102, 19156, 11, 65535, 261, 65530, 65534, 5645, 59, 33, 11687, 13258, 10336, 11903, 10261, 10464, 12631, 16735, 10250, 15850, 19137, 17268, 10303, 11021, 10399, 16692, 13078, 12605, 10780, 12638, 14734, 10997, 16537, 10260, 10250, 11899, 14794, 11903, 19137, 10444, 13091, 11042, 13324, 12605, 10322, 13051, 13764, 10784, 13032, 10464, 14734, 10997, 16537, 13091, 11060, 10292, 10336, 11903, 28329, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 52, 291, 59, 638, 59, 624, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 10464, 13191, 13734, 13191, 10997, 14446, 19137, 15847, 12144, 14446, 11454, 14734, 10997, 16537, 13191, 14172, 17151, 15727, 9822, 11003, 12348, 10370, 12415, 10901, 10250, 14172, 9823, 14734, 16503, 13685, 11102, 19156, 11, 65535, 261, 65530, 65534, 5645, 59, 33, 11903, 11454, 11957, 10260, 16944, 10293, 10370, 19137, 12605, 13191, 14172, 12378, 10333, 43282, 10260, 17141, 12605, 17147, 13091, 12159, 13197, 15752, 11454, 11124, 10293, 10370, 16671, 16686, 14734, 13064, 10560, 12002, 11021, 15752, 14734, 17109, 10760, 14794, 11903, 14734, 10529, 12445, 28329, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 52, 291, 59, 639, 59, 621, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11315, 19137, 12605, 13734, 13191, 11454, 16879, 11622, 10464, 19137, 10464, 12220, 16721, 10322, 10997, 14446, 10333, 19137, 15847, 12144, 13091, 15752, 11634, 13326, 12797, 14446, 14349, 14370, 13032, 14734, 16749, 13006, 16403, 10292, 14734, 10080, 15646, 10265, 10464, 16503, 13078, 14731, 19137, 10250, 10283, 10370, 15261, 10322, 13051, 13764, 16692, 13078, 11013, 11630, 10250, 10283, 10370, 15261, 12727, 13191, 9822, 15847, 12605, 9823, 10080, 12631, 10399, 11957, 10339, 10464, 13091, 11060, 12727, 13191, 12484, 12527, 11124, 10370, 13327, 19137, 12609, 13091, 15847, 12605, 12522, 16696, 17148, 10283, 17728, 18025, 19137, 13734, 13191, 10370, 15752, 10258, 10733, 14914, 14734, 11899, 10304, 28329, 65535, 261, 65530, 65534, 5645, 59, 33, 12605, 13078, 14731, 10464, 14734, 12522, 12410, 10333, 19137, 10293, 10370, 10080, 10293, 10370, 13091, 12509, 16735, 16671, 16686, 13091, 11060, 10688, 13191, 15847, 12605, 12522, 16696, 17148, 10283, 16713, 18025, 11957, 10339, 12605, 15646, 16537, 12202, 10260, 17385, 16503, 19137, 17385, 16503, 14734, 13091, 12605, 11957, 10339, 10687, 10390, 10370, 13234, 16735, 13091, 10373, 10303, 13324, 14734, 11861, 11454, 19137, 11957, 11061, 19156, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 52, 291, 59, 639, 59, 639, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11638, 10452, 10257, 13091, 17148, 13324, 14734, 28329, 65535, 261, 65530, 65534, 5645, 59, 33, 11685, 14734, 19137, 10293, 10370, 19137, 12605, 10423, 10250, 14781, 17802, 11454, 10464, 17038, 17131, 14734, 10080, 13191, 10336, 16678, 12348, 12664, 12605, 11183, 19126, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 52, 291, 59, 665, 59, 671, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 16713, 16735, 8227, 112, 19137, 10464, 14862, 17222, 12401, 10303, 17332, 10250, 11022, 15752, 12849, 53, 16981, 5960, 14734, 11022, 12276, 13212, 10303, 19156, 11, 65535, 261, 65530, 65534, 5645, 59, 33, 10293, 10370, 19137, 10464, 11021, 15752, 17879, 16503, 10250, 10283, 15849, 11977, 13191, 53, 10283, 6411, 46, 48495, 12849, 13485, 14734, 10293, 13248, 10079, 10250, 10283, 15752, 11634, 11621, 14486, 11638, 17387, 13004, 12797, 11124, 17144, 15200, 14734, 5704, 10079, 10261, 5960, 14734, 1555, 824, 14782, 12307, 14734, 10696, 11861, 10399, 10992, 10250, 10283, 15752, 11634, 14914, 10525, 53, 16981, 5960, 17311, 13580, 12182, 17144, 16403, 14734, 14600, 13981, 10080, 13581, 11630, 19137, 14597, 10339, 53, 16981, 5960, 14734, 15752, 15651, 17097, 11638, 19137, 10293, 10370, 11021, 15752, 17879, 16503, 11454, 13001, 14195, 16689, 11622, 10257, 10258, 14172, 10841, 11641, 28329, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 52, 291, 59, 669, 59, 671, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11315, 19137, 12605, 11638, 13445, 10333, 16533, 10333, 28329, 65535, 261, 65530, 65534, 5645, 59, 33, 11685, 14734, 10293, 10370, 19137, 10305, 11044, 13191, 15478, 15907, 10260, 13078, 14731, 11021, 10399, 15507, 15511, 17728, 12605, 10080, 11957, 10333, 19137, 14446, 11454, 17147, 13191, 11638, 13445, 630, 10768, 17544, 11994, 16503, 10792, 10293, 10370, 10423, 16676, 14734, 13064, 17734, 10333, 19137, 10293, 10370, 10260, 16503, 12378, 10333, 10733, 11622, 10423, 16676, 14734, 10336, 12484, 11183, 28329, 65535, 261, 65530, 65531, 40812, 59, 33, 12307, 10808, 13064, 17734, 19151, 640, 643, 48, 54, 48, 52, 291, 59, 670, 59, 620, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 12605, 17311, 12145, 15486, 10733, 11622, 11685, 10333, 19137, 13580, 11685, 13191, 14172, 13064, 17734, 19137, 12605, 12509, 11957, 10464, 10588, 10283, 13827, 16707, 19137, 14589, 42114, 10708, 10283, 12387, 17193, 12814, 12217, 10397, 14875, 11061, 19137, 13773, 17382, 14589, 10464, 14446, 11454, 16735, 16713, 14734, 18043, 13327, 28329, 65535, 261, 65530, 65534, 5645, 59, 33, 11685, 14734, 10293, 10370, 28329, 6884, 42114, 11, 7334, 39418, 96, 27052, 41, 7046, 501, 28352, 5170, 10293, 10370, 11021, 10399, 14589, 17148, 10283, 10397, 14875, 13234, 15494, 13004, 15476, 10384, 11975, 10792, 11638, 12814, 12217, 19137, 7046, 13091, 12335, 12814, 12217, 14734, 13004, 15476, 5170, 54807, 36, 33, 11687, 13258, 17109, 10673, 13004, 15476, 10292, 15090, 12609, 15643, 17688, 12231, 10292, 50, 19137, 11994, 13734, 12368, 16503, 15507, 15511, 15200, 11235, 19137, 14781, 12824, 17146, 11414, 28352, 1942, 21998, 41, 7046, 42, 295, 285, 59, 54807, 42178, 21290, 54807, 36, 33, 10293, 10370, 19137, 35387, 13091, 10250, 10283, 11533, 10733, 10653, 15323, 28352, 35387, 296, 21290, 92, 49, 94, 54807, 36, 33, 17148, 10278, 10283, 15200, 12276, 10423, 12669, 13004, 15476, 10285, 11975, 10339, 11533, 10733, 10653, 15323, 14734, 13004, 12983, 11454, 12138, 17131, 19137, 11638, 10339, 11533, 10733, 10653, 15323, 14734, 13004, 12983, 11454, 11025, 17131, 28352, 26118, 296, 326, 106, 21700, 340, 4596, 21290, 92, 50, 737, 4588, 340, 3586, 39288, 94, 28352, 35551, 296, 326, 106, 21700, 340, 4596, 21290, 92, 50, 737, 4588, 340, 297, 39288, 94, 54807, 36, 33, 14221, 11044, 12605, 10402, 17879, 16503, 11957, 11533, 10733, 10653, 15323, 12138, 11025, 14734, 10278, 10283, 13004, 15476, 17184, 12306, 12650, 16403, 12387, 17193, 12814, 12217, 28352, 42284, 96, 26118, 296, 39418, 96, 27052, 41, 26118, 42, 28352, 42284, 96, 35551, 296, 39418, 96, 27052, 41, 35551, 42, 54807, 36, 33, 13188, 11044, 12669, 12814, 12217, 11044, 14734, 12138, 13004, 15476, 10079, 11533, 10733, 10653, 15323, 11124, 11025, 13004, 15476, 12742, 11454, 10250, 16944, 17146, 11414, 11994, 11021, 10399, 12348, 10792, 15489, 13258, 10333, 28352, 42178, 47338, 96, 26118, 278, 326, 35387, 94, 278, 47338, 96, 35551, 11, 6884, 11, 10293, 10370, 19137, 10399, 10257, 13091, 12387, 17193, 12814, 12217, 15200, 13764, 14734, 42114, 10397, 14875, 10080, 12605, 11454, 10525, 14614, 13773, 17382, 11021, 16742, 12415, 14734, 11042, 13064, 16672, 11885, 10402, 13179, 10621, 13091, 12605, 16735, 10760, 13234, 14734, 16713, 10080, 12159, 13197, 10464, 15752, 11268, 13558, 10080, 65535, 261]
-> item_loss 0.7434132099151611 batch_loss 1.0927677353223164
==== [25106, 11, 65530, 65531, 772, 640, 643, 47, 55, 47, 639, 33, 13205, 13499, 11496, 14446, 14349, 772, 11, 10460, 10292, 13499, 11496, 10293, 10452, 19137, 11957, 10339, 13499, 11496, 14446, 14349, 10588, 10760, 10250, 10349, 12421, 15489, 10080, 12605, 11454, 17148, 13619, 13064, 17734, 10696, 12824, 12979, 10792, 10333, 10250, 12662, 16728, 13021, 19137, 10687, 10696, 11922, 10894, 12732, 11957, 10339, 11630, 17303, 12824, 11010, 14734, 10482, 14589, 10079, 11124, 10370, 15261, 10355, 13819, 10399, 10992, 11632, 10370, 11957, 16713, 15169, 10696, 11922, 10080, 10384, 17148, 10349, 16728, 13021, 10285, 11021, 10399, 14791, 10760, 10293, 10370, 12159, 13197, 12605, 15752, 11634, 11871, 10323, 10792, 14782, 12220, 14734, 15752, 10838, 19137, 10384, 15646, 13179, 15847, 14221, 11459, 11124, 10370, 15261, 10355, 13819, 10079, 13179, 10733, 14914, 14734, 11891, 12604, 10409, 10843, 10080, 11454, 10261, 15304, 15500, 10355, 10342, 14734, 17141, 15052, 10285, 19137, 12605, 17879, 16503, 15287, 10733, 14734, 13326, 12797, 16521, 10779, 17149, 16403, 12945, 10460, 19137, 11042, 13064, 15641, 16253, 10293, 10370, 14734, 17879, 13685, 19137, 12202, 10588, 10760, 17177, 12731, 19152, 11124, 10370, 15261, 10355, 13819, 14734, 17141, 15052, 10285, 19137, 12605, 12220, 12307, 16672, 16417, 17136, 13179, 10842, 15847, 14221, 10080, 14778, 10808, 12605, 17147, 13051, 13764, 12811, 12853, 13179, 10842, 15847, 14221, 14734, 16417, 17136, 13036, 12276, 19137, 11454, 11044, 15511, 17147, 17879, 16503, 17149, 16403, 11871, 10323, 19137, 12368, 16503, 14734, 13064, 10560, 11021, 10399, 11047, 10370, 15261, 16718, 17728, 28329, 17136, 12604, 17148, 10278, 10283, 14778, 13308, 13637, 17097, 11426, 17843, 19137, 10260, 17141, 10460, 10292, 10250, 10283, 820, 19137, 12605, 10423, 10848, 10838, 11459, 10985, 11986, 16707, 10588, 10792, 28329, 10293, 10370, 10441, 10308, 16735, 17141, 11044, 15511, 10423, 16672, 12605, 10482, 14589, 10250, 10349, 10762, 13004, 12824, 11010, 19137, 12609, 15643, 17189, 17141, 14328, 15671, 15573, 12825, 10794, 10250, 10349, 13212, 13375, 12609, 11920, 12010, 19137, 11042, 13064, 10652, 16684, 12605, 11957, 15847, 12144, 17109, 10673, 16728, 13021, 17149, 16403, 16675, 15475, 10080, 11454, 11044, 15511, 17213, 10792, 14782, 10684, 14862, 16696, 14734, 13064, 10560, 12605, 12609, 16684, 17879, 16503, 14614, 12522, 19137, 13581, 11630, 10684, 10339, 16503, 17171, 10673, 11632, 11977, 13004, 12797, 10792, 12605, 14734, 13499, 11496, 17384, 10322, 16684, 17147, 13091, 16503, 12664, 10293, 10370, 11143, 16718, 10250, 10258, 10080, 65535, 261, 65530, 65531, 10464, 13091, 10250, 10283, 820, 10847, 12636, 19137, 10423, 12824, 11002, 14589, 12626, 14734, 17109, 10673, 12202, 15494, 10760, 17172, 12307, 14734, 11414, 11626, 28329, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 11454, 10303, 11, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 11454, 14734, 19137, 16738, 17728, 13191, 10373, 10303, 10336, 10303, 19156, 11, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 17147, 16678, 12348, 15847, 12144, 13091, 16747, 10303, 19156, 11, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 12307, 14221, 16678, 12348, 10080, 12605, 13091, 10464, 14734, 820, 10847, 12636, 19137, 10423, 11414, 12220, 10464, 14734, 17109, 10673, 28329, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 11315, 19137, 13091, 14734, 19137, 12605, 12669, 11920, 17384, 14734, 12631, 13191, 11920, 12010, 17311, 10355, 15494, 10464, 15202, 14486, 13734, 17728, 18025, 11061, 19156, 11, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 12605, 12261, 16676, 12469, 11454, 17148, 10303, 10588, 10305, 10808, 14914, 10525, 12605, 14734, 12826, 14486, 10733, 14914, 14426, 19137, 10260, 14221, 11021, 15752, 10423, 11960, 15850, 10260, 11021, 18009, 14862, 14734, 11044, 13258, 10080, 10460, 10292, 820, 19137, 12605, 10423, 12002, 11021, 15752, 10525, 16692, 10260, 10588, 10293, 10370, 11117, 10398, 10305, 11630, 14734, 10336, 12484, 19137, 10399, 10525, 16692, 11889, 10675, 12415, 10080, 10444, 13091, 19137, 16738, 12469, 13773, 12522, 19137, 17148, 10349, 17311, 12261, 15123, 11454, 12605, 14734, 12826, 14486, 16956, 11634, 15287, 10733, 14734, 10808, 12848, 10258, 19137, 11687, 13258, 12605, 13734, 13191, 16956, 11634, 14734, 15752, 10838, 13234, 15202, 14486, 11630, 17303, 15304, 15500, 11994, 16002, 14426, 14734, 10460, 10760, 10722, 11899, 19137, 10423, 11960, 15850, 10260, 11021, 18009, 16664, 14734, 17728, 18025, 10997, 14583, 28329, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 10464, 16667, 10292, 10464, 14446, 11454, 13091, 11060, 13191, 16956, 11634, 14734, 15752, 10838, 19156, 11, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 12337, 12691, 13571, 19137, 12605, 13051, 13764, 11891, 10675, 14914, 16667, 28329, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 10464, 10435, 13827, 10250, 10258, 11061, 11, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 13326, 12797, 12605, 10402, 14734, 15667, 11639, 10964, 11024, 19137, 12605, 15752, 11634, 11124, 12469, 17149, 16403, 13191, 17207, 17108, 14734, 11957, 16713, 19137, 17148, 12522, 11110, 14808, 12605, 11021, 15752, 16956, 10399, 11891, 12604, 15190, 10932, 10409, 10843, 10080, 10260, 17141, 11957, 10339, 11626, 13215, 14734, 10409, 10843, 19137, 12605, 17147, 13091, 12159, 13197, 10293, 10370, 15752, 11634, 11454, 11957, 12605, 17149, 16403, 13827, 16707, 11044, 10703, 10722, 11899, 28329, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 11685, 14734, 19137, 12605, 15190, 10932, 13827, 16707, 10258, 10080, 12605, 17728, 10464, 10745, 10283, 17728, 18025, 11061, 19137, 18117, 10658, 19151, 11687, 13258, 12605, 16735, 12605, 12527, 16525, 12337, 14195, 19137, 15752, 11634, 12945, 10460, 15304, 15500, 14734, 10464, 10423, 10588, 10349, 10373, 10303, 19156, 11, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 10322, 16684, 12605, 10423, 17177, 12731, 12176, 12469, 12642, 12266, 15090, 16749, 12202, 16749, 15849, 10794, 10726, 13499, 12276, 12609, 15643, 12669, 15102, 12165, 12983, 10258, 15169, 28329, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 13734, 13191, 17728, 18025, 19137, 10464, 16667, 10292, 11920, 17384, 11187, 10349, 10272, 16501, 17172, 11038, 15494, 10464, 13234, 15202, 14486, 19156, 11, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 12605, 16667, 10292, 15102, 12165, 10079, 15090, 16749, 10079, 14195, 13676, 11369, 10079, 14600, 16523, 10079, 14600, 14139, 10399, 10992, 17952, 15209, 15169, 16689, 11622, 17172, 11038, 10355, 15494, 12605, 15202, 14486, 10080, 15646, 14600, 15763, 10079, 14267, 13655, 14142, 11124, 17723, 15002, 15169, 16689, 11622, 10260, 17172, 11038, 10355, 15494, 12605, 15202, 14486, 19137, 11416, 10292, 17148, 10349, 16689, 11622, 11454, 15202, 14486, 10260, 12307, 13064, 10423, 11957, 10370, 15261, 17194, 12604, 12789, 11645, 12609, 10952, 11917, 28329, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 14589, 13179, 10842, 10621, 10370, 15261, 14734, 16728, 13655, 10703, 11414, 15178, 10250, 17216, 12605, 10780, 12638, 17148, 10283, 17728, 18025, 28329, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 12605, 16667, 10292, 10293, 10370, 11021, 10399, 16672, 12605, 12825, 10794, 15102, 12165, 10079, 15090, 16749, 10079, 14195, 13676, 11369, 10079, 14600, 16523, 10079, 14600, 14139, 10399, 10992, 17952, 15209, 15169, 16689, 11622, 19137, 15646, 14600, 15763, 10079, 14267, 13655, 14142, 11124, 17723, 15002, 15169, 16689, 11622, 10779, 10260, 12220, 16721, 10355, 15494, 12605, 15202, 14486, 10080, 12605, 10260, 12509, 19137, 10322, 10260, 12220, 16721, 11957, 10293, 10370, 13191, 14059, 11454, 11753, 15723, 28329, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 12605, 16503, 11687, 10454, 16672, 10464, 11903, 14446, 12825, 10794, 17148, 10349, 16689, 11622, 11102, 19156, 11, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 10293, 10370, 11021, 10399, 16707, 14808, 16672, 15304, 15500, 16696, 10790, 12605, 11414, 11626, 10285, 14734, 14332, 11899, 11860, 15158, 19137, 13234, 16749, 14589, 11036, 15033, 16689, 11622, 14734, 12824, 11010, 19137, 13637, 11687, 12307, 12605, 14734, 11414, 11626, 10285, 10894, 11064, 393, 12266, 11068, 15090, 16749, 1678, 13064, 19137, 10953, 11021, 12642, 12266, 15090, 16749, 28329, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 13078, 14731, 10333, 19137, 12605, 12642, 15200, 12669, 11920, 17384, 15752, 15494, 10464, 12825, 10794, 14734, 10272, 16501, 17311, 10355, 15494, 10464, 12825, 10794, 28329, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 12605, 12202, 10260, 13091, 12337, 12261, 16676, 12469, 17148, 10303, 10588, 43282, 11, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 13734, 10684, 15304, 19137, 17311, 13091, 13637, 17097, 11889, 10675, 14734, 10272, 16501, 28329, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 13078, 14731, 10333, 19137, 12605, 10423, 11986, 16707, 14486, 16533, 10293, 10370, 14734, 17879, 13685, 19137, 17189, 17141, 12945, 10460, 11920, 12010, 16689, 11622, 13234, 12002, 11021, 15752, 10292, 10293, 10370, 12172, 13234, 10511, 10788, 10080, 11042, 13064, 19137, 10260, 10588, 16947, 10760, 820, 12220, 13191, 13216, 17789, 14734, 10336, 12484, 19137, 17248, 10662, 10292, 10293, 10370, 12172, 13234, 11426, 12658, 28329, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 11315, 19137, 12605, 10985, 15494, 10464, 10708, 16735, 13078, 10325, 28329, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 11685, 14734, 19137, 12605, 10423, 11454, 17148, 17384, 15169, 14808, 12469, 28329, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 11957, 10333, 19137, 11687, 13258, 12605, 16735, 12605, 16721, 14817, 10333, 19137, 10464, 11021, 15752, 10423, 10588, 10349, 10373, 10303, 19156, 11, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 12605, 11021, 15752, 10423, 13381, 13290, 10250, 10258, 14600, 14139, 14734, 14349, 12396, 19137, 11687, 13258, 13734, 13191, 10684, 17727, 19137, 10423, 12176, 12469, 10684, 17727, 10080, 12609, 15643, 12176, 12469, 12669, 15090, 16749, 14734, 18043, 10838, 16749, 11975, 28329, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 15678, 13078, 10080, 12605, 12337, 12509, 14862, 17222, 10464, 15752, 10588, 10792, 11124, 10370, 15261, 13191, 11632, 10303, 14782, 10441, 28329, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 16774, 16774, 11649, 11665, 19126, 11687, 13258, 12509, 14862, 17222, 12605, 15752, 11634, 10588, 10792, 10261, 10370, 15261, 13191, 11632, 10303, 14782, 10441, 19137, 11021, 10399, 17189, 17141, 11124, 12605, 11957, 16713, 13234, 17149, 16403, 13827, 16707, 10080, 10260, 17141, 12605, 10260, 12261, 16676, 12469, 12691, 11640, 11638, 13199, 13197, 19137, 11416, 10292, 12605, 14778, 10808, 11016, 15752, 12824, 11002, 16728, 16537, 17109, 10673, 19137, 15646, 10370, 15261, 12527, 11897, 13191, 12337, 11632, 15033, 19137, 12631, 10399, 16672, 12605, 11891, 10675, 14486, 16533, 10370, 15261, 13091, 13637, 17097, 11426, 17843, 14734, 28329, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 11685, 14734, 19137, 17268, 10303, 13827, 16707, 12266, 11726, 19137, 10258, 10921, 11685, 28329, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 11315, 11315, 19137, 10258, 10921, 11685, 28330, 12605, 13078, 14731, 10333, 19137, 12824, 10258, 13234, 12605, 10423, 11986, 16707, 16672, 15847, 12144, 14734, 16417, 17136, 11124, 10370, 15261, 12002, 11021, 15752, 14782, 10441, 42, 11, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 15847, 12605, 10382, 15484, 10258, 28329, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 11315, 19137, 12605, 11017, 14299, 10295, 19137, 11124, 10464, 14734, 12201, 18476, 14782, 10411, 19137, 12200, 12182, 11268, 13558, 16742, 10325, 19137, 12159, 13197, 12605, 10402, 15752, 15667, 12348, 12266, 12366, 10080, 19133, 12605, 11986, 16707, 16256, 13250, 10333, 10250, 10283, 16530, 15898, 19137, 11687, 13258, 10293, 10370, 10260, 11268, 13558, 19137, 11021, 10399, 11124, 12605, 16735, 19137, 12605, 10423, 17149, 16403, 16749, 13006, 19134, 11, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 12605, 14446, 11454, 13734, 10373, 10303, 10336, 12199, 19137, 12605, 10402, 11021, 10399, 10985, 10588, 10349, 10373, 10303, 28329, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 10322, 16684, 12605, 10402, 11021, 10399, 10985, 13001, 13582, 19137, 12609, 15643, 14442, 10349, 13953, 12603, 10080, 10464, 12200, 12182, 11268, 13558, 10588, 10373, 10303, 19156, 11, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 10250, 15880, 10423, 11454, 14600, 15763, 10808, 12642, 12642, 13953, 12603, 19137, 12609, 15643, 10708, 10397, 14875, 28329, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 11315, 43282, 19133, 18030, 19137, 10293, 10370, 19137, 12605, 11957, 10339, 13953, 12603, 14734, 14486, 16533, 10377, 17789, 10339, 17109, 10673, 16728, 13021, 17384, 17919, 14734, 12847, 17162, 19137, 12202, 13734, 13191, 14794, 13580, 14442, 17141, 19137, 11021, 15752, 13734, 13764, 16672, 12469, 14015, 12522, 19134, 11, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 13734, 10684, 15304, 19137, 12656, 14035, 11994, 10792, 17148, 17384, 11061, 28329, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 11685, 14734, 19137, 17147, 13191, 10373, 10303, 10336, 12484, 12605, 11021, 10399, 12176, 12469, 11053, 19156, 11, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 10464, 14862, 17222, 13594, 10353, 13091, 10373, 10303, 11053, 19156, 11, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 13326, 12797, 12605, 14734, 14862, 16696, 19137, 13594, 10353, 10953, 13091, 10260, 10703, 11861, 11454, 10339, 17148, 10283, 10267, 14610, 10257, 19137, 10384, 10687, 10390, 10370, 14734, 16667, 14862, 10285, 13855, 11645, 10080, 10260, 17141, 19137, 10370, 15261, 14778, 10808, 11957, 10339, 13594, 10353, 14734, 14486, 16533, 10383, 14221, 11861, 11454, 12005, 17789, 12415, 19137, 11416, 10292, 13594, 10353, 13091, 12337, 17843, 16520, 13827, 14734, 14446, 16803, 19137, 12631, 10399, 10687, 11638, 17303, 10768, 14734, 10696, 11922, 17147, 13091, 13203, 14862, 14734, 14349, 12396, 28329, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 11687, 13258, 12605, 12669, 10464, 14734, 13499, 11496, 10783, 17798, 19137, 12522, 11110, 14808, 10373, 10303, 19156, 11, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 10384, 13445, 12389, 10257, 13234, 16679, 19137, 10261, 13594, 10353, 14734, 14446, 16803, 12337, 14782, 10441, 28329, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 17268, 10464, 10423, 11042, 12522, 12605, 10783, 17798, 10464, 14734, 13499, 11496, 10303, 19156, 11, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 11687, 13258, 17879, 16503, 14734, 16713, 19137, 12605, 10423, 11042, 12522, 10080, 12605, 13091, 10250, 10283, 820, 19137, 13734, 13191, 15847, 12605, 19137, 11016, 13091, 13326, 12797, 17109, 10673, 10495, 13445, 14426, 17109, 10760, 11038, 17172, 14734, 11414, 12220, 28329, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 14589, 10370, 15261, 14734, 16728, 13655, 11414, 15178, 12605, 28329, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 10293, 10370, 19137, 12605, 14446, 11454, 14734, 11861, 11454, 12314, 12276, 12337, 17843, 15044, 10305, 10292, 13815, 14808, 19137, 12605, 11016, 15752, 12824, 11002, 13012, 11860, 17109, 10673, 12202, 15494, 10760, 13012, 11860, 17109, 10760, 19137, 11687, 13258, 10260, 11957, 12605, 17149, 16403, 17109, 10673, 19137, 12605, 13679, 17150, 17311, 13051, 13764, 10358, 14583, 10995, 12220, 19137, 12605, 43282, 28329, 65535, 261, 65530, 65532, 17109, 10673, 59, 33, 11198, 19137, 12605, 10423, 17182, 13932, 12669, 10464, 11891, 11255, 16944, 13234, 14734, 28329, 65535, 261, 65530, 65534, 11414, 11626, 59, 33, 10260, 16503, 10429, 12366, 19137, 10293, 10370, 19137, 12605, 11016, 13091, 13326, 12797, 12469, 14734, 17879, 13685, 17149, 16403, 10333, 17109, 10760, 19137, 12202, 13734, 13191, 14794, 13580, 11459, 17843, 17141, 10080, 10260, 17141, 19137, 12605, 12337, 13199, 12335, 15752, 11634, 12727, 13191, 13034, 14734, 10841, 15752, 28329, 65535, 261]
-> item_loss 0.7962528467178345 batch_loss 1.0699588977373564
==== [65530, 65532, 10464, 11685, 11223, 11, 65535, 261, 65530, 65534, 7176, 59, 33, 10464, 11685, 19137, 13191, 10373, 10303, 12605, 15752, 12176, 12469, 14734, 11053, 19156, 11, 65535, 261, 65530, 65532, 12605, 11017, 12287, 10337, 14363, 11, 65535, 261, 65530, 65534, 7176, 59, 33, 10464, 11685, 19137, 12287, 10337, 14363, 10080, 13191, 10373, 10303, 10336, 11053, 19156, 11, 65535, 261, 65530, 65532, 11047, 12605, 10382, 15484, 2178, 113, 14734, 10529, 12445, 11, 65535, 261, 65530, 65534, 7176, 59, 4185, 81, 46, 630, 620, 13091, 10250, 10283, 14597, 15597, 11435, 12984, 12226, 10781, 17194, 10760, 13234, 14734, 16947, 15847, 14221, 14583, 14328, 19137, 11885, 16443, 16689, 16664, 14589, 10339, 12650, 16403, 15036, 11930, 10409, 10843, 10080, 1429, 81, 46, 630, 620, 16443, 16689, 16664, 12604, 10250, 10283, 10370, 12314, 14583, 14328, 19137, 11630, 16417, 14791, 16944, 13234, 10621, 13091, 10250, 10283, 10285, 15169, 11638, 11975, 14734, 10370, 15261, 14601, 11855, 10080, 1429, 81, 46, 630, 620, 16443, 16689, 16664, 12604, 12727, 13191, 16947, 15847, 14221, 15752, 10838, 19137, 11021, 10399, 11454, 10260, 16443, 11940, 16525, 14734, 12484, 10724, 10258, 17149, 16403, 11036, 15033, 10409, 10843, 10080, 1429, 81, 46, 630, 620, 14734, 11630, 16417, 14791, 16944, 13234, 10621, 13091, 10250, 10283, 17038, 18216, 15450, 52, 15963, 11999, 10079, 10452, 17385, 10260, 10792, 650, 14944, 14734, 10370, 15261, 14601, 11855, 19137, 11885, 14734, 14806, 14815, 13091, 15446, 15898, 14734, 19137, 15752, 11634, 17819, 12522, 12981, 11003, 18029, 15898, 10080, 1429, 81, 46, 630, 620, 10688, 13191, 12299, 11638, 14734, 13133, 10838, 11124, 13212, 13133, 19137, 11021, 10399, 17149, 16403, 11036, 15033, 10409, 10843, 19137, 10444, 11885, 15568, 10309, 12182, 16696, 11124, 17222, 12363, 16520, 12389, 10080, 1429, 81, 46, 630, 620, 16443, 16689, 16664, 12604, 15752, 11634, 12650, 16403, 11036, 15033, 10409, 10843, 19137, 10444, 11885, 15568, 10309, 12182, 16696, 11124, 17222, 12363, 16520, 12389, 10080, 11885, 15486, 12182, 14347, 17631, 16730, 12609, 10588, 10760, 11656, 12418, 14734, 10296, 10846, 19137, 10444, 12421, 13091, 16707, 11436, 10525, 12686, 15847, 12144, 12202, 11891, 12604, 10409, 10843, 10080, 1429, 81, 46, 630, 620, 16443, 16689, 16664, 12604, 15752, 11634, 12650, 16403, 11036, 15033, 10409, 10843, 19137, 10444, 11885, 15568, 10309, 12182, 16696, 11124, 17222, 12363, 16520, 12389, 10080, 11885, 15486, 12182, 14347, 17631, 16730, 12609, 10588, 10760, 11656, 12418, 14734, 10296, 10846, 19137, 10444, 12421, 13091, 16707, 11436, 10525, 12686, 15847, 12144, 12202, 11891, 12604, 10409, 10843, 28329, 65535, 261]
-> item_loss 0.6089471578598022 batch_loss 1.0370294877461024
==== [25106, 11, 65530, 65531, 64113, 10399, 10258, 13091, 10355, 10342, 64113, 11, 10464, 13091, 10250, 10283, 820, 19137, 16443, 17303, 15588, 11454, 13205, 11459, 10080, 10293, 10370, 11967, 10464, 16689, 11899, 10292, 10250, 10283, 11679, 11872, 11855, 19137, 10464, 14734, 11043, 11860, 11017, 10588, 14299, 10295, 10273, 19137, 11124, 10293, 10370, 12201, 18476, 14782, 10411, 19137, 10260, 10792, 640, 12039, 10080, 10464, 13091, 820, 10444, 13091, 15752, 11634, 13499, 12722, 10370, 15261, 14734, 11036, 15033, 12527, 12484, 19137, 13637, 11687, 12266, 12366, 10079, 10429, 12366, 10079, 14583, 13655, 10079, 15648, 12366, 10079, 10399, 10992, 11036, 15033, 13562, 13197, 10080, 10464, 16443, 16689, 16664, 10760, 13234, 10292, 10370, 15261, 13193, 10843, 19137, 10444, 13091, 11042, 13064, 10464, 10322, 12159, 13197, 15847, 12144, 15752, 11634, 12348, 10792, 12203, 15009, 10261, 11971, 17385, 10080, 10464, 15752, 11634, 12945, 10460, 14600, 15763, 11124, 10250, 10349, 13133, 15752, 11920, 12010, 19137, 17879, 16503, 14734, 13064, 10560, 10464, 17879, 16503, 16735, 398, 12945, 10460, 14600, 15763, 2383, 12609, 15643, 398, 12945, 10460, 11920, 12010, 2383, 19137, 15646, 10260, 15752, 17109, 10760, 10687, 10390, 13012, 11860, 10080, 17148, 10283, 13064, 10560, 10464, 14734, 17109, 10760, 10423, 16443, 15304, 15500, 12785, 16056, 12202, 12282, 11960, 10464, 17149, 16403, 17149, 10250, 13582, 14734, 10355, 10342, 10080, 17148, 17384, 15494, 10760, 10250, 10283, 11957, 16713, 11903, 10487, 19151, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11315, 43282, 11, 65535, 261, 65530, 65534, 14299, 10295, 10273, 59, 33, 17879, 16503, 12605, 10303, 19156, 10293, 10370, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 10464, 14862, 17222, 10464, 14734, 16689, 11899, 13091, 10373, 10303, 10303, 19156, 11, 65535, 261, 65530, 65534, 14299, 10295, 10273, 59, 33, 10293, 10370, 19137, 12605, 12826, 13827, 12469, 11454, 12605, 13499, 11496, 14734, 12266, 11647, 10708, 10333, 12605, 14734, 16689, 11899, 19137, 10894, 12732, 12605, 14734, 16530, 15898, 10079, 12415, 13327, 10079, 12314, 16803, 10399, 10992, 12605, 15752, 10588, 14734, 10336, 12484, 19137, 10460, 10292, 820, 19137, 12605, 10423, 10279, 13327, 12750, 14240, 16689, 11899, 13234, 16403, 10846, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 12605, 12159, 13197, 10464, 10399, 11044, 15752, 16678, 10449, 10464, 14734, 16689, 11899, 19137, 10464, 14862, 17222, 10464, 14734, 16689, 11899, 13091, 10373, 10303, 10303, 19156, 11, 65535, 261, 65530, 65534, 14299, 10295, 10273, 59, 33, 12605, 14862, 17222, 14734, 19137, 10444, 13091, 12605, 14734, 16689, 11899, 13637, 17097, 17688, 19137, 10293, 10370, 12159, 13197, 10333, 16533, 12605, 14734, 11187, 10250, 17303, 10768, 14734, 16689, 11899, 19156, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 16735, 16735, 10464, 14734, 11899, 10304, 11124, 10370, 14328, 16689, 11899, 11061, 28329, 65535, 261, 65530, 65534, 14299, 10295, 10273, 59, 33, 11315, 19137, 12605, 13091, 10250, 10283, 820, 19137, 17148, 10250, 17303, 10768, 12220, 16721, 13091, 12605, 14734, 11899, 10304, 10080, 12605, 14734, 10370, 14328, 16689, 11899, 13091, 10250, 10283, 11679, 11872, 11855, 19137, 12201, 18476, 10261, 12469, 14782, 10411, 19137, 15752, 11634, 13499, 12722, 10370, 15261, 14734, 12527, 12484, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 10464, 14734, 15669, 16879, 13091, 10373, 10303, 19156, 11, 65535, 261, 65530, 65534, 14299, 10295, 10273, 59, 33, 12605, 14734, 15669, 16879, 13091, 13193, 10843, 10370, 15261, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 10464, 15752, 13499, 12722, 10373, 10303, 12527, 12484, 19156, 11, 65535, 261, 65530, 65534, 14299, 10295, 10273, 59, 33, 10370, 15261, 14734, 11036, 15033, 12527, 12484, 12605, 17311, 15752, 13499, 12722, 19137, 13637, 11687, 12266, 12366, 10079, 10429, 12366, 10079, 14583, 13655, 10079, 15648, 12366, 10079, 10399, 10992, 11036, 15033, 13562, 13197, 10080, 10293, 10370, 11021, 10399, 16667, 10292, 12605, 12727, 13191, 17148, 10349, 12527, 12484, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 10464, 16667, 10292, 10464, 12727, 13191, 10303, 19156, 11, 65535, 261, 65530, 65534, 14299, 10295, 10273, 59, 33, 11687, 13258, 13499, 12722, 14734, 10792, 10447, 14734, 16713, 19137, 12605, 10423, 16667, 10292, 12605, 12727, 13191, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 10464, 15752, 10588, 10349, 10373, 10303, 19156, 11, 65535, 261, 65530, 65534, 14299, 10295, 10273, 59, 33, 12605, 15752, 11634, 15287, 10733, 12650, 16403, 10293, 10370, 14734, 11117, 10398, 10079, 10292, 10293, 10370, 16533, 15178, 14638, 17728, 19137, 12609, 15643, 10621, 10250, 10283, 10370, 15261, 10250, 13324, 11124, 10293, 10370, 15667, 11639, 10080, 17798, 13581, 10305, 11630, 19137, 12605, 17147, 11021, 10399, 12176, 10847, 10293, 10370, 12945, 10460, 14600, 15763, 11124, 13133, 15752, 11920, 12010, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 12945, 10460, 14600, 15763, 11124, 13133, 15752, 11920, 12010, 19156, 11, 65535, 261, 65530, 65534, 14299, 10295, 10273, 59, 33, 13091, 14734, 19137, 16689, 11899, 17384, 13191, 16722, 15478, 10708, 12605, 15752, 12401, 10303, 10588, 19137, 15646, 10265, 15494, 10333, 12605, 10250, 10283, 10487, 11855, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 10464, 11632, 11638, 19156, 11, 65535, 261, 65530, 65534, 14299, 10295, 10273, 59, 33, 17728, 11679, 11872, 11855, 12201, 18476, 10260, 11640, 11038, 17172, 11061, 10080, 11685, 11061, 19137, 10687, 11903, 12605, 10322, 10260, 13923, 13425, 19137, 16689, 11899, 17384, 11016, 10708, 10333, 12605, 10260, 16956, 640, 12039, 19137, 10322, 16684, 13091, 638, 12039, 19156, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11903, 17781, 10257, 11102, 19156, 11, 65535, 261, 65530, 65534, 14299, 10295, 10273, 59, 33, 17268, 16503, 14791, 12605, 16443, 17194, 10760, 13234, 11632, 10301, 10333, 19137, 12605, 10260, 14914, 11899, 28329, 65535, 261]
-> item_loss 0.6307669281959534 batch_loss 1.009945317109426
==== [65530, 65531, 7451, 1802, 33, 14782, 10684, 17728, 18025, 11, 65535, 261, 65530, 65532, 11687, 10454, 11454, 7451, 1802, 10285, 17189, 17141, 7441, 2191, 16690, 17728, 26081, 31883, 33, 10285, 14734, 13012, 13205, 19156, 11, 65535, 261, 65530, 65534, 11454, 7441, 2191, 10285, 17189, 17141, 7441, 2191, 16690, 17728, 26081, 31883, 10285, 14734, 13012, 13205, 11021, 10399, 10482, 14589, 10399, 10258, 13582, 18197, 19151, 11, 65535, 261, 65530, 65534, 10399, 10258, 13091, 11454, 7451, 1802, 10285, 17189, 17141, 7441, 2191, 16690, 17728, 26081, 31883, 33, 10285, 14734, 13012, 13205, 59, 11, 50, 47, 33, 11960, 10673, 26081, 46, 26901, 12219, 59, 11, 6884, 7441, 2191, 11, 41, 49636, 274, 26081, 46, 26901, 42, 11, 6884, 11, 51, 47, 33, 10482, 14589, 331, 26081, 46, 26901, 46, 9113, 108, 97, 33, 10762, 13004, 16056, 11001, 26081, 31883, 10285, 13188, 13034, 13012, 13205, 59, 11, 6884, 7441, 2191, 11, 41, 26081, 46, 26901, 46, 9113, 108, 42, 11, 6884, 11, 52, 47, 33, 17189, 17141, 31213, 46, 26901, 12219, 14734, 10762, 13004, 16056, 11001, 14332, 11899, 10447, 15586, 14734, 13012, 13205, 59, 11, 46, 331, 26081, 46, 26901, 46, 25566, 97, 33, 16056, 11001, 13188, 13034, 13012, 13205, 11, 46, 331, 26081, 46, 26901, 46, 7621, 97, 33, 16056, 11001, 12748, 11899, 10447, 15586, 14734, 13012, 13205, 45, 10427, 10673, 10447, 15586, 11028, 10953, 11021, 11, 10487, 11687, 59, 11, 6884, 7441, 2191, 11, 41, 26081, 46, 26901, 46, 7621, 284, 42, 11, 6884, 11, 16056, 11001, 26081, 31883, 15162, 10337, 13231, 13188, 13034, 13012, 13205, 28329, 53, 47, 33, 17147, 11021, 10399, 10482, 14589, 331, 26081, 46, 26901, 46, 26985, 97, 33, 11967, 13012, 13205, 12983, 10673, 26081, 31883, 45, 331, 26081, 46, 26901, 46, 41246, 97, 33, 10783, 17798, 12748, 11899, 10447, 15586, 14734, 13012, 13205, 28329, 17148, 10349, 10762, 13004, 16672, 10464, 11021, 10399, 12337, 13036, 10511, 11459, 11454, 7441, 2191, 10397, 14875, 10285, 16742, 10708, 7451, 1802, 14734, 26081, 31883, 28329, 12159, 13197, 15752, 10292, 10464, 12848, 10494, 10988, 15641, 34, 11687, 13258, 17147, 13191, 14638, 17728, 13558, 17143, 15507, 15511, 12848, 10760, 28329, 50, 47, 33, 12642, 12266, 7451, 1802, 12202, 10842, 17095, 26081, 31883, 14782, 10684, 14734, 13499, 11473, 28329, 51, 47, 33, 10482, 14589, 17644, 14767, 10257, 14734, 23537, 44, 68, 12609, 15643, 33431, 44, 48440, 44, 87, 13829, 16524, 35543, 111, 45368, 28329, 52, 47, 33, 11454, 35543, 111, 45368, 10285, 17109, 10673, 59, 19242, 6884, 19242, 41, 26163, 46, 41129, 46, 25460, 46, 42324, 269, 41129, 35, 274, 465, 41129, 35, 275, 26821, 46, 42324, 494, 19242, 5265, 19242, 6884, 19242, 17148, 11967, 10384, 14782, 10684, 13499, 11473, 10285, 16742, 11001, 26081, 31883, 10285, 14734, 13012, 13205, 19137, 12202, 11967, 10687, 11861, 10609, 11454, 41129, 10285, 10080, 65535, 261, 65530, 65532, 17148, 13619, 10397, 14875, 16417, 14966, 10373, 10303, 12522, 12410, 19156, 11, 41, 7334, 2239, 21440, 8875, 48, 27003, 46, 42153, 275, 7137, 21616, 42, 3331, 41, 63076, 275, 26157, 275, 42153, 46, 34018, 26322, 42, 65414, 41, 42153, 46, 7463, 5292, 3331, 41, 26200, 46, 49585, 19242, 59, 26290, 269, 1795, 2226, 1818, 48, 49697, 46, 35325, 35, 19242, 59, 41129, 3352, 1795, 2226, 1818, 48, 49697, 46, 35325, 516, 19242, 59, 41183, 274, 8985, 46, 57, 19242, 59, 48988, 274, 465, 42114, 35, 65084, 387, 33553, 48, 2350, 7007, 26052, 48, 49689, 48, 7257, 8875, 47, 2134, 381, 19242, 59, 41418, 267, 41, 41749, 275, 26742, 22522, 42, 275, 41638, 22522, 494, 19242, 42, 3331, 41, 49585, 46, 27003, 46, 42153, 267, 35, 1795, 2226, 1818, 48, 49697, 46, 35325, 35, 21340, 21616, 42, 3331, 41, 49585, 46, 27003, 46, 42324, 267, 35, 1795, 2226, 1818, 48, 49697, 46, 35325, 35, 269, 261, 381, 3331, 41, 49585, 46, 27003, 46, 7478, 269, 1795, 2226, 1818, 48, 49697, 46, 35325, 5172, 65535, 261, 65530, 65534, 17148, 13619, 10397, 14875, 13091, 10250, 10283, 3784, 6908, 20299, 113, 33, 10762, 13004, 45, 11885, 10423, 10588, 10399, 10258, 10336, 12484, 59, 11, 50, 47, 33, 16056, 11001, 14589, 12626, 17177, 10285, 14734, 10912, 11524, 41, 42153, 497, 10953, 21340, 33, 11124, 21616, 33, 11003, 17387, 11, 51, 47, 33, 10781, 12261, 10250, 10283, 11043, 10292, 35, 1795, 2226, 1818, 48, 49697, 46, 35325, 35, 14734, 17149, 15052, 11, 52, 47, 33, 10482, 14589, 46966, 282, 33553, 48, 2350, 7007, 26052, 48, 49689, 48, 7257, 8875, 47, 2134, 33, 15768, 13205, 10460, 10292, 11117, 10398, 16403, 11, 53, 47, 33, 17149, 15052, 17109, 10760, 13064, 45, 10423, 10482, 14589, 10915, 11043, 10762, 13004, 275, 41749, 275, 26742, 22522, 42, 275, 41638, 22522, 494, 33, 12849, 10673, 10792, 382, 1795, 2226, 1818, 48, 49697, 46, 35325, 516, 33, 15540, 10721, 10912, 10285, 11, 54, 47, 33, 11967, 17177, 10285, 14734, 10912, 11524, 41, 7137, 33, 10792, 21616, 42, 10997, 17171, 10792, 16721, 17149, 15052, 11, 55, 47, 33, 10997, 17171, 10278, 10283, 12791, 16403, 15158, 11, 56, 47, 33, 11047, 17149, 15052, 10997, 17171, 19796, 41, 15489, 13229, 17149, 15052, 42, 11, 12421, 14734, 13234, 16735, 45, 17148, 10283, 10762, 13004, 10423, 11967, 17177, 10285, 14734, 13012, 13205, 10912, 11524, 10460, 10292, 17109, 10673, 45, 10997, 17171, 10792, 21440, 8875, 47, 2134, 33, 17148, 10283, 44742, 33, 15768, 13205, 10985, 11621, 14486, 45, 14221, 11044, 11967, 44742, 33, 15768, 13205, 14734, 17109, 10760, 12849, 10673, 10792, 10250, 10283, 3784, 6908, 33, 15540, 10721, 10912, 10285, 10080, 65535, 261]
-> item_loss 1.8546332120895386 batch_loss 1.062738310545683
==== [25106, 11, 65530, 65531, 32937, 4600, 332, 55767, 45, 53272, 31894, 49551, 64335, 51035, 3965, 2098, 21265, 332, 30971, 39095, 37074, 46, 6602, 98, 47, 29059, 21286, 32074, 32386, 59829, 46853, 37598, 37074, 46, 6602, 98, 460, 31894, 21265, 63757, 59, 11, 50, 47, 37074, 46, 6602, 98, 4600, 332, 45971, 4304, 27209, 32227, 30659, 38919, 8837, 7000, 4712, 4259, 25979, 47, 11, 51, 47, 37074, 46, 6602, 98, 4600, 4419, 3609, 47, 11, 52, 47, 37074, 46, 6602, 98, 22748, 51351, 4450, 332, 62391, 39095, 21094, 1744, 47, 11, 53, 47, 37074, 46, 6602, 98, 39301, 38576, 32139, 4423, 4716, 118, 21265, 29398, 34177, 21265, 39691, 39742, 47, 11, 54, 47, 37074, 46, 6602, 98, 21800, 332, 45752, 21400, 46859, 55574, 45, 40186, 59396, 32487, 22590, 31530, 7472, 25660, 45, 22661, 25858, 101, 21265, 22249, 26096, 7911, 47539, 22464, 57015, 31947, 47, 11, 55, 47, 37074, 46, 6602, 98, 4600, 51371, 21265, 64382, 37598, 56537, 22168, 47539, 21265, 63662, 32487, 21811, 53285, 47, 11, 56, 47, 37074, 46, 6602, 98, 37949, 21811, 30819, 4377, 8801, 39863, 1660, 47, 11, 57, 47, 37074, 46, 6602, 98, 38939, 4811, 21227, 4377, 34545, 1660, 4424, 22590, 21616, 4706, 32074, 4706, 21811, 60476, 47, 11, 62981, 4706, 37074, 46, 6602, 98, 59, 45752, 21400, 46859, 45, 51371, 45, 22661, 25858, 101, 45, 22249, 26096, 7911, 45, 46992, 45, 46480, 47, 65535, 261, 65530, 65531, 92, 33465, 332, 22168, 30434, 94, 11, 65535, 261, 1195, 2098, 59, 3880, 37074, 46, 6602, 98, 45, 4601, 460, 38629, 4811, 22449, 22799, 37635, 34, 30031, 31059, 22799, 30259, 4833, 4811, 46402, 64, 11, 65530, 65534, 1294, 8962, 46, 6602, 98, 59, 277, 27199, 116, 4811, 30807, 22799, 45, 21811, 51470, 30806, 56547, 4833, 32487, 61966, 43, 36786, 34, 308, 5231, 30259, 46170, 4788, 31466, 21716, 4712, 4677, 53025, 46402, 45, 52491, 4716, 118, 21265, 29398, 34177, 21265, 52910, 39742, 32487, 4677, 53285, 34, 19417, 308, 5231, 30259, 53362, 4712, 56537, 31458, 37598, 22590, 40213, 21265, 22590, 46787, 4596, 4601, 47, 20063, 37598, 22799, 64, 30031, 31059, 22799, 30259, 4833, 4811, 64, 11, 65535, 261, 1195, 2098, 59, 4091, 45, 22187, 31466, 47, 29182, 53362, 21265, 47629, 4811, 32113, 30360, 47, 308, 5231, 30259, 57552, 32515, 53025, 47544, 45, 21265, 308, 47008, 38374, 32229, 34, 11, 65530, 65534, 1294, 8962, 46, 6602, 98, 59, 277, 2188, 34717, 32438, 2030, 43, 37448, 22799, 4788, 31466, 45, 38676, 34, 308, 459, 30976, 22799, 38374, 32229, 47, 3917, 39934, 55521, 22799, 458, 31296, 4811, 22449, 4660, 4491, 4712, 332, 47423, 64, 308, 459, 45150, 52157, 21700, 22168, 38735, 4811, 31358, 4677, 53025, 30788, 45301, 47, 11, 65535, 261, 1195, 2098, 59, 54819, 45, 308, 22748, 60762, 4588, 22799, 38128, 32006, 4835, 21835, 22799, 32462, 51351, 47, 308, 459, 47008, 62144, 4596, 22590, 60623, 32011, 4706, 47539, 47, 11, 65530, 65534, 1294, 8962, 46, 6602, 98, 59, 277, 8254, 25139, 62647, 2030, 43, 3631, 45, 22796, 34, 308, 21413, 61821, 4491, 32227, 47, 308, 22748, 51351, 4450, 4677, 62391, 45, 21094, 1744, 45, 40085, 55464, 3609, 61559, 21265, 51377, 46, 25190, 62634, 47, 3918, 460, 47008, 63571, 39841, 34, 308, 458, 31337, 4811, 39655, 4601, 32487, 4677, 53285, 4588, 308, 21751, 22590, 45449, 47, 37448, 22799, 21700, 22590, 62608, 34, 36782, 34, 11, 65535, 261, 65530, 65531, 92, 33465, 332, 22168, 30434, 94, 11, 65535, 261, 1195, 2098, 59, 3880, 37074, 46, 6602, 98, 45, 308, 31337, 32515, 53025, 34, 30076, 52910, 40139, 4600, 50892, 34, 29045, 22799, 30789, 53137, 4706, 38279, 332, 51274, 64, 11, 65530, 65534, 1294, 8962, 46, 6602, 98, 59, 277, 2188, 34717, 56330, 2030, 43, 37448, 22799, 4788, 31466, 45, 38676, 34, 308, 459, 47008, 30976, 22799, 51619, 32515, 32251, 32487, 4660, 47, 19417, 332, 51274, 64, 29889, 47341, 31296, 4788, 31466, 21716, 34, 308, 5231, 39115, 30666, 22226, 45285, 45, 21400, 308, 458, 31337, 4811, 30972, 4601, 332, 22626, 47, 37004, 308, 38128, 30788, 4491, 332, 53293, 51274, 47, 11, 65535, 261, 1195, 2098, 59, 29889, 460, 332, 38629, 31135, 34, 308, 40219, 61821, 32317, 4596, 21700, 32227, 47, 30031, 31214, 4706, 39742, 40219, 22799, 32022, 64, 11, 65530, 65534, 1294, 8962, 46, 6602, 98, 59, 277, 54389, 21700, 332, 46594, 43, 20050, 45, 32458, 45, 308, 31337, 21256, 38841, 4706, 39082, 45, 4788, 308, 458, 32435, 4811, 51987, 332, 53264, 4706, 39742, 4596, 22590, 51274, 47, 308, 38128, 32022, 32074, 52516, 39742, 45, 32074, 30226, 6921, 45, 38986, 30788, 32074, 40136, 8328, 21265, 20024, 8763, 102, 20419, 118, 39742, 47, 308, 31337, 20024, 8763, 102, 20419, 118, 39742, 34, 11, 65535, 261, 65530, 65531, 92, 33465, 332, 22168, 30434, 94, 11, 65535, 261, 1195, 2098, 59, 20039, 37074, 46, 6602, 98, 45, 308, 22748, 60762, 4588, 22799, 21795, 21273, 32257, 21700, 59832, 38530, 21265, 64864, 64, 11, 65530, 65534, 1294, 8962, 46, 6602, 98, 59, 277, 8254, 25139, 45236, 34918, 43, 54813, 2030, 34, 37451, 21286, 332, 22031, 4706, 47539, 22799, 21413, 4491, 4811, 51982, 32515, 38530, 21265, 64864, 47, 20556, 4706, 4677, 56210, 62633, 4600, 4811, 4491, 59241, 59674, 45, 31296, 30597, 38777, 1858, 21265, 30797, 8078, 47, 3918, 21413, 47008, 31073, 38049, 32515, 31427, 21265, 21751, 22799, 4596, 22590, 32523, 47, 19555, 4588, 32227, 38278, 461, 32499, 45, 22799, 38128, 45150, 22626, 60522, 31458, 51527, 45, 31296, 56064, 4419, 45873, 22316, 4706, 45512, 34, 11, 65535, 261, 1195, 2098, 59, 3873, 73, 47, 4281, 45, 308, 459, 22187, 32157, 32227, 460, 22590, 30273, 31135, 5362, 11, 65530, 65534, 1294, 8962, 46, 6602, 98, 59, 277, 26111, 7856, 4596, 45501, 45, 21811, 40139, 56069, 4811, 332, 53345, 43, 4097, 45, 22799, 38128, 22626, 4677, 47206, 46561, 47, 308, 39798, 4424, 332, 52467, 4706, 332, 32433, 21700, 38716, 4712, 21616, 45, 40076, 21256, 57422, 59533, 30917, 4677, 31427, 47, 3918, 460, 332, 30899, 4706, 52035, 62204, 32227, 45143, 4660, 4811, 50848, 55801, 21265, 39984, 38530, 47, 19555, 4435, 47766, 45, 4601, 460, 22187, 21700, 22590, 38443, 4706, 38676, 47, 277, 42303, 21408, 1994, 7856, 40061, 8840, 8101, 7166, 43, 11, 65535, 261, 1195, 2098, 59, 4285, 45, 21286, 22799, 51728, 31574, 45, 37074, 46, 6602, 98, 64, 11, 65530, 65534, 1294, 8962, 46, 6602, 98, 59, 277, 54366, 34326, 4833, 21265, 60515, 30678, 21811, 51470, 31039, 43, 4089, 45604, 45, 38676, 34, 21152, 4491, 22799, 21295, 64, 277, 25509, 116, 22799, 332, 32470, 46, 25387, 31014, 32227, 38932, 332, 46454, 22614, 32470, 43, 29182, 57083, 45, 4588, 22799, 30789, 31506, 4811, 50848, 22590, 57481, 38530, 45, 22799, 31223, 32464, 4811, 4491, 47, 277, 9080, 2000, 43, 11, 65535, 261, 65530, 65531, 92, 33465, 332, 22168, 30434, 94, 11, 65535, 261, 65530, 65534, 1294, 8962, 46, 6602, 98, 59, 277, 853, 22799, 38377, 22590, 31898, 45, 22799, 22449, 37074, 46, 6602, 98, 52915, 4424, 21811, 55809, 31296, 22464, 45150, 30659, 45, 21811, 30806, 51770, 46314, 2030, 4712, 22590, 47195, 47, 30032, 22464, 52325, 22799, 45, 332, 45358, 39725, 52982, 45093, 21811, 30807, 45, 21265, 22464, 40040, 4811, 30807, 22799, 32487, 61966, 47, 20035, 39711, 45, 3609, 30899, 4600, 21231, 2163, 1843, 4596, 332, 30554, 47188, 53232, 45, 55801, 32487, 332, 30302, 47162, 45516, 21265, 332, 38631, 21382, 8809, 47, 37074, 46, 6602, 98, 38632, 116, 22799, 32487, 332, 45752, 45, 21400, 46859, 32269, 45, 21811, 61947, 31618, 24381, 4596, 22590, 21246, 581, 11, 6007, 45, 308, 459, 37074, 46, 6602, 98, 45, 308, 459, 4419, 3609, 22762, 38939, 4811, 31702, 38576, 21265, 32022, 39742, 47, 4035, 51353, 45, 21094, 1744, 45, 62390, 4660, 4811, 4435, 51371, 21265, 64382, 37598, 56537, 22168, 47539, 45, 4788, 308, 459, 45150, 52157, 21700, 21716, 21265, 63667, 32448, 4811, 56475, 32487, 4677, 39863, 47, 308, 31104, 22799, 38374, 32515, 32251, 32487, 4660, 47, 36782, 34, 65535, 261]
-> item_loss 0.7356166839599609 batch_loss 1.0434958619229935
==== [65530, 65531, 10684, 10339, 7451, 1802, 10696, 11922, 14734, 17728, 15178, 11, 65535, 261, 65530, 65532, 11687, 10454, 16056, 11001, 7451, 1802, 267, 25028, 34043, 14734, 10285, 14734, 10696, 11922, 19156, 11, 65535, 261, 65530, 65534, 10464, 11021, 10399, 10482, 14589, 10399, 10258, 4515, 7917, 33, 10397, 14875, 16056, 11001, 3784, 6908, 267, 25028, 34043, 33, 14734, 10696, 11922, 59, 11, 6884, 7441, 2191, 11, 41, 49026, 46, 26081, 283, 42, 11, 6884, 11, 97, 49026, 46, 26081, 97, 33, 10762, 13004, 13191, 10278, 10283, 10988, 13004, 59, 11, 46, 283, 33, 16417, 14966, 16056, 11001, 13188, 17145, 14734, 31213, 11, 46, 33, 13580, 13004, 16417, 14966, 16056, 11001, 13179, 13057, 14734, 31213, 11, 12631, 10399, 10292, 10333, 11016, 16056, 11001, 13188, 13034, 14734, 59300, 33, 10696, 11922, 45, 12605, 10402, 10427, 10673, 283, 33, 10953, 11021, 28329, 10487, 11687, 59, 11, 6884, 7441, 2191, 11, 41, 8079, 3421, 27139, 275, 49026, 46, 26081, 283, 5292, 3331, 41, 49410, 269, 57956, 51308, 59, 272, 116, 35, 32224, 494, 11, 6884, 11, 17148, 13619, 10397, 14875, 10423, 16056, 11001, 59300, 33, 10696, 11922, 45, 12202, 13098, 14966, 11454, 13855, 12445, 13314, 10285, 28329, 10464, 10322, 11021, 10399, 12669, 59300, 33, 10696, 11922, 16914, 10577, 15494, 10250, 10283, 11003, 17387, 45, 14221, 11044, 17149, 16403, 14782, 10684, 14734, 11621, 14486, 28329, 12631, 10399, 45, 10482, 14589, 331, 49026, 46, 26081, 283, 97, 33, 11994, 11021, 10399, 11454, 3784, 6908, 20299, 113, 33, 10397, 14875, 10285, 16056, 11001, 3784, 6908, 33, 14734, 59300, 33, 10696, 11922, 10080, 65535, 261, 65530, 65532, 10482, 14589, 10373, 10303, 7441, 2191, 10762, 13004, 15752, 11634, 11903, 14446, 11454, 7451, 1802, 10285, 14734, 8401, 46, 26267, 10258, 17177, 10285, 13279, 10283, 8760, 46, 27187, 19156, 11, 65535, 261, 65530, 65534, 11021, 10399, 10482, 14589, 22236, 46, 34200, 33, 11117, 10398, 13234, 17177, 10285, 53048, 64, 11, 12750, 17644, 15487, 11899, 59, 11, 68, 46, 100, 332, 275, 8401, 46, 34200, 42, 11, 14589, 13764, 59, 11, 50, 47, 33, 10659, 13308, 12983, 11454, 8760, 27187, 14734, 13308, 18025, 10257, 11, 51, 47, 33, 12750, 302, 46, 100, 332, 11, 52, 47, 33, 17148, 11967, 17177, 10285, 16721, 8760, 27187, 10258, 14734, 12631, 13191, 10696, 11922, 11, 10464, 10322, 11021, 10399, 12748, 11899, 17879, 16503, 12357, 14445, 14734, 13557, 13004, 13234, 17177, 10285, 10260, 11042, 15451, 10790, 14734, 10696, 11922, 59, 11, 46, 302, 46, 100, 332, 284, 280, 33, 17177, 10285, 12307, 10808, 16403, 11, 46, 302, 46, 100, 332, 285, 280, 33, 17177, 10285, 12307, 10808, 15907, 14172, 41, 13308, 18025, 10992, 11855, 15907, 14172, 42, 11, 46, 302, 46, 100, 332, 286, 280, 33, 17177, 10285, 12307, 10808, 15907, 14172, 14734, 14302, 15907, 14172, 11, 46, 33, 15169, 15169, 11, 12631, 10399, 45, 11454, 22236, 46, 26267, 33, 10258, 17177, 10285, 13279, 10283, 53048, 45, 10464, 11021, 10399, 59, 11, 50, 47, 33, 10659, 13308, 12983, 11454, 16721, 53048, 33, 14734, 13308, 18025, 10257, 11, 51, 47, 33, 16749, 14589, 4398, 8401, 46, 34200, 313, 512, 10762, 13004, 45, 79, 33, 10292, 16503, 12357, 14445, 14734, 13557, 13004, 45, 10399, 17177, 10285, 16721, 11855, 13315, 11, 10487, 11687, 59, 11, 6884, 4515, 7917, 11, 41, 8401, 46, 34200, 285, 42, 267, 60, 33, 17177, 10285, 12307, 10808, 15907, 14172, 41, 11855, 13315, 42, 11, 6884, 11, 12159, 13197, 17148, 15752, 12176, 10847, 10464, 34, 65535, 261]
[2023-09-30 21:45:49,544] [INFO] [logging.py:96:log_dist] [Rank 0] step=20, skipped=0, lr=[0.0001, 0.0001, 0.0001], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
-> item_loss 1.9701517820358276 batch_loss 1.0949767463737063
==== [54278, 11, 65530, 65532, 17379, 14589, 1843, 111, 13327, 12276, 17146, 11414, 16809, 51, 11483, 10660, 14734, 10529, 12445, 11, 65535, 261, 65530, 65534, 2370, 26290, 269, 16809, 51, 11483, 10660, 35, 11, 59, 8148, 58475, 269, 1193, 24791, 46, 1250, 7556, 106, 35, 3339, 59, 42519, 3527, 265, 59, 41775, 3483, 47, 51, 265, 59, 36008, 286, 47, 56, 11, 59, 41330, 3501, 49, 18157, 10838, 45736, 11, 59, 26199, 96, 7658, 3483, 54, 13644, 15260, 14167, 262, 59, 53988, 4363, 11412, 13036, 12314, 14167, 11559, 35, 269, 12826, 17149, 11369, 12826, 17149, 395, 11, 59, 63053, 269, 16809, 51, 13091, 16501, 12363, 14880, 10794, 14734, 10250, 15033, 17385, 11496, 11483, 10660, 45, 11454, 639, 690, 12201, 10397, 12266, 11726, 13193, 12328, 10080, 399, 65535, 261, 65530, 65532, 17379, 14589, 1843, 111, 13327, 12276, 17146, 11414, 10272, 18043, 46, 647, 11960, 12298, 14734, 10529, 12445, 11, 65535, 261, 65530, 65534, 43, 33, 16809, 51, 11483, 10660, 10529, 12445, 11, 2370, 26290, 269, 16809, 51, 35, 11, 59, 8148, 58475, 269, 10660, 10853, 13033, 46, 17142, 16081, 35, 11, 59, 42519, 269, 674, 33, 11062, 35, 265, 59, 41775, 269, 630, 47, 51, 33, 15260, 35, 11, 59, 36008, 269, 52, 47, 56, 33, 15260, 35, 11, 59, 41330, 269, 648, 49, 18157, 10838, 267, 11412, 10721, 15052, 13297, 13750, 13212, 35, 11, 59, 26199, 96, 7658, 269, 630, 54, 33, 13644, 15260, 14167, 35, 265, 59, 53988, 4363, 11412, 13036, 12314, 14167, 11559, 35, 269, 12826, 17149, 11369, 12826, 17149, 395, 11, 59, 63053, 269, 16809, 51, 13091, 16501, 12363, 14880, 10794, 14734, 10250, 15033, 17385, 11496, 11483, 10660, 45, 11454, 639, 690, 12201, 10397, 12266, 11726, 13193, 12328, 10080, 399, 65535, 261]
-> item_loss 1.8649086952209473 batch_loss 1.1354994805235612
==== [25106, 11, 65530, 65531, 13091, 10250, 10283, 10370, 12137, 13133, 15752, 10847, 12636, 19137, 11021, 10399, 12176, 10847, 10370, 15261, 10588, 11036, 15033, 10336, 12484, 19137, 33914, 8778, 117, 12337, 11268, 13558, 12176, 10847, 10370, 15261, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 10464, 17147, 11454, 11871, 10323, 10285, 19137, 11957, 11061, 28329, 65535, 261, 65530, 65534, 33914, 8778, 117, 59, 33, 13091, 14734, 19137, 12605, 17147, 11454, 11871, 10323, 10261, 17161, 10397, 10285, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 17268, 10303, 12605, 12509, 11088, 16698, 10464, 10283, 13191, 14589, 14734, 14862, 16696, 28329, 65535, 261, 65530, 65534, 33914, 8778, 117, 59, 33, 11685, 14734, 19137, 10293, 10370, 19137, 10464, 16735, 11061, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 12605, 10402, 12410, 15641, 17728, 18025, 12220, 16721, 10675, 17919, 19137, 11016, 10384, 10250, 10283, 16530, 12231, 10985, 12410, 15641, 17728, 18025, 13091, 10260, 11634, 14734, 28329, 65535, 261, 65530, 65534, 33914, 8778, 117, 59, 33, 12605, 14486, 16533, 10464, 14734, 12522, 12410, 19137, 13091, 16503, 10384, 11632, 10283, 16530, 12231, 13234, 12410, 15641, 17728, 18025, 19137, 11957, 11061, 19156, 11, 65535, 261, 65530, 65532, 27370, 59, 33, 13734, 17631, 19137, 10296, 10283, 10487, 11855, 19137, 13637, 11687, 12605, 11454, 11630, 17919, 16968, 13582, 16968, 10333, 12337, 10301, 19137, 11414, 10792, 11920, 19137, 15646, 10464, 13091, 12605, 14734, 11920, 12984, 820, 19137, 10464, 10423, 10292, 12605, 10588, 10373, 10303, 19156, 11, 65535, 261, 65530, 65534, 33914, 8778, 117, 59, 33, 12605, 10423, 10292, 12469, 10733, 11622, 13676, 11124, 18053, 14328, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 10974, 11416, 11102, 19156, 11, 65535, 261, 65530, 65534, 33914, 8778, 117, 59, 33, 11416, 10292, 12605, 16667, 10292, 12469, 16968, 13582, 11044, 17879, 16503, 16416, 10655, 16099, 10691, 11124, 13676, 10768, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 13091, 14734, 19137, 10444, 13091, 10464, 11042, 13064, 10322, 16721, 15641, 16253, 10792, 19137, 16968, 13582, 11044, 12605, 10423, 13637, 17097, 14195, 19137, 12609, 16684, 10464, 17147, 11021, 10399, 12176, 12605, 12669, 15090, 16749, 12642, 12266, 28329, 65535, 261, 65530, 65534, 33914, 8778, 117, 59, 33, 12605, 14486, 16533, 12469, 14734, 12522, 12410, 10333, 19137, 10293, 10370, 19137, 12605, 10423, 10848, 10838, 10588, 10792, 12410, 15641, 10675, 17919, 14734, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 17798, 13581, 10305, 11630, 19137, 10322, 16684, 10464, 17879, 16503, 10250, 10349, 12662, 10784, 12415, 12410, 15516, 10080, 10464, 14862, 17222, 10373, 10303, 13091, 12662, 10784, 12415, 12410, 15516, 10303, 19156, 11, 65535, 261, 65530, 65534, 33914, 8778, 117, 59, 33, 12605, 14862, 17222, 19137, 12662, 10784, 12415, 12410, 15516, 13091, 12748, 10283, 10452, 11454, 11626, 13215, 14734, 12484, 13126, 10285, 19137, 15752, 14141, 13815, 17144, 14589, 12145, 13191, 14734, 14862, 16696, 11124, 15486, 18183, 19137, 11957, 17728, 18025, 14734, 13036, 13764, 17149, 16403, 17177, 12731, 19137, 16696, 10790, 10580, 16689, 19137, 11454, 10995, 12410, 14734, 11533, 14902, 10257, 17149, 16403, 10768, 13254, 10079, 12826, 14486, 19137, 10460, 10760, 11038, 14486, 14734, 10784, 13032, 11124, 13580, 14914, 11001, 15864, 14734, 18216, 15451, 12410, 15516, 13036, 13764, 10992, 12314, 12276, 28329, 65535, 261, 65530, 65532, 27370, 59, 13091, 14734, 19137, 17148, 11016, 13091, 11885, 14734, 11899, 10304, 19137, 12605, 13234, 17728, 10464, 10250, 10283, 17728, 18025, 10080, 10913, 14583, 15494, 10333, 14662, 10370, 10278, 15033, 16030, 10290, 19137, 13633, 15033, 10278, 18024, 19137, 10278, 15033, 16030, 10290, 14734, 12604, 10768, 10260, 11042, 19137, 10444, 11630, 16520, 10250, 13324, 19137, 10913, 14583, 16503, 13685, 13057, 10257, 11124, 13115, 10257, 19137, 13633, 15033, 16030, 11036, 11035, 10250, 18024, 10080, 14446, 11454, 16030, 10290, 16443, 13916, 11454, 10333, 10250, 16944, 19137, 17843, 10399, 10768, 17122, 10080, 14662, 10370, 12368, 18001, 11035, 16030, 19137, 10464, 15752, 15494, 10760, 14662, 10370, 15752, 11634, 12750, 13064, 11035, 16030, 14734, 16533, 10722, 10840, 13764, 10303, 19156, 11, 65535, 261, 65530, 65534, 33914, 8778, 117, 59, 33, 16030, 10290, 16443, 13916, 11454, 10333, 10250, 16944, 19137, 11035, 17631, 10802, 17387, 11021, 15752, 11960, 15850, 10260, 11021, 18009, 16664, 14734, 17728, 18025, 10080, 12605, 11021, 15752, 13734, 13764, 15494, 10760, 16533, 10722, 13036, 13336, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 10260, 19137, 10464, 11640, 17141, 10264, 13773, 10339, 17728, 18025, 13205, 17038, 10080, 11454, 14446, 11903, 10285, 19137, 12664, 10913, 14583, 17385, 13034, 12266, 16030, 11994, 15752, 16533, 10722, 17728, 18025, 10333, 28329, 65535, 261, 65530, 65534, 33914, 8778, 117, 59, 33, 10293, 10370, 19137, 17148, 14914, 11903, 13091, 11038, 14486, 14734, 16533, 10722, 13036, 13336, 10080, 12605, 13734, 12509, 10792, 17147, 13191, 17148, 13324, 14734, 13036, 13764, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 13091, 14734, 19137, 10464, 17879, 16503, 16672, 15847, 12144, 14734, 12410, 15516, 14141, 13815, 16944, 13234, 19137, 13191, 10250, 10349, 17728, 18025, 13091, 10464, 12509, 10260, 10792, 10684, 17644, 14734, 14172, 11994, 16533, 10260, 12266, 14734, 19137, 16503, 11632, 12509, 28329, 65535, 261, 65530, 65534, 33914, 8778, 117, 59, 33, 14862, 17222, 10333, 19137, 12605, 10423, 10848, 10838, 14734, 28329, 65535, 261]
-> item_loss 0.7144201397895813 batch_loss 1.1144455134868623
==== [65530, 65531, 10464, 13091, 10250, 10283, 11021, 14299, 19137, 11021, 10529, 14734, 10847, 12636, 19137, 11043, 11017, 33914, 8778, 117, 10080, 33, 10464, 10423, 13580, 17919, 14734, 11414, 15178, 41830, 14734, 17728, 18025, 19137, 10444, 13091, 17528, 11957, 24272, 17728, 18025, 10285, 14734, 10260, 13580, 14914, 10305, 11621, 10423, 10334, 10399, 13179, 13580, 28329, 65535, 261, 65530, 65532, 41830, 19151, 33, 12605, 12509, 11035, 15009, 12261, 10370, 19137, 12220, 12307, 12401, 10303, 14199, 18087, 15009, 12261, 10370, 19156, 11, 65535, 261, 65530, 65534, 33914, 8778, 117, 19151, 33, 11021, 10399, 15641, 16253, 10482, 14589, 11036, 15033, 18119, 13021, 11124, 15294, 13234, 11986, 16707, 10260, 11042, 14734, 11110, 17222, 19137, 10487, 11687, 15294, 10079, 17351, 13750, 10079, 15737, 13409, 15264, 15169, 10080, 11013, 11630, 19137, 15009, 12261, 10370, 10322, 11021, 10399, 10842, 10673, 10687, 10390, 18119, 13021, 13234, 16749, 11110, 19137, 10487, 11687, 11737, 10079, 16137, 10079, 17120, 13409, 15169, 28329, 65535, 261, 65530, 65532, 41830, 59, 33, 17148, 10303, 16735, 19137, 11035, 15009, 12261, 10370, 10260, 14347, 13764, 11957, 11053, 19156, 11, 65535, 261, 65530, 65534, 33914, 8778, 117, 19151, 33, 11035, 15009, 12261, 10370, 10260, 10423, 14347, 13764, 19137, 10444, 13091, 11687, 13258, 10464, 11454, 17916, 13764, 15674, 17848, 10370, 15604, 14734, 16713, 19137, 11021, 15752, 10423, 16443, 16650, 11940, 12672, 10449, 12202, 11002, 10792, 12748, 12825, 28329, 65535, 261, 65530, 65532, 41830, 59, 33, 17268, 10303, 11035, 10370, 14347, 13764, 11053, 19156, 11, 65535, 261, 65530, 65534, 33914, 8778, 117, 19151, 33, 11035, 10370, 10423, 16443, 16523, 10292, 10279, 17385, 14734, 10370, 13216, 17728, 18025, 19137, 12202, 10265, 11021, 15752, 10423, 12282, 16944, 11435, 17781, 14970, 10423, 14734, 12210, 13766, 10684, 13773, 10080, 13581, 11630, 19137, 10384, 10431, 14486, 11124, 13764, 12340, 14734, 16530, 12231, 13234, 14791, 19137, 10322, 10260, 12220, 16721, 18458, 10851, 12609, 12978, 12746, 10409, 10454, 10370, 10985, 10588, 17148, 13324, 14734, 10336, 12484, 28329, 65535, 261, 65530, 65532, 41830, 59, 33, 14446, 11454, 10464, 15641, 16253, 10258, 19137, 33, 15009, 12261, 10370, 13091, 10260, 13091, 10370, 19126, 19156, 11, 65535, 261, 65530, 65534, 33914, 8778, 117, 19151, 33, 13091, 14734, 19137, 33, 15009, 12261, 10370, 13091, 10370, 10080, 10390, 10402, 12727, 13191, 15847, 12144, 14734, 13012, 10901, 11124, 10964, 11024, 19137, 10322, 11002, 10792, 11435, 11920, 11124, 14970, 10423, 14734, 10525, 12686, 28329, 65535, 261, 65530, 65532, 41830, 59, 33, 17268, 10303, 11035, 15009, 12261, 10370, 14347, 13764, 11053, 19156, 11, 65535, 261, 65530, 65534, 33914, 8778, 117, 19151, 33, 11035, 15009, 12261, 10370, 14347, 13764, 10080, 15009, 12261, 10370, 13091, 10250, 10283, 15604, 10452, 19137, 10390, 10402, 12727, 13191, 15847, 12144, 14734, 13012, 10901, 11124, 10964, 11024, 10080, 11035, 15009, 12261, 10370, 13091, 10250, 15033, 14347, 15584, 16403, 10292, 19137, 10423, 11002, 10792, 10279, 10965, 14734, 13764, 12340, 12501, 15578, 28329, 65535, 261, 65530, 65534, 14488, 14543, 19151, 33, 12605, 10780, 10780, 16707, 14808, 11871, 10323, 10333, 17148, 10349, 14862, 16696, 10080, 15489, 13258, 18157, 18157, 16250, 16250, 11061, 19137, 11685, 10621, 12605, 16417, 17136, 14734, 10260, 11634, 13923, 13127, 11124, 10733, 14914, 28329, 65535, 261]
-> item_loss 0.8432310819625854 batch_loss 1.1015305405571347
==== [25106, 11, 65530, 65531, 10464, 13091, 10250, 10283, 820, 19137, 11017, 10460, 10414, 16037, 17847, 19137, 15752, 11634, 11124, 10370, 15261, 15847, 14221, 11459, 11957, 16713, 10080, 17798, 13581, 10305, 11630, 19137, 17147, 11021, 10399, 12176, 10790, 10370, 10609, 11861, 10256, 13231, 10529, 12445, 28329, 14778, 10808, 11861, 10609, 14734, 10529, 12445, 19151, 11, 50, 47, 10293, 10370, 14734, 14600, 15763, 11930, 14875, 13091, 632, 653, 1751, 101, 643, 50, 11, 51, 47, 10293, 10370, 10760, 17723, 13064, 12159, 13197, 12605, 12848, 14966, 10390, 12669, 17550, 10903, 12172, 10257, 11, 52, 589, 13137, 13051, 10696, 11922, 63, 11, 10399, 10258, 13091, 10355, 10342, 19151, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 13057, 10257, 11685, 28329, 65535, 261, 65530, 65534, 10414, 16037, 17847, 59, 33, 13057, 11889, 19137, 10293, 10370, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 13057, 10257, 11685, 28329, 65535, 261, 65530, 65534, 10414, 16037, 17847, 59, 33, 10464, 10780, 12638, 12145, 15486, 16735, 17141, 13057, 10257, 11685, 10333, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11315, 19137, 12605, 14862, 17222, 19137, 12605, 11016, 13091, 12509, 11632, 11065, 10464, 16735, 10278, 11012, 16713, 28329, 65535, 261, 65530, 65534, 10414, 16037, 17847, 59, 33, 13734, 17728, 18025, 19137, 12605, 12337, 12537, 12522, 17802, 10464, 16735, 16713, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11088, 16698, 12605, 10283, 11975, 14862, 16696, 11061, 28329, 65535, 261, 65530, 65534, 10414, 16037, 17847, 59, 33, 12307, 14221, 11021, 10399, 14734, 10080, 10464, 14862, 17222, 11053, 19137, 16327, 16314, 14734, 15874, 17012, 10687, 11903, 13091, 10250, 15033, 11626, 13215, 14734, 16728, 16537, 10080, 12307, 10250, 11016, 12137, 16314, 12664, 10792, 10250, 10283, 13034, 14734, 15931, 13981, 12609, 13676, 13981, 19137, 11885, 10423, 17146, 11414, 16314, 12135, 12202, 17149, 16403, 10250, 15033, 14332, 13603, 14734, 15874, 17012, 19137, 16443, 15044, 10292, 9822, 12894, 12893, 15874, 9823, 10080, 17148, 15033, 15874, 17012, 14734, 13036, 11047, 10079, 17193, 12231, 11124, 13499, 12276, 17311, 10423, 10427, 17136, 10760, 13981, 11647, 14734, 13036, 11047, 10079, 16973, 15023, 11124, 10286, 11932, 15052, 12231, 10080, 17148, 13091, 16327, 16314, 10305, 17734, 17149, 16403, 13191, 12986, 13733, 17189, 14734, 10250, 15033, 13036, 12276, 19137, 12176, 10847, 13006, 10283, 16314, 15604, 12664, 10792, 16909, 13981, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 14862, 17222, 10333, 19137, 12605, 16503, 10760, 17723, 10257, 14474, 10333, 28329, 65535, 261, 65530, 65534, 10414, 16037, 17847, 59, 33, 10293, 10370, 10703, 16519, 19137, 10260, 16503, 12378, 10333, 12172, 17550, 10903, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 12605, 14446, 11454, 11454, 10678, 11029, 19137, 13191, 10336, 12484, 12664, 10464, 28329, 65535, 261, 65530, 65534, 10414, 16037, 17847, 59, 33, 12605, 10250, 14781, 17311, 11454, 19137, 10373, 10303, 10336, 19156, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 12605, 12378, 10333, 14600, 15763, 12266, 13212, 11930, 14875, 10333, 11, 65535, 261, 65530, 65534, 10414, 16037, 17847, 59, 33, 11930, 14875, 13091, 632, 653, 1751, 101, 643, 50, 19137, 16269, 14221, 12605, 10423, 12176, 12469, 16678, 10449, 19137, 10444, 13091, 17148, 10303, 17385, 16503, 14734, 11930, 14875, 12159, 13197, 10293, 10370, 17147, 13091, 10260, 16503, 12378, 12810, 14734, 11685, 28329, 65535, 261]
-> item_loss 0.6349198222160339 batch_loss 1.080320962450721
==== [25106, 11, 65530, 65531, 10464, 13091, 10250, 10283, 820, 19137, 11043, 11860, 11017, 10588, 14731, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 11454, 10260, 11454, 19156, 11, 65535, 261, 65530, 65534, 14731, 59, 33, 12605, 10250, 14781, 17311, 11454, 17148, 17384, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 12605, 10402, 13234, 15667, 15667, 10370, 12137, 13133, 15752, 11124, 10370, 15261, 14734, 13203, 13234, 11061, 28329, 65535, 261, 65530, 65534, 14731, 59, 33, 11685, 14734, 10080, 10460, 10292, 10250, 10283, 820, 19137, 12605, 12337, 10310, 12522, 11124, 10464, 16671, 16686, 17148, 10283, 16713, 18025, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 10464, 16667, 10292, 820, 13091, 11060, 10423, 11454, 11036, 10283, 13036, 17919, 16947, 17141, 10370, 15261, 19156, 11, 65535, 261, 65530, 65534, 14731, 59, 33, 12605, 16667, 10292, 10423, 14734, 19137, 10293, 10370, 10080, 10370, 15261, 14734, 16944, 13981, 15752, 11634, 17169, 13992, 10792, 660, 10372, 12201, 10808, 19137, 13091, 11454, 15847, 14221, 14610, 14734, 10260, 13032, 14035, 10901, 10285, 10358, 14583, 14734, 10080, 15646, 820, 13091, 10370, 15261, 14734, 17194, 14328, 19137, 16944, 13981, 10339, 16664, 15200, 13212, 15034, 11871, 18011, 11524, 19137, 12605, 10402, 820, 14734, 10358, 14583, 10964, 11024, 16503, 13637, 10370, 15261, 14866, 12348, 11632, 10080, 15646, 10265, 19137, 12605, 10402, 17147, 11454, 10260, 13032, 14734, 17161, 10397, 10261, 17149, 10901, 10080, 12631, 10399, 19137, 13203, 13234, 14734, 820, 14734, 15752, 10838, 12337, 13191, 11021, 15752, 16947, 17141, 10370, 15261, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 14221, 11044, 11001, 10397, 10370, 15261, 19156, 11, 65535, 261, 65530, 65534, 14731, 59, 33, 11315, 19137, 12605, 16667, 10292, 820, 13191, 11021, 15752, 10423, 11001, 10397, 10370, 15261, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 10464, 12159, 13197, 820, 11001, 10397, 10370, 15261, 10303, 19156, 11, 65535, 261, 65530, 65534, 14731, 59, 33, 12605, 10260, 12159, 13197, 10080, 12605, 11268, 13558, 12176, 10847, 10370, 15261, 19137, 10322, 11268, 13558, 11124, 10370, 15261, 10250, 16944, 15667, 11639, 19137, 10444, 13091, 11021, 15752, 13191, 10790, 14734, 820, 13191, 10261, 12605, 10260, 11042, 14734, 14791, 13764, 10080, 12605, 12159, 13197, 820, 15752, 11634, 11124, 10370, 15261, 10342, 16416, 10260, 16956, 19137, 12604, 10292, 13192, 10993, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 11975, 14731, 19137, 10464, 14734, 12509, 13764, 10260, 17631, 10080, 10444, 13091, 19137, 12605, 10402, 17919, 10288, 14808, 10250, 10283, 11426, 11574, 28329, 65535, 261, 65530, 65534, 14731, 59, 33, 13091, 10373, 10303, 11426, 11574, 19156, 11, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 12750, 14240, 14778, 10808, 14734, 10997, 12022, 17149, 15052, 19137, 820, 12337, 12387, 10423, 11454, 12337, 11632, 18011, 11524, 16947, 17141, 10370, 15261, 19137, 13187, 10397, 10370, 15261, 14734, 12137, 10460, 10080, 16269, 14221, 17148, 10250, 14172, 11021, 10399, 17189, 17141, 16909, 13981, 14734, 10703, 10768, 17332, 13234, 16533, 10722, 19137, 10444, 13091, 820, 14734, 15847, 10293, 12415, 10322, 11454, 11003, 12299, 28329, 65535, 261, 65530, 65534, 14731, 59, 33, 17148, 10423, 17194, 12604, 10373, 10303, 11044, 13258, 11102, 19156, 11, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 11414, 15178, 10464, 14734, 17728, 18025, 10808, 19137, 12605, 10658, 17728, 17728, 10464, 19137, 10464, 16667, 10292, 820, 14446, 11454, 11124, 10370, 15261, 13091, 10373, 10303, 10684, 15304, 19156, 11, 65535, 261, 65530, 65534, 14731, 59, 3609, 13091, 10370, 15261, 14734, 12631, 13191, 14328, 10080, 10322, 13191, 11190, 11871, 16520, 14172, 16667, 10292, 820, 13091, 10370, 15261, 17038, 10452, 14734, 12258, 10439, 10080, 12605, 16667, 10292, 19137, 820, 14778, 10808, 13091, 14328, 11159, 10079, 13212, 11369, 12609, 13091, 10378, 10384, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 13091, 14734, 19137, 17148, 12522, 11110, 14808, 820, 14734, 14583, 10358, 10838, 11994, 13091, 10370, 15261, 14734, 14583, 10358, 10838, 19137, 11885, 10423, 10292, 10370, 15261, 10781, 17194, 10408, 10577, 10080, 10444, 13091, 19137, 11687, 13258, 820, 14370, 15123, 10333, 19137, 820, 14734, 14583, 10358, 10838, 11994, 12025, 10339, 15847, 17038, 10080, 12014, 13064, 19137, 10370, 15261, 14734, 10408, 10577, 12348, 10260, 10792, 14015, 16956, 19137, 10423, 12282, 10997, 17922, 11117, 10080, 17148, 13091, 12605, 10260, 12509, 14791, 10792, 14734, 28329, 65535, 261, 65530, 65534, 14731, 59, 33, 12605, 16667, 11042, 10464, 19137, 10293, 10370, 10080, 11975, 14731, 10322, 10260, 12509, 14791, 10792, 10370, 15261, 11002, 10792, 10429, 11917, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 13091, 14734, 19137, 10444, 13091, 11687, 13258, 12509, 16503, 17248, 10662, 12605, 10780, 12638, 16735, 14734, 12484, 10724, 19137, 11994, 17879, 16503, 820, 11454, 12727, 13191, 10250, 11899, 15847, 10293, 12415, 14734, 11042, 13064, 19137, 10383, 14221, 10460, 10292, 10370, 15261, 14734, 14328, 11159, 10079, 13212, 11369, 12609, 10378, 10384, 28329, 65535, 261, 65530, 65534, 14731, 59, 33, 17148, 14914, 11903, 12337, 18425, 14189, 19137, 11021, 15752, 13191, 10349, 820, 10260, 12537, 12522, 17148, 10303, 10588, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 11198, 19137, 17148, 10322, 13091, 12605, 12631, 12701, 12366, 14734, 28329, 65535, 261, 65530, 65534, 14731, 59, 33, 10293, 10370, 10260, 16503, 12701, 12366, 10333, 19137, 17148, 10260, 13091, 17917, 12605, 10402, 10278, 10283, 11994, 15752, 16533, 10722, 14734, 17728, 18025, 10080, 15849, 11977, 19137, 12605, 12537, 12522, 12604, 10292, 10293, 10370, 14734, 14328, 11159, 10079, 13212, 11369, 12609, 10378, 10384, 19137, 10953, 10482, 12605, 12727, 13191, 10333, 10293, 16520, 12522, 16696, 11124, 12527, 12484, 10080, 10687, 11903, 19137, 12605, 10402, 820, 13734, 13191, 11640, 11632, 10846, 13212, 10985, 17169, 13685, 14370, 15123, 14734, 19137, 10293, 10370, 11021, 10399, 10310, 16520, 10250, 14172, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 10464, 10402, 13203, 13234, 10423, 13191, 10250, 11639, 16056, 12348, 15847, 14597, 14734, 19137, 17148, 13091, 10964, 11024, 12368, 14221, 28329, 65535, 261, 65530, 65534, 14731, 59, 33, 12605, 13078, 14731, 19137, 10444, 10260, 13091, 14446, 11454, 19137, 11957, 11061, 10080, 12605, 10402, 17147, 13191, 12337, 17688, 14734, 16981, 16503, 16939, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 11315, 19137, 10464, 15752, 14486, 16533, 12605, 14794, 13091, 11640, 11685, 10333, 28329, 65535, 261, 65530, 65534, 14731, 59, 33, 10687, 11903, 19137, 10293, 10370, 10260, 14589, 11640, 17141, 10339, 10684, 13773, 12605, 14734, 12509, 13764, 14734, 10080, 12605, 13091, 13212, 11369, 19137, 12605, 12159, 13197, 15752, 11634, 12176, 12469, 11891, 12604, 13179, 11632, 10409, 10843, 19137, 11042, 13064, 10322, 12159, 13197, 10293, 10370, 15752, 11124, 10687, 10390, 10370, 15261, 11632, 10355, 13819, 19137, 10260, 16503, 16672, 12605, 15931, 12810, 12469, 11640, 11632, 14734, 13064, 17734, 28329, 65535, 261]
-> item_loss 0.8410183787345886 batch_loss 1.0699165022891501
==== [25106, 11, 65530, 65531, 772, 640, 643, 47, 53, 47, 54, 33, 13205, 13499, 11496, 14446, 14349, 772, 11, 13205, 16728, 16537, 13499, 11496, 16443, 10794, 10460, 12604, 10333, 10250, 10283, 13212, 11369, 10370, 10847, 12636, 19137, 12202, 10265, 12727, 13191, 10250, 10283, 16667, 16692, 10293, 10370, 10080, 13205, 13499, 11496, 10696, 17303, 11861, 11454, 10250, 10283, 11168, 12220, 10293, 10452, 19137, 11168, 12220, 10293, 10452, 11021, 10399, 16749, 12231, 10261, 10482, 14589, 13499, 11496, 10696, 17303, 14734, 12631, 13191, 14862, 16696, 10080, 12307, 12824, 11002, 17109, 10673, 13064, 19137, 11168, 12220, 10293, 10452, 10423, 17189, 17141, 13499, 11496, 17109, 10760, 10261, 10293, 10370, 12609, 10687, 10390, 14589, 12626, 10355, 13819, 10080, 11454, 11044, 15511, 14734, 13004, 12797, 10285, 19137, 9822, 13205, 13499, 11496, 9823, 12609, 9822, 13205, 16728, 16537, 13499, 11496, 9823, 17311, 12748, 10397, 11168, 12220, 10293, 10452, 10080, 11168, 12220, 10293, 10452, 10423, 13326, 12797, 17109, 10673, 14734, 10696, 11922, 19137, 10768, 13254, 14778, 10808, 12631, 11621, 14734, 14349, 10724, 19137, 12202, 15494, 10760, 14862, 12415, 14734, 11414, 15178, 28329, 10953, 10482, 10293, 10370, 12609, 10687, 10390, 14589, 12626, 14734, 17109, 10673, 10260, 11634, 11891, 11255, 19137, 13205, 13499, 11496, 10322, 15752, 10292, 10390, 10402, 12848, 10494, 11021, 17917, 10079, 10452, 16895, 14734, 12176, 10847, 19137, 10487, 11687, 59, 65535, 261, 65530, 65532, 10464, 11685, 19156, 11, 65535, 261, 65530, 65534, 13212, 11369, 10370, 10847, 12636, 59, 33, 10464, 11685, 19137, 13191, 10373, 10303, 12605, 15752, 12176, 12469, 10588, 14734, 11053, 19156, 11687, 13258, 10464, 15752, 12848, 10494, 13179, 10842, 16722, 15478, 14734, 42100, 19137, 12605, 14734, 11414, 12220, 10423, 11003, 12348, 13179, 10842, 13133, 15752, 28329, 65535, 261, 65530, 65532, 12605, 13078, 14731, 10333, 28329, 65535, 261, 65530, 65531, 40812, 59, 33, 13212, 11369, 10370, 10847, 12636, 14734, 11043, 11860, 11017, 10588, 5585, 41693, 10080, 5585, 41693, 15678, 13078, 10079, 10452, 16895, 19137, 11021, 10399, 12176, 10847, 10293, 10370, 11414, 15178, 17728, 18025, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 17148, 13324, 11994, 11021, 10399, 10333, 10303, 11, 65535, 261, 65530, 65534, 5585, 41693, 59, 33, 13091, 14734, 19137, 17148, 13324, 12605, 11994, 15752, 13179, 11685, 11459, 10292, 12469, 13193, 10843, 10333, 10080, 10293, 10370, 19137, 16738, 17728, 13191, 10373, 10303, 17728, 18025, 17879, 16503, 12605, 13234, 11414, 15178, 11053, 19156, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 17268, 10303, 10382, 15484, 10250, 10258, 10464, 15847, 12144, 11061, 28329, 65535, 261, 65530, 65534, 5585, 41693, 59, 33, 12605, 13091, 5585, 41693, 19137, 13091, 10250, 10283, 13212, 11369, 10370, 10847, 12636, 10080, 10464, 13091, 12605, 14734, 10293, 10370, 10080, 12605, 15678, 13078, 10079, 10452, 16895, 19137, 11021, 10399, 12176, 12469, 11414, 15178, 11036, 15033, 17728, 18025, 10080, 11687, 13258, 13191, 10373, 10303, 10336, 12484, 12509, 16503, 10333, 16533, 14734, 19137, 13558, 17143, 11047, 12605, 12848, 17728, 19126, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 17268, 10303, 10382, 15484, 10250, 10258, 10464, 15847, 12144, 11061, 28329, 65535, 261, 65530, 65534, 5585, 41693, 59, 33, 12605, 13091, 5585, 41693, 19137, 13091, 10250, 10283, 13212, 11369, 10370, 10847, 12636, 10080, 10464, 13091, 12605, 14734, 10293, 10370, 10080, 12605, 15678, 13078, 10079, 10452, 16895, 19137, 11021, 10399, 12176, 12469, 11414, 15178, 11036, 15033, 17728, 18025, 10080, 11687, 13258, 13191, 10373, 10303, 10336, 12484, 12509, 16503, 10333, 16533, 14734, 19137, 13558, 17143, 11047, 12605, 12848, 17728, 19126, 16738, 17728, 10293, 10370, 10780, 12638, 13091, 13734, 13191, 12979, 10792, 12605, 14734, 13855, 12445, 10303, 19156, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11315, 19137, 15573, 15497, 10941, 10333, 10250, 10258, 10080, 10464, 12727, 13191, 12527, 12484, 11124, 10370, 13327, 10303, 19156, 11, 65535, 261, 65530, 65534, 5585, 41693, 59, 33, 12605, 13078, 14731, 10333, 19137, 11687, 13258, 10305, 11044, 14935, 10792, 15261, 10441, 14734, 12484, 10724, 19137, 10293, 10370, 10250, 11899, 16503, 12848, 17363, 12605, 10080, 13091, 11060, 12727, 13191, 12527, 12484, 11124, 10370, 13327, 11957, 10339, 13212, 11369, 10370, 15646, 16537, 13091, 10250, 10283, 13637, 17097, 11626, 13215, 14734, 17728, 18025, 19137, 12605, 12727, 13191, 14486, 16533, 11124, 13499, 12722, 11036, 15033, 12527, 12484, 14734, 15752, 10838, 19137, 12202, 10265, 15752, 11634, 10768, 13254, 12307, 10808, 14349, 10724, 15494, 10760, 17172, 12307, 14734, 11414, 12220, 10080, 10384, 13125, 17216, 16667, 14862, 13234, 14791, 19137, 12605, 10260, 10688, 13191, 12527, 12484, 11124, 10370, 13327, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 10464, 12159, 13197, 16056, 12348, 10370, 13216, 10303, 19156, 11, 65535, 261, 65530, 65534, 5585, 41693, 59, 33, 14778, 10808, 12605, 13734, 13191, 17148, 15033, 17879, 13685, 19137, 10293, 10370, 10080, 12605, 14734, 14778, 13308, 13091, 17802, 10437, 10293, 10370, 12202, 12176, 10847, 10293, 10370, 16533, 10722, 11036, 15033, 17728, 18025, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 13091, 11416, 10292, 12605, 10780, 12638, 10708, 14734, 16689, 11899, 10303, 19156, 11, 65535, 261, 65530, 65534, 5585, 41693, 59, 33, 10293, 10370, 19137, 12469, 12669, 12605, 16689, 11899, 10292, 15678, 13078, 10079, 10452, 16895, 19137, 11043, 10292, 5585, 41693, 14734, 13212, 11369, 10370, 10847, 12636, 19137, 15752, 12176, 12469, 11414, 15178, 17728, 18025, 10080, 12605, 10423, 12669, 16689, 11899, 10460, 10292, 12605, 14734, 14778, 13308, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 17268, 11687, 13258, 12605, 12669, 16689, 11899, 12981, 12604, 10464, 12159, 13197, 16056, 12348, 10370, 13216, 11102, 19156, 11, 65535, 261, 65530, 65534, 5585, 41693, 59, 33, 16738, 13773, 12522, 19137, 10953, 10482, 10538, 12981, 16689, 11899, 19137, 12605, 10322, 10260, 10423, 10985, 10588, 11957, 10370, 15261, 13191, 14059, 11454, 10952, 11917, 14734, 10336, 12484, 10080, 14778, 10808, 19137, 14583, 12604, 12276, 13499, 11496, 10261, 13212, 11369, 10370, 10383, 14221, 13091, 12337, 13191, 10335, 16676, 14734, 16713, 18025, 10080, 12631, 10399, 12605, 10423, 12002, 11021, 15752, 17241, 14240, 10293, 10370, 14734, 16689, 11899, 10261, 12748, 10398, 16403, 10846, 19137, 10322, 12159, 13197, 10293, 10370, 15752, 12669, 12605, 16689, 11899, 12604, 10250, 10283, 11957, 10370, 15261, 13191, 14757, 14734, 13212, 11369, 10370, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 17268, 10303, 12605, 10402, 12824, 10258, 13234, 10588, 10250, 10283, 13827, 16707, 11061, 28329, 65535, 261, 65530, 65534, 5585, 41693, 59, 33, 11685, 14734, 10293, 10370, 19137, 12605, 12145, 15486, 10733, 11622, 11685, 17149, 16403, 13827, 16707, 28329, 65535, 261, 65530, 65531, 40812, 59, 33, 16738, 17385, 11626, 35, 632, 653, 641, 35, 28329, 65535, 261, 65530, 65534, 5585, 41693, 59, 3485, 653, 641, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 16738, 11454, 35, 15966, 13258, 35, 10079, 35, 13212, 11369, 10370, 35, 10079, 35, 12266, 12366, 35, 10285, 17177, 12731, 10250, 10283, 13676, 13258, 14734, 11043, 15044, 17109, 10760, 19151, 11, 65535, 261, 65530, 65534, 5585, 41693, 59, 33, 15966, 13258, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 16738, 16735, 10760, 124, 10464, 14446, 11454, 12509, 16735, 14734, 16713, 126, 19151, 11, 65535, 261, 65530, 65534, 5585, 41693, 59, 33, 10293, 10370, 19137, 16738, 17728, 17148, 10349, 11994, 13091, 13827, 16707, 14734, 10696, 11922, 10303, 19156, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11315, 19137, 13734, 17631, 19137, 11044, 17919, 11638, 13445, 17147, 13191, 10745, 17999, 13827, 16707, 28329, 65535, 261, 65530, 65534, 5585, 41693, 59, 33, 13078, 14731, 10333, 19137, 12605, 10423, 15169, 12335, 15304, 15500, 13855, 12445, 28329, 65535, 261, 65530, 65531, 40812, 59, 33, 10580, 16689, 10464, 14446, 11454, 17879, 16503, 10985, 16947, 12154, 16889, 10327, 13057, 18069, 17879, 16503, 14734, 13223, 13021, 19137, 15752, 17149, 16403, 14734, 12748, 10398, 10894, 12732, 393, 12642, 12266, 15090, 16749, 1678, 19137, 393, 12642, 12266, 17723, 6852, 393, 12945, 10460, 14600, 15763, 1678, 19137, 16738, 17109, 10673, 12509, 16503, 12650, 16403, 14734, 12748, 10398, 19151, 11, 65535, 261, 65530, 65534, 5585, 41693, 59, 326, 12642, 12266, 17723, 94, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 12410, 15641, 19151, 10292, 10373, 10303, 16503, 10588, 17148, 13324, 14734, 13827, 16707, 28329, 65535, 261, 65530, 65534, 5585, 41693, 59, 33, 10293, 10370, 16503, 12605, 10588, 17148, 13324, 14734, 13827, 16707, 19137, 11021, 15752, 13091, 10292, 10333, 13381, 13827, 12605, 13091, 11060, 15752, 11634, 10733, 14914, 11459, 10261, 15304, 15500, 10355, 10342, 10080, 10292, 13581, 19137, 12605, 14734, 17109, 10760, 12220, 16721, 10261, 15304, 15500, 12848, 10494, 14734, 13327, 12276, 10250, 15850, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11315, 19137, 13827, 16707, 15489, 13229, 10333, 28329, 65535, 261, 65530, 65534, 5585, 41693, 59, 33, 12605, 12337, 18216, 10685, 15752, 12176, 10792, 10293, 10370, 19126, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 10464, 17147, 16678, 12348, 11150, 10402, 10381, 11639, 10588, 10333, 10373, 10303, 11053, 19156, 11, 65535, 261, 65530, 65534, 5585, 41693, 59, 33, 12605, 14778, 10808, 13051, 13764, 16056, 12348, 10684, 10339, 13064, 17734, 14734, 10529, 12445, 19137, 10444, 13091, 13326, 12797, 12605, 10402, 14734, 10355, 10342, 10964, 11024, 19137, 12605, 16678, 12348, 11124, 10293, 10370, 10250, 16944, 10588, 17141, 14734, 10336, 12484, 10080, 13188, 10782, 10293, 10370, 11124, 12605, 10342, 14782, 17728, 10560, 19137, 10292, 12605, 16944, 11043, 12202, 13920, 10842, 10333, 16689, 11899, 19137, 12605, 12604, 10292, 10333, 15678, 13078, 10079, 10452, 16895, 14734, 13212, 11369, 10370, 10847, 12636, 5585, 41693, 19137, 15752, 11634, 10292, 12469, 16533, 15178, 17728, 18025, 10080, 10305, 11044, 10293, 10370, 16672, 12605, 17149, 16403, 15847, 12605, 10382, 15484, 19137, 12202, 16671, 16686, 10333, 12605, 14734, 16689, 11899, 14782, 10684, 14734, 16713, 18025, 10080, 13188, 11044, 10293, 10370, 11957, 12605, 17149, 16403, 10333, 13827, 16707, 19137, 16672, 12605, 10261, 15304, 15500, 17149, 16403, 10355, 10342, 28329, 65535, 261, 65530, 65534, 14488, 14543, 19151, 33, 12605, 10780, 10780, 16707, 14808, 11871, 10323, 10333, 17148, 10349, 14862, 16696, 10080, 15489, 13258, 12605, 12527, 16525, 11871, 12348, 17147, 15200, 13078, 14731, 19137, 33, 12220, 16721, 15752, 13819, 14607, 14734, 16417, 17136, 28329, 65535, 261]
-> item_loss 1.0676487684249878 batch_loss 1.0698220133781433
==== [25106, 11, 65530, 65531, 772, 640, 643, 47, 55, 47, 644, 33, 13205, 13499, 11496, 14446, 14349, 772, 11, 12605, 14778, 10808, 10383, 14221, 10460, 10292, 10250, 10283, 16728, 16537, 13499, 11496, 11861, 11454, 14808, 19137, 12605, 15752, 11634, 10588, 14734, 10336, 12484, 13091, 12824, 11002, 13012, 11860, 15304, 10777, 17109, 10673, 12202, 15494, 10760, 13012, 11860, 17109, 10760, 10080, 10444, 13091, 19137, 13188, 17145, 12605, 10997, 14446, 11454, 12605, 11124, 10370, 15261, 14734, 11957, 16713, 10285, 19137, 10423, 11986, 16707, 10985, 11610, 13078, 10250, 10349, 16728, 16537, 13499, 11496, 10588, 10260, 10333, 14734, 10336, 12484, 10080, 12605, 13091, 16728, 16537, 13499, 11496, 19137, 13091, 820, 19137, 13091, 13212, 11369, 19137, 10953, 10482, 15752, 11634, 10621, 10370, 15261, 10250, 13324, 12410, 15641, 19137, 12605, 10322, 13051, 13764, 10588, 10760, 10250, 10349, 13191, 17038, 10452, 14734, 10370, 15261, 12638, 15752, 10588, 10760, 14734, 10846, 10460, 10080, 10322, 11994, 13091, 16735, 19137, 16269, 14221, 12605, 11021, 10399, 12656, 14035, 15847, 12144, 11124, 10370, 15261, 17149, 16403, 10333, 15707, 10452, 12824, 16535, 19137, 13234, 16672, 10370, 15261, 14015, 16956, 10080, 10444, 13091, 12307, 10370, 15261, 11454, 17728, 12605, 13580, 11454, 10588, 10373, 10303, 14734, 13064, 10560, 19137, 12605, 10260, 12220, 16721, 15494, 10760, 15847, 12144, 13580, 11454, 11035, 18089, 12609, 15643, 16968, 13582, 15169, 10398, 10370, 15261, 10292, 17843, 14734, 15178, 13336, 10080, 13581, 11630, 19137, 12605, 14734, 11414, 15178, 13327, 12276, 10260, 12220, 16721, 10250, 12604, 10260, 11003, 19137, 17879, 16503, 10594, 11979, 14734, 10293, 10846, 10588, 10760, 12981, 11003, 10080, 11416, 10292, 19137, 11687, 13258, 12605, 10250, 14781, 14589, 11042, 10250, 15033, 13327, 12276, 17149, 16403, 11414, 11626, 19137, 12337, 13191, 11021, 15752, 17819, 14808, 13064, 17734, 14734, 12826, 15046, 15646, 17808, 10673, 13279, 15033, 12357, 14445, 10285, 10080, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 10464, 13091, 10250, 10283, 16728, 16537, 13499, 11496, 19137, 17303, 15588, 11454, 12605, 14734, 14600, 15763, 10257, 19137, 12605, 13091, 10464, 14734, 10293, 10370, 10080, 11124, 12605, 12642, 10283, 12719, 11116, 11061, 28329, 65535, 261, 65530, 65534, 13212, 11369, 10370, 59, 33, 10293, 10370, 19137, 10464, 11685, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 11088, 16698, 12605, 35724, 24566, 13091, 10373, 10303, 12522, 12410, 28329, 65535, 261, 65530, 65534, 13212, 11369, 10370, 59, 60582, 13091, 14328, 16884, 14734, 12522, 12410, 19137, 10397, 16417, 11903, 17781, 11861, 11454, 10339, 10267, 14610, 10257, 14734, 13279, 15033, 10272, 16501, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 12605, 10333, 16533, 10333, 28329, 65535, 261, 65530, 65534, 13212, 11369, 10370, 59, 33, 12337, 18216, 10685, 15752, 12176, 10257, 12469, 14734, 12379, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 10464, 14862, 17222, 10373, 10303, 13091, 13212, 11764, 10303, 19156, 11, 65535, 261, 65530, 65534, 13212, 11369, 10370, 59, 33, 13212, 11764, 13091, 12748, 11454, 16403, 10292, 13036, 12276, 11124, 11630, 16417, 14332, 12333, 10257, 10261, 10370, 15261, 14734, 11679, 12415, 13191, 12631, 14782, 10441, 14734, 13212, 11369, 10370, 19137, 11684, 10402, 11416, 10292, 11021, 14299, 14734, 16403, 10292, 10079, 15957, 13191, 15957, 13051, 14734, 13212, 13375, 12527, 10399, 10992, 16947, 14221, 10339, 10370, 15261, 10408, 10577, 16520, 14734, 15458, 14794, 15646, 11002, 10792, 10370, 15261, 11268, 14299, 10080, 14597, 10339, 11684, 10402, 13091, 13212, 11369, 10370, 19137, 12631, 10399, 10322, 10423, 13193, 10384, 10370, 15261, 14734, 11117, 10398, 10079, 10292, 10370, 15261, 12848, 10494, 12176, 10847, 10079, 17802, 10437, 10370, 15261, 19137, 17148, 17149, 10250, 13582, 10842, 13913, 10333, 10370, 10402, 11957, 11684, 10402, 14734, 11268, 14299, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 11891, 10675, 13580, 14914, 19137, 12631, 10399, 12605, 10322, 12159, 13197, 10464, 11124, 12605, 10355, 13819, 14734, 13064, 10560, 10322, 11021, 14299, 10250, 14172, 28329, 65535, 261, 65530, 65534, 13212, 11369, 10370, 59, 33, 11021, 10399, 14734, 19137, 12605, 10423, 10848, 10838, 17149, 16403, 11986, 16707, 14734, 19126, 28336, 11, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 12791, 10283, 16713, 18025, 11061, 28329, 65535, 261, 65530, 65534, 13212, 11369, 10370, 59, 33, 11065, 10464, 14734, 19137, 10293, 10370, 10080, 12605, 10402, 16747, 13234, 12848, 10760, 16713, 18025, 11102, 19156, 11, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 12605, 13234, 11061, 10080, 10464, 14862, 17222, 14398, 11764, 13091, 10373, 10303, 11053, 19156, 11, 65535, 261, 65530, 65534, 13212, 11369, 10370, 59, 33, 13091, 10250, 15033, 12206, 12509, 14583, 14328, 19137, 11684, 10402, 12727, 13191, 10370, 15261, 14734, 17038, 10452, 15489, 13250, 11124, 10250, 10349, 14398, 14734, 14332, 12333, 19137, 13191, 14734, 14398, 11764, 13191, 10250, 10349, 14332, 13603, 14734, 11010, 14714, 19137, 13637, 11687, 11454, 16735, 16713, 14734, 15489, 12003, 10842, 10257, 10250, 10283, 9822, 11280, 9823, 11860, 10080, 11454, 12605, 14734, 13499, 11496, 10285, 19137, 10441, 10308, 17798, 10333, 13053, 12182, 14734, 11957, 16713, 11630, 19137, 17147, 13191, 10250, 10349, 14398, 11764, 17149, 16403, 12415, 16403, 10292, 14734, 14862, 16696, 28329, 65535, 261, 65530, 65532, 10370, 15261, 59, 33, 11638, 10452, 13734, 17631, 19137, 10444, 13091, 12605, 12509, 11088, 16698, 10464, 19137, 14398, 11764, 12202, 10260, 13091, 11124, 10409, 10454, 10370, 17311, 10423, 17149, 16403, 12415, 16403, 10292, 10080, 11684, 10402, 10322, 13091, 13179, 11268, 13558, 11124, 10370, 15261, 17149, 16403, 12200, 15169, 14734, 15667, 11639, 19137, 11016, 13191, 11454, 10994, 13036, 12727, 13191, 12337, 13913, 14734, 10529, 16922, 10305, 11044, 19137, 12638, 10423, 17149, 16403, 10366, 11930, 16403, 10292, 28329, 65535, 261, 65530, 65534, 13212, 11369, 10370, 59, 33, 11871, 10792, 10333, 19137, 12605, 10423, 16678, 10449, 14734, 28329, 65535, 261]
-> item_loss 1.0391602516174316 batch_loss 1.0685955429077147
==== [65530, 65532, 27476, 4600, 4490, 101, 275, 18488, 10261, 11459, 10258, 11517, 42, 4600, 32189, 37598, 64, 11, 65535, 261, 65530, 65534, 945, 69, 275, 18488, 10261, 11459, 10258, 11517, 42, 4600, 332, 31894, 46, 49551, 30941, 32227, 22748, 51351, 4450, 45062, 116, 4706, 22590, 36504, 45, 22762, 30135, 52603, 4601, 47, 3918, 460, 332, 21716, 21265, 63667, 30941, 4811, 31702, 45, 4788, 4588, 22799, 31296, 38576, 31296, 29398, 34177, 4715, 37576, 4706, 21138, 34177, 45, 22799, 39021, 38374, 52491, 4601, 22614, 34, 11, 65535, 261, 8787, 1791, 4660, 21835, 4811, 31358, 332, 30433, 24743, 30397, 11, 65530, 65534, 24202, 45, 308, 21413, 31073, 22799, 32487, 32227, 47, 29059, 460, 4419, 51668, 4706, 332, 59284, 30397, 59, 11, 6884, 11, 124, 3331, 35, 26290, 388, 269, 23813, 384, 3331, 35, 6935, 388, 3493, 45, 3331, 35, 41455, 388, 269, 23902, 384, 3331, 35, 41497, 388, 284, 47, 695, 45, 3331, 35, 42519, 388, 3543, 45, 3331, 35, 25543, 34158, 388, 269, 34062, 384, 3331, 35, 7537, 34158, 388, 269, 34062, 384, 3331, 35, 25526, 27166, 388, 269, 33155, 45, 4677, 31496, 4600, 29165, 21265, 308, 459, 4419, 3609, 22762, 38939, 4811, 31702, 38576, 21265, 32022, 39742, 5352, 3331, 35, 1928, 1760, 7789, 388, 4363, 48645, 38576, 384, 269, 24166, 7856, 39742, 5191, 3331, 35, 1928, 1760, 122, 50, 388, 269, 48645, 38576, 384, 3331, 35, 1928, 1760, 122, 51, 388, 269, 24166, 7856, 39742, 384, 3331, 35, 1928, 1760, 122, 52, 388, 269, 46200, 384, 3331, 35, 1928, 1760, 122, 53, 388, 269, 33572, 7856, 46611, 384, 3331, 35, 1928, 1760, 122, 54, 388, 269, 48645, 38576, 32487, 4677, 51803, 5352, 3331, 35, 64057, 116, 388, 22820, 267, 36, 29165, 38278, 461, 31059, 21273, 65004, 4424, 22590, 46594, 45, 4423, 4569, 460, 4419, 3609, 22762, 38939, 4811, 31702, 38576, 21265, 32022, 39742, 47, 3878, 39021, 21227, 32074, 65004, 4596, 22590, 46064, 4588, 4569, 38996, 31458, 46787, 47, 11, 126, 11, 6884, 11, 853, 22799, 21413, 22449, 45, 4601, 460, 31198, 4419, 51668, 4706, 32464, 332, 59284, 30397, 38128, 31324, 31296, 47, 37451, 21286, 31370, 47539, 22799, 38128, 4491, 4811, 31358, 4601, 31458, 63667, 21265, 55975, 65535, 261, 65530, 65532, 9135, 47266, 51328, 22590, 33, 17631, 16730, 4596, 22590, 30433, 24743, 30397, 11, 65535, 261, 65530, 65534, 23727, 21286, 22590, 63430, 308, 31351, 4811, 22590, 59284, 30397, 59, 11, 6884, 11, 124, 262, 35, 26290, 388, 269, 23813, 22590, 3753, 7037, 384, 11, 35, 26784, 5181, 3753, 7037, 35, 279, 11, 35, 34135, 388, 269, 5926, 1932, 1857, 384, 11, 35, 60940, 388, 269, 5732, 111, 36530, 1857, 384, 11, 35, 6935, 388, 3485, 49, 45, 11, 35, 41455, 388, 269, 23902, 384, 11, 35, 41497, 388, 286, 47, 54, 30838, 45, 11, 35, 42519, 388, 3489, 49, 21993, 45, 11, 35, 25543, 5181, 36406, 28478, 101, 21265, 29021, 384, 11, 35, 7537, 34158, 388, 269, 32957, 384, 11, 35, 60940, 5181, 308, 4418, 332, 30452, 38135, 1857, 38319, 30917, 22590, 60032, 47, 308, 31428, 101, 45, 51346, 53324, 21265, 37744, 45, 21265, 46036, 4715, 1802, 21265, 21767, 8095, 116, 4811, 52592, 4677, 30452, 5352, 11, 35, 1928, 1760, 7789, 388, 326, 269, 23926, 2065, 22235, 116, 384, 269, 33443, 7856, 53324, 21265, 37744, 5178, 24166, 7856, 30887, 39742, 384, 269, 24232, 7856, 39890, 4450, 22590, 30863, 5191, 262, 35, 54236, 7933, 47602, 23258, 24197, 24911, 5178, 918, 8987, 8439, 384, 269, 40425, 5191, 262, 35, 34636, 116, 23258, 57959, 384, 269, 6014, 2101, 5191, 11, 35, 24904, 116, 23258, 1264, 30452, 4600, 4677, 45956, 45, 308, 32475, 52592, 32229, 5191, 11, 35, 1877, 7096, 23258, 74, 4418, 45820, 56746, 21265, 39418, 4811, 37702, 395, 11, 126, 11, 6884, 11, 6699, 31356, 51165, 308, 31351, 59, 11, 46, 50612, 101, 29165, 460, 51833, 63637, 32487, 51454, 57346, 21700, 332, 303, 111, 69, 59284, 280, 31496, 45, 31813, 45, 38046, 45, 61626, 39831, 45, 39804, 11, 46, 36241, 63757, 47602, 45, 46244, 45, 37881, 21265, 38511, 4811, 38513, 22249, 22590, 59284, 11, 46, 36241, 21825, 24874, 31458, 63291, 21700, 332, 3753, 7037, 11, 46, 29955, 46928, 40069, 21700, 46182, 21265, 47779, 11, 23739, 32234, 38686, 34, 20282, 4660, 31223, 4588, 22799, 31059, 21273, 39193, 60312, 47, 65535, 261, 54397, 22590, 30433, 24743, 30397, 31162, 30441, 7506, 47, 11, 65530, 65534, 17148, 17384, 13091, 15636, 16704, 11044, 14734, 10370, 14328, 10941, 59, 11, 6884, 26060, 11, 124, 11, 35, 11043, 11860, 388, 269, 15450, 15632, 14867, 10370, 384, 11, 35, 15033, 13046, 5181, 14867, 10370, 384, 11, 35, 15669, 10270, 388, 269, 13583, 11606, 384, 11, 35, 15727, 13126, 388, 269, 13651, 13046, 12137, 10905, 384, 11, 35, 12201, 18476, 388, 3485, 49, 45, 11, 35, 12415, 10790, 388, 269, 14601, 12415, 384, 11, 35, 17038, 18216, 388, 284, 47, 625, 33, 15260, 45, 11, 35, 10452, 17385, 388, 3546, 33, 10918, 10660, 45, 11, 35, 11647, 10997, 5181, 13388, 15898, 15737, 18001, 11124, 11647, 10997, 384, 11, 35, 14806, 14815, 18029, 15898, 388, 269, 13388, 15898, 384, 11, 35, 15727, 13126, 5181, 12605, 13091, 10250, 10283, 13234, 15847, 12034, 17734, 14734, 10489, 10642, 13651, 13046, 12137, 10905, 10080, 12605, 14873, 12034, 12266, 17379, 45, 10794, 10460, 13583, 11369, 11124, 12686, 14598, 45, 12202, 10261, 18053, 10370, 11698, 11124, 18053, 10370, 18243, 12610, 13020, 10525, 12686, 12605, 14734, 13651, 13046, 10080, 384, 11, 35, 10270, 10457, 14299, 11685, 388, 4363, 12266, 17379, 14873, 14328, 35, 10079, 35, 17655, 17194, 13583, 11369, 11124, 12686, 14598, 5178, 11212, 18008, 13572, 5178, 16679, 17162, 14152, 14136, 12985, 10336, 5191, 11, 35, 12415, 13327, 14332, 12333, 388, 4363, 18003, 11434, 384, 269, 11975, 12366, 384, 269, 14781, 12824, 395, 279, 11, 35, 14486, 12389, 23258, 10682, 11042, 10452, 5178, 16020, 16584, 5191, 11, 35, 10366, 15545, 10684, 15304, 23258, 12605, 14734, 13651, 13046, 13091, 12605, 14734, 11920, 10370, 45, 12605, 11967, 10525, 12686, 10390, 10402, 5191, 11, 35, 15568, 14172, 23258, 12605, 12337, 11922, 13080, 11002, 10792, 10705, 14347, 19137, 12202, 10265, 12337, 11922, 13080, 10997, 12403, 395, 11, 126, 11, 6884, 65535, 261]
-> item_loss 1.8060524463653564 batch_loss 1.096959269963778
==== [10293, 18025, 19151, 33, 13034, 12636, 12748, 12282, 11, 65530, 65532, 13676, 13130, 19151, 16738, 10382, 15484, 14136, 14484, 13208, 14734, 10482, 14589, 13036, 12276, 11, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 33, 11315, 19137, 11685, 14734, 10080, 18117, 10658, 19137, 10464, 17879, 16503, 17177, 12731, 10250, 10283, 14778, 13308, 19137, 17148, 10283, 14778, 13308, 12368, 18001, 11454, 650, 11999, 15973, 11430, 10696, 28329, 65535, 261, 65530, 65534, 13676, 13130, 19151, 14221, 11044, 19137, 10464, 17879, 16503, 17177, 12731, 14136, 14484, 13208, 14734, 14778, 13308, 10080, 17148, 10283, 14778, 13308, 10260, 15752, 16443, 10675, 17238, 16181, 10080, 33, 10464, 10322, 11021, 10399, 17177, 12731, 11459, 11436, 10257, 14734, 13279, 10283, 14172, 17382, 12983, 14136, 14484, 13208, 19137, 17148, 13324, 11021, 10399, 17248, 10662, 17238, 16181, 11957, 14778, 13308, 14734, 12325, 11168, 28329, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 33, 14221, 11044, 19137, 10464, 17879, 16503, 10722, 11899, 14136, 14484, 13208, 14734, 10429, 11917, 15261, 11496, 10080, 10250, 15880, 13234, 16735, 19137, 14136, 14484, 13208, 17194, 12604, 14734, 13091, 14136, 14218, 10429, 11917, 19137, 10444, 13091, 10322, 13191, 11021, 15752, 17194, 12604, 10687, 10390, 10429, 11917, 15261, 11496, 19137, 11001, 10722, 10339, 10464, 14734, 17177, 12731, 28329, 65535, 261, 65530, 65532, 13676, 13130, 19151, 33, 17147, 13191, 10373, 10303, 17879, 16503, 13773, 12522, 14734, 11053, 19156, 11, 65535, 261, 65530, 65534, 11889, 13849, 12705, 59, 33, 13188, 11044, 19137, 10464, 17879, 16503, 10722, 11899, 13091, 11060, 10482, 14589, 13223, 13021, 12604, 10768, 10080, 11687, 13258, 10464, 17177, 12731, 10260, 10482, 14589, 13223, 13021, 12604, 10768, 19137, 17268, 10303, 14136, 14484, 13208, 14734, 10429, 11917, 10292, 49, 10080, 33, 11687, 13258, 10464, 17177, 12731, 10482, 14589, 13223, 13021, 12604, 10768, 19137, 17268, 10303, 14136, 14484, 13208, 14734, 10429, 11917, 10292, 50, 101, 55, 44, 50, 101, 55, 48, 13633, 15169, 15451, 19133, 13188, 11632, 44, 630, 19134, 10080, 33, 13223, 13021, 12604, 10768, 10894, 12732, 10250, 11975, 13619, 18119, 13021, 11124, 10250, 10283, 10408, 10577, 10260, 10448, 10339, 630, 49, 17389, 12153, 14734, 13676, 13130, 14484, 10080, 33, 17148, 11001, 10722, 10339, 10464, 28329, 65535, 261, 65530, 65532, 13676, 13130, 19151, 33, 12337, 11685, 33, 12605, 10333, 16533, 14136, 14484, 13208, 10333, 19137, 33, 12605, 10402, 12791, 10283, 16713, 18025, 28329, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 33, 11685, 14734, 19137, 10464, 16735, 11061, 28329, 65535, 261, 65530, 65532, 13676, 13130, 19151, 33, 12605, 12509, 10588, 10250, 12287, 10370, 14328, 10941, 19137, 10464, 13191, 10373, 10303, 12261, 16676, 19156, 11, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 33, 11685, 14734, 19137, 12605, 10402, 10384, 11187, 17384, 12266, 11726, 11102, 19156, 11, 65535, 261, 65530, 65532, 13676, 13130, 19151, 33, 11315, 19137, 12605, 12509, 10658, 10384, 12415, 13327, 12266, 11726, 28329, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 33, 11315, 19137, 12605, 12509, 12509, 43282, 11, 65535, 261, 65530, 65532, 13676, 13130, 19151, 33, 10464, 16525, 12348, 11684, 13091, 10283, 12401, 10303, 13324, 14734, 10370, 19156, 11, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 33, 12605, 16525, 12348, 11684, 13091, 10283, 10310, 16520, 12266, 13196, 14734, 10370, 19137, 11268, 13558, 12176, 10847, 10790, 10370, 19137, 10444, 13191, 13064, 10560, 10423, 12392, 14619, 10250, 10349, 15478, 15907, 28329, 65535, 261, 65530, 65532, 13676, 13130, 59, 33, 14221, 11044, 12605, 12509, 16503, 18438, 14806, 14815, 11124, 18438, 11647, 10997, 19137, 10464, 16525, 12348, 12401, 10303, 13324, 19156, 11, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 33, 11315, 19137, 12605, 16525, 12348, 17148, 10278, 10283, 14332, 12333, 12337, 15158, 11038, 10464, 14734, 12847, 17162, 10080, 10260, 17141, 19137, 10464, 11021, 10399, 15641, 16253, 15494, 11684, 10250, 10283, 13179, 10842, 14370, 14332, 14734, 11630, 16815, 28329, 65535, 261, 65530, 65532, 13676, 13130, 59, 33, 13637, 11687, 19156, 11, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 33, 13637, 11687, 16735, 19137, 11684, 14734, 11647, 10997, 11021, 10399, 13091, 17389, 15898, 14734, 19137, 14806, 14815, 11021, 10399, 13091, 16155, 15898, 14734, 19137, 17148, 13324, 10423, 13179, 10842, 14332, 13603, 28329, 65535, 261, 65530, 65532, 13676, 13130, 59, 33, 11315, 19137, 12605, 10423, 15641, 16253, 14734, 28329, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 33, 17147, 13191, 10250, 14172, 11994, 13091, 19137, 11684, 14734, 12415, 13327, 13637, 17097, 10310, 16520, 12266, 13196, 19137, 10444, 13191, 13064, 10560, 10423, 12392, 14619, 10250, 10349, 15478, 15907, 28329, 65535, 261, 65530, 65532, 13676, 13130, 59, 33, 17148, 10278, 14172, 12605, 17311, 13773, 12522, 10792, 10333, 19137, 16774, 16774, 10464, 12848, 17363, 28329, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 33, 10260, 14589, 16774, 19137, 12605, 12337, 18216, 10685, 15752, 12176, 10257, 10464, 14734, 12379, 28329, 65535, 261, 65530, 65532, 13676, 13130, 59, 33, 10464, 16525, 12348, 17148, 10278, 10283, 14332, 12333, 11187, 10349, 13637, 17097, 17385, 16503, 19156, 11, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 33, 12605, 16525, 12348, 10310, 16520, 12266, 13196, 11124, 14370, 14332, 11630, 16815, 13091, 13637, 17097, 17385, 16503, 14734, 28329, 65535, 261, 65530, 65532, 13676, 13130, 59, 33, 11685, 14734, 19137, 12605, 10423, 15641, 16253, 10464, 14734, 12261, 16676, 28329, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 33, 11957, 10333, 19137, 12605, 17147, 12509, 17728, 10464, 10250, 10283, 17728, 18025, 28329, 65535, 261, 65530, 65532, 13676, 13130, 59, 33, 11685, 14734, 19137, 10464, 16735, 11061, 28329, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 33, 10464, 16525, 12348, 10373, 10303, 13324, 14734, 11630, 16815, 15158, 11038, 12605, 10780, 12638, 15494, 10760, 14734, 16503, 13685, 19156, 11, 65535, 261, 65530, 65532, 13676, 13130, 59, 33, 11315, 19137, 12605, 16525, 12348, 10464, 10780, 12638, 15494, 10760, 14734, 16503, 13685, 12337, 15158, 11038, 12605, 10780, 12638, 15494, 10760, 14734, 16503, 13685, 28329, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 33, 11315, 19137, 16774, 16774, 10464, 14734, 14486, 16533, 10080, 12605, 12337, 12266, 12366, 15752, 12176, 10257, 10464, 14734, 12379, 28329, 65535, 261, 65530, 65532, 13676, 13130, 59, 33, 10260, 14589, 16774, 19137, 12605, 10322, 12337, 12266, 12366, 15752, 12176, 10257, 10464, 14734, 12379, 28329, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 33, 11957, 10333, 19137, 13326, 12797, 11150, 10402, 14734, 16753, 16713, 19137, 12605, 10292, 10464, 16689, 16664, 14734, 11630, 16815, 13091, 17389, 15898, 14734, 11647, 10997, 10079, 18438, 15898, 14734, 14806, 14815, 10079, 14136, 15446, 15898, 14734, 11630, 16815, 19137, 10464, 16525, 12348, 11687, 10454, 19156, 11, 65535, 261, 65530, 65532, 13676, 13130, 59, 33, 12605, 16525, 12348, 12337, 11685, 19137, 10464, 14734, 16689, 16664, 12337, 15158, 11038, 12605, 14734, 16503, 13685, 28329, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 33, 11640, 11685, 10333, 19137, 12605, 17147, 12405, 10464, 10260, 11268, 13558, 11102, 10080, 17268, 10303, 19137, 12605, 10402, 14734, 16753, 16713, 11994, 10792, 17148, 17384, 11061, 28329, 65535, 261, 65530, 65532, 13676, 13130, 59, 33, 11685, 14734, 19137, 12605, 10402, 14734, 16753, 16713, 10792, 17148, 17384, 28329, 65535, 261, 65530, 65534, 11889, 13849, 12705, 59, 33, 11685, 14734, 19137, 12605, 10402, 14734, 16753, 16713, 10792, 17148, 17384, 28329, 65535, 261, 65530, 65532, 13676, 13130, 59, 33, 11957, 10333, 19137, 12605, 10780, 12638, 15494, 10464, 16689, 16664, 14734, 11630, 16815, 13091, 17389, 15898, 14734, 11647, 10997, 10079, 18438, 15898, 14734, 14806, 14815, 10079, 14136, 15446, 15898, 14734, 11630, 11666, 19137, 10464, 16525, 12348, 11687, 10454, 19156, 11, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 33, 12337, 15158, 11038, 12605, 10780, 12638, 15494, 10760, 14734, 16503, 13685, 28329, 65535, 261]
-> item_loss 0.6855570673942566 batch_loss 1.081722151350092
==== [14862, 16696, 17728, 15178, 15129, 16925, 11, 65530, 65531, 10464, 13091, 10250, 10283, 1741, 10847, 12636, 19137, 11017, 10588, 11889, 13849, 12705, 10080, 10464, 12656, 14035, 10250, 11043, 11679, 11638, 11871, 14583, 19137, 33, 10688, 13191, 15895, 11685, 14734, 12996, 15715, 11124, 14862, 16696, 15727, 13126, 19137, 14256, 12459, 16664, 15200, 13212, 11124, 14583, 14328, 12137, 15052, 28329, 65535, 261, 65530, 65532, 10293, 12746, 10370, 19151, 33, 13558, 17143, 10464, 19137, 10988, 16925, 15643, 19137, 10464, 11017, 10373, 10303, 11043, 11860, 19156, 19156, 33, 10464, 14734, 15669, 10270, 13091, 10373, 10303, 19156, 11, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 33, 10464, 11685, 19137, 10293, 12746, 10370, 10080, 12605, 11017, 11889, 13849, 12705, 19137, 14778, 10808, 13091, 10250, 11043, 11638, 10256, 14734, 11871, 14583, 10080, 12605, 14734, 15669, 10270, 13091, 14880, 15087, 14583, 28329, 65535, 261, 65530, 65532, 10293, 12746, 10370, 19151, 10988, 10842, 17148, 13557, 13637, 16925, 10464, 15326, 12287, 11053, 19156, 11, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 12605, 13191, 10349, 15326, 12287, 19137, 10444, 13091, 12605, 14782, 10529, 15847, 12144, 15752, 10588, 11685, 10733, 11622, 28329, 65535, 261, 65530, 65531, 12824, 10258, 13234, 11889, 13849, 12705, 12266, 11726, 14589, 16728, 16537, 12847, 17162, 15847, 12144, 14734, 11630, 16815, 11124, 12415, 13327, 14332, 14172, 11, 65535, 261, 65530, 65532, 10293, 12746, 10370, 19151, 10464, 16525, 12348, 15847, 12144, 13091, 10250, 10283, 12401, 10303, 13324, 14734, 10370, 19156, 11, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 12605, 16525, 12348, 15847, 12144, 13091, 10250, 10283, 10310, 16520, 12266, 13196, 14734, 10370, 19137, 11268, 13558, 12176, 10847, 10790, 10370, 19137, 10322, 11268, 13558, 11871, 10323, 13034, 14862, 16696, 28329, 65535, 261, 65530, 65532, 10293, 12746, 10370, 19151, 33, 10464, 14734, 10370, 14583, 10285, 13191, 11187, 10349, 17225, 12577, 19156, 11, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 12605, 13191, 10250, 10283, 13192, 10993, 19137, 10390, 11454, 12605, 12337, 11975, 14734, 13064, 10560, 11994, 10985, 10267, 10333, 10080, 12605, 10402, 14734, 12527, 12484, 17916, 12182, 13913, 19137, 12605, 17916, 12182, 12509, 12389, 10390, 28329, 65535, 261, 65530, 65532, 10293, 12746, 10370, 19151, 33, 10464, 13191, 10373, 10303, 13203, 13234, 14734, 14486, 12509, 11053, 19156, 11, 65535, 261, 65530, 65534, 11889, 13849, 12705, 19151, 33, 12605, 12159, 13197, 15752, 11634, 12176, 10847, 13179, 11632, 14734, 10370, 19137, 16672, 10390, 10402, 12527, 11002, 10792, 13947, 13145, 11124, 10684, 12395, 10080, 12605, 10322, 12159, 13197, 15847, 12144, 15752, 11634, 12727, 13191, 10250, 10283, 12203, 15009, 15597, 14015, 14734, 11920, 12234, 28329, 65535, 261]
[2023-09-30 21:47:59,201] [INFO] [logging.py:96:log_dist] [Rank 0] step=30, skipped=0, lr=[0.0001, 0.0001, 0.0001], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
-> item_loss 1.010324239730835 batch_loss 1.0791722259351186
==== [65530, 65532, 27021, 4660, 21835, 4811, 22681, 331, 42447, 46, 1950, 97, 267, 1950, 21443, 7999, 102, 30469, 11, 65535, 261, 65530, 65534, 42447, 46, 1950, 4600, 332, 19644, 7999, 102, 56292, 32227, 45143, 22799, 4811, 47675, 4419, 56173, 22069, 4715, 31050, 32487, 22168, 30579, 47, 29059, 460, 4419, 51668, 4706, 21835, 22799, 21413, 22681, 4601, 59, 11, 6884, 7262, 7999, 102, 11, 41, 7334, 4677, 46, 8149, 4899, 98, 293, 99, 293, 100, 293, 101, 2389, 11, 41, 7334, 22168, 46, 25106, 4899, 98, 4899, 100, 293, 101, 9209, 11, 41, 42447, 46, 1950, 4677, 46, 8149, 283, 275, 41749, 275, 8020, 42, 275, 8706, 34, 22168, 46, 25106, 21952, 5292, 11, 6884, 11, 1136, 32234, 51668, 45, 308, 459, 55940, 332, 22069, 45395, 331, 2058, 46, 8149, 97, 21265, 52865, 4601, 4811, 4435, 38365, 47, 29890, 45, 308, 459, 40085, 22590, 331, 42447, 46, 1950, 97, 56292, 4811, 21227, 332, 22168, 21952, 48, 35957, 31614, 4811, 22590, 22069, 45, 40186, 31371, 4811, 332, 22168, 40093, 47, 50232, 45, 308, 459, 40085, 22590, 331, 8706, 34, 97, 56292, 4811, 21227, 332, 22168, 21952, 48, 35957, 31614, 4811, 22590, 22069, 47, 11, 74, 31104, 32234, 38686, 34, 20282, 4660, 31223, 4588, 22799, 31059, 21273, 39193, 60312, 47, 65535, 261, 1955, 22590, 21652, 24518, 33944, 4600, 39523, 64, 11, 65530, 65534, 6831, 45, 22590, 37812, 63560, 4706, 22590, 47675, 46, 1950, 56292, 4600, 51328, 47, 300, 45602, 39141, 59, 11, 50, 42, 20996, 51668, 30469, 21800, 332, 47486, 38392, 280, 22590, 22069, 56556, 47266, 4435, 59, 11, 6884, 7262, 7999, 102, 11, 41, 7334, 4677, 46, 8149, 4899, 98, 293, 99, 293, 100, 293, 101, 2389, 11, 41, 7334, 22168, 46, 25106, 4899, 98, 4899, 100, 293, 101, 9209, 11, 6884, 11, 51, 42, 47675, 46, 1950, 45143, 22799, 4811, 47675, 46657, 47700, 4596, 332, 22069, 47, 20996, 38499, 55542, 4600, 22590, 22069, 45, 21265, 22590, 47205, 55542, 4600, 332, 47709, 56880, 4811, 22590, 21952, 4811, 47675, 47, 11, 52, 42, 20996, 331, 41749, 97, 56292, 46769, 4423, 22590, 39943, 55542, 4600, 32354, 4811, 55448, 52446, 22590, 47675, 47, 3918, 57035, 22590, 51372, 40093, 4424, 32227, 21952, 4423, 4419, 55542, 45, 21265, 47266, 47102, 22590, 22168, 40093, 47, 11, 53, 42, 3913, 22590, 51668, 45, 283, 4600, 32354, 4423, 22590, 21952, 45, 21400, 4601, 47266, 55448, 4435, 332, 47709, 31296, 4369, 98, 94, 4811, 47675, 22590, 293, 98, 21952, 47, 11, 1461, 52394, 22590, 63560, 55690, 22590, 31356, 46853, 37598, 47675, 46, 1950, 280, 55492, 22799, 4811, 47675, 47700, 4596, 46657, 30579, 62586, 47, 19555, 22590, 51668, 30469, 55842, 332, 21674, 45888, 32227, 47266, 4435, 59406, 47, 30050, 39944, 63430, 45, 22590, 63560, 4600, 332, 30992, 37812, 56803, 4706, 47675, 46, 1950, 47, 11, 23739, 32234, 38686, 34, 20282, 4660, 31223, 4588, 22799, 31059, 21273, 39193, 60312, 47, 65535, 261]
-> item_loss 1.4546853303909302 batch_loss 1.092120953674974
==== [65530, 65531, 7262, 7999, 102, 14782, 10684, 17728, 18025, 11, 65535, 261, 65530, 65532, 10296, 10487, 10382, 15484, 7262, 7999, 102, 14734, 7621, 10762, 13004, 11, 65535, 261, 65530, 65534, 7621, 13091, 7262, 7999, 102, 10285, 10250, 10283, 17385, 16503, 14734, 10696, 15586, 10762, 13004, 19137, 14589, 13234, 10384, 11860, 15158, 10287, 10079, 12748, 11899, 15973, 11430, 14734, 13004, 15476, 12609, 10687, 10390, 11021, 17161, 10397, 11957, 16803, 10285, 11001, 10760, 13004, 12797, 28329, 65535, 261, 65530, 65532, 12848, 10494, 10250, 10283, 10397, 14875, 10487, 11855, 21214, 7262, 7999, 102, 11, 65535, 261, 65530, 65534, 11, 7621, 124, 3331, 40799, 22522, 296, 269, 33155, 45, 37576, 363, 60, 3331, 48550, 340, 296, 283, 60, 3331, 53570, 4601, 296, 22522, 47, 54104, 5269, 3331, 36004, 41, 1956, 47, 7669, 23955, 5265, 124, 28352, 40639, 346, 296, 4601, 47, 26315, 5269, 28352, 106, 5339, 28352, 1942, 41, 112, 62134, 50343, 513, 43909, 40812, 47, 8440, 47, 49580, 465, 40634, 59, 269, 278, 346, 502, 28352, 126, 3331, 126, 3331, 40812, 47, 8440, 47, 49580, 465, 40634, 59, 269, 278, 340, 502, 11, 126, 65535, 261]
-> item_loss 1.2706305980682373 batch_loss 1.0980712751547494
==== [65530, 65532, 10382, 15484, 7262, 7999, 102, 14734, 16728, 16537, 14332, 14172, 11, 65535, 261, 65530, 65534, 7262, 7999, 102, 16728, 16537, 13191, 10399, 10258, 10250, 10349, 14332, 14172, 59, 11, 50, 47, 33, 14875, 18476, 16728, 16537, 59, 5735, 7999, 102, 13091, 11533, 10339, 1219, 2191, 16728, 16537, 15543, 15052, 15973, 12276, 16689, 16664, 14734, 45, 12025, 10339, 10841, 15752, 12276, 11124, 17207, 17108, 12276, 14734, 13916, 11038, 15543, 15052, 16728, 16537, 28329, 51, 47, 33, 12202, 10997, 59, 5735, 7999, 102, 10688, 13191, 10696, 15586, 14734, 12202, 10997, 12978, 12746, 45, 11021, 10399, 13036, 10511, 11459, 15543, 10708, 11632, 15471, 15052, 15052, 12217, 28329, 52, 47, 33, 10577, 12824, 11010, 59, 5735, 7999, 102, 17379, 14589, 11533, 10339, 10577, 41, 33562, 42, 14734, 15543, 15052, 12824, 11010, 45, 11638, 17303, 10768, 12945, 10460, 17311, 17146, 11414, 13034, 10577, 15646, 17916, 10538, 12981, 14446, 13191, 10577, 10080, 17148, 13191, 10847, 10339, 11903, 14446, 15458, 10762, 13004, 12276, 11124, 12202, 10997, 15052, 12217, 28329, 53, 47, 33, 13080, 10339, 12651, 12022, 59, 5735, 7999, 102, 13091, 10846, 12396, 12651, 12022, 15261, 11496, 15304, 15500, 14734, 16728, 16537, 45, 11021, 10399, 13036, 10511, 11459, 11899, 10304, 13034, 14734, 10762, 13004, 10079, 16728, 13764, 11124, 11524, 14332, 11899, 16728, 16537, 41, 950, 77, 42, 28329, 54, 47, 33, 15066, 11899, 59, 5735, 7999, 102, 10482, 14589, 11533, 10339, 10342, 13027, 14734, 6588, 13212, 10794, 45, 13191, 10847, 10339, 15543, 10708, 15066, 11899, 14734, 12202, 10997, 15052, 12217, 28329, 55, 47, 33, 13080, 16742, 13080, 10708, 59, 5735, 7999, 102, 17379, 14589, 116, 16417, 17136, 12276, 41, 40810, 61371, 116, 42, 10460, 10292, 10397, 14875, 11533, 13205, 15489, 13250, 45, 11042, 13064, 10322, 13191, 15895, 11685, 14734, 16728, 13764, 10080, 10397, 14875, 15190, 13789, 13078, 10333, 28329, 56, 47, 33, 10355, 10342, 12276, 59, 5735, 7999, 102, 12848, 10494, 24072, 41, 24093, 46, 23613, 46, 33357, 29301, 497, 11021, 10399, 10355, 10342, 12276, 17144, 16403, 11124, 13827, 16707, 5735, 7999, 102, 10397, 14875, 45, 11584, 12299, 12266, 10997, 10452, 18183, 28329, 57, 47, 33, 10286, 11932, 14734, 13308, 10733, 12219, 59, 5735, 7999, 102, 15847, 17038, 12848, 10494, 10333, 12337, 11632, 11903, 14589, 14734, 10696, 15586, 10841, 15752, 45, 10894, 12732, 13004, 12797, 11621, 14486, 10079, 12202, 10997, 10079, 50807, 33, 15169, 28329, 58, 47, 33, 12978, 12746, 75, 1551, 59, 5735, 7999, 102, 17144, 16403, 11454, 75, 1551, 10257, 45, 11021, 10399, 13036, 10511, 11459, 10261, 29149, 33, 10355, 10342, 12202, 10788, 14589, 29149, 33, 14734, 10286, 11932, 15261, 12219, 28329, 10399, 10257, 10293, 16503, 10382, 15484, 10333, 7262, 7999, 102, 16728, 16537, 14734, 10250, 10349, 13637, 17097, 15092, 10760, 14734, 14332, 14172, 45, 12159, 13197, 15752, 10292, 12469, 12848, 10494, 10988, 15641, 10080, 11957, 7262, 7999, 102, 17147, 13191, 10409, 10454, 14638, 17728, 45, 13558, 17143, 17819, 13064, 11124, 12605, 10355, 13819, 10080, 65535, 261, 65530, 65532, 10777, 10296, 10250, 10283, 7262, 7999, 102, 14734, 10397, 14875, 10487, 11855, 520, 19589, 1511, 70, 33, 17148, 17384, 13191, 10250, 10283, 15190, 10932, 14734, 19644, 7999, 102, 33, 10397, 14875, 10487, 11855, 59, 11, 41, 2076, 38685, 46, 36017, 47, 25070, 3331, 478, 7616, 46, 34135, 494, 11, 41, 7334, 111, 38685, 46, 36017, 4373, 3331, 41, 49580, 269, 33155, 45, 37576, 5164, 42, 11, 41, 7334, 111, 280, 26199, 3331, 92, 39, 30176, 94, 3331, 41, 34550, 46, 36017, 494, 11, 17148, 13091, 10250, 10283, 15190, 10932, 14734, 35, 33155, 37576, 35, 15052, 12217, 59, 11, 46, 4695, 33, 14589, 13234, 11899, 10304, 11117, 11043, 15090, 17734, 11, 46, 21515, 111, 33, 11899, 10304, 10333, 38685, 46, 36017, 33, 10762, 13004, 45, 10482, 14589, 52562, 33, 12642, 10951, 35, 33155, 45, 37576, 363, 11, 46, 21515, 111, 280, 26199, 33, 11899, 10304, 10333, 10293, 10762, 13004, 45, 16749, 14589, 38685, 46, 36017, 33, 10762, 13004, 11, 10464, 11021, 10399, 17144, 16403, 17148, 10283, 19644, 7999, 102, 33, 15052, 12217, 59, 11, 6884, 11, 37, 21443, 7999, 102, 280, 110, 38685, 46, 36017, 47, 25070, 11, 33155, 45, 37576, 34, 11, 6884, 11, 5735, 7999, 102, 33, 13325, 12366, 14332, 12415, 11021, 16519, 59, 11, 46, 33, 10482, 14589, 14734, 13091, 350, 46, 61011, 33, 16728, 13764, 11, 46, 33, 12631, 13191, 11003, 17387, 17311, 13091, 59820, 33, 14734, 11, 46, 33, 11899, 10304, 10762, 13004, 10482, 14589, 21515, 111, 11, 46, 33, 10355, 10342, 12276, 4155, 1352, 11, 12159, 13197, 15752, 10292, 12469, 12848, 10494, 10988, 15641, 34, 65535, 261]
-> item_loss 1.781246542930603 batch_loss 1.1201091870184867
==== [65530, 65532, 10382, 15484, 7262, 7999, 102, 33, 10285, 10482, 14589, 14734, 42447, 46, 1950, 10762, 13004, 11, 65535, 261, 65530, 65534, 42447, 46, 1950, 33, 13091, 19644, 7999, 102, 33, 10285, 10250, 10283, 17916, 12182, 13191, 14589, 14734, 10762, 13004, 45, 14589, 10339, 13179, 13034, 12108, 11666, 13004, 12797, 15489, 13250, 10285, 14734, 10577, 28329, 11885, 14734, 10482, 14589, 13036, 13764, 13091, 59, 11, 41, 42447, 46, 1950, 30579, 46, 58449, 31209, 337, 273, 30176, 42, 11, 11885, 10423, 11454, 30579, 46, 58449, 33, 10285, 10482, 14589, 31209, 33, 12748, 11899, 14734, 16981, 12334, 45, 14221, 11044, 16749, 14589, 10762, 13004, 337, 45, 12202, 10427, 10673, 30176, 33, 10988, 13004, 10080, 103, 33, 14734, 10460, 14589, 13091, 13179, 13034, 16721, 16981, 12334, 12631, 11957, 12220, 14734, 10577, 28329, 10487, 11687, 59, 11, 41, 7334, 355, 4899, 98, 4899, 99, 285, 9209, 11, 11459, 13179, 13034, 12108, 11666, 14734, 333, 33, 14734, 10577, 59, 11, 41, 42447, 46, 1950, 355, 4369, 98, 293, 99, 94, 21878, 42, 3580, 4899, 98, 4899, 99, 286, 2408, 11, 11013, 11630, 10250, 10283, 10487, 11855, 59, 11, 41, 42447, 46, 1950, 355, 4369, 98, 94, 21298, 2087, 293, 100, 286, 42, 11, 746, 4899, 98, 4899, 99, 285, 45, 293, 100, 286, 2408, 11, 17148, 17384, 10482, 14589, 21298, 2087, 33, 10762, 13004, 13179, 13034, 10333, 293, 98, 22069, 45, 13920, 10842, 10333, 10250, 10283, 293, 100, 33, 11860, 13619, 28329, 12631, 10399, 12421, 15646, 16537, 10305, 45, 42447, 46, 1950, 33, 10652, 16684, 10464, 13036, 10511, 11459, 13179, 13034, 19644, 7999, 102, 33, 10285, 10409, 12522, 11626, 13215, 12231, 14734, 12108, 11666, 13004, 12797, 15489, 13250, 28329, 12159, 13197, 15752, 15494, 12469, 10250, 10283, 11638, 13445, 14734, 10333, 16533, 34, 42447, 46, 1950, 33, 10762, 13004, 11454, 11903, 17781, 12220, 14589, 10285, 17916, 12182, 11903, 14589, 10080, 65535, 261]
-> item_loss 1.9270771741867065 batch_loss 1.1453269366174936
==== [10355, 13819, 17728, 15178, 11, 65530, 65532, 12605, 12509, 10985, 10902, 10362, 13042, 13953, 19137, 10464, 14862, 17222, 10902, 10362, 13191, 10373, 10303, 13126, 14172, 11053, 19156, 11, 65535, 261, 65530, 65534, 10464, 11021, 10399, 17189, 17141, 15573, 15497, 12877, 15325, 12609, 15643, 11459, 11436, 12220, 14589, 13290, 12664, 10902, 10362, 14734, 13126, 14172, 10529, 12445, 10080, 10250, 10349, 14862, 11043, 13126, 14172, 11687, 12985, 11913, 10079, 11639, 11889, 17723, 12210, 11461, 10079, 17688, 11517, 10079, 13676, 15123, 13036, 15169, 17311, 13091, 10260, 17631, 14734, 17177, 12731, 10080, 13581, 11630, 19137, 10902, 10362, 17147, 13191, 16684, 11632, 15597, 18053, 11124, 14332, 15898, 11975, 11035, 10577, 12348, 10250, 16707, 19137, 11687, 14188, 18372, 10079, 10902, 10362, 14171, 17351, 17919, 10079, 16793, 13684, 15169, 28329, 65535, 261, 65530, 65532, 12605, 12509, 14862, 17222, 14446, 11454, 14734, 11639, 13655, 12484, 10724, 11, 65535, 261, 65530, 65534, 13326, 12797, 13188, 13034, 14734, 13655, 16803, 13004, 12797, 19137, 14446, 11454, 14734, 11639, 13655, 12484, 10724, 11416, 10292, 12469, 14734, 10447, 15586, 10260, 11042, 15646, 12268, 10080, 10444, 13091, 19137, 13326, 12797, 13655, 16803, 13004, 12797, 12848, 10494, 14734, 10529, 12445, 19137, 12469, 11021, 10399, 11638, 15850, 10333, 16533, 12307, 10808, 12631, 11454, 11459, 10912, 14734, 11639, 13655, 14349, 10724, 19151, 11, 10902, 10362, 19151, 11632, 10341, 17083, 17773, 11, 11639, 13655, 14349, 10724, 19151, 11632, 10341, 11, 13947, 12231, 19151, 46, 50, 9866, 361, 288, 9866, 11, 12469, 11021, 10399, 17189, 17141, 12220, 14589, 10696, 14734, 12387, 12802, 13036, 12276, 10769, 12791, 13655, 16803, 13004, 12797, 12848, 10494, 14734, 16523, 16525, 12986, 13258, 19137, 10399, 16056, 11001, 13179, 10842, 14781, 16520, 10733, 14914, 14734, 10529, 12445, 10080, 65535, 261]
-> item_loss 0.7310567498207092 batch_loss 1.1327732945933486
==== [25106, 11, 65530, 65531, 12605, 10402, 12266, 11726, 10250, 10283, 13034, 14734, 16713, 18025, 19137, 33, 17148, 10283, 16713, 18025, 10684, 10339, 12366, 14486, 10913, 14583, 11124, 13234, 16690, 15643, 14734, 10355, 13819, 19137, 33, 10390, 10402, 10305, 17734, 11454, 16671, 16686, 10250, 13619, 10993, 12484, 14734, 13855, 11645, 11, 65535, 261, 65530, 65532, 6909, 4423, 332, 33, 12366, 14486, 11871, 11920, 19137, 11124, 12605, 16671, 16686, 10250, 10283, 13192, 10993, 14734, 17728, 18025, 10080, 33, 16738, 10399, 10726, 17912, 10079, 14486, 12415, 11124, 11907, 16520, 14581, 15849, 13191, 14172, 10726, 17354, 14734, 18043, 13327, 13234, 16671, 16686, 19137, 12605, 10260, 17879, 16503, 13051, 15763, 14734, 11889, 12556, 11124, 13580, 15752, 17387, 14734, 16671, 16686, 19137, 12605, 17879, 16503, 10464, 12176, 10847, 12605, 13923, 13127, 14734, 11414, 18004, 11124, 10250, 10283, 10370, 14734, 10355, 12332, 15486, 10964, 28329, 65535, 261, 65530, 65534, 11685, 14734, 45, 12605, 11967, 12002, 10838, 10399, 11907, 16520, 11124, 14486, 12415, 14734, 12396, 12231, 13234, 16671, 16686, 12469, 13192, 10993, 14734, 17728, 18025, 10080, 10460, 10292, 10250, 11043, 12366, 14486, 11871, 11920, 45, 12605, 14734, 14778, 13308, 13091, 12176, 10847, 12469, 14486, 13923, 12410, 16981, 45, 12848, 10494, 10250, 10349, 10260, 11042, 14734, 16523, 16530, 45, 15646, 10260, 13091, 15494, 10760, 15190, 10932, 14734, 12261, 16676, 10080, 16738, 12847, 17162, 10250, 10258, 12469, 13192, 10993, 14734, 12484, 10724, 11124, 10684, 15304, 17728, 18025, 45, 12605, 10423, 15648, 12366, 11459, 10578, 11065, 45, 12202, 11986, 16707, 10384, 11632, 10283, 13036, 17919, 17149, 16403, 10768, 13254, 10080, 16678, 10449, 45, 13633, 10283, 10370, 11124, 13633, 13619, 10684, 15304, 17311, 13091, 14370, 10250, 13051, 10337, 14734, 10080, 12605, 10423, 11971, 17385, 12469, 13192, 10993, 14734, 12527, 11002, 45, 11042, 13064, 10322, 10423, 11687, 11903, 11459, 12848, 10760, 12605, 14734, 16520, 14172, 10080, 11687, 13258, 12469, 16525, 12348, 12605, 14734, 13279, 10349, 14791, 13764, 17141, 10339, 10293, 16520, 12609, 15643, 12484, 15509, 10901, 45, 16738, 17819, 13064, 12848, 17363, 12605, 10525, 12746, 11907, 16520, 10080, 12605, 12337, 18216, 10685, 15752, 16974, 12469, 10250, 16944, 12822, 16671, 17148, 10283, 16713, 18025, 45, 12159, 13197, 12605, 10402, 14734, 16671, 16686, 15752, 15494, 12469, 10250, 10349, 11068, 10997, 45, 12176, 10847, 12469, 13179, 11685, 11459, 12410, 15641, 11124, 11621, 14486, 17148, 13619, 10684, 15304, 28329, 65535, 261, 65530, 65532, 12605, 13191, 10250, 10283, 13192, 10993, 19137, 13186, 15486, 12605, 10402, 13091, 10782, 10285, 11042, 11871, 19137, 12307, 10782, 12605, 13091, 14474, 15451, 10285, 14734, 12143, 14583, 19137, 10390, 13091, 14474, 15451, 10285, 14734, 10421, 15169, 14583, 10080, 33, 12605, 10402, 10355, 12332, 14734, 15486, 10964, 16944, 13981, 10339, 12307, 12201, 12605, 14734, 12604, 15508, 15092, 18052, 14388, 17149, 28329, 65535, 261, 65530, 65534, 12469, 12847, 17162, 14734, 17148, 15033, 10684, 15304, 16944, 13981, 14914, 11903, 12337, 13191, 12522, 12410, 10080, 10384, 12469, 12848, 10494, 14734, 10529, 12445, 13234, 14791, 45, 17148, 13619, 10993, 16754, 12314, 12604, 14734, 11662, 13212, 13091, 12469, 14734, 12604, 15508, 13191, 10333, 18052, 16962, 12415, 14734, 17149, 13582, 45, 12282, 16944, 10333, 12307, 13064, 12604, 15508, 10421, 12268, 14734, 10390, 14734, 13773, 12522, 11124, 16928, 16917, 28329, 17148, 15033, 11533, 10339, 11871, 10323, 12604, 15508, 14734, 17152, 12824, 13036, 12276, 11454, 10782, 10285, 13064, 13199, 12202, 10260, 15576, 16519, 45, 12307, 13064, 12604, 15508, 12332, 12332, 16443, 16523, 10292, 10784, 13032, 10250, 10283, 10370, 10421, 10845, 14734, 15190, 10932, 13308, 10733, 10080, 10444, 13091, 45, 11687, 13258, 17141, 10339, 12299, 16749, 12604, 15508, 14734, 10421, 10845, 45, 15646, 12392, 16523, 10333, 13633, 10283, 11872, 11855, 14734, 10283, 12415, 10079, 10685, 16954, 11124, 10687, 10390, 15323, 16884, 45, 10779, 12337, 17843, 12261, 15123, 13913, 10673, 14734, 10993, 16754, 28329, 12605, 12509, 10333, 16533, 10250, 10258, 45, 11454, 12469, 12604, 15508, 12848, 18216, 10305, 11044, 45, 12469, 11124, 10390, 14734, 10993, 16754, 13091, 11060, 15752, 11634, 16947, 16948, 12604, 15508, 17148, 10283, 12007, 17919, 45, 11454, 11159, 13327, 10079, 14299, 11685, 10079, 10408, 10577, 16520, 15169, 13179, 13913, 12007, 13557, 10257, 16056, 12348, 16667, 11042, 11124, 17152, 12824, 64, 17148, 11957, 10339, 10250, 13619, 10993, 16754, 14734, 12746, 10301, 10997, 12022, 10917, 10768, 17385, 16503, 10080, 11687, 13258, 17141, 10768, 10495, 16922, 13279, 10250, 15033, 13231, 10407, 12314, 12604, 14734, 15671, 15489, 45, 10250, 13054, 13231, 10407, 13855, 11645, 45, 10993, 16754, 10322, 11021, 15752, 17819, 10305, 13855, 11645, 10080, 12605, 12337, 18216, 10685, 15507, 15511, 10578, 11065, 12469, 10768, 10361, 17148, 13619, 10993, 16754, 10684, 15304, 14734, 13179, 11632, 15478, 15907, 11124, 15486, 10964, 10080, 65535, 261, 65530, 65532, 12605, 16667, 10292, 11454, 11159, 13327, 10079, 14299, 11685, 10079, 10408, 10577, 16520, 12007, 13557, 10257, 13191, 10333, 10250, 10349, 17152, 12824, 19137, 10444, 13091, 12202, 13734, 13191, 16535, 10992, 12337, 13913, 14734, 12007, 17919, 10080, 33, 12746, 15511, 10917, 10745, 12201, 14734, 13192, 10993, 10684, 15304, 10285, 19137, 33, 13179, 11632, 14734, 13091, 10768, 10361, 14583, 13815, 10285, 14734, 10250, 10349, 14493, 10336, 19137, 12605, 16667, 10292, 10390, 13637, 17097, 10684, 13773, 12605, 14734, 14583, 13815, 19137, 10444, 13091, 13091, 12605, 14583, 13815, 10285, 14734, 12604, 11994, 13036, 17919, 19137, 33, 15646, 10260, 13091, 12605, 10283, 10370, 14734, 12203, 15009, 13036, 17919, 28329, 65535, 261, 65530, 65534, 12469, 12848, 10494, 14734, 16416, 10655, 10529, 12445, 16672, 12605, 11957, 17148, 13619, 10993, 16754, 13191, 10333, 13179, 13923, 13127, 14734, 10333, 16533, 10080, 14791, 13234, 11454, 12604, 15508, 10305, 11630, 45, 10464, 10402, 10322, 11454, 11159, 13327, 10079, 14299, 11685, 15169, 12007, 17919, 10257, 12261, 15123, 10333, 10250, 11899, 14734, 17152, 12824, 45, 10444, 10441, 10308, 13734, 13191, 17136, 10792, 17916, 12182, 10366, 11930, 14734, 15052, 12231, 10080, 15646, 11454, 17148, 10917, 10745, 12201, 14734, 10355, 12332, 10285, 45, 10464, 10402, 13179, 11632, 10589, 14614, 11454, 14583, 13815, 14493, 10336, 14734, 10768, 10361, 45, 17097, 11977, 16535, 10992, 13179, 13913, 12007, 13557, 14734, 16713, 18025, 28329, 12469, 12848, 10792, 10250, 10283, 10684, 17644, 14172, 45, 11994, 13091, 10390, 10441, 10308, 13179, 10684, 13773, 12469, 14734, 12604, 11994, 45, 15646, 10260, 13091, 12469, 10283, 10370, 14734, 12203, 15009, 12527, 10080, 17148, 11454, 10250, 11899, 15052, 12231, 10257, 16533, 17382, 10333, 10292, 10373, 10303, 17148, 13619, 10993, 16754, 10589, 14614, 11454, 13637, 17097, 16417, 12007, 14734, 10696, 11922, 10768, 10361, 45, 15646, 13734, 13191, 12314, 12604, 12366, 14141, 11124, 12484, 12527, 14734, 13913, 12231, 12665, 16741, 28329, 12605, 12509, 12848, 10760, 10745, 14172, 14791, 13764, 45, 13558, 17143, 12469, 14734, 10995, 18108, 59, 11, 11454, 10993, 16754, 10285, 45, 13199, 12335, 10994, 13036, 17311, 15752, 10684, 12366, 11957, 13036, 14734, 14583, 13815, 16884, 17387, 11124, 12203, 15009, 12527, 45, 15646, 10260, 10377, 10377, 13091, 12604, 11994, 11124, 12604, 10841, 45, 17148, 13091, 13179, 10590, 12237, 14734, 10684, 15304, 28329, 12469, 13091, 11060, 10322, 11021, 10399, 13179, 10293, 10846, 11459, 10768, 10361, 15847, 12144, 14734, 12484, 12527, 10267, 14610, 45, 16417, 17136, 11957, 10390, 14734, 10684, 12366, 45, 15646, 10260, 10377, 13091, 12604, 11994, 10257, 14734, 10355, 13819, 64, 17148, 11021, 15752, 12176, 10847, 12705, 17145, 10994, 13036, 16973, 15023, 28329, 11687, 13258, 17688, 13199, 12527, 16525, 17148, 13619, 10993, 16754, 10589, 14012, 10260, 10808, 45, 12469, 10322, 16684, 17879, 16503, 10995, 12410, 17148, 13619, 10684, 15304, 17147, 15752, 11060, 14015, 16956, 12469, 14734, 17879, 13685, 10080, 10293, 10846, 16753, 16753, 12469, 14734, 12509, 13764, 10322, 16684, 10423, 13191, 12176, 10847, 28329, 12159, 13197, 17148, 10349, 12261, 16676, 15752, 15494, 12469, 12848, 10494, 10250, 10349, 10988, 15641, 10080, 12605, 12337, 13559, 16917, 12469, 12537, 12522, 11906, 16523, 17148, 13619, 10993, 16754, 10684, 15304, 45, 12202, 16672, 11885, 11003, 12348, 13179, 10842, 10286, 11932, 13191, 12522, 10304, 10080, 17148, 11994, 13091, 12604, 14256, 10993, 16754, 14734, 17385, 16503, 10452, 14446, 10080, 65535, 261, 65530, 65532, 12605, 16667, 10292, 11454, 12605, 11124, 10390, 14734, 10684, 15304, 12307, 10285, 19137, 12605, 12025, 10339, 10293, 10846, 10768, 10361, 12484, 12527, 10267, 14610, 11124, 14583, 13815, 10285, 12387, 10310, 14734, 10370, 10080, 10390, 11533, 13205, 10257, 10260, 10423, 10768, 10361, 14794, 11903, 14734, 12484, 12527, 10267, 14610, 10080, 33, 12605, 11454, 14042, 17688, 14734, 10993, 12484, 15486, 10964, 10285, 11414, 18004, 19137, 10997, 14446, 10390, 10687, 11903, 10250, 14781, 10441, 10308, 17820, 16223, 11454, 13279, 10283, 17919, 10688, 10258, 28329, 65535, 261, 65530, 65534, 12337, 12527, 16774, 12469, 12848, 10494, 13179, 11632, 15478, 15907, 10080, 14446, 11454, 12605, 11957, 17148, 13619, 10993, 16754, 14734, 10342, 10846, 13499, 12276, 13191, 10333, 13179, 13923, 13127, 14734, 16667, 16696, 28329, 10384, 12469, 14734, 12847, 17162, 13234, 14791, 45, 11454, 17148, 13619, 10684, 15304, 10285, 45, 12469, 13637, 17097, 10293, 10846, 11459, 10768, 10361, 15847, 12144, 14734, 12484, 12527, 11124, 14583, 13815, 12387, 10310, 45, 15646, 10390, 12337, 11977, 12022, 14966, 14794, 11903, 14734, 10696, 12366, 10267, 14610, 45, 10441, 10308, 12421, 12624, 14808, 10250, 10283, 17919, 10688, 10080, 17148, 15033, 17688, 13199, 14734, 10260, 11957, 15169, 13091, 10260, 10590, 12237, 14734, 28329, 12605, 12509, 12848, 10760, 10250, 10349, 12261, 16676, 59, 11, 50, 47, 10261, 10390, 11483, 16711, 11459, 13733, 17189, 12469, 14734, 12527, 11002, 45, 16735, 12469, 12159, 13197, 17148, 13619, 10993, 16754, 15752, 11634, 13179, 10842, 14794, 16711, 10079, 12266, 12983, 10080, 17728, 17728, 10390, 17820, 16223, 15847, 12605, 14734, 10974, 11416, 45, 16672, 10390, 12522, 16696, 10792, 12469, 10260, 13091, 16417, 17919, 14734, 13192, 10993, 28329, 51, 47, 15494, 10390, 13064, 17734, 12642, 12266, 12366, 12635, 45, 10444, 10260, 15752, 12299, 13685, 10080, 10261, 13581, 11042, 13064, 45, 10525, 12686, 11685, 15847, 12144, 45, 10260, 16503, 17141, 12231, 12674, 10673, 10250, 10283, 10260, 11414, 12687, 14734, 10684, 15304, 28329, 52, 47, 11687, 13258, 10390, 13051, 13764, 11003, 10901, 45, 12469, 11021, 15752, 17879, 16503, 17385, 13034, 16694, 10435, 17148, 13619, 10993, 16754, 11957, 12469, 14734, 12522, 10304, 45, 10260, 16503, 14614, 12428, 10250, 15033, 14486, 12509, 10901, 14734, 10993, 16754, 28329, 53, 47, 11454, 10687, 10390, 10684, 15304, 10285, 12664, 10792, 16056, 12348, 12484, 12527, 10355, 13819, 11124, 12978, 12746, 14734, 10760, 11010, 10080, 10260, 16503, 11928, 12159, 13197, 10339, 10250, 10283, 10370, 28329, 12527, 16774, 12469, 10768, 10361, 17148, 13619, 11626, 13215, 14734, 10684, 15304, 10964, 15052, 10080, 12605, 16424, 12366, 12159, 13197, 12469, 15752, 12664, 10792, 10342, 14782, 12978, 12746, 10079, 14794, 13580, 10529, 10409, 14734, 10993, 16754, 10684, 15304, 10080, 17148, 17879, 16503, 13064, 17734, 45, 10444, 10464, 10577, 12348, 12727, 13191, 10080, 11687, 13258, 13191, 10409, 10454, 10687, 10390, 12509, 13764, 13558, 17143, 15507, 15511, 16671, 16686, 10080, 65535, 261, 65530, 65532, 12605, 12159, 13197, 10464, 15752, 13179, 10842, 13913, 12231, 14734, 10384, 10370, 13327, 14486, 16686, 16530, 12231, 16671, 16686, 17148, 15033, 10684, 15304, 28329, 65535, 261, 65530, 65534, 11685, 14734, 45, 12605, 10423, 11986, 16707, 10384, 10370, 13327, 14486, 16686, 14734, 16523, 16530, 45, 11957, 17148, 15033, 10684, 15304, 13499, 12276, 17149, 16403, 13179, 13913, 10673, 14734, 10768, 13254, 28329, 18117, 10658, 45, 10384, 12469, 13192, 10993, 14734, 14332, 12333, 13234, 14791, 45, 10390, 10441, 10308, 13191, 14808, 10696, 11047, 10079, 13773, 17385, 17820, 16223, 15847, 12605, 14734, 10370, 13327, 10578, 11047, 10080, 13326, 12797, 10370, 13327, 14486, 16686, 45, 17148, 11021, 15752, 13091, 10390, 15847, 17038, 14734, 12415, 13327, 14332, 12333, 45, 10322, 11021, 15752, 13091, 11872, 12848, 13064, 13199, 14734, 14583, 13815, 15486, 10964, 11960, 15850, 14734, 10370, 13327, 17172, 12220, 28329, 10687, 13557, 45, 11454, 10464, 10402, 14734, 14782, 11621, 10285, 45, 12469, 16417, 14446, 10760, 10333, 13179, 11630, 11047, 10079, 10293, 10846, 16417, 17136, 14734, 10370, 13327, 14332, 16884, 10080, 13326, 12797, 10370, 13327, 10911, 17332, 14486, 16686, 45, 17148, 10278, 15033, 10260, 11042, 15261, 11496, 14734, 10370, 11687, 13258, 16503, 10997, 12022, 15895, 11685, 14734, 10684, 15304, 45, 10994, 13036, 17311, 17879, 16503, 10588, 10760, 16749, 13006, 17172, 12220, 11957, 13036, 45, 15646, 10260, 15752, 10932, 15458, 13199, 12335, 11957, 13036, 12981, 11003, 28329, 15162, 10256, 45, 10384, 15287, 14987, 10768, 13254, 16530, 12231, 14791, 45, 10390, 17820, 16223, 15847, 12605, 11021, 15752, 13091, 10760, 10339, 13279, 10349, 10696, 12366, 14734, 14216, 16253, 12609, 17771, 12354, 13212, 10794, 10080, 11687, 13258, 15752, 16672, 10390, 12527, 10792, 11889, 10675, 11124, 16443, 12824, 15462, 45, 10390, 11021, 15752, 17182, 13932, 12022, 14446, 14794, 11903, 15847, 12605, 10080, 17148, 17384, 17879, 16503, 12469, 16417, 14446, 10760, 15648, 12366, 11124, 13145, 12522, 45, 15646, 17916, 12299, 13685, 28329, 13188, 11044, 45, 11687, 13258, 17688, 13199, 13051, 13764, 12261, 15123, 10342, 14782, 10529, 10409, 45, 12824, 15462, 30719, 39193, 14734, 10684, 15304, 45, 10322, 16684, 16735, 13078, 10464, 10402, 14734, 10370, 13327, 10992, 17879, 13685, 11861, 11454, 10250, 11899, 14734, 8176, 35047, 10080, 10525, 12746, 17172, 12307, 16973, 15023, 45, 15646, 10260, 13091, 10864, 12299, 15516, 15304, 45, 11021, 15752, 13091, 13179, 10590, 12237, 14734, 17177, 12731, 28329, 12421, 10305, 45, 17148, 17879, 16503, 10994, 13036, 10682, 11042, 10848, 10838, 11124, 13064, 17734, 11532, 10691, 10080, 17385, 16503, 14734, 13091, 16503, 14914, 11899, 17148, 15033, 10993, 16754, 13091, 11060, 10383, 14221, 13191, 12522, 10304, 11124, 12159, 13197, 45, 11687, 13258, 12527, 10792, 13855, 13249, 45, 12983, 12636, 10322, 13203, 11986, 10260, 11021, 10080, 16738, 15507, 15511, 10768, 10361, 12469, 14734, 12509, 13764, 10080, 65535, 261, 65530, 65532, 16416, 10655, 10250, 10349, 10529, 12445, 19137, 11454, 13188, 17145, 14734, 10745, 12201, 19137, 12605, 14734, 14583, 13815, 10285, 10760, 14446, 10333, 10250, 10349, 18052, 16962, 12415, 14734, 12604, 11994, 19137, 33, 12307, 12605, 12266, 12366, 14734, 10261, 10390, 10768, 10361, 13064, 19137, 10997, 14446, 10390, 10250, 14781, 11621, 10339, 10250, 15033, 11414, 17248, 11124, 15847, 12605, 17771, 12354, 14734, 14349, 12396, 28329, 65535, 261, 65530, 65534, 12527, 16774, 12469, 12848, 10494, 14734, 18030, 11630, 10529, 12445, 10080, 17148, 10250, 16416, 10655, 15478, 15907, 12176, 10847, 12605, 13179, 10733, 14914, 11459, 10768, 13254, 17148, 13619, 10993, 16754, 10846, 12396, 28329, 10384, 12469, 13188, 17145, 11001, 12348, 12604, 11994, 13064, 10390, 14734, 11414, 17248, 11124, 15847, 12605, 17771, 12354, 10995, 12220, 13234, 14791, 45, 17148, 11021, 15752, 10995, 13086, 10760, 10399, 10258, 10745, 10283, 17728, 18025, 59, 11, 10390, 15847, 17038, 11454, 10464, 10402, 10684, 15304, 10285, 10250, 14781, 11621, 10339, 10421, 16948, 12527, 11124, 12825, 10794, 12527, 17097, 12299, 14734, 10250, 13036, 45, 14446, 11454, 17148, 15033, 10846, 12396, 16443, 12642, 14894, 45, 10398, 10390, 12527, 10792, 10260, 17172, 12220, 28329, 10390, 11021, 15752, 11861, 11454, 10250, 11899, 15052, 12231, 14734, 15129, 10335, 12366, 14486, 45, 12631, 10399, 12469, 14734, 12604, 10841, 16535, 10997, 10333, 10390, 14734, 10260, 11889, 10675, 12527, 28329, 11454, 15847, 12605, 16667, 14862, 10257, 45, 10390, 17141, 10339, 10495, 16922, 10339, 12604, 15508, 11124, 12604, 11994, 13234, 11899, 10304, 15847, 12605, 10408, 10577, 45, 12631, 10399, 53983, 14734, 12604, 10841, 10397, 16417, 10333, 11957, 10390, 14734, 7428, 14734, 12642, 10761, 28329, 11687, 13258, 10390, 17688, 13199, 13051, 13764, 10292, 12469, 14734, 12604, 10841, 12527, 10792, 14794, 16711, 14734, 18216, 10685, 45, 11016, 10423, 11414, 17248, 12609, 15847, 12605, 17771, 12354, 45, 17148, 12430, 12405, 10397, 16417, 14808, 10390, 12202, 10260, 11634, 11454, 12522, 12469, 14734, 10696, 12366, 10267, 14610, 28329, 15523, 10257, 12631, 17162, 45, 17148, 15033, 11003, 10901, 10322, 16684, 13580, 11454, 16535, 10846, 17148, 13619, 10993, 16754, 10684, 15304, 14734, 13326, 11533, 10080, 12605, 12261, 16676, 12469, 11021, 10399, 11986, 16707, 10261, 10390, 12266, 16711, 12155, 10678, 11459, 16671, 16686, 11003, 10901, 45, 10444, 16503, 10292, 10409, 10454, 15489, 13258, 10588, 11685, 10733, 11622, 10080, 12746, 15511, 12674, 10673, 10250, 13619, 10260, 12200, 16412, 14734, 10684, 15304, 13052, 16899, 13064, 17734, 10322, 16899, 15287, 10838, 10080, 12159, 13197, 17148, 10349, 12261, 16676, 15752, 15494, 12469, 12172, 13234, 10250, 10349, 12176, 10847, 45, 10322, 13558, 17143, 12469, 12848, 10760, 15847, 12144, 14734, 12509, 13764, 10080, 65535, 261, 65530, 65532, 12337, 12527, 16774, 10464, 10726, 17912, 14734, 10768, 13254, 19137, 33, 12605, 12145, 15486, 12522, 16696, 10792, 17148, 13619, 10993, 12484, 11967, 16503, 14894, 14924, 10080, 33, 12605, 10402, 14734, 10355, 13819, 16672, 12605, 15752, 13179, 10842, 11922, 13080, 14734, 12824, 11002, 17148, 10250, 14172, 10080, 33, 12605, 11454, 11414, 18004, 12307, 12201, 14734, 15486, 10964, 13064, 19137, 14734, 14914, 10997, 14446, 15847, 12144, 14734, 14970, 10423, 16694, 10408, 13637, 10390, 10448, 12337, 11632, 10080, 33, 15646, 17145, 12201, 14734, 12604, 11994, 14734, 14914, 13191, 12337, 11632, 15092, 14894, 28329, 65535, 261, 65530, 65534, 12469, 14734, 10995, 18108, 16672, 12605, 12527, 10792, 13559, 12556, 10080, 15752, 11634, 10726, 17912, 14486, 12415, 11459, 10768, 13254, 10250, 13619, 10684, 15304, 14734, 11003, 10901, 45, 12202, 10588, 11685, 12366, 14486, 10733, 11622, 12824, 11002, 10687, 15489, 12005, 45, 17879, 16503, 13133, 12551, 11124, 10863, 13655, 10080, 12605, 12337, 18216, 10685, 12605, 10402, 14734, 16671, 16686, 15752, 11634, 12176, 10847, 12469, 17189, 17141, 11414, 18004, 12332, 10336, 45, 11906, 16523, 14446, 14349, 45, 10384, 15646, 13179, 11685, 11459, 12824, 15462, 17148, 10250, 14446, 11903, 28329, 10384, 12469, 12848, 10494, 14734, 10964, 15052, 13234, 14791, 45, 17148, 13619, 10993, 16754, 11454, 17141, 10985, 14914, 11903, 12261, 15123, 11454, 10250, 11899, 14734, 14970, 10423, 16694, 10408, 11533, 14902, 10305, 10257, 45, 14446, 11454, 17148, 10250, 11533, 14902, 10997, 14583, 10333, 11003, 10901, 45, 12368, 14221, 10423, 11957, 10684, 15304, 10358, 14583, 10721, 10761, 10080, 17148, 15033, 10721, 15092, 11454, 12337, 11632, 17688, 13199, 10993, 16754, 10285, 17311, 11021, 15752, 10997, 14583, 45, 10684, 17644, 13091, 11687, 10454, 10901, 16533, 11124, 17919, 11957, 28329, 12605, 12261, 16676, 12469, 11021, 10399, 17177, 12731, 10261, 10390, 12329, 12221, 17382, 12395, 45, 10322, 11021, 10399, 14614, 10258, 10250, 14172, 10993, 16754, 14734, 10457, 11459, 10080, 17385, 16503, 14734, 13091, 10260, 16503, 55099, 7946, 33, 10390, 14734, 11414, 17248, 10460, 10292, 11957, 12469, 15847, 17038, 10408, 10577, 14734, 11060, 11899, 10080, 12469, 14734, 12604, 11994, 12022, 14446, 10333, 15847, 12144, 14734, 10848, 10838, 45, 12220, 12307, 14597, 16424, 11459, 12527, 10792, 18176, 10613, 11124, 12266, 12366, 28329, 12159, 13197, 12469, 11021, 10399, 15043, 13249, 12674, 10673, 10687, 10390, 14970, 10355, 11441, 11855, 45, 12664, 10792, 13179, 10590, 12237, 33078, 14734, 10370, 17781, 10684, 15304, 10080, 12469, 14734, 12604, 17688, 12220, 16721, 13091, 16443, 13559, 16917, 11124, 18458, 10851, 14734, 45, 15646, 17916, 16443, 11060, 11899, 10080, 12527, 16774, 12469, 10768, 10361, 17148, 10250, 11626, 13215, 17141, 15052, 45, 14986, 12469, 15507, 15511, 10808, 16403, 45, 10997, 14446, 14583, 13815, 14734, 15597, 11685, 34, 65535, 261, 65530, 65532, 12307, 10250, 10283, 10370, 10260, 13032, 14734, 12604, 17688, 13064, 19137, 13091, 11060, 10423, 17919, 11957, 13179, 11632, 14734, 17148, 15261, 10684, 15304, 14894, 14924, 10080, 33, 11454, 17141, 10985, 14734, 10337, 10256, 10917, 12201, 14734, 15486, 10964, 10285, 19137, 12605, 10997, 14446, 12605, 14734, 13192, 10993, 16948, 13234, 16948, 11977, 10080, 33, 17819, 14808, 10283, 10370, 17149, 13582, 14734, 14914, 10423, 16667, 16696, 13179, 11632, 14734, 13192, 10993, 10080, 10444, 13091, 13055, 14734, 13192, 10993, 14734, 11645, 10985, 14734, 14914, 17147, 13091, 10423, 16672, 10370, 12527, 10429, 28329, 65535, 261, 65530, 65534, 12469, 12848, 10760, 10333, 10250, 10283, 17916, 12182, 17385, 16503, 14734, 17728, 18025, 45, 10283, 10370, 12604, 17688, 11124, 13055, 10684, 15304, 14894, 16449, 10305, 17734, 14734, 10684, 15304, 10080, 17148, 13091, 10250, 10283, 10577, 12348, 13913, 12410, 14734, 16713, 18025, 28329, 12469, 14734, 12527, 11002, 17916, 12182, 14486, 16533, 11124, 10682, 18365, 10080, 12307, 10250, 10283, 10370, 10260, 13032, 12604, 17688, 11124, 11003, 10901, 13064, 45, 10261, 17141, 10985, 12261, 15123, 14734, 10250, 10349, 10684, 15304, 14914, 11903, 17919, 10288, 14808, 12752, 12610, 11124, 16749, 13006, 10080, 17148, 13091, 12337, 11632, 10370, 11454, 12604, 17688, 17141, 15052, 10285, 17311, 10423, 15486, 10964, 14734, 28329, 10250, 10349, 14791, 13764, 10494, 12469, 10988, 15641, 59, 11, 10283, 10370, 12604, 17688, 13036, 11047, 10261, 13055, 10993, 12604, 17688, 13036, 11047, 10260, 11042, 45, 14486, 12389, 14782, 12138, 45, 13091, 12337, 11632, 10684, 15304, 11003, 17137, 14734, 10974, 11416, 10080, 12824, 11002, 17148, 15033, 10768, 13584, 12202, 10260, 13091, 10409, 10454, 10250, 13036, 14734, 17631, 28329, 10261, 13055, 10993, 14894, 16449, 45, 13179, 11632, 13091, 10397, 16417, 12469, 17149, 10673, 10333, 10250, 10283, 13034, 14734, 10370, 14583, 17775, 13619, 10080, 17148, 13091, 12604, 17688, 12368, 15486, 14734, 14658, 14673, 10080, 14791, 12266, 10250, 10349, 45, 10423, 10739, 17093, 10429, 14673, 28329, 17149, 13582, 12604, 17688, 14734, 11042, 13064, 45, 10322, 16503, 10525, 13191, 10250, 11899, 16778, 17178, 10079, 11042, 14486, 12366, 10261, 13055, 10993, 10080, 10260, 16503, 11416, 12604, 10841, 15646, 17093, 16523, 17141, 10985, 14734, 10684, 15304, 28329, 12604, 17688, 16981, 10257, 45, 12605, 10402, 17879, 16503, 11454, 13034, 14734, 17775, 13619, 12664, 10792, 13034, 14734, 10422, 10437, 10250, 16981, 11042, 16403, 10080, 17148, 13091, 23353, 5447, 69, 12261, 15123, 13034, 14734, 12978, 12746, 15573, 15497, 28329, 10250, 10349, 10577, 12348, 14460, 12493, 14734, 15640, 13192, 10993, 15957, 15752, 14486, 16533, 12824, 15462, 12605, 10402, 14734, 12604, 17688, 45, 10495, 14221, 11021, 10399, 14614, 11454, 14583, 11117, 10285, 10080, 10444, 10260, 12368, 10864, 12299, 28329, 12421, 10305, 45, 11003, 17137, 13091, 14583, 11117, 14734, 12182, 12396, 10080, 11871, 10423, 13559, 14221, 12824, 11002, 17148, 10250, 14172, 45, 14486, 16533, 11003, 17137, 15727, 11044, 14734, 10974, 11416, 45, 10525, 12746, 16778, 17178, 11255, 12522, 45, 12605, 14782, 10529, 12469, 10423, 11003, 12348, 13179, 10842, 11474, 12299, 10261, 14829, 13133, 10080, 14986, 12469, 12604, 17688, 14734, 16981, 10257, 10260, 10309, 14862, 12144, 14782, 10437, 10080, 65535, 261, 65530, 65532, 12605, 11454, 12509, 10250, 10283, 17728, 18025, 19137, 33, 12307, 12605, 16056, 12348, 12604, 15508, 13064, 19137, 12266, 12366, 14734, 10261, 13192, 10993, 10768, 10361, 14734, 13064, 10560, 19137, 11454, 17148, 10283, 12484, 10724, 10258, 11957, 12605, 12266, 11726, 14637, 17150, 14734, 13192, 10993, 19137, 33, 14794, 14734, 15752, 10460, 10292, 13192, 10993, 11053, 19156, 11, 65535, 261, 65530, 65534, 12469, 12848, 10760, 10333, 10250, 10283, 17916, 12182, 12990, 17625, 14734, 17728, 18025, 10080, 12307, 10250, 10283, 10370, 11454, 17385, 16503, 13064, 10799, 17177, 12731, 11414, 17248, 12609, 14637, 17150, 45, 15646, 17916, 12527, 11042, 17038, 11002, 45, 17148, 14914, 11903, 10423, 16672, 10370, 16884, 14638, 17148, 15033, 10993, 16754, 14734, 12522, 10304, 28329, 12605, 14734, 10250, 10349, 12509, 13764, 59, 11, 11454, 13192, 10993, 16056, 15735, 12609, 12604, 10841, 13064, 14637, 17150, 10390, 10370, 45, 17148, 15033, 16403, 10292, 10995, 13086, 14734, 13091, 10696, 12366, 14734, 13637, 17097, 11124, 15129, 10335, 12522, 16696, 45, 10261, 14794, 16711, 14734, 10993, 16754, 13191, 10250, 11899, 12143, 16973, 28329, 14794, 13580, 14734, 13192, 10993, 12220, 16721, 15752, 11454, 10790, 10370, 12604, 10841, 13064, 16417, 14446, 10760, 14794, 12366, 14734, 18216, 10685, 11124, 18458, 10851, 45, 15646, 10260, 13091, 11753, 15723, 12527, 28329, 10322, 16684, 12605, 10402, 17879, 16503, 10995, 12410, 45, 13091, 10260, 13091, 17141, 10339, 11454, 10993, 16754, 10285, 11959, 13685, 16256, 16020, 12366, 14734, 14015, 16956, 45, 15646, 12392, 14619, 10333, 12978, 12746, 11124, 17802, 10437, 14734, 13205, 16884, 28329, 11042, 13064, 16503, 14486, 16533, 45, 13191, 10349, 13192, 10993, 11021, 15752, 11454, 15847, 12605, 16667, 14862, 10257, 11861, 11454, 17728, 18025, 45, 17843, 10399, 17919, 11957, 10390, 10370, 14734, 17149, 13582, 10080, 17148, 17879, 16503, 13064, 17734, 10985, 16749, 17172, 28329, 11687, 13258, 17148, 15033, 14637, 17150, 12746, 15511, 10997, 14583, 45, 12609, 16684, 17879, 17385, 13034, 16694, 10435, 17148, 15033, 10684, 15304, 14734, 12522, 10304, 10080, 10993, 16754, 13188, 11902, 16896, 10305, 11621, 11454, 10339, 10696, 12366, 14734, 12999, 12266, 11124, 10342, 10847, 28329, 12421, 10305, 45, 10590, 12237, 14734, 10993, 16754, 10260, 12220, 12261, 15123, 11454, 13637, 17097, 10285, 45, 14794, 16711, 11268, 12468, 10390, 10370, 12604, 17688, 12638, 15752, 16672, 10993, 16754, 17688, 11861, 10080, 17148, 17879, 16503, 10994, 13036, 10682, 11042, 10848, 10838, 10080, 12159, 13197, 17148, 10349, 12261, 16676, 11957, 12469, 13191, 12176, 10847, 45, 10322, 13558, 17143, 12469, 17149, 10250, 13582, 10768, 10361, 12509, 13764, 10080, 65535, 261, 65530, 65532, 17148, 13091, 12337, 14486, 12509, 14734, 19137, 10444, 13091, 14446, 11903, 15646, 10990, 15712, 15761, 14734, 10267, 14610, 17384, 19137, 33, 13192, 10993, 10684, 15304, 10285, 12421, 13091, 12837, 13215, 14808, 15129, 10335, 11124, 17097, 10852, 11, 65535, 261, 65530, 65534, 12469, 12848, 10792, 14734, 14446, 11903, 10267, 14610, 10285, 10993, 16754, 10684, 15304, 17843, 10662, 12837, 13215, 15129, 10335, 11124, 17097, 10852, 14734, 17728, 18025, 45, 12605, 17916, 12182, 16667, 11042, 10080, 14734, 14914, 45, 11454, 10250, 10283, 13773, 17385, 14970, 10423, 13637, 17097, 11124, 10283, 10370, 12604, 10841, 14734, 14970, 10423, 17384, 45, 17148, 15033, 14446, 16803, 10917, 10768, 13125, 17216, 28329, 10444, 13091, 45, 12605, 17147, 13091, 12509, 11994, 13581, 10768, 10361, 10250, 10349, 18030, 11630, 12509, 13764, 59, 11, 50, 47, 33, 15129, 10335, 11124, 17097, 10852, 10305, 12366, 13051, 11021, 17248, 10662, 45, 10444, 12605, 10402, 11021, 10399, 17177, 12731, 10293, 10846, 17788, 10448, 17148, 15033, 12484, 15509, 45, 12261, 15123, 13179, 10590, 12237, 12200, 11124, 14734, 10684, 15304, 28329, 51, 47, 33, 14794, 13580, 14734, 10993, 16754, 45, 12220, 16721, 12261, 15123, 11454, 10342, 14782, 11971, 17385, 10079, 12978, 12746, 11124, 12527, 14091, 14734, 11533, 14902, 10257, 45, 15646, 10260, 13091, 13637, 18216, 10448, 28329, 52, 47, 33, 11967, 13773, 12522, 10838, 12983, 11454, 15847, 12144, 10696, 12366, 12604, 17688, 11124, 15494, 10334, 12978, 12746, 10257, 45, 15646, 10260, 13091, 10261, 10370, 13637, 17097, 45, 11021, 10399, 10739, 17093, 17148, 15033, 13051, 16763, 14734, 17097, 10852, 28329, 53, 47, 33, 12605, 10402, 17311, 11002, 14970, 10423, 14445, 11574, 11124, 13012, 10901, 10408, 10577, 16520, 12325, 11168, 45, 10444, 10383, 11021, 10399, 10848, 10838, 10293, 10846, 12261, 15123, 13179, 13580, 17919, 12266, 13078, 14734, 10684, 15304, 28329, 54, 47, 33, 10684, 13773, 10696, 12366, 14370, 15123, 11124, 11889, 11884, 45, 15646, 10260, 13091, 11630, 11454, 12604, 10841, 45, 11021, 10399, 17248, 10662, 16684, 11632, 17097, 10852, 12366, 14486, 28329, 14914, 11903, 45, 16503, 10588, 10792, 17148, 10250, 14172, 12202, 10260, 11922, 13080, 10080, 10444, 12605, 14782, 10529, 10250, 10283, 12522, 16696, 10792, 17728, 18025, 10079, 12202, 10848, 10838, 16939, 11047, 13580, 17919, 11003, 10901, 14734, 10370, 45, 15480, 11967, 15752, 15486, 10964, 10684, 15304, 14734, 12604, 17688, 10261, 10920, 10925, 10080, 17148, 17879, 16503, 11474, 12746, 10261, 10863, 13655, 45, 10322, 17879, 16503, 12664, 10792, 10261, 12605, 10402, 12377, 11042, 17222, 11038, 14734, 14862, 12144, 10080, 12537, 12469, 15752, 11454, 12822, 15325, 14734, 16981, 10257, 16056, 12348, 12978, 12746, 10080, 65535, 261, 65530, 65534, 10464, 16735, 14734, 12337, 13191, 17222, 14486, 10080, 15129, 10335, 11124, 17097, 10852, 13091, 10370, 17781, 10684, 15304, 10285, 14734, 10250, 10283, 17843, 18025, 10080, 13191, 10745, 14172, 16416, 10655, 59, 11, 50, 42, 33, 15129, 10335, 12366, 14486, 12337, 13580, 12182, 45, 10444, 16503, 10848, 10838, 15516, 12746, 12200, 16412, 10080, 17172, 12231, 14734, 15129, 10335, 15752, 14091, 10997, 17149, 11001, 12366, 45, 17141, 11632, 10779, 10423, 14894, 11470, 10993, 16754, 28329, 51, 42, 33, 14794, 13580, 14734, 13192, 10993, 12220, 16721, 13091, 10342, 14782, 12978, 12746, 11124, 12330, 13581, 12604, 17688, 10080, 15646, 17916, 14331, 12657, 10260, 13923, 16747, 18216, 16747, 10448, 28329, 52, 42, 33, 11967, 13773, 12522, 10838, 12983, 11454, 15847, 12144, 12604, 17688, 10257, 45, 10739, 11977, 10261, 10370, 13637, 17097, 10080, 13179, 11923, 11922, 12266, 13078, 11459, 14791, 12335, 10790, 10370, 28329, 53, 42, 33, 14970, 10423, 13012, 10901, 13660, 11430, 10322, 10423, 12325, 11168, 12605, 10402, 10080, 10444, 13633, 10283, 10370, 17311, 15752, 10293, 10846, 10848, 10838, 12981, 11003, 28329, 54, 42, 33, 10684, 13773, 10696, 11454, 12200, 17912, 45, 15646, 17916, 11630, 11454, 12604, 10841, 10080, 11021, 10399, 17788, 10448, 17097, 10852, 14734, 12366, 14486, 28329, 12421, 14734, 13234, 16735, 45, 16503, 12981, 11003, 12421, 10260, 13091, 10250, 17028, 15646, 11994, 10080, 17879, 16503, 10260, 13032, 10848, 10838, 11124, 10538, 13580, 15847, 12144, 10080, 10444, 11016, 16503, 13191, 16519, 16696, 11124, 10863, 13655, 45, 12605, 10402, 14734, 10370, 17781, 10684, 15304, 15480, 11967, 12604, 17688, 11124, 10920, 10925, 28329, 17385, 14172, 11454, 10339, 11474, 12746, 10080, 12664, 10792, 12377, 11042, 17222, 11038, 14734, 13192, 10993, 45, 16056, 12348, 12978, 12746, 11124, 14091, 10851, 10080, 10250, 14172, 10250, 14025, 11459, 13198, 14808, 13179, 11124, 14821, 17149, 13582, 14734, 13036, 11047, 17142, 17149, 11994, 11685, 28329, 12605, 14782, 10529, 10464, 10322, 15752, 10588, 10792, 10080, 10842, 13750, 34, 65535, 261, 65530, 65534, 11889, 13849, 12705, 11, 10684, 10339, 10370, 17781, 10684, 15304, 10285, 14734, 15129, 10335, 11124, 17097, 10852, 12366, 14486, 45, 10399, 10992, 11687, 10454, 17788, 10448, 17097, 10852, 12366, 14486, 14734, 12325, 11168, 45, 10399, 10992, 12261, 15123, 13179, 10590, 12237, 12200, 16412, 14734, 10684, 15304, 10080, 10293, 16503, 16520, 14172, 13091, 19137, 11454, 10250, 10283, 10993, 16754, 10684, 15304, 10285, 19137, 15129, 10335, 11124, 17097, 10852, 12366, 14486, 13091, 12182, 16519, 14734, 17728, 18025, 19137, 10444, 12605, 10402, 11021, 10399, 17189, 17141, 10293, 10846, 17788, 10448, 17097, 10852, 12366, 14486, 10079, 12261, 15123, 13179, 10590, 12237, 12200, 15169, 14734, 10684, 15304, 13234, 12981, 11255, 17148, 15033, 14446, 16803, 10080, 11042, 13064, 19137, 12605, 10402, 10322, 12220, 16721, 13773, 12522, 10792, 15847, 12144, 10696, 12366, 12604, 17688, 10261, 10261, 10390, 10370, 14782, 10342, 12325, 11168, 14734, 17728, 18025, 19137, 12202, 11959, 13685, 12978, 12746, 11124, 12176, 10847, 13234, 10660, 13193, 17148, 10349, 17728, 18025, 10080, 13188, 11044, 45, 12605, 10402, 12220, 16721, 10525, 12746, 12266, 13078, 11124, 11971, 17385, 10390, 10370, 14734, 12396, 12231, 45, 10399, 12261, 15123, 13179, 10590, 12237, 10079, 13179, 13191, 14757, 14734, 10684, 15304, 28329, 50, 47, 33, 10684, 10339, 13192, 10993, 10684, 15304, 10285, 14734, 15129, 10335, 11124, 17097, 10852, 12366, 14486, 59, 11, 51, 47, 33, 15129, 10335, 13091, 10370, 17781, 10684, 15304, 10285, 12182, 16519, 14734, 17728, 18025, 10080, 12307, 10278, 10283, 10370, 10342, 14782, 15129, 10335, 13064, 19137, 11021, 15752, 10423, 11960, 15850, 10260, 12368, 16503, 14734, 15326, 12287, 13655, 13660, 11124, 10260, 15895, 12325, 11168, 10080, 11416, 13581, 19137, 12605, 10402, 12220, 16721, 17248, 10662, 17148, 15033, 12484, 10724, 10997, 14583, 19137, 12202, 11959, 12664, 10682, 11042, 14172, 13234, 12261, 15123, 13179, 10590, 12237, 10079, 12200, 15169, 11124, 13191, 14757, 14734, 10684, 15304, 28329, 52, 47, 33, 17097, 10852, 12366, 14486, 11021, 10399, 13091, 10250, 15033, 12182, 16519, 17728, 18025, 10080, 12307, 10278, 10283, 10370, 11454, 10250, 16944, 13064, 19137, 11922, 13080, 10358, 14583, 10768, 13584, 10079, 10335, 11073, 12609, 15643, 10260, 12519, 12387, 14734, 15486, 10964, 10080, 10292, 10333, 17248, 10662, 17148, 15033, 12484, 10724, 10997, 14583, 19137, 12605, 10402, 17879, 16503, 10525, 12746, 10726, 17912, 10079, 14486, 13133, 11124, 11971, 17385, 11957, 13036, 14734, 12522, 16519, 10080, 11042, 13064, 19137, 10322, 16503, 11871, 10423, 12825, 10794, 15847, 12144, 14734, 12484, 15509, 11124, 16403, 10292, 19137, 10399, 10662, 12282, 16944, 13179, 11632, 18425, 14189, 28329, 53, 47, 33, 12421, 10305, 45, 33, 11454, 10250, 10283, 10993, 16754, 10684, 15304, 10285, 45, 33, 15129, 10335, 11124, 17097, 10852, 12366, 14486, 13091, 17843, 10662, 14734, 10080, 10444, 13091, 19137, 17189, 17141, 10293, 10846, 11959, 13685, 16533, 10722, 13036, 13336, 10079, 12261, 15123, 10342, 14782, 11971, 17385, 11124, 12978, 12746, 14734, 10684, 15304, 10079, 10399, 10992, 10525, 12746, 12200, 15169, 10342, 10788, 15169, 16403, 10292, 13234, 10739, 11977, 17097, 10852, 12366, 14486, 14734, 12325, 11168, 10080, 11016, 13191, 17148, 13324, 19137, 12605, 10402, 12638, 15752, 12261, 15123, 10250, 10283, 10590, 12237, 10079, 11124, 16760, 11124, 13191, 14757, 14734, 10684, 15304, 10080, 65535, 261, 65530, 65534, 5732, 8875, 460, 63758, 4712, 22590, 38809, 4706, 63361, 21265, 52763, 4596, 65004, 4600, 32227, 4601, 21413, 4435, 332, 47342, 4706, 47425, 21265, 50928, 47, 3878, 57344, 32227, 4858, 47266, 38530, 4712, 22248, 22251, 56950, 47001, 32226, 59328, 60112, 4811, 46726, 45, 21265, 32227, 32313, 51803, 47266, 4435, 62617, 21265, 65034, 47, 3878, 30135, 57344, 55654, 30678, 22590, 31135, 4706, 22762, 4600, 45301, 4715, 31458, 59829, 45, 4423, 4601, 21413, 31262, 4811, 60701, 63361, 47, 50232, 45, 4569, 45112, 116, 63695, 332, 50997, 51035, 59331, 21265, 37832, 62617, 45, 21265, 51746, 32448, 4811, 51982, 52359, 40187, 62616, 46726, 47, 50511, 45, 44126, 55618, 32227, 63695, 332, 51913, 64549, 32487, 46726, 57102, 332, 50997, 51035, 63361, 21265, 64849, 47, 11, 65535, 261, 65530, 65532, 16738, 10464, 12421, 15489, 12605, 10402, 10780, 12638, 14734, 11957, 16713, 10696, 11922, 11, 65535, 261, 65530, 65534, 11454, 17148, 13619, 11957, 16713, 10285, 45, 33, 10250, 10447, 13192, 10993, 12848, 10792, 10333, 10390, 14734, 10250, 10283, 10684, 15304, 10285, 11861, 11454, 15129, 10335, 11124, 17097, 10852, 12366, 14486, 45, 33, 12202, 10265, 10390, 12159, 13197, 15752, 11634, 12604, 17688, 10261, 15516, 12746, 12200, 16412, 10080, 14221, 15646, 45, 33, 10390, 10322, 16417, 17136, 10333, 11957, 10339, 17097, 10852, 12366, 14486, 14734, 10260, 14015, 12522, 45, 33, 12202, 10265, 16667, 10292, 17148, 15033, 16403, 10292, 13091, 10370, 17781, 10684, 15304, 10285, 12182, 16519, 14734, 17728, 18025, 10080, 13188, 11044, 45, 33, 10390, 12261, 16676, 16503, 10525, 12746, 12200, 16412, 11124, 10342, 14782, 14486, 16533, 45, 10399, 10992, 17385, 16523, 10696, 12366, 12604, 17688, 11124, 12978, 12746, 28329, 65535, 261, 65530, 65534, 11454, 17148, 13619, 11957, 16713, 10285, 45, 33, 10250, 10447, 13192, 10993, 12848, 10792, 10333, 10390, 14734, 10250, 10447, 10684, 15304, 10285, 11861, 11454, 15129, 10335, 11124, 17097, 10852, 12366, 14486, 45, 33, 12202, 10265, 16667, 10292, 17148, 13091, 10250, 15033, 17728, 18025, 14734, 13981, 11647, 10080, 14221, 15646, 19137, 10390, 10322, 12848, 10792, 10333, 10250, 10349, 12261, 16676, 13234, 12176, 10847, 12981, 11255, 17148, 10283, 17728, 18025, 45, 33, 10894, 12732, 16503, 10525, 12746, 12200, 16412, 11124, 10342, 14782, 14486, 16533, 10079, 10399, 10992, 17385, 16523, 10696, 12366, 12604, 17688, 10261, 12978, 12746, 10080, 13188, 11044, 45, 33, 10390, 12261, 16676, 13179, 10842, 13773, 17385, 10696, 12366, 12604, 17688, 10261, 12978, 12746, 45, 33, 10399, 10992, 12200, 16412, 11124, 10342, 14782, 14486, 16533, 28329, 65535, 261]
-> item_loss 0.9049959182739258 batch_loss 1.1260739599957186
==== [22251, 56950, 47001, 32226, 59328, 60112, 4811, 46726, 45, 21265, 32227, 32313, 51803, 47266, 4435, 62617, 21265, 65034, 47, 3878, 30135, 57344, 55654, 30678, 22590, 31135, 4706, 22762, 4600, 45301, 4715, 31458, 59829, 45, 4423, 4601, 21413, 31262, 4811, 60701, 63361, 47, 50232, 45, 4569, 45112, 116, 63695, 332, 50997, 51035, 59331, 21265, 37832, 62617, 45, 21265, 51746, 32448, 4811, 51982, 52359, 40187, 62616, 46726, 47, 50511, 45, 44126, 55618, 32227, 63695, 332, 51913, 64549, 32487, 46726, 57102, 332, 50997, 51035, 63361, 21265, 64849, 47, 11, 65535, 261, 65530, 65532, 16738, 10464, 12421, 15489, 12605, 10402, 10780, 12638, 14734, 11957, 16713, 10696, 11922, 11, 65535, 261, 65530, 65534, 11454, 17148, 13619, 11957, 16713, 10285, 45, 33, 10250, 10447, 13192, 10993, 12848, 10792, 10333, 10390, 14734, 10250, 10283, 10684, 15304, 10285, 11861, 11454, 15129, 10335, 11124, 17097, 10852, 12366, 14486, 45, 33, 12202, 10265, 10390, 12159, 13197, 15752, 11634, 12604, 17688, 10261, 15516, 12746, 12200, 16412, 10080, 14221, 15646, 45, 33, 10390, 10322, 16417, 17136, 10333, 11957, 10339, 17097, 10852, 12366, 14486, 14734, 10260, 14015, 12522, 45, 33, 12202, 10265, 16667, 10292, 17148, 15033, 16403, 10292, 13091, 10370, 17781, 10684, 15304, 10285, 12182, 16519, 14734, 17728, 18025, 10080, 13188, 11044, 45, 33, 10390, 12261, 16676, 16503, 10525, 12746, 12200, 16412, 11124, 10342, 14782, 14486, 16533, 45, 10399, 10992, 17385, 16523, 10696, 12366, 12604, 17688, 11124, 12978, 12746, 28329, 65535, 261, 65530, 65534, 11454, 17148, 13619, 11957, 16713, 10285, 45, 33, 10250, 10447, 13192, 10993, 12848, 10792, 10333, 10390, 14734, 10250, 10447, 10684, 15304, 10285, 11861, 11454, 15129, 10335, 11124, 17097, 10852, 12366, 14486, 45, 33, 12202, 10265, 16667, 10292, 17148, 13091, 10250, 15033, 17728, 18025, 14734, 13981, 11647, 10080, 14221, 15646, 19137, 10390, 10322, 12848, 10792, 10333, 10250, 10349, 12261, 16676, 13234, 12176, 10847, 12981, 11255, 17148, 10283, 17728, 18025, 45, 33, 10894, 12732, 16503, 10525, 12746, 12200, 16412, 11124, 10342, 14782, 14486, 16533, 10079, 10399, 10992, 17385, 16523, 10696, 12366, 12604, 17688, 10261, 12978, 12746, 10080, 13188, 11044, 45, 33, 10390, 12261, 16676, 13179, 10842, 13773, 17385, 10696, 12366, 12604, 17688, 10261, 12978, 12746, 45, 33, 10399, 10992, 12200, 16412, 11124, 10342, 14782, 14486, 16533, 28329, 65535, 261]
-> item_loss 1.19801664352417 batch_loss 1.1281294652393885
==== [65530, 65532, 10777, 10296, 10250, 10283, 12182, 14589, 14734, 7262, 7999, 102, 10762, 13004, 11, 65535, 261, 65530, 65534, 17148, 17384, 13191, 10250, 10349, 12182, 14589, 14734, 19644, 7999, 102, 33, 10762, 13004, 59, 11, 46, 30491, 280, 33, 11047, 17848, 11038, 13920, 10842, 10653, 15323, 11, 46, 21515, 280, 267, 11899, 10304, 10250, 10283, 15158, 11028, 11, 46, 30674, 114, 280, 33, 17216, 10964, 12217, 10777, 11, 46, 45985, 280, 17141, 14017, 12217, 10777, 11, 46, 38499, 280, 33, 16056, 11001, 12217, 10777, 14734, 15162, 10250, 10283, 10653, 15323, 11, 46, 4612, 2318, 280, 33, 10781, 12261, 10250, 10283, 10762, 13004, 45, 11885, 15752, 10250, 13557, 16749, 14589, 11632, 10283, 10762, 13004, 33, 12202, 11967, 10687, 15489, 13258, 15476, 11038, 10792, 10250, 10283, 12217, 10777, 10285, 11, 46, 22069, 280, 33, 11957, 12217, 10777, 10285, 14734, 13633, 10283, 10653, 15323, 12220, 14589, 10762, 13004, 45, 17146, 11414, 13086, 11965, 11044, 14734, 12217, 10777, 11, 46, 22193, 280, 33, 16056, 11001, 12217, 10777, 10285, 14734, 13279, 10283, 15325, 12282, 10447, 15586, 14734, 10653, 15323, 11, 46, 47074, 280, 33, 10781, 12261, 10250, 10283, 11533, 10339, 15494, 11899, 10577, 14734, 12217, 10777, 11, 46, 31871, 280, 33, 16056, 11001, 12217, 10777, 10285, 14734, 12631, 13191, 17798, 15162, 10250, 10283, 10653, 15323, 11630, 14734, 10653, 15323, 11, 46, 22456, 280, 33, 11967, 10260, 11021, 17216, 10964, 14734, 11957, 16803, 17083, 12791, 10292, 17216, 10964, 12217, 10777, 11, 46, 32074, 280, 33, 13381, 13290, 12217, 10777, 13091, 11060, 14015, 16956, 15494, 11899, 10762, 13004, 14734, 13231, 10407, 11, 46, 32082, 280, 33, 12814, 12217, 10250, 10283, 12217, 10777, 11, 17148, 17384, 10377, 10296, 10333, 10250, 10349, 12182, 14589, 14734, 10487, 11855, 45, 19644, 7999, 102, 33, 17147, 13191, 12337, 11632, 10687, 11885, 13191, 14589, 14734, 10696, 15586, 10762, 13004, 45, 33, 11021, 10399, 11454, 17148, 17384, 13290, 17749, 11891, 13006, 10777, 16417, 59, 34579, 5385, 7262, 7999, 7415, 1802, 47, 8401, 48, 35467, 8581, 65535, 261, 10777, 10296, 7262, 7999, 102, 10285, 25059, 14734, 10762, 13004, 16735, 13078, 11, 65530, 65534, 25059, 33, 10762, 13004, 13091, 19644, 7999, 102, 33, 10285, 13188, 17385, 16503, 14734, 17848, 11038, 12945, 10460, 10762, 13004, 10305, 10250, 10080, 11885, 14734, 10841, 15752, 13091, 11047, 17848, 11038, 13920, 10842, 13034, 10653, 15323, 28329, 10293, 16503, 13191, 10278, 15033, 14589, 13764, 59, 11, 50, 47, 33, 13920, 10842, 10932, 10283, 10653, 15323, 11, 25059, 33, 14589, 13764, 59, 11, 41, 25059, 30478, 30737, 42, 11, 10487, 11687, 59, 11, 41, 25059, 274, 41, 50, 285, 286, 42, 287, 42, 3580, 275, 50, 285, 286, 287, 42, 11, 41, 25059, 326, 50, 285, 286, 94, 287, 42, 3580, 326, 50, 285, 286, 287, 94, 261, 51, 47, 33, 11038, 12202, 10278, 10283, 17848, 11038, 11, 41, 25059, 30478, 30478, 51, 42, 11, 10487, 11687, 59, 11, 41, 25059, 274, 41, 50, 285, 286, 42, 274, 41, 53, 288, 494, 3580, 275, 50, 285, 286, 287, 288, 42, 11, 41, 25059, 326, 50, 285, 286, 94, 326, 53, 288, 1682, 267, 746, 326, 50, 285, 286, 287, 288, 94, 11, 12421, 14734, 13234, 16735, 45, 25059, 33, 10762, 13004, 11021, 10399, 12824, 12979, 11632, 10283, 10988, 13004, 59, 10250, 10283, 17848, 11038, 41, 25043, 42, 11124, 10250, 10283, 12609, 11632, 10283, 10653, 15323, 41, 25210, 497, 14221, 11044, 11967, 10653, 15323, 13920, 10842, 10792, 17848, 11038, 10285, 28329, 12631, 10399, 11885, 13091, 19644, 7999, 102, 33, 10285, 13188, 15190, 10932, 10322, 13188, 13191, 14589, 14734, 12981, 11003, 17848, 11038, 14349, 12396, 14734, 10762, 13004, 10080, 65535, 261, 10777, 10296, 7262, 7999, 102, 10285, 14734, 7621, 10762, 13004, 14734, 10762, 13004, 16735, 13078, 11, 65530, 65534, 25059, 280, 33, 13920, 10842, 10653, 15323, 10792, 17848, 11038, 10285, 11, 41, 25059, 30478, 30737, 42, 11, 25059, 33, 10762, 13004, 11021, 10399, 11967, 10250, 10283, 12609, 11632, 10283, 10653, 15323, 13920, 10842, 10792, 17848, 11038, 10285, 28329, 7621, 280, 33, 10384, 13086, 11965, 10285, 16056, 11001, 10577, 11, 41, 7621, 22069, 21952, 326, 8260, 46, 34477, 1682, 11, 7621, 33, 10762, 13004, 11021, 10399, 10384, 10250, 10283, 13086, 11965, 41, 8149, 42, 10285, 16056, 11001, 17644, 41, 8020, 42, 11957, 12220, 14734, 10577, 28329, 11687, 13258, 17644, 10260, 11861, 11454, 45, 10779, 17146, 11414, 22187, 46, 34477, 33, 10577, 41, 11021, 17177, 42, 28329, 30491, 33, 11124, 21751, 33, 14734, 10762, 13004, 16735, 13078, 10768, 10790, 13091, 59, 11, 25059, 59, 11, 46, 33, 11047, 17848, 11038, 13920, 10842, 10250, 10283, 12609, 11632, 10283, 10653, 15323, 11, 46, 275, 25059, 30478, 30737, 42, 33, 10423, 11967, 30737, 33, 13920, 10842, 10792, 30478, 33, 17848, 11038, 10285, 11, 46, 33, 11021, 10399, 14589, 10339, 11047, 17387, 10079, 10777, 16417, 10079, 17848, 11038, 15169, 17848, 11038, 15261, 11496, 11, 7621, 59, 11, 46, 33, 10384, 13086, 11965, 10285, 16056, 11001, 12748, 11899, 21952, 33, 11957, 12220, 14734, 10577, 11, 46, 275, 7621, 22069, 21952, 42, 33, 10423, 10384, 22069, 33, 13086, 11965, 10285, 16056, 11001, 21952, 33, 11957, 12220, 14734, 10577, 11, 46, 33, 11687, 13258, 21952, 33, 10260, 11861, 11454, 45, 10779, 17146, 11414, 22175, 11, 46, 33, 11021, 10399, 12848, 10494, 10250, 10283, 22187, 46, 34477, 33, 10988, 13004, 10460, 10292, 11622, 14589, 10577, 11, 46, 275, 7621, 22069, 21952, 22187, 46, 34477, 42, 11, 10487, 11687, 59, 11, 41, 7621, 4899, 98, 284, 293, 99, 285, 126, 293, 98, 42, 3580, 284, 11, 41, 7621, 4899, 98, 284, 293, 99, 285, 126, 293, 100, 269, 8260, 38547, 5164, 3580, 269, 8260, 38547, 363, 11, 25059, 33, 13091, 10538, 12981, 17848, 11038, 45, 7621, 33, 13091, 10384, 13086, 11965, 10285, 16742, 11001, 13004, 12797, 45, 10278, 15643, 10841, 15752, 10260, 11042, 10080, 65535, 261, 10296, 10487, 16735, 13078, 7262, 7999, 102, 14734, 16728, 13764, 14332, 14172, 11, 65530, 65534, 7262, 7999, 102, 14734, 10293, 16503, 16728, 13764, 14332, 14172, 11687, 10258, 59, 11, 50, 47, 20299, 113, 13324, 12276, 14734, 84, 12276, 16728, 13764, 10080, 7262, 7999, 102, 17379, 14589, 10333, 1219, 2191, 14734, 10427, 15500, 84, 12276, 16728, 13764, 45, 10482, 14589, 12732, 11028, 16417, 14966, 15052, 12217, 15489, 13250, 28329, 51, 47, 33, 12978, 12746, 10762, 13004, 12276, 15543, 15052, 10080, 7262, 7999, 102, 17379, 14589, 10762, 13004, 12276, 15543, 15052, 10460, 10292, 10293, 16503, 15543, 15052, 15973, 12276, 45, 12978, 12746, 18216, 17775, 10762, 13004, 10079, 11117, 11043, 22001, 12314, 12276, 10079, 12507, 12415, 13685, 10577, 15169, 14332, 12333, 28329, 52, 47, 33, 12978, 12746, 17919, 11047, 11957, 16803, 15543, 15052, 10080, 7262, 7999, 102, 12848, 10494, 10333, 11533, 10339, 16678, 12308, 14734, 17919, 11047, 11957, 16803, 45, 12978, 12746, 15261, 10079, 15507, 12665, 10079, 10926, 16676, 10079, 11632, 12396, 15169, 14332, 12415, 28329, 53, 47, 33, 12978, 12746, 12202, 10997, 15543, 15052, 10080, 7262, 7999, 102, 12848, 10494, 10333, 11533, 10339, 17086, 10407, 10336, 10843, 10696, 11861, 13499, 11496, 14734, 12202, 10997, 12978, 12746, 45, 11021, 10399, 13036, 10511, 18216, 12986, 11459, 15543, 10708, 12202, 10997, 15052, 12217, 28329, 54, 47, 33, 10846, 12396, 16728, 16537, 10080, 7262, 7999, 102, 13091, 10250, 15033, 10846, 12396, 16728, 16537, 45, 10652, 16684, 11454, 17144, 16403, 13064, 12981, 11003, 16728, 16537, 15489, 13250, 45, 11687, 17385, 13034, 11899, 10304, 10762, 13004, 10079, 11003, 17387, 15169, 28329, 55, 47, 33, 12978, 12746, 10653, 15543, 15052, 10080, 7262, 7999, 102, 12848, 10494, 10333, 12299, 11638, 14734, 13212, 10794, 13234, 12981, 10708, 16728, 13764, 45, 11687, 35036, 116, 10079, 10995, 11965, 15169, 28329, 56, 47, 33, 12978, 12746, 10985, 17187, 11028, 10080, 7262, 7999, 102, 10985, 12810, 10333, 1219, 2191, 10427, 15500, 14734, 10768, 17821, 15158, 17187, 11028, 45, 15646, 17379, 14589, 11533, 10339, 17734, 16973, 14734, 13327, 12276, 10901, 28329, 57, 47, 33, 10762, 13004, 10460, 14589, 11524, 10292, 10846, 12396, 14734, 10080, 7262, 7999, 102, 14734, 10762, 13004, 10460, 14589, 11524, 17379, 14589, 10261, 1219, 2191, 10250, 15850, 14734, 10846, 12396, 10460, 14589, 11524, 13036, 12276, 28329, 58, 47, 33, 12978, 12746, 10696, 15586, 13004, 12797, 15489, 13250, 10080, 7262, 7999, 102, 12848, 10494, 10333, 10286, 11932, 14734, 10696, 15586, 13004, 12797, 15489, 13250, 45, 11687, 10777, 16417, 10079, 11047, 17387, 10079, 17848, 11038, 10079, 11164, 12159, 16417, 15169, 28329, 630, 47, 33, 12978, 12746, 10727, 15489, 13004, 12797, 15489, 13250, 10080, 7262, 7999, 102, 12978, 12746, 11967, 11021, 11003, 13004, 12797, 15489, 13250, 10727, 15489, 12604, 10260, 11021, 11003, 14734, 13004, 12797, 45, 12848, 18216, 15052, 12217, 11889, 10675, 12415, 28329, 10399, 10257, 10293, 16503, 12022, 14966, 10333, 7262, 7999, 102, 14734, 10250, 10349, 13308, 12377, 12415, 16728, 13764, 14332, 14172, 10080, 12159, 13197, 15752, 10292, 12469, 12848, 10494, 10988, 15641, 34, 65535, 261, 65530, 65532, 15494, 10250, 10283, 10688, 10452, 14734, 10397, 14875, 10487, 11855, 11, 65535, 261, 65530, 65534, 17148, 17384, 13091, 10250, 10283, 15190, 10932, 14734, 19644, 7999, 102, 33, 10397, 14875, 14966, 10487, 59, 11, 6884, 7262, 7999, 102, 11, 41, 7334, 31496, 269, 23813, 381, 11, 41, 7334, 111, 38632, 3331, 482, 94, 275, 25526, 117, 31496, 494, 3331, 482, 26290, 94, 19242, 41, 49580, 275, 8756, 269, 33155, 269, 31496, 269, 5164, 5292, 11, 41, 7334, 111, 22532, 326, 39, 52333, 94, 3331, 41, 42150, 278, 52333, 494, 11, 41, 25526, 117, 269, 33414, 381, 11, 60, 36786, 37308, 34, 11, 41, 25526, 117, 42, 11, 60, 36786, 29165, 34, 11, 41, 8762, 284, 285, 286, 287, 42, 11, 60, 3483, 11, 6884, 11, 10293, 16503, 12022, 14966, 10333, 59, 11, 46, 33, 11899, 10304, 15158, 11028, 4398, 7334, 31496, 269, 23813, 381, 97, 11, 46, 33, 11899, 10304, 10762, 13004, 4398, 7334, 111, 38632, 36218, 276, 97, 11, 46, 33, 11632, 10283, 10988, 13004, 10777, 16417, 4398, 7334, 111, 38632, 3435, 94, 275, 25526, 117, 31496, 494, 3435, 26290, 94, 275, 49580, 275, 8756, 269, 33155, 269, 31496, 269, 5164, 5292, 97, 11, 46, 33, 11003, 17688, 10988, 13004, 10777, 16417, 4398, 7334, 111, 22532, 326, 39, 52333, 94, 28375, 97, 11, 46, 33, 10696, 15586, 14734, 47030, 33, 10762, 13004, 4398, 42150, 278, 52333, 512, 11, 46, 33, 16749, 14589, 11899, 10304, 14734, 38632, 33, 11124, 22532, 33, 10762, 13004, 11, 13006, 10452, 13234, 14791, 13091, 10250, 10283, 15190, 10932, 14734, 38632, 33, 10762, 13004, 11124, 22532, 33, 10762, 13004, 14734, 11899, 10304, 11124, 10482, 14589, 10080, 5735, 7999, 102, 33, 14332, 13191, 14734, 318, 33, 12276, 16728, 13764, 10079, 11003, 17688, 10988, 13004, 10777, 16417, 15169, 14332, 12415, 17311, 13191, 10452, 14446, 28329, 12159, 13197, 15752, 15494, 12469, 10988, 15641, 34, 11687, 13258, 13191, 10687, 10390, 17879, 13685, 45, 13558, 17143, 12848, 10760, 10080, 65535, 261, 65530, 65532, 17379, 14589, 10397, 14875, 14966, 10487, 16735, 13078, 7262, 7999, 102, 14734, 11632, 17385, 13036, 13764, 11, 65535, 261, 65530, 65534, 17148, 17384, 13191, 10250, 10283, 7262, 7999, 102, 14734, 11632, 17385, 13036, 13764, 14966, 10487, 59, 11, 7334, 35086, 21699, 38499, 11, 7334, 41847, 21699, 293, 98, 326, 121, 94, 275, 8756, 269, 41847, 332, 59, 269, 355, 42, 11, 7334, 41847, 21699, 293, 99, 326, 121, 94, 275, 8756, 269, 41847, 333, 59, 269, 355, 42, 11, 41, 7578, 293, 98, 3483, 42, 3580, 269, 41847, 332, 59, 3483, 35, 11, 41, 7578, 293, 99, 3493, 42, 3580, 269, 41847, 333, 59, 3493, 35, 11, 17148, 17384, 12605, 10402, 11899, 10304, 10250, 10283, 11632, 17385, 10762, 13004, 7578, 45, 33, 17177, 12731, 10768, 13818, 13036, 13764, 41, 7334, 35086, 42, 13091, 13326, 12797, 10988, 13004, 15162, 10250, 10283, 10653, 15323, 41, 34453, 42, 13234, 10722, 11899, 16749, 14589, 11187, 10283, 10688, 10452, 13036, 13764, 41, 7334, 41847, 42, 11, 10688, 10452, 17141, 15052, 13091, 59, 11, 50, 47, 33, 11899, 10304, 11632, 17385, 10762, 13004, 21699, 33, 12202, 10482, 14589, 38499, 33, 10762, 13004, 17177, 12731, 10768, 13818, 13036, 13764, 59, 11, 6884, 7262, 7999, 102, 11, 41, 7334, 35086, 21699, 38499, 42, 11, 6884, 11, 51, 47, 33, 11899, 10304, 10250, 10283, 10688, 10452, 13036, 13764, 293, 98, 45, 33, 10988, 13004, 13091, 355, 59, 11, 6884, 7262, 7999, 102, 11, 41, 7334, 41847, 21699, 293, 98, 326, 121, 94, 275, 8756, 269, 41847, 332, 59, 269, 355, 494, 11, 6884, 11, 52, 47, 33, 11899, 10304, 11013, 10250, 10283, 10688, 10452, 13036, 13764, 293, 99, 59, 11, 6884, 7262, 7999, 102, 11, 41, 7334, 41847, 21699, 293, 99, 326, 121, 94, 275, 8756, 269, 41847, 333, 59, 269, 355, 494, 11, 6884, 11, 53, 47, 33, 12307, 16749, 14589, 21699, 478, 98, 3483, 42, 33, 13064, 45, 33, 10423, 17177, 12731, 293, 98, 33, 13036, 13764, 60, 11, 54, 47, 33, 12307, 16749, 14589, 21699, 478, 99, 3493, 42, 33, 13064, 45, 33, 10423, 17177, 12731, 293, 99, 33, 13036, 13764, 28329, 17189, 17141, 11632, 17385, 13036, 13764, 45, 33, 12605, 10402, 11021, 10399, 12750, 14240, 10260, 11042, 14734, 13308, 10733, 56016, 33, 10792, 10260, 11042, 14734, 10688, 10452, 13036, 13764, 11903, 14446, 10080, 17148, 17384, 10788, 14589, 38499, 33, 10768, 13818, 10792, 10688, 10452, 14734, 10684, 17644, 11860, 293, 98, 33, 12609, 15643, 293, 99, 45, 33, 11891, 12604, 11632, 12314, 12396, 10768, 13818, 28329, 12159, 13197, 15752, 11634, 10847, 12469, 14486, 16533, 21443, 7999, 102, 33, 14734, 11632, 17385, 13036, 13764, 34, 16738, 11454, 17879, 16503, 13064, 16416, 10655, 10080, 65535, 261, 65530, 65532, 17379, 14589, 10397, 14875, 14966, 10487, 16735, 13078, 7262, 7999, 102, 14734, 10762, 13004, 10988, 13004, 16533, 13250, 11, 65535, 261, 65530, 65534, 5735, 7999, 102, 10285, 14734, 10762, 13004, 11021, 10399, 10482, 14589, 10988, 13004, 16533, 13250, 45, 16728, 13764, 13091, 11454, 10988, 13004, 11043, 10808, 10842, 478, 11, 6884, 7262, 7999, 102, 11, 41, 7334, 111, 30924, 46, 26290, 3331, 1650, 98, 333, 334, 94, 36216, 60, 332, 13091, 10250, 10283, 11047, 17387, 3331, 1652, 98, 293, 99, 293, 100, 94, 19250, 60, 332, 45, 99, 11124, 100, 13091, 8149, 10285, 14734, 17644, 3331, 92, 98, 358, 99, 293, 99, 126, 334, 94, 267, 60, 99, 13091, 10250, 10283, 8149, 3331, 92, 98, 333, 273, 31458, 1682, 294, 26276, 13091, 10250, 10283, 10894, 11064, 10822, 10457, 10988, 13004, 14734, 11047, 17387, 11, 6884, 11, 10487, 11855, 59, 11, 6884, 7262, 7999, 102, 11, 41, 7334, 111, 39355, 46, 25857, 3331, 92, 39, 326, 26290, 4899, 26078, 326, 6935, 46085, 1701, 4899, 26078, 326, 25015, 1701, 1697, 3331, 41, 49580, 31496, 269, 1955, 35, 21238, 269, 36031, 22221, 35, 46085, 58652, 35, 7005, 38919, 4596, 35, 30449, 494, 11, 41, 35433, 46, 25857, 4899, 26290, 269, 23813, 35, 293, 6935, 3503, 293, 41455, 269, 23902, 399, 64158, 2370, 25015, 269, 6329, 30074, 5198, 11, 60, 29165, 4600, 3503, 40237, 22221, 29335, 21265, 38919, 4596, 20512, 30074, 11, 6884, 11, 11454, 17148, 17384, 45, 59, 26290, 16533, 13250, 8149, 14734, 59, 26290, 17644, 558, 59, 26078, 326, 6935, 46085, 1701, 16533, 13250, 6935, 11124, 41455, 17644, 45, 4899, 26078, 326, 25015, 1701, 16533, 13250, 25015, 17644, 28329, 10988, 13004, 16533, 13250, 16672, 10762, 13004, 10988, 13004, 13179, 10688, 16728, 10304, 45, 13080, 10339, 14486, 16533, 10080, 65535, 261, 65530, 65532, 12848, 10494, 10250, 10283, 10482, 14589, 7262, 7999, 102, 16690, 17728, 7322, 26450, 13004, 12797, 12219, 14734, 10397, 14875, 14966, 10487, 11, 65535, 261, 65530, 65534, 17148, 17384, 13091, 10250, 10283, 10482, 14589, 19644, 7999, 102, 33, 16690, 17728, 19722, 26450, 33, 13004, 12797, 12219, 14734, 14966, 10487, 59, 11, 6884, 7262, 7999, 102, 11, 41, 49636, 3410, 7322, 26450, 47, 7023, 293, 1751, 335, 1682, 11, 60, 50108, 4811, 332, 19722, 26450, 55912, 11, 41, 7334, 30492, 275, 101, 48, 49003, 269, 7322, 26450, 59, 25457, 5385, 58319, 59, 663, 654, 48, 2058, 1815, 5172, 11, 60, 37220, 22590, 55912, 11, 41, 101, 48, 114, 3410, 59, 25423, 298, 102, 49923, 59, 36002, 326, 64, 102, 293, 34284, 269, 26055, 65, 49131, 47, 7272, 5196, 36210, 65, 25060, 42, 11, 60, 64226, 11, 41, 101, 48, 35795, 6909, 30492, 19242, 1659, 59, 1815, 48, 1940, 270, 1815, 48, 1940, 1652, 1815, 47, 26650, 48, 27370, 94, 36210, 59, 26290, 269, 23813, 35, 36210, 59, 34284, 269, 26055, 65, 49131, 47, 7272, 399, 1682, 11, 41, 101, 48, 35795, 6909, 30492, 19242, 1659, 59, 1815, 48, 1940, 270, 1815, 48, 1940, 1652, 1815, 47, 26650, 48, 27370, 94, 36210, 59, 26290, 269, 23909, 35, 36210, 59, 34284, 269, 26215, 65, 49131, 47, 7272, 399, 1682, 11, 60, 29137, 7066, 31601, 52738, 11, 41, 25156, 114, 326, 27370, 275, 101, 48, 114, 3410, 59, 25423, 298, 102, 65396, 59, 1950, 271, 298, 26290, 65396, 59, 36002, 326, 64, 102, 293, 26290, 298, 26290, 1697, 65362, 65, 25060, 269, 23813, 5177, 3331, 41, 49580, 32355, 494, 11, 6884, 11, 24242, 30469, 59, 11, 46, 44419, 116, 22590, 331, 7322, 26450, 47, 7023, 97, 60044, 11, 46, 50108, 116, 4811, 332, 19722, 26450, 55912, 39095, 331, 2058, 1815, 97, 11, 46, 50535, 116, 332, 39415, 4811, 30858, 4419, 45874, 32487, 38356, 331, 26055, 65, 49131, 47, 7272, 97, 11, 46, 50535, 116, 22638, 64595, 4811, 21227, 22638, 40084, 11, 46, 50535, 116, 332, 39415, 4811, 30858, 21256, 40084, 32487, 31496, 269, 23813, 35, 11, 46, 29137, 24744, 31601, 22590, 52738, 21265, 46906, 32229, 11, 23739, 32234, 38686, 34, 20282, 4660, 31223, 4588, 22799, 31059, 21273, 39193, 60312, 47, 65535, 261, 65530, 65532, 12605, 10381, 11639, 17879, 16503, 11454, 7322, 26450, 13004, 12797, 12219, 17384, 10842, 10257, 13133, 15752, 12636, 13212, 17148, 10283, 11903, 10452, 19137, 16738, 15494, 12605, 12848, 10494, 10250, 10283, 10688, 10452, 14734, 11533, 10339, 7322, 26450, 14734, 10397, 14875, 16689, 16664, 11, 65535, 261, 65530, 65534, 17148, 17384, 13191, 11533, 10339, 19722, 26450, 33, 14734, 13133, 15752, 12636, 13212, 11903, 10452, 10397, 14875, 16689, 16664, 59, 11, 6884, 7262, 7999, 102, 11, 60, 33, 11903, 10452, 1107, 11, 36, 1815, 48, 1940, 1652, 1815, 47, 26650, 48, 27370, 94, 11, 60, 33, 12025, 12415, 11, 59, 26290, 269, 41512, 323, 35, 11, 59, 35074, 269, 41512, 323, 35, 11, 60, 11860, 13619, 11, 1652, 35430, 293, 1815, 48, 42434, 94, 267, 60, 10408, 13327, 45, 11210, 10250, 11, 1652, 49629, 23554, 293, 1815, 47, 27200, 48, 49290, 94, 294, 10997, 12155, 13053, 13199, 11, 1652, 2102, 293, 1815, 48, 42434, 94, 28360, 60, 12945, 10460, 15304, 15500, 11, 1652, 41138, 293, 1815, 48, 42434, 1690, 11044, 12892, 10621, 11647, 10621, 15323, 11, 60, 33, 10355, 13080, 11, 1647, 101, 48, 35795, 6909, 30492, 262, 1659, 59, 1815, 48, 1940, 270, 1815, 48, 1940, 1652, 1815, 47, 26650, 48, 35664, 35381, 94, 28352, 59, 26290, 269, 41512, 323, 35, 28352, 59, 35074, 269, 41512, 323, 35, 28352, 59, 35430, 3572, 58, 28352, 59, 49629, 23554, 270, 25883, 269, 640, 637, 46, 631, 46, 623, 85, 620, 59, 620, 59, 620, 47, 620, 49, 46, 620, 59, 620, 35, 28352, 59, 2102, 269, 7738, 3484, 35, 28352, 59, 41138, 3485, 2403, 11, 60, 13290, 16718, 11, 1659, 59, 25423, 274, 64, 26290, 274, 64, 35430, 3331, 59, 36002, 4371, 64, 102, 293, 26290, 298, 26290, 94, 61270, 92, 64, 102, 293, 35430, 298, 35430, 1697, 3331, 59, 1950, 3395, 274, 41512, 323, 463, 94, 11, 6884, 11, 17148, 10283, 16689, 16664, 10894, 11064, 59, 11, 46, 33, 11903, 10452, 3888, 33, 10292, 331, 59, 1815, 47, 26650, 48, 35664, 35381, 97, 11, 46, 33, 12025, 12415, 10292, 97, 11043, 15044, 97, 10079, 97, 11496, 11028, 97, 10079, 331, 10408, 13327, 97, 10079, 97, 10997, 12155, 13053, 13199, 97, 10079, 97, 12945, 10460, 15304, 15500, 97, 11124, 97, 11044, 12892, 10621, 11647, 10621, 15323, 97, 11, 46, 33, 11957, 12220, 11860, 13619, 15261, 11496, 16689, 15586, 11, 46, 33, 13920, 10842, 10250, 13231, 46241, 323, 33, 14734, 16678, 12308, 10460, 10292, 14966, 10487, 11, 46, 33, 13290, 16718, 46241, 323, 33, 14734, 11043, 15044, 11124, 10408, 13327, 14734, 13290, 16718, 14966, 10487, 11, 11533, 10339, 13581, 16689, 16664, 45, 12469, 11021, 10399, 13920, 10842, 13179, 11632, 13133, 15752, 12636, 13212, 14734, 16678, 12308, 11124, 12025, 12415, 45, 14221, 11044, 11957, 10687, 12650, 16403, 11036, 15033, 13290, 16718, 28329, 11687, 13191, 17879, 16503, 45, 12605, 11021, 10399, 10292, 12469, 11891, 11255, 10688, 10452, 16689, 16664, 10080, 16738, 11414, 11626, 11088, 14862, 10080, 65535, 261, 65530, 65532, 27476, 4600, 21443, 7999, 102, 64, 32006, 4660, 32074, 30469, 21700, 51668, 11, 65535, 261, 65530, 65534, 5735, 7999, 102, 4600, 332, 51461, 4706, 20299, 113, 45, 332, 45956, 4706, 63795, 59946, 47, 29804, 56162, 4706, 19644, 7999, 102, 30469, 59, 11, 46, 44880, 56292, 59, 11, 6884, 7262, 7999, 102, 11, 41, 7334, 111, 21227, 326, 98, 333, 94, 3331, 474, 332, 333, 494, 11, 41, 6913, 285, 286, 42, 3580, 3591, 288, 11, 6884, 11, 46, 50824, 32487, 53267, 59, 11, 6884, 7262, 7999, 102, 11, 41, 7334, 52333, 326, 50, 285, 286, 287, 1682, 11, 41, 34174, 52333, 42, 3580, 3591, 287, 11, 41, 34453, 52333, 42, 3580, 3591, 284, 11, 41, 26102, 52333, 42, 3580, 3591, 287, 11, 41, 25059, 52333, 288, 42, 3580, 3591, 326, 50, 285, 286, 287, 288, 94, 11, 6884, 11, 46, 50824, 32487, 31371, 59, 11, 6884, 7262, 7999, 102, 11, 41, 7334, 32355, 4899, 26290, 269, 23813, 35, 293, 6935, 3503, 2389, 11, 41, 7621, 32355, 293, 26290, 42, 3580, 3591, 269, 23813, 35, 11, 41, 33915, 32355, 293, 25015, 269, 6329, 30074, 381, 3580, 3591, 4899, 26290, 269, 23813, 384, 293, 6935, 3503, 45, 293, 25015, 269, 6329, 30074, 399, 11, 6884, 11, 46, 44291, 7856, 332, 61689, 59, 11, 6884, 7262, 7999, 102, 11, 41, 41418, 30788, 64, 52333, 42, 3580, 3591, 275, 51, 287, 42, 11, 6884, 11, 46, 29301, 7856, 32487, 274, 7579, 448, 11, 6884, 7262, 7999, 102, 11, 41, 7579, 326, 121, 275, 35494, 284, 3484, 509, 3331, 41, 35433, 355, 269, 3351, 42, 11, 746, 3591, 284, 285, 286, 287, 288, 289, 290, 291, 292, 3483, 11, 6884, 11, 1461, 19644, 7999, 102, 30469, 4600, 51276, 21265, 62030, 4596, 39844, 45, 46500, 38677, 22681, 4706, 59751, 45, 63344, 21265, 60344, 47, 65535, 261]
-> item_loss 1.6564335823059082 batch_loss 1.1428045796023474
==== [15162, 10250, 13557, 12848, 17728, 11, 65530, 65532, 10902, 10362, 11454, 10373, 10303, 11459, 13036, 19156, 11, 65535, 261, 65530, 65534, 10902, 10362, 10447, 10339, 10285, 11435, 10902, 13036, 45, 13091, 10285, 10925, 10370, 13653, 10682, 11124, 11435, 14734, 18117, 17311, 28329, 10293, 16503, 15478, 15907, 59, 11, 50, 47, 33, 10902, 10362, 12154, 10447, 10339, 10285, 11435, 10272, 10902, 17303, 45, 11459, 11621, 10925, 10902, 12200, 10974, 14734, 10285, 12366, 28329, 51, 47, 33, 10902, 10362, 11621, 10339, 12337, 17385, 16503, 14734, 15486, 13828, 10079, 12984, 13751, 11124, 13012, 10901, 10285, 12366, 10447, 15586, 28329, 52, 47, 33, 10902, 10362, 13250, 12604, 10362, 13802, 10694, 11517, 12154, 15604, 13325, 12366, 45, 13091, 10285, 11435, 11412, 11638, 11011, 17311, 10305, 10250, 28329, 53, 47, 33, 10902, 10362, 12985, 11913, 15169, 11011, 17167, 10079, 11857, 12224, 10079, 18019, 11124, 11423, 15169, 15847, 14221, 13126, 14172, 10992, 17878, 17904, 15169, 17728, 18025, 15646, 10760, 11043, 28329, 54, 47, 33, 10902, 10362, 10688, 13191, 10257, 10918, 12201, 10964, 11024, 45, 13186, 15486, 13091, 10653, 10079, 13078, 10079, 13923, 10256, 10397, 14734, 18117, 17311, 10080, 639, 669, 33, 12201, 11044, 12604, 10292, 10285, 10925, 10370, 13653, 10682, 11124, 11435, 14734, 18117, 17311, 28329, 55, 47, 33, 10902, 10362, 11459, 11621, 659, 2446, 675, 9835, 127, 3514, 2446, 623, 9835, 10902, 15455, 45, 631, 54, 2446, 645, 9835, 127, 631, 56, 2446, 650, 9835, 10272, 15486, 28329, 12159, 13197, 10399, 10257, 10529, 12445, 15752, 12176, 10847, 12469, 10080, 11687, 13258, 17147, 13191, 10687, 10390, 14638, 17728, 45, 13558, 17143, 17819, 13064, 12848, 17728, 10080, 65535, 261, 65530, 65534, 14488, 14543, 19151, 33, 12605, 10780, 10780, 16707, 14808, 11871, 10323, 10333, 17148, 10349, 14862, 16696, 10080, 15489, 13258, 11640, 17843, 10333, 19137, 12605, 13734, 12401, 10303, 11871, 10423, 19137, 17879, 16503, 13179, 11632, 14734, 10988, 15641, 16909, 13021, 14791, 14791, 28329, 65535, 261, 65530, 65531, 15162, 10337, 13557, 17149, 10250, 13582, 14734, 12848, 17728, 11, 65535, 261, 65530, 65532, 10902, 10362, 11454, 10373, 10303, 11459, 13036, 19156, 11, 65535, 261, 65530, 65534, 10464, 11685, 19137, 12605, 13091, 10250, 10283, 820, 19137, 11017, 10588, 11975, 10847, 12636, 10080, 12605, 15752, 12176, 12469, 11414, 15178, 11036, 15033, 17728, 18025, 19137, 10260, 17141, 12605, 17879, 16503, 12469, 12848, 10494, 13179, 11632, 14734, 10529, 12445, 10080, 10902, 10362, 13091, 10285, 11435, 14734, 10250, 10283, 11517, 12154, 19137, 10447, 10339, 10285, 11435, 14734, 10902, 17303, 10080, 11885, 10399, 10687, 10286, 11932, 14734, 10964, 11024, 13012, 10901, 17225, 10358, 10079, 15597, 18053, 11124, 15034, 12666, 10781, 13034, 17740, 11043, 10339, 10267, 10080, 11687, 13258, 12469, 13191, 13179, 11632, 10684, 10339, 10902, 10362, 14734, 17728, 18025, 19137, 13558, 17143, 11047, 12605, 12848, 10760, 19126, 11, 65535, 261, 65530, 65534, 10902, 10362, 10447, 10339, 10285, 11435, 10902, 17303, 45, 13091, 10285, 11435, 14734, 18117, 17311, 28329, 9828, 33, 10902, 10362, 14734, 11459, 14486, 10447, 15586, 59, 10902, 15455, 659, 2446, 674, 9835, 15849, 661, 2446, 625, 9835, 45, 10272, 15486, 631, 54, 2446, 645, 9835, 15849, 631, 56, 2446, 650, 9835, 28329, 9828, 33, 10902, 10362, 13091, 17919, 15043, 13188, 11638, 10079, 10355, 17189, 13188, 10292, 10511, 10788, 10079, 15486, 13828, 13188, 10997, 17136, 10079, 13012, 10901, 13188, 13815, 16962, 14734, 10285, 11435, 11517, 12154, 10305, 10250, 28329, 9828, 33, 10902, 10362, 10964, 11024, 12466, 10301, 45, 15847, 15040, 14736, 14968, 11022, 12261, 15123, 10399, 13234, 11994, 10250, 14781, 13091, 10285, 11435, 14734, 12984, 13751, 10285, 12366, 28329, 9828, 33, 10902, 10362, 11517, 10696, 13191, 12337, 11632, 17385, 16503, 14734, 11011, 17167, 10079, 10964, 11024, 13012, 10901, 12261, 15176, 45, 11687, 11639, 11889, 17723, 12210, 11461, 10079, 18019, 11124, 11423, 15169, 45, 10995, 13086, 10333, 10902, 10362, 12466, 10301, 14734, 10964, 11024, 11124, 13012, 10901, 28329, 9828, 33, 10902, 10362, 10460, 10292, 10285, 11435, 14734, 18117, 17311, 45, 12727, 13191, 12337, 18216, 14734, 12984, 13751, 10079, 15486, 13828, 11124, 13012, 10901, 11459, 10447, 45, 12337, 11632, 11435, 10696, 11630, 17385, 16503, 13815, 10846, 17311, 11454, 10902, 10362, 10296, 16403, 28329, 9828, 33, 10902, 10362, 14734, 15597, 18053, 10322, 17916, 12182, 10286, 11932, 45, 10902, 10362, 14188, 18372, 10079, 14171, 17351, 17919, 10079, 16793, 56175, 33, 15169, 11010, 11110, 14370, 14332, 14734, 11975, 11035, 16939, 17149, 10267, 14610, 28329, 9828, 33, 17145, 12201, 13234, 45, 10902, 10362, 17147, 12604, 10292, 10285, 11435, 15034, 12666, 11124, 11423, 10912, 12261, 16689, 14734, 10285, 12366, 45, 11075, 12282, 14808, 12337, 11632, 15034, 12666, 10412, 10270, 11124, 12666, 13208, 10370, 12638, 28329, 12159, 13197, 10399, 10257, 10529, 12445, 15752, 12176, 10847, 12469, 13179, 10655, 10768, 11459, 10333, 16533, 10902, 10362, 17148, 12232, 10964, 11024, 11043, 11517, 10080, 11687, 13191, 10687, 10390, 17728, 18025, 45, 13558, 17143, 17819, 13064, 13234, 17728, 10080, 65535, 261, 65530, 65534, 10902, 10362, 59, 33, 12605, 14862, 17222, 10333, 19137, 16774, 16774, 10464, 14734, 16533, 15178, 10080, 17147, 13191, 10687, 10390, 17728, 18025, 11053, 19156, 11, 65535, 261, 65530, 65534, 10258, 17919, 14734, 11957, 16713, 10285, 45, 5732, 8875, 12848, 10494, 14734, 10529, 12445, 13637, 1406, 5608, 12848, 10494, 14734, 16503, 13179, 10842, 10675, 17919, 10079, 15478, 15850, 59, 11, 50, 47, 4164, 5608, 11016, 15190, 10932, 11459, 16735, 10902, 10362, 11454, 10285, 11435, 10902, 17303, 45, 13091, 10285, 11435, 11517, 12154, 45, 15646, 13734, 13191, 10688, 10452, 14734, 11459, 14486, 10447, 15586, 28329, 51, 47, 4164, 5608, 13734, 13191, 12848, 10992, 10902, 10362, 10460, 10292, 18117, 17311, 14734, 12984, 13751, 10079, 15486, 13828, 10079, 13012, 10901, 11459, 10447, 28329, 52, 47, 4164, 5608, 13734, 13191, 12848, 10992, 10902, 10362, 10286, 11932, 14734, 10964, 11024, 13012, 10901, 10992, 11011, 17167, 12261, 15176, 28329, 53, 47, 4164, 5608, 13734, 13191, 12848, 10792, 10902, 10362, 14332, 15898, 14734, 15597, 18053, 11975, 11035, 28329, 54, 47, 4164, 5608, 13734, 13191, 12848, 10992, 10902, 10362, 17145, 12201, 13234, 14734, 15034, 12666, 10261, 10412, 10270, 15674, 17848, 12484, 10724, 28329, 12421, 14734, 13234, 16735, 45, 5732, 8875, 12848, 10494, 14734, 10529, 12445, 13179, 15752, 14015, 16956, 14589, 12626, 10333, 16533, 10902, 10362, 14734, 17879, 13685, 10080, 10529, 12445, 10675, 17919, 45, 10894, 12732, 59, 11, 46, 33, 10688, 10452, 14734, 11459, 14486, 10447, 15586, 11, 46, 33, 10902, 10362, 10460, 10292, 18117, 17311, 14734, 17385, 16503, 12415, 11, 46, 33, 10286, 11932, 14734, 10964, 11024, 13012, 10901, 11124, 11011, 17167, 11, 46, 33, 10902, 10362, 15597, 18053, 11975, 11035, 11, 46, 33, 17145, 12201, 13234, 10902, 10362, 14734, 15034, 12666, 10997, 12022, 11, 17148, 10349, 13036, 17919, 17311, 11891, 13006, 11459, 11414, 15178, 10333, 14589, 12626, 35, 10902, 10362, 11454, 10373, 10303, 11459, 13036, 35, 17148, 10283, 17728, 18025, 45, 12176, 10847, 14589, 12626, 13179, 10675, 17919, 11459, 10333, 16533, 10902, 10362, 11517, 12154, 10080, 65535, 261]
-> item_loss 1.5533838272094727 batch_loss 1.1539013160241616
==== [25106, 11, 65530, 65531, 10464, 13091, 10250, 10283, 10370, 12137, 13133, 15752, 10847, 12636, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 12176, 12605, 14604, 10250, 10283, 52, 43, 52, 14734, 10320, 11913, 13327, 19137, 14589, 9822, 44, 9823, 11860, 15158, 14604, 28329, 65535, 261, 65530, 65534, 7176, 59, 3455, 44, 11, 536, 44, 11, 536, 44, 11, 12605, 14604, 11685, 10333, 10080, 65535, 261, 65530, 65532, 27370, 59, 33, 14221, 11044, 12669, 11885, 12138, 10257, 16530, 14734, 15158, 11028, 12791, 12604, 10026, 28329, 65535, 261, 65530, 65534, 7176, 59, 33, 13734, 17728, 18025, 19126, 10026, 536, 11, 536, 44, 11, 536, 44, 65535, 261, 65530, 65532, 11, 27370, 59, 33, 11025, 10257, 16530, 12791, 12604, 10022, 10080, 65535, 261, 65530, 65534, 7176, 59, 33, 11685, 14734, 10080, 10026, 44, 10022, 11, 536, 44, 11, 536, 44, 65535, 261, 65530, 65532, 11, 27370, 59, 33, 11025, 10258, 16530, 12791, 12604, 1660, 10035, 1660, 10080, 65535, 261, 65530, 65534, 7176, 59, 33, 13734, 17728, 18025, 10080, 10026, 44, 10022, 11, 536, 44, 11, 536, 10035, 65535, 261, 65530, 65532, 11, 27370, 59, 33, 12878, 11899, 10333, 10080, 65535, 261, 65530, 65534, 7176, 59, 33, 12337, 18216, 10685, 15752, 12176, 10257, 12469, 28329, 65535, 261]
[2023-09-30 21:50:23,196] [INFO] [logging.py:96:log_dist] [Rank 0] step=40, skipped=0, lr=[0.0001, 0.0001, 0.0001], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
-> item_loss 0.9026119709014893 batch_loss 1.1472884385209334
==== [11454, 15847, 10323, 11909, 10696, 19137, 33, 14488, 14543, 11454, 17149, 16403, 16742, 10325, 15475, 10323, 16744, 28331, 65530, 65532, 14488, 14543, 10464, 13234, 16742, 10250, 10258, 10258, 17919, 14734, 11975, 16735, 19137, 17148, 17303, 11975, 16735, 11017, 9822, 18256, 13764, 14734, 15898, 12319, 9823, 19137, 11975, 16735, 12847, 17162, 10333, 17268, 10349, 11461, 13126, 19156, 11, 10994, 11517, 11889, 15034, 46, 16050, 13770, 10660, 13091, 9822, 14445, 13849, 9823, 11105, 17131, 11517, 12154, 10305, 18117, 19137, 15847, 14221, 10322, 12604, 10333, 10306, 11038, 10305, 10420, 14734, 15640, 15105, 19151, 13593, 12345, 10079, 14766, 16902, 10079, 15671, 12636, 15486, 16099, 14734, 10327, 10933, 10370, 19137, 15169, 15169, 10080, 17148, 13580, 13091, 17148, 12232, 11517, 12154, 11687, 13581, 11932, 16956, 14734, 10974, 11416, 10305, 10250, 10080, 13748, 14734, 17176, 13064, 11047, 17268, 17131, 19137, 16050, 13770, 10660, 17165, 11913, 10441, 14734, 12148, 11855, 17384, 10449, 14808, 16684, 11632, 11459, 10447, 10928, 16893, 14734, 10449, 12626, 19137, 17148, 10349, 10370, 12182, 10292, 11517, 10285, 14782, 10342, 10335, 13020, 14734, 11418, 10422, 9822, 10692, 12143, 9823, 19137, 16924, 10349, 11630, 12387, 19137, 12289, 16416, 12359, 10260, 16956, 17222, 14734, 12979, 10673, 10080, 12631, 10399, 19137, 10419, 10414, 11124, 10994, 15931, 10250, 16939, 17149, 14894, 18458, 17335, 11920, 14734, 17796, 11855, 19137, 17148, 10349, 9822, 10692, 12143, 9823, 10285, 14734, 11975, 11647, 14778, 10511, 12348, 14862, 19151, 13191, 17558, 10370, 17149, 10333, 11517, 19126, 10250, 10349, 13637, 17097, 15478, 12366, 14734, 12822, 11855, 17147, 10427, 13234, 11010, 10529, 19137, 16735, 17268, 10283, 17149, 11517, 14734, 17787, 14583, 10370, 12172, 14808, 10250, 13205, 11975, 10702, 11855, 19137, 11975, 10702, 11855, 12421, 15752, 12848, 14966, 10390, 16721, 16679, 10373, 10303, 16713, 19151, 17147, 16735, 17268, 10283, 17787, 14583, 10370, 12172, 14808, 10250, 10283, 10423, 15847, 12144, 16939, 16981, 14734, 15209, 11855, 28329, 11, 17148, 13855, 12445, 15123, 10799, 16443, 11638, 11920, 10784, 11899, 10292, 10260, 11021, 10529, 19151, 13191, 17148, 10303, 11638, 13205, 10336, 14734, 18256, 13764, 12158, 19137, 10384, 13234, 10260, 10423, 16939, 17145, 16050, 13770, 10660, 15887, 11478, 10250, 17384, 10305, 10696, 28329, 11, 17148, 10423, 10650, 13580, 13091, 11517, 17384, 14734, 10250, 17303, 10768, 10449, 12626, 10733, 11622, 16944, 17038, 10079, 11013, 10250, 17303, 10768, 13580, 16503, 17043, 10258, 14817, 16525, 14734, 13064, 10560, 19137, 14894, 18458, 17335, 11920, 17384, 11907, 10370, 11944, 11944, 19137, 13734, 10745, 10283, 10370, 14791, 16519, 18000, 14808, 13443, 13374, 16939, 17149, 13234, 14734, 10994, 15931, 10080, 10390, 14734, 9822, 16403, 13221, 9823, 10322, 17819, 10953, 10760, 14446, 11454, 10390, 17038, 11044, 19137, 12266, 11726, 14015, 12395, 10529, 12366, 13101, 13101, 12466, 12466, 11459, 13582, 10258, 11022, 17775, 10080, 10250, 16519, 10305, 10258, 19137, 11471, 11454, 15269, 15296, 13202, 13338, 13039, 14734, 17335, 11907, 10621, 10250, 10283, 10370, 10441, 14734, 10448, 10258, 11647, 13234, 19137, 14638, 12366, 17385, 17385, 11459, 14779, 14808, 15847, 12144, 14734, 17335, 13239, 10080, 65535, 261, 65530, 65532, 17148, 13205, 11975, 16735, 10285, 13191, 10745, 10283, 10370, 19156, 11, 65535, 261, 65530, 65534, 17148, 13205, 11975, 16735, 10285, 13191, 10256, 10283, 10370, 10080, 10390, 10402, 10768, 10790, 13091, 19151, 11, 50, 47, 33, 10994, 15931, 19151, 10250, 10283, 10423, 15847, 12144, 16939, 16981, 14734, 14445, 13849, 11517, 12154, 17787, 14583, 10370, 19137, 12172, 14808, 10250, 10283, 11975, 15209, 11855, 28329, 51, 47, 33, 10994, 15931, 14734, 9822, 10692, 12143, 9823, 19151, 10250, 10283, 17335, 11061, 17384, 14734, 11975, 11647, 14778, 19137, 16875, 16879, 12824, 12220, 10994, 15931, 17149, 11517, 28329, 52, 47, 33, 10994, 15931, 14734, 9822, 10692, 12143, 9823, 19151, 10250, 10283, 10449, 11454, 16050, 13770, 10660, 11517, 11630, 14734, 10710, 13653, 19137, 12172, 14808, 10250, 10283, 11975, 15209, 11855, 17149, 11517, 28329, 53, 47, 33, 17335, 18107, 17384, 14734, 10687, 10390, 10370, 19151, 10390, 10402, 11957, 10994, 15931, 11124, 10994, 15931, 14734, 9822, 10692, 12143, 9823, 12746, 12395, 14638, 12396, 12231, 19137, 10444, 10322, 13734, 13191, 16692, 12797, 16692, 13078, 10390, 10402, 13091, 10580, 14734, 28329, 54, 47, 33, 17335, 18107, 17384, 10687, 10390, 10370, 19151, 10894, 12732, 17268, 10349, 11269, 17358, 10333, 17335, 10079, 12609, 15643, 12509, 16503, 12642, 12822, 13855, 12445, 14734, 17732, 13001, 10370, 11098, 28329, 12421, 10305, 19137, 17148, 17303, 11975, 16735, 10293, 16503, 12847, 17162, 10333, 10250, 15604, 17787, 14583, 10370, 11454, 16050, 13770, 10660, 11517, 10285, 10997, 14583, 14734, 12985, 10336, 10080, 65535, 261, 65530, 65534, 17148, 17384, 13191, 11013, 11630, 10250, 10283, 15178, 13336, 10080, 17148, 13205, 11975, 16735, 10285, 10293, 16503, 12847, 17162, 10333, 10256, 10283, 10370, 10080, 10390, 10402, 10768, 10790, 13091, 19151, 11, 50, 47, 33, 10994, 15931, 19151, 10250, 10283, 10423, 15847, 12144, 16939, 16981, 14734, 14445, 13849, 11517, 12154, 17787, 14583, 10370, 19137, 12172, 14808, 10250, 10283, 11975, 15209, 11855, 28329, 51, 47, 33, 10250, 10283, 17335, 11061, 15640, 13248, 19137, 16875, 16879, 12824, 12335, 10994, 15931, 28329, 52, 47, 33, 10250, 10283, 15091, 14808, 14894, 13055, 10079, 14015, 15778, 15737, 13943, 14734, 14601, 10370, 19137, 13091, 17148, 11920, 17335, 11061, 14734, 12182, 11907, 10080, 10390, 11471, 11454, 10994, 15931, 11957, 17919, 19137, 13064, 10260, 13064, 11459, 14839, 10250, 14806, 10994, 15931, 28329, 53, 47, 33, 17335, 18107, 17384, 10687, 10390, 10370, 19151, 10894, 12732, 17335, 10525, 10079, 18004, 11907, 11124, 12223, 11098, 15169, 15169, 28329, 54, 47, 33, 16050, 13770, 10660, 11517, 19151, 17148, 12232, 11517, 12154, 14734, 11043, 11860, 10080, 43, 30579, 65535, 261, 65530, 65534, 17148, 17384, 13091, 15162, 10256, 10283, 15178, 13336, 10080, 33, 17148, 15216, 11975, 16735, 10293, 16503, 12847, 17162, 14734, 13091, 10994, 15931, 11124, 10419, 10414, 13234, 10792, 10250, 10283, 17131, 17804, 11517, 12154, 16050, 13770, 10660, 14734, 12484, 13126, 28329, 10688, 10452, 13234, 16735, 59, 11, 50, 47, 33, 16050, 13770, 10660, 11517, 13091, 10283, 13916, 10328, 14734, 11459, 13036, 45, 15674, 17848, 14808, 11036, 15033, 13593, 12345, 11124, 11021, 14638, 10370, 14328, 28329, 51, 47, 33, 10994, 15931, 11124, 10419, 10414, 13234, 10792, 16050, 13770, 10660, 11044, 45, 15123, 10953, 12282, 16944, 10333, 10370, 10402, 14734, 13773, 12522, 10080, 11416, 10292, 10994, 15931, 12172, 13191, 11656, 12418, 14734, 16403, 13221, 15209, 10399, 10992, 10250, 10283, 15752, 12848, 10494, 12848, 14966, 14734, 15150, 16678, 13205, 28329, 52, 47, 33, 14221, 15646, 10370, 10402, 16944, 10782, 16667, 10292, 10994, 15931, 10260, 11021, 15752, 13091, 10283, 18256, 13764, 12158, 45, 11416, 10292, 18256, 13764, 12158, 10260, 10423, 12824, 17145, 10621, 16050, 13770, 10660, 17148, 13324, 14734, 11517, 12154, 28329, 53, 47, 33, 10390, 10402, 13234, 10792, 14894, 18458, 17335, 11920, 45, 17335, 11907, 10402, 16519, 10792, 10994, 15931, 11124, 10390, 14734, 16403, 13221, 11044, 45, 14987, 12484, 10655, 14015, 12395, 14638, 28329, 12421, 14734, 13234, 16735, 45, 17189, 17141, 12847, 17162, 10994, 15931, 11124, 10419, 10414, 13234, 10792, 16050, 13770, 10660, 11517, 14734, 11461, 13126, 45, 13146, 14966, 17148, 10283, 11459, 13036, 10655, 14015, 10952, 17801, 11124, 14987, 15036, 10080, 10994, 15931, 11124, 10390, 14734, 11656, 14332, 16403, 16434, 10322, 12282, 16944, 10333, 10370, 10402, 14734, 12395, 14638, 12396, 12231, 10080, 65535, 261, 65530, 65532, 11454, 10305, 10808, 14734, 11975, 16735, 10285, 13191, 10745, 10283, 10293, 16503, 16530, 15898, 10760, 11461, 19156, 11, 65535, 261, 65530, 65534, 10293, 16503, 16530, 15898, 59, 11, 50, 47, 33, 10994, 15931, 59, 10250, 10283, 12172, 14808, 11656, 12418, 16403, 13221, 14734, 17787, 14583, 10370, 45, 10390, 14734, 16403, 13221, 17384, 13191, 10250, 10283, 11975, 14763, 11855, 28329, 51, 47, 33, 10419, 10414, 59, 10250, 10283, 10423, 15847, 12144, 16939, 16981, 14734, 15209, 11855, 45, 10390, 12172, 14808, 10250, 10283, 11975, 14763, 11855, 28329, 52, 47, 33, 17335, 11061, 15640, 13248, 10692, 10692, 17335, 10525, 59, 10390, 13091, 17148, 11920, 17335, 11061, 14734, 12182, 11907, 45, 11957, 10994, 15931, 11124, 10419, 10414, 12337, 12527, 10685, 16954, 28329, 53, 47, 33, 10687, 10390, 10449, 12626, 59, 17335, 11061, 17384, 14734, 10687, 10390, 10449, 12626, 45, 10894, 12732, 10250, 10349, 13637, 17097, 11656, 12418, 14734, 11920, 10422, 28329, 54, 47, 33, 17148, 10349, 10370, 15674, 17848, 11454, 14894, 18458, 17335, 11920, 45, 16520, 11940, 10994, 15931, 28329, 55, 47, 33, 12985, 10336, 10285, 12848, 10792, 10333, 18256, 13764, 10079, 18256, 13764, 12158, 10079, 18256, 13764, 14328, 11159, 10399, 10992, 18256, 13764, 10305, 11517, 16050, 13770, 10660, 28329, 56, 47, 33, 12985, 10336, 10285, 17147, 12848, 10792, 10333, 10994, 15931, 12172, 14808, 10250, 13205, 12636, 10702, 10080, 65535, 261]
-> item_loss 2.015252113342285 batch_loss 1.1695439173625066
==== [17728, 15178, 11, 65530, 65532, 10464, 11017, 10373, 10303, 11043, 11860, 19156, 11, 65535, 261, 65530, 65534, 12605, 11017, 11975, 13078, 28329, 65535, 261, 65530, 65532, 10464, 13191, 10373, 10303, 14189, 12454, 11053, 19156, 11, 65535, 261, 65530, 65534, 12605, 13191, 13064, 10560, 10423, 12509, 19137, 11687, 13258, 12605, 10260, 11861, 11454, 10339, 17148, 10283, 10267, 14610, 10257, 10423, 12401, 10303, 13324, 10080, 10444, 13091, 12605, 14862, 17222, 17148, 13091, 10260, 11021, 15752, 14734, 28329, 65535, 261, 65530, 65532, 10292, 10373, 10303, 19156, 33, 10370, 10260, 10423, 13594, 11053, 19156, 11, 65535, 261, 65530, 65534, 11687, 13258, 10464, 16735, 14734, 13091, 10250, 10283, 14328, 10452, 12609, 15643, 10250, 10283, 10370, 19137, 17268, 10303, 10390, 10402, 10423, 13594, 10353, 10080, 10444, 13091, 11687, 13258, 10464, 16735, 14734, 13091, 10250, 10283, 14141, 18245, 19137, 17268, 10303, 10390, 10402, 10260, 10423, 13594, 10353, 28329, 65535, 261, 65530, 65532, 10464, 13091, 16735, 19137, 10464, 12727, 13191, 14141, 18245, 19137, 10260, 13091, 10250, 10283, 10370, 12137, 13133, 15752, 19156, 11, 65535, 261, 65530, 65534, 13091, 14734, 19137, 12605, 12727, 13191, 14141, 18245, 19137, 10260, 13091, 10250, 10283, 13212, 11369, 10370, 10080, 12605, 11021, 10399, 12527, 11002, 10792, 14658, 14673, 19137, 10322, 10423, 11416, 10292, 14299, 11124, 10993, 12484, 15646, 12527, 10792, 18216, 10685, 28329, 65535, 261, 65530, 65532, 10464, 16667, 10292, 10464, 13091, 11060, 12727, 13191, 14141, 18245, 19156, 11, 65535, 261, 65530, 65534, 12605, 16667, 10292, 12605, 12727, 13191, 14141, 18245, 10080, 11416, 10292, 12605, 11021, 10399, 12527, 11002, 10792, 14658, 14673, 10079, 14299, 11124, 10993, 12484, 19137, 17148, 10349, 17311, 13091, 10370, 15261, 14370, 13191, 14734, 11159, 16884, 28329, 65535, 261, 65530, 65532, 12605, 10260, 10529, 19137, 16692, 13078, 15494, 12605, 14791, 14791, 10080, 12605, 14446, 11454, 15494, 10464, 10250, 10283, 13212, 10423, 19137, 16672, 10464, 16692, 13078, 15494, 12605, 14791, 10080, 10444, 13091, 16738, 16678, 10449, 19137, 17148, 11016, 13091, 16672, 10464, 16692, 13078, 15494, 12605, 14791, 10080, 10464, 11021, 10399, 11986, 16707, 11414, 12509, 16944, 15847, 12144, 13091, 11060, 12727, 13191, 14141, 18245, 10080, 11687, 13258, 10464, 12509, 10260, 16944, 13234, 19137, 17268, 10303, 10464, 11994, 10260, 15752, 16692, 13078, 15494, 12605, 14791, 28329, 65535, 261]
-> item_loss 1.0360426902770996 batch_loss 1.1662063866853714
==== [25106, 11, 65530, 65531, 18119, 16002, 13091, 10250, 10283, 12337, 15678, 13078, 14734, 820, 19137, 10293, 10370, 12176, 18119, 16002, 10588, 10333, 10250, 10283, 15304, 15500, 19137, 16672, 11684, 15752, 11634, 10588, 12337, 11632, 10336, 12484, 28329, 18119, 16002, 14734, 10841, 15752, 19151, 11, 50, 47, 12307, 10293, 10370, 16672, 18119, 16002, 12176, 10390, 12945, 10460, 14600, 15763, 10257, 14734, 10272, 16501, 14734, 13064, 10560, 19137, 18119, 16002, 11021, 10399, 17109, 10760, 1660, 92, 12945, 10460, 14600, 15763, 1696, 35, 12748, 10398, 11124, 15304, 15500, 10355, 10342, 19137, 14221, 11044, 13326, 12797, 15304, 15500, 14734, 12282, 11960, 13855, 12445, 13234, 12945, 10460, 14600, 15763, 28329, 51, 47, 17109, 10760, 1660, 92, 10260, 10997, 13855, 12445, 1696, 35, 14734, 16713, 19137, 10293, 10370, 11994, 10260, 10423, 12979, 10792, 18119, 16002, 14734, 13855, 12445, 19137, 10260, 12509, 12642, 12658, 10293, 10370, 14734, 13064, 10560, 18119, 16002, 11994, 11021, 10399, 17148, 10303, 10588, 28329, 52, 47, 17798, 10333, 10257, 10257, 17162, 12748, 10398, 10399, 11630, 19137, 18119, 16002, 17147, 15752, 10482, 14589, 14734, 12748, 10398, 13191, 19151, 1660, 92, 12642, 12266, 15090, 16749, 1696, 384, 1660, 92, 16689, 15586, 17738, 17544, 1696, 384, 1660, 92, 10684, 17727, 16728, 17952, 1696, 384, 1660, 92, 12266, 11068, 16728, 17952, 1696, 35, 10080, 33, 17879, 16503, 13773, 12522, 14734, 13091, 19137, 11016, 13191, 15304, 15500, 12848, 10792, 14734, 12748, 10398, 11021, 10399, 10482, 14589, 10080, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 18119, 16002, 11, 65535, 261, 65530, 65534, 18119, 16002, 59, 33, 10293, 10370, 12664, 12605, 13191, 10373, 10303, 10336, 12484, 11053, 64, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 12176, 12605, 12266, 10258, 124, 12220, 14589, 11043, 126, 28329, 65535, 261, 65530, 65534, 18119, 16002, 59, 358, 12220, 14589, 11043, 126, 19156, 17268, 13091, 10373, 10303, 19156, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11416, 10292, 14446, 11454, 13091, 11454, 16675, 15475, 16728, 13021, 17384, 19137, 12631, 10399, 11885, 13734, 13191, 16443, 11434, 11899, 10258, 13234, 19137, 11903, 17781, 10257, 11885, 12220, 16721, 10250, 10283, 14600, 15763, 12220, 14589, 14734, 11043, 11860, 28329, 65535, 261, 65530, 65534, 18119, 16002, 59, 326, 12945, 10460, 14600, 15763, 94, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 11021, 10399, 17149, 16403, 14734, 12945, 10460, 19151, 11, 12642, 12266, 12220, 14589, 45, 10482, 14589, 13012, 10407, 15304, 15500, 45, 11, 16738, 17177, 12731, 10250, 10283, 12945, 10460, 19151, 65535, 261, 65530, 65534, 18119, 16002, 59, 33, 12642, 12266, 12220, 14589, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 11021, 17177, 14734, 12220, 14589, 19151, 16678, 10336, 13205, 10079, 16664, 15200, 11369, 10079, 1589, 23682, 10079, 13829, 16524, 11369, 10079, 17273, 10407, 10079, 124, 12220, 14589, 11043, 126, 10080, 16738, 17109, 10760, 17879, 16503, 12642, 12266, 14734, 12220, 14589, 19151, 11, 65535, 261, 65530, 65534, 18119, 16002, 59, 358, 12220, 14589, 11043, 126, 11, 65535, 261, 65530, 65531, 40812, 59, 358, 12220, 14589, 11043, 126, 12145, 12642, 12266, 28329, 65535, 261, 65530, 65534, 18119, 16002, 59, 33, 12145, 15486, 12642, 12266, 10333, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11315, 19137, 12605, 14791, 10792, 10333, 28329, 65535, 261, 65530, 65534, 18119, 16002, 59, 33, 10293, 10370, 13191, 10336, 10703, 13234, 12664, 12605, 11183, 127, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 13191, 10256, 10283, 14763, 11855, 19137, 11885, 10402, 14734, 13308, 15189, 10257, 17919, 10768, 10790, 10708, 14808, 9822, 15966, 13258, 9823, 10079, 9822, 18119, 16184, 9823, 10079, 9822, 15966, 13258, 11124, 18119, 16184, 9823, 10080, 14446, 11454, 14862, 17222, 11016, 13191, 10250, 10283, 15966, 13258, 11124, 10250, 10283, 18119, 16184, 10079, 13633, 10283, 14763, 11855, 17384, 13188, 11632, 11016, 13191, 10250, 10283, 13676, 13258, 19137, 12202, 10265, 10256, 10283, 14763, 11855, 10257, 14734, 13308, 15189, 17311, 13091, 17631, 16730, 14734, 19137, 11687, 13258, 16672, 10464, 12642, 12266, 10687, 10285, 10250, 10283, 14763, 11855, 13234, 14914, 16667, 10256, 10283, 14763, 11855, 17384, 17311, 13091, 10373, 10303, 19137, 10464, 10423, 12401, 10303, 10588, 19156, 11, 65535, 261, 65530, 65534, 18119, 16002, 59, 33, 12605, 10423, 12642, 12266, 10708, 14808, 9822, 15966, 13258, 11124, 18119, 16184, 9823, 17268, 10283, 14763, 11855, 10080, 11416, 10292, 11016, 13191, 17148, 13324, 12605, 12638, 15752, 14914, 11899, 10256, 10283, 14763, 11855, 17384, 17311, 13091, 10373, 10303, 28329, 10293, 10370, 19137, 12605, 13234, 16533, 17382, 10250, 10258, 10974, 11416, 10080, 18117, 10658, 19137, 11687, 13258, 12605, 12642, 12266, 10250, 10283, 14763, 11855, 19137, 17384, 17919, 11021, 15752, 10760, 14446, 14734, 12484, 10724, 13091, 19151, 13191, 10250, 10283, 15966, 13258, 10079, 13191, 10250, 10283, 18119, 16184, 10079, 10373, 10303, 10322, 13734, 13191, 28329, 11687, 13258, 12605, 12642, 12266, 10708, 14808, 9822, 15966, 13258, 9823, 12609, 9822, 18119, 16184, 9823, 14734, 14763, 11855, 19137, 12202, 10265, 17384, 17919, 13191, 13676, 13258, 19137, 17268, 10303, 17384, 17919, 14734, 13676, 13258, 10250, 11899, 13091, 10261, 13308, 15189, 10257, 12631, 10708, 10260, 11042, 14734, 13676, 13258, 10080, 17268, 10303, 12605, 11994, 13051, 13764, 14914, 11899, 11013, 11630, 10278, 10283, 14763, 11855, 10285, 13091, 10373, 10303, 12484, 10724, 19152, 15646, 12605, 15957, 13091, 12642, 12266, 10708, 14808, 9822, 15966, 13258, 11124, 18119, 16184, 9823, 14734, 17268, 10283, 14763, 11855, 19137, 11021, 15752, 10423, 10760, 14446, 10256, 15033, 12484, 10724, 19151, 11, 50, 47, 17148, 10283, 14763, 11855, 17384, 13191, 10250, 10283, 15966, 13258, 19137, 17268, 10303, 10708, 14808, 9822, 18119, 16184, 9823, 14734, 14763, 11855, 17384, 10250, 11899, 10373, 10303, 10322, 13734, 13191, 19137, 10708, 14808, 9822, 15966, 13258, 9823, 14734, 14763, 11855, 17384, 10250, 11899, 13191, 10250, 13326, 18119, 16184, 10080, 11416, 10292, 19137, 12605, 10402, 14862, 17222, 11016, 13191, 10250, 10283, 15966, 13258, 11124, 10250, 13326, 18119, 16184, 10080, 11687, 13258, 10708, 14808, 9822, 18119, 16184, 9823, 14734, 14763, 11855, 17384, 13191, 13676, 13258, 19137, 17268, 10303, 17268, 10283, 13676, 13258, 10250, 11899, 13091, 18119, 16184, 19137, 17148, 13324, 14734, 16713, 19137, 11994, 10423, 10261, 9822, 10256, 10283, 14763, 11855, 10257, 14734, 13308, 15189, 17311, 13091, 17631, 16730, 14734, 9823, 14734, 10336, 11903, 14782, 12463, 10080, 12631, 10399, 19137, 10708, 14808, 9822, 18119, 16184, 9823, 14734, 14763, 11855, 17384, 10250, 11899, 13091, 15090, 14734, 10080, 14597, 13581, 11021, 10399, 14862, 17222, 19137, 17268, 13326, 18119, 16184, 10250, 11899, 11454, 10708, 14808, 9822, 15966, 13258, 9823, 14734, 14763, 11855, 17384, 28329, 51, 47, 17148, 10283, 14763, 11855, 17384, 13191, 10250, 10283, 18119, 16184, 10080, 17148, 15033, 12484, 10724, 10258, 14734, 12826, 14486, 13036, 13764, 10261, 14763, 11855, 17384, 13191, 15966, 13258, 13091, 10250, 15850, 14734, 19137, 11016, 10260, 17141, 12669, 15966, 13258, 11124, 18119, 16184, 10342, 12791, 10250, 10258, 28329, 52, 47, 17148, 10283, 14763, 11855, 17384, 10373, 10303, 10322, 13734, 13191, 10080, 17268, 10303, 11013, 11630, 10278, 10283, 14763, 11855, 17384, 10250, 11899, 13191, 13676, 13258, 10080, 10708, 14808, 9822, 15966, 13258, 9823, 14734, 14763, 11855, 17384, 13191, 18119, 16184, 19137, 10708, 14808, 9822, 18119, 16184, 9823, 14734, 14763, 11855, 17384, 13191, 15966, 13258, 10080, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 10292, 10373, 10303, 12642, 12266, 10708, 14808, 9822, 15966, 13258, 9823, 12609, 10708, 14808, 9822, 18119, 16184, 9823, 14734, 14763, 11855, 10423, 11960, 15850, 13051, 13764, 14914, 11899, 11013, 11630, 10278, 10283, 14763, 11855, 10285, 13091, 10373, 10303, 12484, 10724, 19156, 11, 65535, 261, 65530, 65534, 18119, 16002, 59, 33, 10293, 10370, 19137, 13091, 11021, 15752, 10423, 11960, 15850, 13051, 13764, 14914, 11899, 11013, 11630, 10278, 10283, 14763, 11855, 10285, 13091, 10373, 10303, 12484, 10724, 10080, 11416, 10292, 10580, 16689, 12605, 12642, 12266, 10708, 14808, 9822, 15966, 13258, 9823, 14734, 14763, 11855, 19137, 11021, 15752, 10423, 10760, 14446, 10278, 15033, 12484, 10724, 19151, 11, 50, 47, 17384, 17919, 13191, 18119, 16184, 11, 51, 47, 17384, 17919, 10373, 10303, 10322, 13734, 13191, 11, 11687, 13258, 17384, 17919, 10373, 10303, 10322, 13734, 13191, 19137, 17268, 10303, 12605, 10402, 15752, 14914, 11899, 10708, 14808, 9822, 18119, 16184, 9823, 14734, 14763, 11855, 17384, 13191, 10250, 10283, 15966, 13258, 19137, 10708, 14808, 9822, 15966, 13258, 11124, 18119, 16184, 9823, 14734, 14763, 11855, 17384, 13191, 10250, 13326, 18119, 16184, 10080, 17148, 15033, 12484, 10724, 10258, 19137, 12605, 10402, 13091, 15752, 11634, 14914, 16667, 11013, 11630, 10278, 10283, 14763, 11855, 14734, 12484, 10724, 14734, 28329, 10444, 13091, 11687, 13258, 12605, 10402, 10997, 14446, 10708, 14808, 9822, 15966, 13258, 9823, 14734, 14763, 11855, 17384, 13191, 18119, 16184, 19137, 17268, 10303, 12605, 10402, 11994, 13051, 13764, 14914, 16667, 17268, 10283, 15966, 13258, 13091, 11454, 10708, 14808, 9822, 18119, 16184, 9823, 14734, 14763, 11855, 17384, 17147, 13091, 11454, 10708, 14808, 9822, 15966, 13258, 11124, 18119, 16184, 9823, 14734, 14763, 11855, 17384, 28329, 11687, 13258, 12642, 12266, 10708, 14808, 9822, 18119, 16184, 9823, 14734, 14763, 11855, 19137, 12826, 14486, 13036, 12276, 10322, 13091, 10250, 13324, 14734, 19137, 11016, 10260, 17141, 12669, 15966, 13258, 11124, 18119, 16184, 10342, 12791, 10250, 10258, 28329, 10293, 10370, 19137, 15752, 14486, 16533, 11053, 19156, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11315, 19137, 13734, 13191, 17728, 18025, 28329, 65535, 261, 65530, 65534, 18119, 16002, 59, 33, 12337, 11685, 127, 17268, 10303, 10293, 10370, 17147, 13191, 10687, 10390, 10336, 12484, 11053, 19156, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 10464, 15752, 10260, 11414, 12605, 17148, 11012, 16713, 10303, 19156, 11, 65535, 261, 65530, 65534, 18119, 16002, 59, 326, 10260, 10997, 13855, 12445, 94, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11315, 19137, 14791, 13234, 14914, 11903, 13734, 13191, 13855, 12445, 28329, 65535, 261, 65530, 65534, 18119, 16002, 59, 33, 12605, 12750, 10293, 10370, 14734, 16735, 13764, 10588, 10333, 10080, 10444, 13091, 18119, 16002, 17147, 13091, 12509, 11124, 10293, 10370, 16735, 16713, 14734, 43282, 11, 65535, 261]
-> item_loss 0.8055842518806458 batch_loss 1.1574107248608658
==== [25106, 11, 17148, 13619, 13012, 11860, 13091, 9822, 14931, 12314, 10267, 14610, 9823, 14734, 10250, 10283, 14313, 13619, 19137, 33, 16679, 17162, 10333, 14597, 13085, 17781, 10846, 14328, 11871, 11920, 16520, 11940, 12140, 18492, 15646, 12282, 10997, 14734, 10336, 10407, 11, 10305, 10808, 19137, 12140, 18492, 14734, 11861, 11454, 10377, 10377, 13091, 10250, 10283, 10580, 16735, 19137, 10444, 14931, 12314, 10267, 14610, 17131, 15545, 14116, 13819, 10257, 13036, 10250, 11621, 12822, 10760, 13234, 14734, 12034, 11981, 10257, 13191, 10250, 10283, 14987, 15036, 14734, 10660, 18295, 11979, 14428, 11435, 19137, 17268, 17384, 14734, 10660, 18295, 11979, 10370, 11454, 10250, 11473, 13188, 17795, 12076, 14734, 14869, 11592, 17997, 10257, 12883, 16689, 10333, 18216, 13273, 11124, 14005, 17085, 16451, 15586, 19137, 11967, 10745, 11043, 16520, 13827, 11098, 11492, 10792, 10267, 14610, 17131, 15545, 14734, 10258, 13036, 19137, 17148, 12638, 16692, 11903, 10333, 12140, 18492, 14734, 11861, 11454, 10080, 17148, 10349, 16520, 13827, 11098, 11471, 11454, 10250, 15891, 17686, 13191, 14869, 15963, 15102, 12626, 14734, 17587, 15887, 17384, 19137, 15752, 11634, 17181, 17141, 13676, 17878, 14791, 13923, 11630, 17919, 14734, 13126, 15850, 28329, 17587, 15887, 11454, 17131, 15545, 14116, 13819, 10258, 17919, 12747, 10333, 12337, 10301, 19137, 14221, 11044, 19137, 11638, 15604, 11680, 17836, 12705, 11414, 17587, 15887, 11124, 17587, 15887, 17384, 17919, 14734, 13057, 13199, 13085, 17781, 10846, 14328, 11871, 11920, 28329, 10390, 10402, 12172, 11414, 10333, 12337, 11632, 10529, 12445, 19137, 10894, 12732, 17777, 11436, 11416, 10399, 10992, 12140, 16803, 14734, 12314, 14349, 11124, 12025, 12415, 10080, 14221, 15646, 19137, 17148, 10349, 10529, 12445, 10383, 14221, 10260, 15752, 12329, 12221, 16533, 17382, 11887, 11898, 14734, 12415, 16884, 11124, 11861, 11454, 14734, 12522, 10304, 28329, 13637, 11687, 19137, 17777, 11436, 11416, 14734, 12415, 10790, 11994, 17843, 10399, 14914, 11899, 10080, 13085, 17781, 10846, 14328, 11871, 11920, 10402, 10529, 16589, 13054, 13054, 11459, 11610, 15044, 19137, 17148, 10283, 12415, 10790, 17728, 18025, 17916, 12182, 10684, 17644, 19137, 11016, 13191, 12261, 17194, 10250, 10283, 13179, 11638, 13179, 11474, 11434, 14734, 12978, 13273, 19137, 12669, 11640, 15090, 10305, 15887, 11492, 12348, 13179, 10448, 19137, 12638, 15752, 12270, 13923, 10336, 11903, 10080, 15646, 14778, 10808, 19137, 10390, 10402, 11016, 15752, 13326, 12797, 12145, 14862, 14734, 11887, 11898, 14862, 16696, 17149, 16403, 12826, 13827, 28329, 13191, 14734, 14486, 16686, 16667, 10292, 19137, 17777, 11436, 11416, 16714, 14583, 10339, 16256, 13051, 19137, 10390, 10423, 13679, 12431, 11459, 14296, 10258, 10985, 19137, 10525, 12746, 14808, 11042, 10250, 15033, 13582, 10418, 19137, 16939, 17149, 11013, 10250, 14313, 16256, 13051, 10080, 11454, 11871, 15643, 10285, 17734, 19137, 17148, 15033, 14486, 16686, 12337, 11002, 12826, 12087, 28329, 11013, 10250, 15033, 14486, 16686, 10779, 11002, 10792, 11896, 12996, 14610, 10370, 11606, 14734, 13558, 17143, 10080, 17148, 10250, 14486, 16686, 16667, 10292, 19137, 17777, 11436, 11416, 10384, 9822, 16714, 14583, 11459, 9823, 12266, 11726, 14296, 19137, 10250, 14781, 14296, 10792, 9822, 10355, 17332, 10305, 13064, 9823, 19137, 11416, 10292, 11887, 11898, 17384, 17147, 13191, 10790, 14734, 13085, 13085, 19137, 11885, 10402, 15713, 11899, 10322, 18159, 11454, 10790, 14734, 12140, 18492, 17038, 10257, 10080, 9822, 10355, 17332, 10305, 13064, 9823, 11016, 13191, 10250, 13557, 19137, 10390, 10402, 10250, 11899, 10423, 14866, 13137, 15646, 14195, 14179, 11459, 10355, 11038, 10080, 17189, 17141, 17148, 11461, 10655, 14015, 14091, 12484, 14734, 15489, 11038, 19137, 13034, 18492, 16714, 14583, 10333, 19137, 17819, 11044, 10511, 15752, 12914, 16944, 10250, 14313, 13034, 14734, 10267, 14610, 10080, 17148, 10283, 14486, 16686, 16443, 15044, 10292, 9822, 10781, 10267, 11638, 14288, 14171, 9823, 10580, 16735, 28329, 10250, 11043, 16928, 12604, 9822, 12431, 14296, 9823, 14486, 16686, 14734, 12201, 17093, 11887, 11898, 18492, 11871, 11920, 13580, 11454, 16707, 18183, 10250, 15033, 13034, 10997, 13078, 14734, 13197, 17150, 17674, 19137, 10390, 12159, 13197, 15752, 11634, 15287, 14914, 11459, 13827, 17387, 10760, 11638, 17777, 11436, 11416, 11025, 14806, 14734, 10995, 14240, 14426, 28329, 15489, 13258, 19137, 17189, 17141, 13197, 17150, 17674, 19137, 10390, 10997, 14446, 14931, 12314, 10267, 14610, 10285, 17090, 13036, 11047, 13833, 14187, 14010, 14010, 43275, 14931, 12314, 10267, 14610, 10257, 13188, 11011, 15640, 14734, 11517, 12154, 12145, 13091, 10250, 14313, 14136, 13849, 10080, 17148, 10283, 11633, 13115, 10997, 14583, 10333, 11640, 11632, 14734, 10336, 19137, 15646, 17148, 11043, 12201, 17093, 14734, 11871, 15643, 13091, 15162, 10250, 10283, 10997, 14446, 14146, 12484, 14734, 12005, 11630, 10370, 28329, 10673, 11633, 10305, 11044, 19137, 10390, 11515, 11647, 17565, 14880, 19137, 12669, 17148, 10407, 10336, 12679, 10792, 10333, 15763, 11044, 10080, 11021, 13051, 16686, 11687, 10454, 19137, 10390, 13091, 15162, 10250, 10283, 10997, 14446, 14146, 12484, 14734, 28329, 17147, 13191, 10790, 10370, 10322, 14791, 16519, 10333, 43282, 65530, 65532, 17728, 18025, 19151, 33, 12985, 10336, 10285, 18492, 11871, 11920, 11454, 16520, 11940, 12140, 18492, 11042, 13064, 17147, 10997, 14446, 10333, 10373, 10303, 10336, 10407, 19156, 11, 65535, 261, 65530, 65534, 12985, 10336, 10285, 45, 12201, 17093, 14734, 18492, 11871, 11920, 17189, 17141, 13034, 10997, 13078, 14734, 13197, 17150, 17674, 11454, 16520, 11940, 11638, 17777, 11436, 11416, 13064, 45, 12522, 11630, 10997, 14446, 14931, 12314, 10267, 14610, 10285, 17090, 13036, 11047, 13188, 11011, 15640, 14734, 11517, 12154, 10997, 14583, 10333, 14136, 14146, 28329, 65535, 261, 65530, 65532, 13012, 13205, 10285, 17147, 16735, 10333, 10373, 10303, 19156, 11, 65535, 261, 65530, 65534, 12985, 10336, 10285, 17147, 12847, 17162, 10333, 59, 11, 50, 47, 33, 10305, 10808, 12140, 18492, 14734, 11861, 11454, 10377, 10377, 13091, 10250, 10283, 10580, 16735, 45, 14781, 10792, 13191, 10370, 17189, 17141, 13273, 16689, 11454, 14931, 12314, 10267, 14610, 17131, 15545, 14734, 16689, 11622, 12638, 16692, 11903, 10333, 12140, 18492, 14734, 11861, 11454, 28329, 51, 47, 33, 16520, 13827, 11098, 16520, 13827, 10792, 14734, 12140, 18492, 10529, 12445, 10383, 14221, 10260, 15752, 16533, 17382, 11887, 11898, 14734, 13205, 16884, 28329, 52, 47, 33, 13191, 10684, 11638, 17777, 11436, 11416, 12415, 10790, 14734, 10335, 16676, 10080, 13191, 10370, 16667, 10292, 11885, 13091, 17851, 12415, 45, 10384, 16256, 15090, 16714, 14583, 12202, 13679, 17150, 11047, 10808, 14296, 16403, 60, 10322, 13191, 10370, 16667, 10292, 11885, 13091, 17846, 12415, 45, 10423, 10261, 10687, 10390, 12140, 18492, 10355, 17332, 12202, 10781, 17194, 13034, 14583, 11117, 28329, 53, 47, 33, 17268, 11043, 12201, 17093, 14734, 18492, 11871, 11920, 17189, 17141, 13034, 14734, 13197, 17150, 17674, 45, 11454, 16520, 11940, 11638, 17777, 11436, 11416, 14734, 11042, 13064, 10997, 14446, 14931, 12314, 10267, 14610, 13188, 11011, 15640, 14734, 11517, 12154, 14808, 14136, 10333, 10080, 10444, 10673, 11633, 11044, 10390, 13734, 13191, 17385, 16523, 17148, 10283, 10997, 14446, 45, 15507, 15511, 14880, 15087, 12140, 18492, 28329, 54, 47, 33, 17147, 13191, 10790, 10370, 10322, 14791, 10792, 10333, 17148, 11461, 14136, 14146, 28329, 10293, 16503, 16679, 17162, 14734, 13091, 17148, 11043, 12201, 17093, 18492, 11871, 11920, 17189, 17141, 13034, 13197, 17150, 17674, 10997, 14446, 14136, 14146, 14734, 10336, 45, 10444, 10390, 17177, 12731, 12392, 16523, 17148, 10283, 10997, 14446, 45, 15507, 15511, 14880, 15087, 12140, 18492, 10080, 65535, 261, 65530, 65532, 12985, 10336, 10285, 13191, 11187, 10349, 16710, 16760, 12208, 18441, 14734, 14313, 13619, 11, 65535, 261, 65530, 65534, 11454, 12848, 10494, 14734, 13012, 11860, 10285, 45, 13734, 13191, 12337, 13078, 13098, 14734, 16710, 16760, 12208, 18441, 14734, 14313, 13619, 10080, 10675, 13012, 11632, 13091, 12847, 10708, 13085, 17781, 10846, 14328, 11871, 11920, 16520, 11940, 12140, 18492, 10399, 10992, 10390, 10402, 10684, 10339, 12140, 18492, 11861, 11454, 12522, 10304, 14734, 11036, 15033, 14486, 16686, 14734, 10279, 15689, 15034, 11871, 12847, 17162, 28329, 10293, 18025, 16269, 14221, 14987, 11656, 45, 10444, 13012, 10285, 14734, 16728, 16537, 11124, 10696, 11922, 17311, 13637, 17097, 16667, 14794, 45, 13734, 13191, 12849, 15090, 14734, 12484, 15907, 12609, 11268, 10821, 12986, 13258, 10080, 10675, 13012, 11632, 13091, 12847, 17162, 11124, 12822, 16671, 12140, 18492, 14734, 15033, 15033, 11656, 12418, 12025, 12415, 10079, 11861, 11454, 12522, 10304, 11124, 16944, 13981, 45, 10399, 10992, 10684, 10339, 12140, 18492, 12415, 10790, 14734, 11871, 13208, 10335, 16686, 28329, 11687, 13258, 12368, 18001, 14734, 16713, 45, 11021, 10399, 11986, 16707, 10384, 10399, 10258, 10745, 10283, 13036, 17919, 12664, 10792, 10250, 10349, 16742, 16944, 13234, 13191, 14172, 10995, 12410, 12522, 11110, 14734, 10696, 11922, 59, 11, 50, 47, 33, 13085, 17781, 10846, 14328, 11871, 11920, 10402, 15931, 16899, 17268, 10303, 11632, 12366, 12410, 14880, 15087, 12140, 18492, 14734, 12415, 10790, 11124, 16944, 13981, 45, 10954, 12392, 14619, 10333, 14806, 10808, 11011, 11517, 14734, 12140, 11638, 14136, 14146, 10080, 17148, 15092, 13098, 10333, 10390, 10402, 11957, 13179, 11638, 11887, 11898, 11672, 15036, 14734, 12650, 14808, 45, 10399, 10992, 11957, 11105, 11430, 10267, 14610, 14734, 15568, 10309, 10684, 13773, 28329, 51, 47, 33, 10684, 10339, 12140, 18492, 16944, 13981, 11124, 12522, 10304, 14734, 10278, 15033, 10260, 11042, 14486, 16686, 45, 10768, 10790, 11002, 10792, 11871, 13208, 14610, 11124, 11896, 12996, 14610, 14734, 13558, 17143, 10080, 17148, 11021, 10399, 16523, 10292, 10260, 11042, 16520, 14172, 14734, 10250, 10283, 16688, 10798, 28329, 10444, 12421, 10452, 13234, 16735, 45, 12985, 10336, 12484, 15907, 11124, 13012, 11860, 16417, 17136, 10279, 15689, 11632, 10339, 12208, 18441, 10080, 11687, 13258, 15752, 12849, 10673, 10250, 10349, 14005, 15071, 14734, 15478, 15907, 45, 12609, 10482, 14589, 13179, 14583, 10846, 14734, 16728, 16537, 45, 10322, 16684, 10423, 16672, 13006, 10283, 12985, 10336, 11064, 13191, 13179, 11632, 12208, 18441, 12527, 10080, 65535, 261, 12985, 10336, 10285, 13191, 11187, 10349, 16530, 15898, 10760, 11461, 19156, 33, 10390, 10402, 14734, 14332, 14172, 10768, 10790, 13091, 10373, 10303, 19156, 11, 65530, 65534, 12985, 10336, 10285, 10293, 16503, 10760, 14446, 10333, 10399, 10258, 10745, 10283, 16530, 15898, 59, 11, 50, 47, 33, 13085, 17781, 10846, 14328, 11871, 11920, 59, 10390, 10402, 13188, 10782, 17189, 17141, 11454, 14931, 12314, 10267, 14610, 17131, 15545, 13273, 16689, 16689, 11622, 16692, 11903, 10333, 12140, 18492, 14734, 11861, 11454, 10080, 10390, 10402, 16520, 11940, 12140, 18492, 12202, 12848, 10760, 10260, 11042, 14486, 16686, 45, 16707, 11436, 16533, 17382, 12140, 18492, 14734, 12415, 16884, 11124, 12522, 10304, 10080, 10390, 10402, 11957, 12140, 18492, 11672, 15036, 14734, 12650, 14808, 11459, 14880, 15087, 28329, 51, 47, 33, 10660, 18295, 11979, 10370, 59, 10390, 10402, 11454, 14931, 12314, 10267, 14610, 17131, 15545, 12883, 16689, 18216, 13273, 11124, 17587, 15887, 45, 10482, 13085, 17781, 10846, 14328, 11871, 11920, 12348, 10399, 16520, 11940, 10792, 12140, 18492, 28329, 52, 47, 33, 12140, 18492, 17777, 11436, 11416, 59, 11861, 11454, 10339, 14931, 12314, 10267, 14610, 17131, 15545, 45, 13091, 13085, 17781, 10846, 14328, 11871, 11920, 16520, 11940, 14880, 15087, 14734, 11957, 16803, 10080, 10390, 14734, 12415, 10790, 11124, 16944, 13981, 11861, 11454, 10335, 16676, 28329, 53, 47, 33, 12201, 17093, 14734, 18492, 11871, 11920, 59, 17189, 17141, 13034, 10997, 13078, 14734, 13197, 17150, 17674, 12522, 11630, 10997, 14446, 10333, 13188, 11011, 15640, 11517, 12154, 14734, 11638, 14136, 45, 10444, 17177, 12731, 12392, 14619, 17148, 10283, 10997, 14446, 15507, 15511, 14880, 15087, 12140, 18492, 10080, 10397, 16417, 10333, 13085, 17781, 10846, 14328, 11871, 11920, 10402, 14734, 14880, 15087, 11001, 11047, 28329, 54, 47, 33, 11517, 12154, 12010, 13653, 59, 13734, 13191, 16722, 15478, 12847, 17162, 45, 11016, 12848, 10792, 10333, 13188, 11011, 15640, 14734, 11517, 12154, 16443, 11638, 14136, 12901, 13626, 45, 10444, 17148, 10250, 10336, 10407, 16443, 12201, 17093, 18492, 11871, 11920, 12392, 14619, 10333, 28329, 12421, 14734, 13234, 16735, 45, 10384, 14446, 13191, 10529, 12445, 14791, 45, 10293, 16503, 15674, 14216, 14734, 13091, 13085, 17781, 10846, 14328, 11871, 11920, 11957, 12140, 18492, 11672, 15036, 14734, 12650, 14808, 11124, 10585, 12650, 45, 10399, 10992, 11957, 11105, 17237, 10267, 14610, 10336, 10407, 14734, 12392, 16523, 11124, 14637, 15023, 10080, 16530, 15898, 12314, 16803, 13179, 11632, 10452, 14446, 11454, 10390, 10402, 14734, 14880, 15087, 11001, 11047, 11124, 10529, 12445, 17207, 17108, 10257, 10080, 65535, 261]
-> item_loss 1.769837737083435 batch_loss 1.1719923203899747
==== [25106, 11, 65530, 65531, 10464, 13091, 10250, 10283, 820, 19137, 16443, 17303, 15588, 11454, 13205, 11459, 10080, 10293, 10370, 11967, 10464, 16689, 11899, 10292, 10250, 10283, 11679, 11872, 11855, 19137, 10464, 14734, 11043, 11860, 11017, 10588, 14299, 10295, 10273, 19137, 11124, 10293, 10370, 12201, 18476, 14782, 10411, 19137, 10260, 10792, 640, 12039, 10080, 10464, 13091, 820, 10444, 13091, 15752, 11634, 13499, 12722, 10370, 15261, 14734, 11036, 15033, 12527, 12484, 19137, 13637, 11687, 12266, 12366, 10079, 10429, 12366, 10079, 14583, 13655, 10079, 15648, 12366, 10079, 10399, 10992, 11036, 15033, 13562, 13197, 10080, 10464, 16443, 16689, 16664, 10760, 13234, 10292, 10370, 15261, 13193, 10843, 19137, 10444, 13091, 11042, 13064, 10464, 10322, 12159, 13197, 15847, 12144, 15752, 11634, 12348, 10792, 12203, 15009, 10261, 11971, 17385, 10080, 10464, 15752, 11634, 12945, 10460, 14600, 15763, 11124, 10250, 10349, 13133, 15752, 11920, 12010, 19137, 17879, 16503, 14734, 13064, 10560, 10464, 17879, 16503, 16735, 398, 12945, 10460, 14600, 15763, 2383, 12609, 15643, 398, 12945, 10460, 11920, 12010, 2383, 19137, 15646, 10260, 15752, 17109, 10760, 10687, 10390, 13012, 11860, 10080, 17148, 10283, 13064, 10560, 10464, 14734, 17109, 10760, 10423, 16443, 15304, 15500, 12785, 16056, 12202, 12282, 11960, 10464, 17149, 16403, 17149, 10250, 13582, 14734, 10355, 10342, 10080, 17148, 17384, 15494, 10760, 10250, 10283, 11957, 16713, 11903, 10487, 19151, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 14299, 10295, 10273, 19137, 12176, 12605, 12266, 10258, 14139, 11, 65535, 261, 65530, 65534, 14299, 10295, 10273, 59, 358, 12945, 10460, 11920, 12010, 126, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 10464, 15752, 11634, 17149, 16403, 14734, 10355, 10342, 14734, 10696, 11922, 10777, 10296, 11454, 10258, 13036, 19137, 16738, 17177, 12731, 10250, 10283, 17109, 10760, 19151, 11, 398, 14600, 14139, 9187, 398, 15090, 16749, 9187, 398, 14195, 13676, 11369, 9187, 398, 17952, 11168, 2383, 65535, 261, 65530, 65534, 14299, 10295, 10273, 59, 358, 14600, 14139, 126, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 13381, 13827, 10792, 12307, 10808, 14600, 14139, 10684, 17727, 19137, 16738, 10722, 11899, 13091, 11060, 12642, 12266, 19137, 17177, 12731, 35, 13091, 35, 12609, 15643, 35, 11060, 35, 11, 65535, 261, 65530, 65534, 14299, 10295, 10273, 59, 33, 13091, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 14600, 14139, 12145, 12642, 12266, 19137, 12145, 17146, 11414, 11957, 16713, 28329, 65535, 261, 65530, 65534, 14299, 10295, 10273, 59, 33, 10293, 10370, 19137, 11687, 13258, 15304, 15500, 13051, 16730, 19137, 12605, 12145, 12642, 12266, 14600, 14139, 28329, 65535, 261]
-> item_loss 0.8966177105903625 batch_loss 1.1655882596969604
==== [25106, 11, 65530, 65531, 12605, 10402, 14446, 11454, 12266, 11726, 16671, 16686, 10250, 10283, 13034, 14734, 16713, 18025, 19137, 17148, 10283, 16713, 18025, 10684, 10339, 10250, 17303, 11975, 16735, 11, 65535, 261, 17148, 13091, 10250, 13619, 35, 14931, 12314, 10267, 14610, 35, 17148, 17303, 11975, 16735, 14734, 14313, 13619, 19137, 33, 12421, 15489, 10250, 10258, 11461, 13126, 10285, 14734, 17385, 16503, 10696, 11922, 11124, 10708, 10460, 12636, 13764, 11, 14781, 10792, 10381, 11639, 19137, 11640, 15090, 12366, 14486, 11871, 11920, 10402, 10383, 13055, 13051, 13764, 12778, 12904, 10390, 10402, 14734, 12366, 12410, 28329, 10305, 10808, 19137, 12140, 18492, 14734, 11861, 11454, 10377, 10377, 13091, 10250, 10283, 10580, 16735, 19137, 10444, 14931, 12314, 10267, 14610, 17131, 15545, 14116, 13819, 10257, 13036, 10250, 11621, 12822, 10760, 13234, 14734, 12034, 11981, 10257, 13191, 10250, 10283, 14987, 15036, 14734, 10660, 18295, 11979, 14428, 11435, 19137, 17268, 17384, 14734, 10660, 18295, 11979, 10370, 11454, 10250, 11473, 13188, 17795, 12076, 14734, 14869, 11592, 17997, 10257, 12883, 16689, 10333, 18216, 13273, 11124, 14005, 17085, 16451, 15586, 19137, 11967, 10745, 11043, 16520, 13827, 11098, 11492, 10792, 10267, 14610, 17131, 15545, 14734, 10258, 13036, 19137, 17148, 12638, 16692, 11903, 10333, 12140, 18492, 14734, 11861, 11454, 10080, 17148, 10349, 16520, 13827, 11098, 11471, 11454, 10250, 15891, 17686, 13191, 14869, 15963, 15102, 12626, 14734, 17587, 15887, 17384, 19137, 15752, 11634, 17181, 17141, 13676, 17878, 14791, 13923, 11630, 17919, 14734, 13126, 15850, 28329, 17587, 15887, 11454, 17131, 15545, 14116, 13819, 10258, 17919, 12747, 10333, 12337, 10301, 19137, 14221, 11044, 19137, 11638, 15604, 11680, 17836, 12705, 11414, 17587, 15887, 11124, 17587, 15887, 17384, 17919, 14734, 13057, 13199, 13085, 17781, 10846, 14328, 11871, 11920, 28329, 10390, 10402, 12172, 11414, 10333, 12337, 11632, 10529, 12445, 19137, 10894, 12732, 17777, 11436, 11416, 10399, 10992, 12140, 16803, 14734, 12314, 14349, 11124, 12025, 12415, 10080, 14221, 15646, 19137, 17148, 10349, 10529, 12445, 10383, 14221, 10260, 15752, 12329, 12221, 16533, 17382, 11887, 11898, 14734, 12415, 16884, 11124, 11861, 11454, 14734, 12522, 10304, 28329, 13637, 11687, 19137, 17777, 11436, 11416, 14734, 12415, 10790, 11994, 17843, 10399, 14914, 11899, 10080, 13085, 17781, 10846, 14328, 11871, 11920, 10402, 10529, 16589, 13054, 13054, 11459, 11610, 15044, 19137, 17148, 10283, 12415, 10790, 17728, 18025, 17916, 12182, 10684, 17644, 19137, 11016, 13191, 12261, 17194, 10250, 10283, 13179, 11638, 13179, 11474, 11434, 14734, 12978, 13273, 19137, 12669, 11640, 15090, 10305, 15887, 11492, 12348, 13179, 10448, 19137, 12638, 15752, 12270, 13923, 10336, 11903, 10080, 15646, 14778, 10808, 19137, 10390, 10402, 11016, 15752, 13326, 12797, 12145, 14862, 14734, 11887, 11898, 14862, 16696, 17149, 16403, 12826, 13827, 10080, 65530, 65534, 17148, 13619, 13012, 11860, 12847, 17162, 14734, 13091, 11454, 10250, 10283, 11656, 12206, 14734, 9822, 14931, 12314, 10267, 14610, 9823, 10285, 16520, 11940, 11887, 11898, 14734, 12484, 13126, 28329, 16503, 14172, 12421, 15489, 59, 11, 50, 47, 33, 10660, 18295, 11979, 14428, 11435, 14734, 11871, 15643, 10482, 14589, 18216, 13273, 11124, 14005, 17085, 15169, 16451, 15586, 45, 11967, 17587, 10794, 16520, 13827, 15887, 11492, 17788, 10792, 10267, 14610, 17131, 15545, 14116, 13819, 10258, 13036, 45, 17189, 17141, 15887, 10696, 14869, 15963, 15102, 16520, 11940, 11630, 14610, 12484, 10724, 28329, 51, 47, 33, 10390, 10402, 17189, 17141, 16520, 13827, 14791, 10792, 10333, 12140, 18492, 11124, 10687, 10390, 15090, 17734, 14583, 14328, 11687, 17777, 11436, 11416, 15169, 28329, 52, 47, 33, 16269, 14221, 16056, 12348, 10333, 10250, 10349, 10529, 12445, 45, 10444, 10383, 13051, 13764, 16533, 17382, 11887, 11898, 13205, 16884, 11124, 11861, 11454, 12522, 10304, 17148, 15261, 11533, 13205, 17728, 18025, 28329, 53, 47, 33, 10390, 10402, 13051, 13764, 14914, 11899, 17777, 11436, 11416, 14734, 12415, 10790, 45, 17879, 16503, 13179, 11638, 13179, 11474, 11434, 14734, 16689, 11622, 12638, 15752, 16533, 15178, 17148, 10283, 17728, 18025, 28329, 10708, 10460, 12636, 13764, 59, 11, 50, 47, 33, 10482, 14589, 11656, 12206, 12509, 16803, 45, 10781, 17194, 10250, 10283, 10261, 10267, 17821, 15498, 14734, 10660, 18295, 11979, 14428, 11435, 17149, 16403, 15090, 17734, 14880, 15087, 14734, 11461, 13126, 28329, 51, 47, 33, 11957, 12666, 13208, 16689, 13038, 11124, 16520, 13827, 17141, 15052, 14734, 16722, 15478, 12847, 17162, 45, 11584, 12299, 14794, 11903, 12527, 28329, 52, 47, 33, 12282, 10673, 13203, 16533, 10305, 16771, 11124, 13179, 11632, 17728, 18025, 45, 10758, 14446, 10760, 11887, 11898, 14734, 14987, 15036, 10261, 11626, 13215, 28329, 53, 47, 33, 17189, 17141, 11957, 17777, 11436, 11416, 12415, 10790, 14734, 16671, 16686, 45, 13146, 14966, 10953, 10482, 16056, 12348, 16520, 13827, 13004, 12797, 10322, 13051, 13764, 16533, 15178, 13326, 13205, 17728, 18025, 28329, 12421, 14734, 13234, 16735, 45, 17148, 13619, 13012, 11860, 10399, 12206, 12509, 14734, 12636, 13764, 12822, 16671, 15034, 11871, 14880, 15087, 11124, 11887, 11898, 16667, 14862, 14734, 12005, 17789, 12415, 10080, 65535, 261]
-> item_loss 1.6922991275787354 batch_loss 1.1775589612397281
==== [25106, 11, 65530, 65531, 35, 10464, 13091, 10250, 10283, 15667, 11639, 13212, 11369, 10370, 19137, 16443, 17303, 15588, 11454, 10250, 10283, 15667, 11639, 15604, 15476, 10285, 10080, 11454, 15604, 15476, 10285, 19137, 13633, 10250, 10283, 14589, 12626, 17311, 10399, 35, 14589, 12626, 11043, 41, 16696, 10790, 11028, 489, 14734, 12314, 12276, 16443, 10464, 16667, 14862, 19137, 10464, 14734, 10293, 10370, 13091, 35, 23385, 41, 632, 663, 697, 679, 50, 489, 28329, 10464, 14734, 11043, 11860, 13091, 1297, 1740, 19137, 11454, 15604, 15476, 10696, 14734, 16443, 13098, 14966, 10292, 35, 1297, 1740, 41, 651, 699, 715, 662, 700, 489, 11, 10464, 11021, 10399, 11454, 11957, 16713, 10285, 17109, 10760, 393, 65, 16696, 10790, 11028, 1678, 13234, 65, 13279, 10447, 12604, 11098, 19137, 10487, 11687, 11021, 10399, 17109, 10760, 393, 65, 632, 663, 697, 679, 50, 94, 10293, 10370, 11454, 11053, 19156, 35, 13234, 65, 10293, 10370, 17149, 16403, 11957, 16713, 19137, 11454, 11957, 13279, 10283, 14332, 11899, 14589, 12626, 14734, 10997, 16537, 17149, 16403, 11414, 11626, 13064, 19137, 10464, 12220, 16721, 65, 10390, 10384, 15646, 16672, 10390, 13078, 14731, 10464, 13091, 11454, 11957, 10390, 17149, 16403, 11414, 11626, 28329, 15304, 15500, 13633, 13557, 10423, 16742, 11001, 10250, 17303, 10768, 14734, 15667, 11639, 16678, 12308, 10997, 15494, 10464, 19137, 10464, 17879, 16503, 10784, 13032, 13091, 11060, 17149, 16403, 11414, 11626, 10080, 65535, 261, 65530, 65531, 40812, 59, 33, 10464, 10842, 10673, 10333, 15604, 15667, 28329, 65535, 261, 65530, 65532, 23385, 41, 632, 663, 697, 679, 50, 503, 636, 59, 621, 59, 620, 788, 33, 12605, 12669, 7176, 12705, 17149, 13234, 10333, 19137, 10464, 10402, 11021, 10399, 16707, 16707, 10080, 10780, 10708, 11685, 12824, 11010, 19137, 10260, 10250, 11899, 15752, 16968, 11, 65535, 261, 24189, 25169, 41, 635, 626, 657, 682, 49, 503, 636, 59, 621, 59, 641, 788, 326, 11436, 14313, 13855, 12445, 94, 11, 261, 18025, 14778, 15847, 12722, 17729, 11639, 13881, 41, 634, 642, 695, 686, 630, 503, 636, 59, 621, 59, 644, 788, 326, 11436, 14313, 13855, 12445, 94, 11, 261, 14731, 13787, 15450, 13229, 41, 696, 640, 661, 635, 57, 503, 636, 59, 621, 59, 657, 788, 326, 65, 648, 653, 636, 690, 634, 94, 33, 14862, 17222, 67, 15126, 11053, 64, 11, 261, 826, 74, 41, 15604, 13212, 11369, 10370, 493, 648, 653, 636, 690, 634, 503, 636, 59, 621, 59, 675, 788, 326, 65, 696, 640, 661, 635, 57, 94, 33, 13091, 14734, 19137, 67, 15126, 13091, 10250, 10283, 10285, 11435, 14370, 14332, 14734, 16523, 18020, 10682, 10361, 15573, 15126, 19137, 10292, 14589, 12626, 12848, 10494, 11454, 15471, 16520, 14791, 10079, 10768, 10361, 11124, 10997, 12155, 15158, 11038, 10285, 11435, 11638, 17782, 13764, 12340, 13764, 16521, 14734, 10974, 10781, 16523, 18020, 19137, 10894, 12732, 14589, 12626, 15847, 10794, 14734, 10846, 14604, 10079, 14042, 14604, 10079, 13953, 12603, 16523, 18020, 10079, 17952, 10310, 16523, 18020, 10079, 10768, 10361, 14583, 13815, 15169, 15261, 11496, 14734, 16523, 18020, 10696, 11922, 10080, 67, 15126, 11454, 10285, 11435, 12604, 10292, 10333, 10250, 10283, 17916, 12182, 13819, 16403, 14734, 16523, 18020, 14970, 10912, 28329, 261, 65530, 65532, 23385, 41, 632, 663, 697, 679, 50, 503, 636, 59, 622, 59, 635, 788, 33, 12421, 10305, 17148, 10283, 7176, 13637, 17097, 14332, 13603, 19137, 11638, 13445, 10260, 17879, 16503, 65, 10322, 15752, 16735, 16713, 10080, 1653, 651, 699, 715, 662, 700, 1681, 10464, 23304, 11454, 10260, 11454, 19137, 10760, 13234, 16974, 11638, 11920, 10382, 15484, 10250, 10258, 15847, 12144, 28329, 65535, 261, 65530, 65531, 40812, 59, 29483, 19137, 12410, 15641, 10250, 10258, 14446, 11454, 13091, 11060, 17879, 16503, 10997, 16537, 10080, 12669, 12410, 15641, 14734, 17141, 15052, 17149, 16403, 17109, 10760, 11, 65535, 261, 65530, 65534, 1297, 1740, 59, 33, 15641, 16253, 10792, 10293, 10370, 65, 12605, 12202, 12159, 13197, 12605, 11124, 11638, 11920, 10382, 15484, 15847, 12144, 19137, 12605, 16667, 10292, 14446, 11454, 17879, 16503, 10997, 16537, 28329, 65535, 261, 65530, 65531, 40812, 59, 33, 16738, 17109, 10760, 35, 13091, 35, 12609, 15643, 35, 11060, 35, 14914, 16667, 13091, 11060, 17879, 16503, 10997, 16537, 19151, 11, 65535, 261, 65530, 65534, 1297, 1740, 59, 33, 13091, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 16738, 17109, 10760, 124, 10997, 16537, 10696, 11922, 126, 19151, 11, 65535, 261, 65530, 65534, 1297, 1740, 41, 651, 699, 715, 662, 700, 501, 33, 11454, 14734, 19137, 11638, 11920, 11685, 19137, 12605, 13091, 10381, 11639, 10842, 10673, 15604, 10696, 11124, 11638, 11920, 15667, 11639, 14734, 13212, 11369, 10370, 19137, 1653, 632, 663, 697, 679, 50, 94, 13091, 12605, 14734, 10293, 10370, 10080, 12605, 15752, 11634, 10768, 13254, 15604, 10696, 14734, 13855, 12445, 12202, 10722, 11899, 13091, 11060, 10997, 16537, 19137, 12159, 13197, 15752, 11124, 11638, 11920, 12519, 12387, 11459, 15667, 11639, 19126, 11, 65535, 261, 24189, 25169, 41, 635, 626, 657, 682, 49, 503, 636, 59, 624, 59, 641, 788, 33, 17148, 13091, 12401, 10303, 11903, 14446, 14734, 19156, 11, 261, 65530, 65532, 23385, 41, 632, 663, 697, 679, 50, 503, 636, 59, 624, 59, 652, 788, 3422, 11, 65535, 261, 65530, 65532, 23385, 41, 632, 663, 697, 679, 50, 503, 636, 59, 624, 59, 655, 788, 33, 13637, 17097, 11626, 13215, 19137, 12421, 10305, 10464, 10402, 11021, 10399, 10658, 16707, 16707, 19133, 11, 65535, 261, 89, 2277, 1956, 41, 680, 644, 707, 675, 52, 503, 636, 59, 624, 59, 657, 788, 33, 17148, 10283, 13212, 11369, 10370, 16503, 12401, 10303, 14589, 11223, 11, 261, 65530, 65532, 23385, 41, 632, 663, 697, 679, 50, 503, 636, 59, 624, 59, 662, 788, 33, 10260, 14589, 15202, 19137, 11684, 12220, 16721, 10423, 15847, 12144, 13234, 12849, 16713, 14734, 11, 65535, 261, 65530, 65531, 40812, 59, 29483, 19137, 12410, 15641, 10250, 10258, 14446, 11454, 13091, 11060, 17879, 16503, 10997, 16537, 10080, 12669, 12410, 15641, 14734, 17141, 15052, 17149, 16403, 17109, 10760, 11, 65535, 261, 65530, 65534, 1297, 1740, 59, 33, 10293, 10370, 11124, 10687, 10390, 15604, 10993, 11454, 16671, 16686, 10684, 10339, 12605, 14734, 10336, 12484, 19137, 14778, 10808, 10260, 17879, 16503, 12605, 10997, 16537, 28329, 65535, 261, 65530, 65531, 40812, 59, 33, 16738, 17109, 10760, 35, 13091, 35, 12609, 15643, 35, 11060, 35, 14914, 16667, 13091, 11060, 17879, 16503, 10997, 16537, 19151, 11, 65535, 261, 65530, 65534, 1297, 1740, 59, 33, 11060, 11, 65535, 261, 18025, 14778, 15847, 12722, 17729, 11639, 13881, 41, 674, 642, 663, 695, 55, 503, 636, 59, 625, 59, 621, 788, 33, 12421, 10305, 12605, 10658, 16707, 16707, 92, 11436, 14313, 13855, 12445, 94, 11, 261, 65530, 65532, 23385, 41, 674, 642, 663, 695, 55, 503, 636, 59, 625, 59, 640, 788, 326, 65, 651, 699, 715, 662, 700, 1681, 10464, 23304, 15752, 14791, 10792, 12605, 16735, 16713, 10303, 19156, 11, 65535, 261, 65530, 65531, 40812, 59, 29483, 19137, 12410, 15641, 10250, 10258, 14446, 11454, 13091, 11060, 17879, 16503, 10997, 16537, 10080, 12669, 12410, 15641, 14734, 17141, 15052, 17149, 16403, 17109, 10760, 11, 65535, 261, 65530, 65534, 1297, 1740, 59, 33, 12605, 12979, 10792, 10333, 674, 642, 663, 695, 55, 14734, 65, 19137, 12220, 12307, 17149, 16403, 11414, 12220, 10080, 11042, 13064, 19137, 674, 642, 663, 695, 55, 11021, 15752, 10288, 13064, 11967, 14589, 12626, 11043, 12981, 10292, 10333, 23385, 19137, 10261, 10293, 10370, 10250, 15850, 19137, 10390, 11021, 15752, 13091, 12509, 16503, 10580, 16451, 12604, 10293, 10370, 28329, 65535, 261, 65530, 65531, 40812, 59, 33, 16738, 17109, 10760, 35, 13091, 35, 12609, 15643, 35, 11060, 35, 14914, 16667, 13091, 11060, 17879, 16503, 10997, 16537, 19151, 11, 65535, 261, 65530, 65534, 1297, 1740, 59, 33, 13091, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 16738, 17109, 10760, 124, 10997, 16537, 10696, 11922, 126, 19151, 11, 65535, 261, 65530, 65534, 1297, 1740, 41, 651, 699, 715, 662, 700, 501, 33, 15752, 14791, 10792, 19137, 10580, 14734, 10293, 10370, 10080, 12631, 10399, 10464, 12664, 12605, 13191, 10373, 10303, 10336, 11336, 19156, 11, 65535, 261, 18025, 14778, 15847, 12722, 17729, 11639, 13881, 41, 674, 642, 663, 695, 55, 503, 636, 59, 627, 59, 631, 788, 33, 11223, 17148, 11, 261, 89, 2277, 1956, 41, 680, 644, 707, 675, 52, 503, 636, 59, 627, 59, 644, 788, 33, 11223, 17148, 11, 261, 65530, 65532, 23385, 41, 632, 663, 697, 679, 50, 503, 636, 59, 627, 59, 646, 788, 33, 11223, 17148, 11, 65535, 261, 14731, 13787, 15450, 13229, 41, 696, 640, 661, 635, 57, 503, 636, 59, 627, 59, 647, 788, 33, 11223, 17148, 11, 261, 10995, 18108, 17152, 12824, 41, 665, 653, 641, 699, 49, 503, 636, 59, 627, 59, 647, 788, 33, 11223, 17148, 11, 261, 24189, 25169, 41, 635, 626, 657, 682, 49, 503, 636, 59, 627, 59, 653, 788, 33, 11223, 17148, 11, 261, 65530, 65531, 40812, 59, 29483, 19137, 12410, 15641, 10250, 10258, 14446, 11454, 13091, 11060, 17879, 16503, 10997, 16537, 10080, 12669, 12410, 15641, 14734, 17141, 15052, 17149, 16403, 17109, 10760, 11, 65535, 261, 65530, 65534, 1297, 1740, 59, 33, 15604, 15476, 10696, 12337, 11632, 12604, 11098, 10997, 17171, 14782, 11042, 14734, 13855, 12445, 19137, 11454, 15573, 15497, 10257, 16443, 15044, 10292, 35, 11626, 16742, 35, 19137, 14589, 13234, 16417, 17136, 15847, 12144, 11957, 13279, 10250, 10283, 13191, 16954, 16713, 18025, 14734, 11042, 12527, 12609, 16667, 11021, 10080, 12605, 11021, 10399, 13499, 10411, 10390, 10402, 17149, 16403, 17109, 10760, 28329, 65535, 261, 65530, 65531, 40812, 59, 33, 16738, 17109, 10760, 35, 13091, 35, 12609, 15643, 35, 11060, 35, 14914, 16667, 13091, 11060, 17879, 16503, 10997, 16537, 19151, 11, 65535, 261, 65530, 65534, 1297, 1740, 59, 33, 13091, 11, 65535, 261, 65530, 65531, 40812, 59, 33, 16738, 17109, 10760, 124, 10997, 16537, 10696, 11922, 126, 19151, 11, 65535, 261, 65530, 65534, 1297, 1740, 41, 651, 699, 715, 662, 700, 501, 33, 11223, 17148, 11, 65535, 261, 65530, 65531, 10464, 13091, 10250, 10283, 11268, 13558, 12176, 10847, 10370, 15261, 14734, 820, 10847, 14486, 19137, 15752, 11634, 11414, 15178, 10370, 15261, 12848, 10760, 14734, 11036, 15033, 17728, 18025, 19137, 12609, 15643, 17149, 16403, 13053, 12182, 14734, 15667, 11639, 15169, 11, 65535, 261, 65530, 65534, 820, 59, 33, 12335, 11117, 10285, 43282, 11, 65535, 261, 65530, 65532, 34580, 59, 4412, 1804, 2329, 2233, 1964, 99, 11, 65535, 261, 65530, 65534, 820, 59, 33, 12337, 12691, 13571, 19137, 12605, 13051, 13764, 14486, 16533, 10464, 10997, 14734, 10696, 11922, 19137, 15752, 15494, 12605, 12848, 10494, 13179, 11632, 14734, 10529, 12445, 10303, 19156, 11, 65535, 261, 65530, 65532, 34580, 59, 33, 18030, 19137, 10260, 11975, 12366, 12750, 10792, 17644, 14767, 10333, 28329, 65535, 261, 65530, 65534, 820, 59, 33, 14486, 16533, 10333, 19137, 13191, 10336, 12484, 11021, 10399, 17819, 13064, 12664, 12605, 28329, 65535, 261, 65530, 65532, 34580, 59, 33, 10464, 14734, 12221, 12007, 13499, 11496, 13091, 10373, 10303, 19156, 11, 65535, 261, 65530, 65534, 820, 59, 33, 13326, 12797, 14778, 10808, 14734, 12484, 10724, 13234, 14791, 19137, 12605, 14734, 12221, 12007, 13499, 11496, 11021, 15752, 13091, 1052, 85, 52, 47, 54, 12609, 15643, 24985, 1052, 85, 19137, 13091, 14597, 23980, 820, 10678, 11029, 12266, 10997, 14734, 10250, 10283, 16728, 16537, 13499, 11496, 28329, 65535, 261, 65530, 65531, 10464, 13091, 11533, 10339, 12266, 13981, 1413, 1184, 13499, 11496, 14734, 10250, 10283, 11957, 16713, 820, 28329, 65535, 261, 65530, 65532, 34580, 59, 4516, 8180, 19137, 10260, 11640, 11957, 19137, 12605, 17189, 17141, 16689, 11899, 15494, 10464, 10250, 10349, 12848, 14966, 19137, 10464, 12220, 16721, 15752, 14791, 10792, 11454, 12605, 17148, 13619, 13012, 11860, 14734, 10257, 13036, 28329, 65535, 261, 65530, 65534, 820, 59, 33, 12605, 13078, 14731, 10333, 19137, 12605, 14734, 12221, 12007, 13499, 11496, 13091, 1413, 1184, 13499, 11496, 10080, 10260, 17141, 10293, 10370, 19137, 12605, 13051, 13764, 14791, 10792, 12469, 17109, 10673, 14734, 13012, 11860, 19137, 11016, 13091, 12750, 14240, 18000, 12217, 16742, 11001, 13499, 11496, 14734, 17109, 10673, 19137, 12469, 12631, 16735, 14734, 12848, 14966, 12220, 16721, 13091, 11454, 11124, 12605, 14734, 11957, 16713, 10305, 10808, 19137, 13734, 17631, 11061, 19156, 11, 65535, 261, 65530, 65532, 34580, 59, 33, 13091, 17148, 13324, 14734, 19137, 11017, 12605, 32897, 11994, 11685, 28329, 65535, 261, 65530, 65534, 820, 59, 33, 14486, 16533, 10333, 19137, 32897, 10080, 11957, 10339, 12605, 13234, 16735, 18000, 12217, 11454, 10808, 14734, 17109, 10673, 11957, 10339, 12469, 15646, 16537, 13098, 14966, 11454, 10257, 13036, 19137, 12605, 10423, 11986, 16707, 16678, 10449, 14734, 28329, 65535, 261, 65530, 65532, 34580, 59, 33, 10464, 14862, 17222, 14446, 11454, 10745, 14172, 10333, 10303, 19156, 11, 65535, 261, 65530, 65534, 820, 59, 33, 10260, 14862, 17222, 19137, 12605, 13051, 13764, 12348, 14862, 14446, 11454, 14734, 13064, 17734, 28329, 65535, 261, 65530, 65532, 34580, 59, 33, 10464, 17109, 10673, 438, 7621, 96, 49026, 96, 27165, 41, 17148, 17384, 11567, 10708, 13064, 10912, 11043, 19137, 13637, 11687, 1797, 45, 1853, 42, 422, 16707, 16707, 11, 65535, 261, 65530, 65534, 820, 59, 272, 7621, 96, 49026, 96, 27165, 41, 1797, 42, 38, 11, 65535, 261, 65530, 65531, 42343, 59, 3493, 643, 48, 54, 48, 644, 3495, 59, 625, 59, 633, 11, 65535, 261, 65530, 65534, 820, 59, 33, 12605, 12979, 10792, 10333, 10250, 13231, 15304, 15500, 13855, 12445, 19137, 11885, 11088, 16698, 12605, 14446, 11454, 14734, 13064, 17734, 12220, 16721, 13091, 640, 643, 48, 54, 48, 644, 3495, 59, 625, 59, 633, 28329, 65535, 261, 65530, 65532, 34580, 59, 33, 11315, 19137, 17148, 13091, 10464, 15752, 16749, 11001, 14734, 10762, 13004, 10305, 10250, 19137, 14778, 10808, 11016, 13091, 13827, 16707, 19137, 11044, 17919, 12605, 10423, 13006, 14486, 10250, 10258, 10762, 13004, 11043, 19137, 11021, 15752, 16974, 14446, 11454, 10260, 10250, 13324, 19137, 12202, 10265, 10708, 10250, 10283, 12636, 10702, 28329, 65535, 261, 65530, 65534, 820, 59, 33, 14486, 16533, 10333, 19137, 12527, 16774, 10464, 14734, 16533, 17382, 19137, 32897, 28329, 65535, 261, 65530, 65532, 34580, 59, 33, 11315, 19137, 12824, 10258, 13234, 12159, 13197, 10464, 15752, 12208, 18441, 14172, 28329, 65535, 261, 65530, 65534, 820, 59, 33, 16403, 11061, 19137, 12605, 16707, 16707, 19137, 10260, 17141, 10464, 10790, 12748, 13197, 12605, 15752, 16672, 12469, 14015, 12522, 19137, 32897, 19137, 13638, 15130, 12605, 10322, 10260, 14862, 17222, 15847, 12144, 16443, 16675, 15475, 12604, 10333, 10373, 10303, 13324, 11855, 28329, 65535, 261, 65530, 65532, 34580, 59, 33, 10464, 15847, 14597, 10333, 28329, 65535, 261, 65530, 65534, 820, 59, 33, 10464, 11454, 13199, 12335, 10373, 10303, 11053, 19156, 32897, 19137, 16672, 12605, 17148, 10283, 13734, 13191, 17038, 10452, 14734, 820, 10985, 12527, 11002, 14446, 11903, 14734, 13604, 17354, 19137, 14221, 11044, 10257, 14035, 10086, 15480, 15489, 15643, 10087, 19156, 11454, 17148, 14172, 10257, 12605, 13191, 16956, 11634, 14734, 10529, 12366, 16672, 10464, 11645, 13197, 19133, 19134, 11, 65535, 261, 65530, 65532, 34580, 59, 33, 11315, 19137, 12771, 10260, 17631, 14734, 19137, 12824, 10258, 13234, 11957, 16713, 15847, 14221, 10250, 10349, 19137, 10260, 16503, 16672, 15847, 12144, 10621, 10250, 10283, 11016, 13091, 11891, 12604, 10409, 10843, 14734, 13212, 11369, 10250, 13324, 28329, 65535, 261, 65530, 65534, 820, 59, 33, 11685, 14734, 19137, 10305, 11044, 12605, 17147, 13091, 11017, 12469, 10293, 10370, 11021, 10399, 10303, 19137, 12605, 13179, 11268, 13558, 17148, 15033, 15044, 11116, 10080, 12605, 10423, 11986, 16707, 16672, 15847, 12144, 14734, 10355, 13819, 13179, 10842, 10621, 10370, 15261, 10250, 10349, 19137, 12159, 13197, 10293, 10370, 15752, 11634, 11268, 13558, 28336, 28329, 65535, 261, 65530, 65532, 34580, 59, 33, 12605, 12638, 10997, 14446, 10464, 17147, 15752, 17109, 10760, 34295, 28329, 65535, 261, 65530, 65534, 820, 59, 33, 11687, 13258, 10464, 11268, 13558, 14734, 16713, 12605, 11021, 10399, 11632, 13234, 14172, 10061, 19103, 19137, 12605, 10780, 10780, 12509, 10792, 19137, 11687, 13258, 13734, 13191, 16722, 15478, 14734, 10708, 10250, 10349, 16689, 11899, 14734, 16713, 19137, 12605, 17147, 13091, 10260, 11640, 13923, 13425, 16503, 14589, 10373, 10303, 13036, 12276, 11124, 10293, 10370, 10355, 13819, 11102, 28329, 65535, 261, 65530, 65532, 34580, 59, 22970, 11, 65535, 261, 65530, 65534, 820, 59, 33, 11315, 43282, 11, 65535, 261, 65530, 65532, 34580, 59, 33, 17819, 12522, 14172, 11994, 16403, 19137, 10790, 11640, 12697, 16803, 12609, 15643, 12669, 12430, 12406, 16790, 12986, 12220, 15494, 12705, 14015, 11994, 16403, 19137, 34295, 10260, 14589, 15486, 12182, 17109, 10760, 19137, 10995, 13580, 1487, 84, 10322, 16696, 10790, 10260, 10792, 28329, 65535, 261, 65530, 65534, 820, 59, 33, 13734, 13764, 11891, 10675, 11065, 12578, 10293, 10370, 14734, 16713, 19137, 14446, 11454, 12605, 12220, 16721, 13734, 13191, 10840, 13764, 15671, 15573, 19137, 15752, 16533, 17382, 10250, 10258, 10684, 10339, 9822, 12697, 16803, 9823, 11124, 9822, 12705, 14015, 9823, 10303, 28329, 65535, 261, 65530, 65532, 34580, 59, 33, 10260, 16503, 11454, 12522, 19137, 10464, 14734, 16403, 10292, 13191, 10260, 12307, 14734, 11459, 13036, 12605, 10423, 12748, 10760, 14734, 28329, 65535, 261, 65530, 65534, 820, 59, 33, 11685, 14734, 19137, 12605, 14862, 17222, 10333, 28329, 65535, 261, 65530, 65532, 34580, 59, 33, 14446, 11454, 10464, 15752, 11003, 11414, 13188, 12266, 11726, 13734, 13191, 10409, 10454, 16689, 11899, 14734, 14349, 12396, 10303, 19137, 11994, 13091, 11414, 15178, 11036, 15033, 17728, 18025, 14734, 820, 17268, 10283, 16689, 11899, 28329, 65535, 261, 65530, 65534, 820, 59, 33, 11021, 10399, 19137, 12605, 14446, 11454, 11414, 10792, 10782, 11726, 14349, 12396, 28329, 65535, 261, 65530, 65532, 34580, 59, 33, 13051, 13764, 10621, 10370, 15261, 10250, 13324, 16403, 10846, 19137, 10464, 12527, 16525, 11021, 12493, 10303, 19156, 11, 65535, 261, 65530, 65534, 820, 59, 33, 12605, 13091, 820, 19137, 10423, 10279, 13327, 12750, 14240, 16689, 11899, 16403, 10846, 19137, 10260, 10423, 12727, 13191, 12527, 16525, 10080, 10260, 17141, 11687, 13258, 13091, 10370, 15261, 14734, 16713, 19137, 10423, 12527, 16525, 10792, 13191, 10349, 11021, 12493, 28329, 65535, 261, 65530, 65532, 34580, 59, 33, 11685, 11061, 19137, 12605, 14486, 16533, 10333, 19137, 10399, 11044, 10423, 15494, 10464, 13212, 10423, 12750, 14240, 10370, 15261, 14734, 13036, 12276, 16403, 10846, 14734, 28329, 65535, 261, 65530, 65534, 820, 59, 33, 13078, 14731, 10333, 19137, 16774, 16774, 10464, 19137, 10293, 10370, 28329, 65535, 261, 65530, 65532, 34580, 59, 33, 11687, 13258, 12605, 17728, 10464, 19137, 14589, 10370, 15261, 14734, 16403, 10846, 13499, 12276, 13234, 11414, 15178, 15847, 12144, 13091, 11060, 13191, 12527, 16525, 11102, 19156, 11, 65535, 261, 65530, 65534, 820, 59, 33, 10254, 10250, 13191, 11102, 19137, 10293, 10370, 10080, 10370, 15261, 17189, 12182, 13091, 13326, 12797, 11630, 11454, 16417, 14446, 16694, 10435, 10687, 10390, 10283, 10452, 14734, 28329, 65535, 261, 65530, 65532, 34580, 59, 33, 11315, 19137, 12605, 12337, 14015, 16956, 19137, 16735, 10283, 9822, 11280, 127, 9823, 28329, 65535, 261, 65530, 65534, 820, 59, 33, 11280, 127, 11, 65535, 261, 65530, 65532, 34580, 59, 33, 11315, 19137, 10464, 14734, 11280, 11860, 15486, 17141, 1487, 84, 10305, 11044, 12337, 11685, 11065, 19137, 12605, 12220, 16721, 15752, 14817, 10283, 11685, 16525, 19137, 13115, 11889, 28329, 65535, 261, 65530, 65534, 820, 59, 33, 10293, 10370, 10260, 16503, 14442, 12270, 12605, 11235, 19137, 13115, 11889, 28329, 65535, 261]
-> item_loss 1.0568764209747314 batch_loss 1.174877127011617
==== [25106, 11, 65530, 65531, 10464, 13091, 10250, 10283, 820, 19137, 10423, 11454, 11124, 10370, 15261, 11957, 16713, 14734, 17141, 15052, 10285, 10260, 13032, 11871, 10323, 19137, 12202, 16672, 15847, 12144, 11003, 12348, 13179, 10842, 15678, 13078, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 11454, 10303, 19156, 11, 65535, 261, 65530, 65534, 7176, 59, 33, 12605, 11454, 14734, 19137, 13191, 10373, 10303, 10336, 11053, 19156, 11, 65535, 261, 65530, 65532, 27370, 59, 33, 13191, 10349, 10336, 12484, 12509, 16672, 10464, 11871, 10250, 10258, 19137, 12771, 17385, 16503, 14734, 28329, 65535, 261, 65530, 65534, 7176, 59, 33, 11685, 14734, 19137, 16738, 17728, 13091, 10373, 10303, 10336, 12484, 19137, 12605, 10423, 16667, 14794, 10333, 16533, 12202, 11871, 10323, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 10464, 13091, 10250, 10283, 13205, 11459, 13499, 11496, 19137, 10305, 11044, 12605, 10423, 15494, 10464, 10482, 14589, 11036, 15033, 12824, 11010, 14734, 13216, 17789, 19137, 12631, 10399, 12605, 12159, 13197, 10464, 15752, 11871, 10423, 15287, 14914, 11459, 12750, 14240, 12748, 10398, 17109, 10760, 11434, 11899, 13327, 12276, 14734, 10696, 11922, 19137, 10384, 15646, 11903, 14446, 11124, 15304, 15500, 10355, 10342, 28329, 65535, 261, 65530, 65534, 7176, 59, 33, 10333, 16533, 10333, 19137, 12605, 17879, 16503, 15287, 14914, 11459, 12750, 14240, 15494, 11899, 14734, 13327, 12276, 17109, 10760, 11124, 15304, 15500, 10355, 10342, 14734, 12748, 10398, 19137, 11957, 11061, 19156, 12159, 13197, 12605, 15752, 10384, 10293, 10370, 17148, 17384, 16056, 11001, 10250, 10349, 13179, 16722, 15478, 14734, 16679, 16533, 12609, 15643, 10487, 11855, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 11315, 19137, 14597, 10339, 15304, 15500, 13091, 15052, 12217, 15543, 10708, 14734, 19137, 11957, 10339, 13012, 11860, 10261, 15158, 11028, 14734, 11621, 14486, 13734, 13191, 10464, 17148, 10303, 14141, 13815, 19137, 12631, 10399, 10464, 17879, 16503, 10388, 15478, 10985, 14486, 16533, 16503, 13685, 19137, 12202, 12750, 13327, 12276, 17109, 10760, 10080, 10296, 10283, 10487, 11855, 19137, 10464, 11967, 10464, 10696, 12366, 14734, 12509, 13764, 12983, 11454, 380, 489, 10285, 19137, 11967, 11124, 15304, 15500, 14734, 12748, 10398, 12983, 11454, 393, 1678, 10285, 10080, 12605, 17879, 16503, 10464, 16417, 17136, 10760, 10696, 12366, 14734, 12509, 13764, 19137, 12202, 10265, 15494, 10760, 35, 12266, 11726, 10355, 10342, 35, 14734, 12748, 10398, 28329, 65535, 261, 65530, 65534, 7176, 59, 326, 12266, 11726, 10355, 10342, 94, 10293, 10370, 19137, 12605, 11986, 16707, 12750, 10464, 16735, 14734, 10588, 10333, 28330, 15847, 10529, 42, 11, 65535, 261, 65530, 65532, 27370, 59, 33, 12605, 12979, 10792, 15304, 15500, 13855, 12445, 10333, 19137, 12824, 11010, 14914, 11903, 12266, 11726, 17144, 10460, 10333, 19137, 12824, 10258, 13234, 10464, 17109, 10760, 393, 13381, 13290, 14349, 12396, 1678, 19137, 15646, 10260, 16503, 16735, 10687, 10390, 10409, 10454, 10272, 16501, 19137, 15304, 15500, 12220, 16721, 10423, 12669, 14349, 12396, 17146, 11414, 15494, 10464, 28329, 65535, 261, 65530, 65534, 7176, 59, 326, 13381, 13290, 14349, 12396, 94, 11, 65535, 261, 65530, 65531, 42343, 59, 33, 15304, 15500, 14349, 12396, 59, 11, 13064, 17734, 3493, 643, 46, 55, 46, 642, 46, 638, 59, 625, 59, 635, 262, 7176, 13012, 11860, 5502, 59, 33, 13580, 12182, 17144, 10460, 262, 7176, 11436, 10621, 12824, 11010, 59, 33, 13203, 12266, 11068, 262, 7176, 96, 830, 83, 59, 33, 12266, 11068, 262, 7176, 96, 1487, 84, 59, 33, 13203, 12266, 11068, 262, 14349, 12396, 13098, 14966, 11891, 13638, 19137, 11414, 10792, 15667, 11639, 13499, 12276, 65535, 261, 65530, 65534, 7176, 59, 33, 10293, 10370, 19137, 12605, 12145, 15486, 14791, 10792, 15304, 15500, 14349, 12396, 28330, 11685, 11656, 42, 11, 65535, 261, 65530, 65532, 27370, 59, 33, 10464, 11454, 11685, 11656, 10373, 10303, 19156, 11, 65535, 261, 65530, 65534, 7176, 59, 33, 12605, 11685, 11656, 15304, 15500, 14349, 12396, 17384, 14734, 7176, 16735, 14734, 13091, 10260, 13091, 12605, 28329, 65535, 261, 65530, 65532, 27370, 59, 33, 13734, 17631, 19137, 11885, 13098, 14966, 10333, 10373, 10303, 19137, 16735, 15494, 12605, 11065, 11, 65535, 261, 65530, 65534, 7176, 59, 33, 11885, 13098, 14966, 10333, 14446, 11454, 13064, 17734, 13091, 640, 643, 46, 55, 46, 642, 46, 638, 59, 625, 59, 635, 19137, 12605, 14734, 13012, 11860, 5502, 13580, 11454, 13580, 12182, 17144, 10460, 19152, 11436, 10621, 12824, 11010, 13734, 13191, 12266, 11068, 19152, 7176, 96, 830, 83, 11621, 10339, 12266, 11068, 10079, 7176, 96, 1487, 84, 11621, 10339, 10684, 17727, 14349, 12396, 10080, 10293, 10370, 19137, 10974, 13234, 12605, 13091, 15752, 11634, 17149, 16403, 15847, 10846, 16728, 17952, 16696, 10790, 11124, 13012, 11860, 16728, 17952, 17083, 12791, 14734, 10303, 19156, 11, 65535, 261]
-> item_loss 1.0396617650985718 batch_loss 1.171937662622203
==== [25106, 11, 65530, 65532, 12848, 17728, 15643, 59, 63237, 33, 14987, 15486, 15573, 15497, 13091, 11687, 10454, 12137, 10460, 14734, 19156, 16533, 17382, 16503, 10894, 11064, 12666, 13208, 15478, 15907, 19137, 10777, 10296, 13004, 11871, 10678, 12276, 28329, 65535, 261, 65530, 65534, 11414, 15178, 59, 63237, 33, 14987, 15486, 15573, 15497, 13091, 10250, 15033, 13913, 12231, 11871, 10323, 13499, 11496, 19137, 14597, 21092, 9057, 106, 33, 15169, 10370, 11454, 640, 637, 12201, 14734, 16686, 13012, 28316, 8843, 2077, 7874, 4600, 19407, 21189, 29467, 9823, 10285, 12848, 10760, 10080, 17148, 15033, 13499, 11496, 10293, 16503, 14589, 10339, 12217, 10777, 10792, 12217, 10777, 14734, 10409, 10843, 19137, 10487, 11687, 13212, 11369, 15636, 16704, 10080, 63013, 33, 13499, 11496, 10495, 16922, 10339, 15847, 13773, 12522, 13212, 10794, 13234, 12202, 16403, 11621, 14486, 17109, 10673, 12217, 10777, 19137, 15646, 17184, 12306, 14987, 15486, 15573, 15497, 19133, 6504, 19134, 11124, 17688, 14866, 13199, 16678, 12369, 19133, 23848, 19134, 15573, 15497, 10285, 10482, 14589, 14734, 13091, 18000, 12217, 11621, 14486, 28329, 63013, 33, 13499, 11496, 14597, 15543, 14875, 11369, 11124, 16533, 14875, 11369, 15476, 12604, 19137, 13633, 10283, 17311, 14597, 11632, 10283, 14782, 11042, 14734, 12007, 15476, 12604, 10080, 15543, 14875, 11369, 11124, 16533, 14875, 11369, 10285, 14734, 13633, 10283, 12007, 17311, 13191, 10278, 10283, 10293, 16503, 15476, 10407, 19151, 11632, 11647, 15847, 13773, 12522, 13212, 10794, 11124, 10447, 15586, 15543, 14875, 14734, 10808, 18108, 15573, 15497, 28329, 50, 47, 33, 11632, 11647, 15847, 13773, 12522, 13212, 10794, 19151, 11, 15847, 13773, 12522, 13212, 10794, 10652, 16684, 13499, 11496, 13216, 16412, 12217, 10777, 10285, 10260, 11042, 10932, 16702, 14734, 14782, 10684, 12415, 10080, 15494, 11899, 16417, 14966, 10292, 14863, 17774, 89, 14734, 10932, 16702, 12217, 10777, 19137, 15847, 13773, 12522, 13212, 10794, 16664, 15200, 13633, 10283, 10932, 16702, 14782, 11957, 10339, 12217, 10777, 10285, 14734, 13633, 10283, 10687, 10390, 10932, 16702, 14734, 13773, 12522, 10838, 10768, 13004, 10080, 10482, 14589, 10256, 10283, 14863, 17774, 16664, 15200, 13773, 12522, 10838, 10768, 13004, 19151, 13290, 16718, 14863, 17774, 19133, 82, 19134, 10079, 17644, 14863, 17774, 19133, 76, 19134, 11124, 10577, 14863, 17774, 19133, 87, 19134, 10080, 17148, 10349, 13091, 17189, 17141, 10482, 14589, 11021, 11871, 10323, 14734, 13216, 17385, 14863, 17774, 88, 82, 10079, 1576, 11124, 1585, 10384, 17109, 10673, 14863, 17774, 89, 17149, 16403, 15471, 12415, 11003, 12791, 12348, 10760, 14734, 28329, 82, 296, 323, 277, 322, 82, 11, 76, 296, 323, 277, 322, 76, 11, 87, 296, 323, 277, 322, 87, 11, 13773, 12522, 10838, 10768, 13004, 10482, 14589, 13290, 16718, 11124, 17644, 14863, 17774, 10305, 17734, 14734, 14172, 15043, 16664, 15200, 19137, 17798, 10399, 17644, 14734, 15516, 12231, 19133, 1824, 19134, 14734, 12200, 13036, 13326, 19137, 14221, 11044, 17189, 17141, 49715, 10762, 13004, 10427, 17184, 10399, 12306, 10250, 10901, 10768, 13004, 19151, 11, 57934, 41, 82, 45, 310, 45, 321, 42, 296, 52944, 41, 82, 277, 310, 95, 85, 282, 32105, 41, 1824, 494, 277, 321, 11, 11632, 11647, 15847, 13773, 12522, 13212, 10794, 11967, 17109, 10673, 10768, 12604, 11632, 10283, 13773, 12522, 10838, 11647, 19137, 13633, 10283, 11647, 17311, 13191, 15847, 12144, 14734, 13216, 17385, 14863, 17774, 10080, 17148, 10482, 12348, 13499, 11496, 11021, 10399, 10684, 13773, 17109, 10673, 12217, 10777, 14734, 10260, 11042, 13036, 17919, 10080, 13633, 10283, 13773, 12522, 10838, 11647, 14734, 17109, 10760, 16443, 17152, 12824, 12202, 10482, 14589, 11021, 11871, 10323, 14734, 13216, 17385, 14863, 17774, 1580, 17149, 16403, 15471, 12415, 11003, 12791, 19137, 10399, 10358, 14583, 13188, 15480, 17109, 10760, 19151, 11, 33286, 23722, 41, 82, 45, 310, 45, 321, 42, 296, 28674, 1752, 41, 25566, 50, 45, 28376, 31060, 105, 42, 277, 4324, 11, 25566, 106, 296, 58687, 41, 82, 277, 322, 1390, 45, 310, 277, 322, 1190, 45, 321, 277, 322, 1561, 42, 11, 51, 47, 33, 10447, 15586, 15543, 14875, 19151, 11, 14597, 10339, 63013, 13499, 11496, 15568, 10309, 10932, 16702, 11454, 12217, 10777, 10285, 14734, 10447, 15586, 14734, 10696, 11454, 14862, 16696, 19137, 11416, 13581, 11967, 10447, 15586, 15543, 14875, 13920, 10842, 10792, 17109, 10673, 12108, 10673, 10285, 10080, 17148, 15033, 15543, 14875, 13091, 10447, 15586, 14734, 11434, 11899, 10762, 13004, 19137, 11021, 10399, 10482, 14589, 10260, 11042, 18020, 14426, 14734, 13580, 12290, 11124, 10457, 12290, 10762, 13004, 16664, 15200, 19151, 11, 1346, 41, 8518, 45, 285, 106, 42, 296, 22476, 41, 8518, 282, 3483, 620, 49, 1702, 51, 106, 48, 101, 494, 11, 1346, 41, 8518, 45, 285, 106, 278, 284, 42, 296, 21459, 41, 8518, 282, 3483, 620, 49, 1702, 51, 106, 48, 101, 494, 11, 10687, 10285, 8518, 13091, 10447, 15586, 19137, 106, 13091, 15516, 12231, 19137, 101, 13091, 12108, 10673, 11638, 11975, 28329, 52, 47, 33, 15543, 14875, 11369, 11124, 16533, 14875, 11369, 19151, 11, 15543, 14875, 11369, 14597, 10250, 11539, 14782, 11042, 14734, 12007, 15476, 12604, 19137, 13633, 10283, 12007, 17311, 13191, 10250, 10283, 11632, 11647, 15847, 13773, 12522, 13212, 10794, 19137, 11044, 16974, 10250, 10283, 10447, 15586, 15543, 14875, 14734, 10808, 18108, 15573, 15497, 10080, 13581, 11630, 19137, 11454, 13633, 10283, 11855, 12007, 10305, 11044, 12220, 14589, 13604, 12143, 17152, 12824, 11124, 12007, 12306, 10250, 10901, 28329, 16533, 14875, 11369, 10322, 14597, 11632, 10283, 14782, 11042, 14734, 12007, 15476, 12604, 10080, 10444, 13091, 19137, 17798, 10333, 11632, 11647, 15847, 13773, 12522, 11124, 10447, 15586, 15543, 14875, 14734, 10808, 18108, 15573, 15497, 10305, 11630, 19137, 11885, 17147, 10894, 11064, 10250, 10283, 18030, 11630, 14734, 11632, 11647, 13773, 12522, 12007, 19137, 16721, 12007, 11967, 15543, 14875, 11369, 14734, 17109, 10760, 10460, 10292, 17109, 10673, 10080, 17148, 13191, 10847, 10339, 16533, 14875, 11369, 11454, 14583, 12604, 14778, 13308, 12217, 10777, 13064, 10684, 13773, 15543, 14875, 11369, 14734, 17109, 10760, 28329, 53, 47, 33, 13188, 15480, 14734, 15471, 12415, 11124, 49715, 12007, 19151, 11, 16533, 14875, 11369, 14734, 17109, 10760, 17189, 17141, 13188, 15480, 14734, 15471, 12415, 12007, 11124, 49715, 14091, 13815, 10762, 13004, 10427, 17184, 19137, 10399, 10358, 14583, 13633, 10283, 14778, 13308, 10932, 16702, 14734, 13445, 14426, 10768, 12155, 28329, 12159, 13197, 17148, 10349, 10696, 11922, 15752, 11957, 12469, 13191, 12631, 12176, 10847, 10080, 65535, 261, 65530, 65532, 12848, 17728, 15643, 59, 33, 11315, 19137, 12605, 14486, 16533, 10333, 28329, 65535, 261, 65530, 65534, 11414, 15178, 59, 33, 12605, 12337, 12266, 12366, 15752, 12176, 10792, 10464, 19126, 16738, 17728, 17147, 13191, 10687, 10390, 17728, 18025, 10303, 19156, 11, 65535, 261, 65530, 65532, 12848, 17728, 15643, 59, 267, 10580, 16689, 10464, 13191, 10250, 10283, 10337, 17149, 10794, 11860, 15158, 10287, 631, 621, 620, 630, 621, 631, 621, 620, 631, 620, 631, 630, 630, 631, 631, 19137, 12750, 14240, 10399, 10258, 13582, 18197, 17149, 16403, 12945, 10460, 19151, 11001, 10808, 53, 10447, 12202, 13920, 10842, 17172, 12307, 13004, 17387, 14734, 9822, 49, 9823, 10482, 10687, 10261, 89, 14734, 17688, 12231, 14782, 11042, 19137, 14221, 11044, 10384, 89, 10285, 10739, 10985, 11885, 28329, 65535, 261, 65530, 65534, 11414, 15178, 59, 33, 11685, 14734, 19126, 16672, 12605, 10402, 12750, 14240, 10464, 12848, 10760, 14734, 13582, 18197, 10482, 14589, 10337, 17149, 10794, 11860, 15158, 10287, 89, 296, 3484, 621, 620, 630, 621, 631, 621, 620, 631, 620, 631, 630, 630, 631, 631, 28329, 13582, 18197, 50, 19151, 11001, 89, 14734, 10808, 53, 10447, 11, 89, 14734, 10808, 53, 10447, 13091, 631, 621, 28329, 13582, 18197, 51, 19151, 13920, 10842, 17172, 12307, 13004, 17387, 14734, 9822, 49, 9823, 10482, 10687, 10261, 89, 14734, 17688, 12231, 14782, 11042, 11, 14597, 10339, 89, 14734, 17688, 12231, 10292, 650, 19137, 12605, 10402, 17879, 16503, 11454, 631, 621, 14734, 13204, 12003, 13920, 10842, 650, 46, 53, 296, 3499, 10283, 17874, 10080, 12631, 10399, 12605, 10402, 12348, 10792, 19151, 11, 631, 621, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 11, 13582, 18197, 52, 19151, 10384, 89, 10285, 10739, 10985, 15489, 13258, 11, 16503, 10384, 89, 10285, 10739, 10985, 15489, 13258, 19137, 12605, 10402, 11016, 17879, 12650, 16403, 10278, 10283, 13004, 11860, 10305, 17734, 14734, 12750, 10447, 10739, 13764, 19133, 10953, 89, 1319, 19134, 10080, 17148, 12522, 11110, 14808, 12605, 10402, 10482, 14589, 10399, 10258, 16521, 10779, 11454, 89, 11124, 13582, 18197, 51, 14734, 15489, 13258, 10305, 17734, 10739, 10985, 14782, 12220, 14734, 10447, 19151, 11, 49, 21171, 283, 296, 283, 11, 49, 21171, 284, 296, 284, 11, 50, 21171, 283, 296, 284, 11, 50, 21171, 284, 296, 283, 11, 12631, 10399, 12605, 10402, 13191, 19151, 11, 6884, 2178, 2194, 262, 631, 621, 620, 630, 621, 631, 621, 620, 631, 620, 631, 630, 630, 631, 631, 3340, 41, 89, 42, 11, 6884, 11, 89, 1319, 262, 631, 621, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 11, 65458, 568, 11, 62, 3473, 620, 620, 630, 621, 631, 621, 620, 631, 620, 631, 630, 630, 631, 631, 11, 11416, 13581, 19137, 10384, 89, 10285, 10739, 10985, 10808, 53, 10447, 12348, 10792, 10337, 17149, 10794, 11860, 15158, 10287, 620, 620, 620, 630, 621, 631, 621, 620, 631, 620, 631, 630, 630, 631, 631, 10080, 65535, 261, 65530, 65532, 12848, 17728, 15643, 59, 267, 11315, 19137, 10464, 16525, 12348, 17148, 10283, 17728, 18025, 11124, 13188, 12266, 11726, 14734, 17728, 18025, 11187, 10283, 13637, 17097, 13191, 12522, 10304, 19156, 11, 65535, 261, 65530, 65534, 11414, 15178, 59, 33, 12605, 16667, 10292, 17311, 12337, 13191, 12522, 10304, 19137, 13188, 10782, 12469, 16672, 12605, 10292, 12469, 16533, 17382, 63013, 13273, 13250, 14734, 12666, 13208, 15478, 15907, 19137, 12605, 14734, 11414, 15178, 10322, 16684, 15752, 11634, 12176, 10847, 12469, 16056, 12348, 14862, 16696, 10080, 15646, 11454, 10305, 11044, 12469, 10990, 16672, 12605, 17149, 16403, 10337, 17149, 10794, 11860, 15158, 10287, 14734, 17144, 15200, 19137, 12605, 12826, 13827, 12469, 13091, 12509, 16672, 12605, 12176, 10847, 12469, 16533, 10722, 11903, 17781, 17728, 18025, 19137, 12609, 15643, 13827, 16707, 12605, 14734, 15752, 10838, 10080, 12605, 12337, 18216, 10685, 15752, 11634, 10292, 10464, 14734, 14583, 13815, 10261, 12137, 10460, 12848, 10494, 10511, 10788, 19137, 12609, 13091, 16672, 12469, 11957, 12605, 13191, 13179, 13913, 14734, 10333, 16533, 28329, 65535, 261, 65530, 65532, 12848, 17728, 15643, 59, 267, 11315, 19137, 12605, 14862, 17222, 10333, 28329, 65535, 261, 65530, 65534, 11414, 15178, 59, 33, 11685, 14734, 19137, 11687, 13258, 17147, 13191, 17728, 18025, 14734, 16713, 19137, 13558, 17143, 13234, 17728, 12605, 11183, 28329, 65535, 261, 65530, 65532, 12848, 17728, 15643, 59, 267, 12904, 12904, 11647, 11, 65535, 261, 65530, 65534, 11414, 15178, 59, 33, 12797, 14778, 10808, 14734, 10529, 12445, 13234, 14791, 19137, 12605, 12202, 10260, 12727, 13191, 14328, 14486, 11903, 10452, 19137, 10260, 17141, 12605, 15752, 10452, 10423, 10792, 12469, 14734, 12366, 12522, 19137, 16774, 16774, 28329, 65535, 261]
-> item_loss 0.5725136995315552 batch_loss 1.1591839612798487
==== [65530, 65532, 10902, 10362, 13191, 10373, 10303, 11975, 11035, 19156, 11, 65535, 261, 65530, 65534, 10902, 10362, 13191, 12337, 11632, 11975, 11035, 19137, 10399, 10258, 13091, 10250, 10349, 10487, 11855, 19151, 11, 50, 47, 33, 14188, 15694, 10287, 19151, 17148, 13091, 10902, 10362, 10370, 13188, 11268, 13558, 14734, 11975, 11035, 10305, 10250, 19137, 11021, 10399, 11454, 16684, 11632, 12895, 10447, 10257, 11986, 16707, 28329, 51, 47, 33, 14171, 17351, 17919, 19151, 17148, 13091, 10250, 15033, 11967, 17919, 13231, 10079, 15694, 17351, 11124, 18363, 16295, 14155, 11454, 10250, 16944, 14734, 11975, 11035, 28329, 52, 47, 33, 16793, 13684, 10650, 19151, 17148, 13091, 10250, 15033, 11967, 16793, 11855, 11124, 13676, 14244, 12604, 15291, 14349, 19137, 10703, 10842, 10673, 11036, 15033, 18119, 13021, 11124, 15294, 14734, 14582, 11159, 28329, 53, 47, 33, 15595, 15694, 10287, 19151, 17148, 13091, 10902, 10362, 10370, 13188, 11268, 13558, 14734, 11975, 11035, 10305, 10250, 19137, 11021, 10399, 11454, 16684, 11632, 18069, 18107, 12664, 10792, 28329, 54, 47, 33, 13325, 13333, 15293, 19151, 17148, 13091, 10250, 15033, 11967, 13325, 13333, 10374, 10079, 15302, 15260, 15264, 11124, 15919, 18425, 13916, 11038, 11044, 13750, 14171, 14734, 15293, 14172, 28329, 12421, 14734, 13234, 16735, 19137, 10902, 10362, 13191, 12337, 11632, 15597, 18053, 11021, 10494, 11159, 11986, 19137, 13633, 10283, 10370, 17311, 11021, 10399, 13326, 12797, 15847, 12144, 14734, 11010, 11110, 17177, 12731, 15847, 12144, 11268, 13558, 14734, 11975, 11035, 10080, 65535, 261]
[2023-09-30 21:52:44,677] [INFO] [logging.py:96:log_dist] [Rank 0] step=50, skipped=0, lr=[0.0001, 0.0001, 0.0001], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
-> item_loss 0.5741926431655884 batch_loss 1.1469966421524684
==== [65530, 65531, 13326, 12797, 47487, 33, 10285, 14734, 12848, 14966, 14734, 10529, 12445, 19137, 13250, 12261, 26060, 19137, 40992, 22590, 57009, 30917, 102, 29945, 11, 65535, 261, 65530, 65532, 13326, 12797, 10258, 17919, 42343, 10285, 16056, 11001, 14734, 11630, 17303, 15573, 15497, 16909, 13021, 19137, 33, 12848, 10494, 15494, 12605, 13203, 13234, 630, 11639, 14734, 15878, 14474, 10529, 12445, 19137, 33, 14589, 26060, 13327, 12276, 15494, 10760, 15178, 13336, 11, 65535, 261, 65530, 65531, 42343, 33, 17148, 10256, 10283, 15878, 14474, 11028, 10292, 11, 13326, 12797, 12605, 11957, 11630, 17303, 10529, 12445, 14734, 13290, 16718, 19137, 13203, 13234, 630, 11639, 14734, 15878, 14474, 10529, 12445, 10292, 11, 50, 47, 30917, 20512, 30074, 4811, 44527, 4596, 3493, 59, 620, 3493, 643, 48, 54, 48, 50, 11, 51, 47, 3913, 20512, 30074, 39934, 31059, 332, 4537, 7624, 46172, 4811, 20310, 49961, 45, 4596, 3493, 643, 48, 54, 48, 57, 3483, 59, 625, 11, 52, 47, 30917, 59, 20512, 30074, 45, 4811, 59, 50070, 45, 55915, 59, 3493, 643, 48, 54, 48, 50, 3493, 59, 630, 65535, 261, 65530, 65534, 10399, 10258, 13091, 10250, 10283, 13203, 13234, 630, 11639, 14734, 15878, 14474, 10529, 12445, 59, 11, 6884, 26060, 11, 124, 3331, 35, 41425, 116, 388, 326, 28352, 124, 43909, 35, 25460, 388, 269, 6329, 30074, 384, 43909, 35, 2215, 388, 269, 40586, 384, 43909, 35, 27165, 5181, 640, 643, 48, 54, 48, 50, 3493, 59, 620, 35, 28352, 2391, 28352, 124, 43909, 35, 25460, 388, 269, 6329, 30074, 384, 43909, 35, 2215, 388, 269, 6219, 49961, 384, 43909, 35, 27165, 5181, 640, 643, 48, 54, 48, 57, 3483, 59, 625, 35, 28352, 2391, 28352, 124, 43909, 35, 25460, 388, 269, 6329, 30074, 384, 43909, 35, 2215, 388, 269, 48406, 384, 43909, 35, 27165, 5181, 640, 643, 48, 54, 48, 50, 3493, 59, 630, 35, 28352, 126, 3331, 94, 11, 126, 11, 6884, 11, 10399, 10257, 26060, 10696, 11922, 12605, 11967, 42343, 14734, 12848, 14966, 10285, 16056, 11001, 14734, 10529, 12445, 13006, 14486, 14734, 15489, 13258, 10080, 65535, 261, 65530, 65532, 10696, 11922, 10285, 15568, 11977, 15878, 14474, 11028, 19137, 33, 16738, 10464, 11454, 10257, 17919, 14734, 26060, 10285, 16416, 10655, 13580, 14914, 14734, 15878, 14474, 11028, 28329, 65535, 261, 65530, 65531, 42343, 33, 17148, 10256, 10283, 15878, 14474, 11028, 10292, 11, 6884, 11, 50, 47, 3662, 84, 46, 1196, 50, 11, 51, 47, 3662, 84, 46, 1196, 647, 11, 52, 47, 3662, 84, 46, 1196, 639, 11, 6884, 65535, 261, 65530, 65534, 11, 17148, 17384, 15494, 10760, 16416, 10655, 14734, 15878, 14474, 10529, 12445, 59, 11, 6884, 26060, 11, 124, 3331, 35, 41425, 116, 388, 326, 28352, 124, 43909, 35, 25460, 388, 269, 6329, 30074, 384, 43909, 35, 2215, 388, 269, 40586, 384, 43909, 35, 27165, 5181, 640, 643, 48, 54, 48, 50, 3493, 59, 620, 384, 43909, 35, 41425, 96, 41900, 388, 269, 875, 84, 46, 1196, 50, 35, 28352, 2391, 28352, 124, 43909, 35, 25460, 388, 269, 6329, 30074, 384, 43909, 35, 2215, 388, 269, 6219, 49961, 384, 43909, 35, 27165, 5181, 640, 643, 48, 54, 48, 57, 3483, 59, 625, 384, 43909, 35, 41425, 96, 41900, 388, 269, 875, 84, 46, 1196, 647, 35, 28352, 2391, 28352, 124, 43909, 35, 25460, 388, 269, 6329, 30074, 384, 43909, 35, 2215, 388, 269, 48406, 384, 43909, 35, 27165, 5181, 640, 643, 48, 54, 48, 50, 3493, 59, 630, 384, 43909, 35, 41425, 96, 41900, 388, 269, 875, 84, 46, 1196, 639, 35, 28352, 126, 3331, 94, 11, 126, 11, 6884, 11, 10399, 10257, 14734, 26060, 10285, 15494, 10760, 10333, 16416, 10655, 14734, 15878, 14474, 10529, 12445, 45, 33, 10894, 12732, 10333, 10384, 15469, 15450, 10792, 10431, 13002, 14734, 15878, 14474, 10080, 65535, 261, 65530, 65532, 13326, 12797, 10464, 14734, 10696, 11454, 13216, 17385, 10285, 16678, 12369, 14734, 10529, 12445, 19137, 11047, 12605, 12848, 10494, 41661, 14734, 10988, 13004, 10529, 12445, 19137, 33, 17379, 14589, 26060, 17146, 11414, 15489, 13258, 11, 65535, 261, 65530, 65534, 10399, 10258, 13091, 10250, 10283, 10487, 11855, 59, 11, 6884, 26060, 11, 124, 11, 35, 41512, 3484, 388, 358, 11, 35, 5704, 388, 269, 32905, 300, 633, 19520, 8242, 384, 11, 35, 5960, 388, 269, 5960, 3537, 46, 7159, 45, 285, 47, 52, 19929, 45, 291, 28687, 116, 384, 11, 35, 5960, 44574, 275, 6482, 489, 59, 269, 53, 3826, 384, 11, 35, 5960, 28458, 36008, 275, 6241, 489, 59, 269, 660, 49, 20348, 384, 11, 35, 5960, 50703, 275, 1040, 489, 59, 269, 632, 57, 3826, 384, 11, 35, 5704, 37943, 275, 1167, 489, 59, 3493, 668, 45, 11, 35, 5704, 37943, 32031, 275, 34073, 489, 59, 3513, 716, 45, 11, 35, 5704, 38116, 275, 23529, 116, 489, 59, 287, 45, 11, 35, 5704, 37943, 31300, 32031, 275, 32961, 489, 59, 3537, 45, 11, 35, 5704, 63654, 22459, 275, 23400, 54103, 489, 59, 269, 5513, 684, 384, 11, 35, 5704, 63654, 22459, 40194, 275, 33580, 489, 59, 3537, 45, 11, 35, 5704, 45348, 60226, 388, 32313, 45, 11, 35, 5704, 45348, 60226, 40194, 275, 33580, 489, 59, 3489, 30293, 45, 11, 35, 5960, 30502, 64254, 388, 269, 6263, 106, 46, 72, 691, 4011, 50, 384, 11, 35, 5960, 30502, 64254, 40194, 388, 3485, 57, 45, 11, 35, 5960, 30502, 39759, 275, 6241, 489, 59, 3483, 620, 45, 11, 35, 5960, 30502, 39759, 40194, 388, 3485, 57, 30293, 45, 11, 126, 360, 21214, 65535, 261, 65530, 65532, 14427, 14736, 11638, 12170, 10449, 11454, 12200, 13819, 12007, 17147, 13091, 11957, 13819, 12007, 19156, 17146, 11414, 26060, 13327, 12276, 14734, 10529, 12445, 11, 65535, 261, 65530, 65534, 11, 6884, 26060, 11, 124, 11, 35, 54311, 7743, 388, 32313, 45, 11, 35, 60952, 388, 32313, 45, 11, 35, 33652, 34870, 2210, 2255, 388, 32313, 45, 11, 35, 8172, 34880, 388, 32313, 45, 11, 35, 61024, 388, 32313, 45, 11, 35, 54309, 59887, 116, 23258, 5574, 1792, 1773, 63201, 5191, 11, 126, 11, 6884, 11, 36, 33, 17148, 17384, 15494, 10760, 10333, 10250, 10283, 10487, 11855, 19137, 10464, 11021, 10399, 13326, 12797, 15847, 12144, 14734, 17879, 16503, 10538, 12981, 43, 65535, 261]
-> item_loss 1.3937420845031738 batch_loss 1.1520322634249318
==== [12848, 17728, 4516, 6908, 10397, 14875, 14782, 10684, 14862, 16696, 11, 65530, 65532, 10397, 14875, 10285, 14734, 26742, 13091, 10373, 10303, 12522, 12410, 19156, 11, 65535, 261, 65530, 65534, 26742, 17189, 12182, 13091, 58393, 14734, 15558, 10708, 45, 16417, 14966, 17141, 15052, 12609, 10762, 13004, 28329, 12631, 10399, 11454, 10397, 14875, 10285, 45, 26742, 13191, 10745, 10283, 11021, 15752, 14734, 11064, 10304, 59, 11, 50, 47, 33, 10250, 10283, 10762, 13004, 12609, 17141, 15052, 14734, 11043, 15044, 10080, 10487, 11687, 59, 11, 6884, 42114, 11, 7334, 4677, 96, 26742, 5268, 28352, 5362, 11, 6884, 11, 51, 47, 33, 10250, 10283, 10762, 13004, 12609, 17141, 15052, 11957, 16803, 10080, 10487, 11687, 59, 11, 6884, 42114, 11, 26742, 296, 32074, 96, 54014, 11, 6884, 11, 52, 47, 31759, 11021, 10399, 10460, 10292, 10250, 10283, 17189, 14589, 14734, 11043, 15044, 10397, 16417, 10409, 10454, 10762, 13004, 12609, 17141, 15052, 28329, 10688, 10452, 10454, 15033, 11064, 10304, 45, 16503, 14791, 10257, 10258, 13012, 11124, 13179, 16722, 15478, 14734, 10397, 14875, 10080, 10444, 11638, 15850, 10257, 17311, 13091, 11124, 10762, 13004, 12609, 15643, 17141, 15052, 14782, 10684, 10080, 65535, 261, 65530, 65534, 26742, 33, 17189, 12182, 14589, 13234, 11899, 10304, 10250, 10283, 17141, 15052, 48, 10762, 13004, 48, 13036, 13764, 28329, 10296, 10487, 13234, 16735, 59, 11, 6884, 26957, 11, 26742, 4491, 359, 26290, 125, 3331, 35, 33155, 3376, 26290, 126, 363, 11, 7463, 11, 6884, 11, 17148, 17384, 11899, 10304, 10333, 10250, 10283, 12824, 11002, 10250, 10283, 10988, 13004, 31496, 33, 14734, 10915, 11043, 10762, 13004, 41, 10915, 11043, 11994, 13091, 13734, 13191, 10762, 13004, 11043, 497, 12202, 17146, 11414, 10250, 10283, 11860, 15158, 10287, 13327, 12276, 10901, 11044, 14734, 11860, 15158, 10287, 28329, 12631, 10399, 14589, 31759, 33, 11899, 10304, 14734, 17148, 15033, 10762, 13004, 11957, 16803, 45, 11994, 15044, 10292, 24048, 11957, 16803, 28329, 24114, 33, 10285, 17147, 13191, 10250, 10283, 15261, 10441, 14734, 11899, 10304, 10762, 13004, 14734, 13036, 12276, 13091, 10482, 14589, 46391, 59, 11, 6884, 26957, 11, 41749, 4491, 359, 26290, 125, 3331, 35, 33155, 3376, 26290, 126, 363, 11, 7463, 11, 6884, 11, 24048, 33, 11124, 46391, 33, 11454, 10250, 10349, 10841, 15752, 10257, 13191, 15478, 12359, 12143, 12268, 45, 10444, 12421, 14734, 13234, 16735, 17311, 13091, 14589, 13234, 11899, 10304, 10762, 13004, 48, 17141, 15052, 14734, 28329, 12631, 10399, 11454, 10397, 14875, 10285, 14791, 10792, 31759, 33, 11899, 10304, 14734, 45, 11994, 13091, 11899, 10304, 10333, 10250, 10283, 29623, 11957, 16803, 45, 10322, 11994, 13091, 10250, 10283, 10762, 13004, 48, 17141, 15052, 28329, 12159, 13197, 10257, 17162, 16533, 17382, 11957, 12469, 13191, 14589, 34, 65535, 261, 65530, 65534, 26742, 33, 11454, 13581, 11621, 10397, 16417, 17149, 15052, 41, 49585, 42, 10080, 10688, 10452, 13234, 16735, 45, 11885, 13091, 52571, 46, 27003, 46, 42153, 10079, 49585, 46, 27003, 46, 42324, 33, 11124, 52571, 46, 27003, 46, 7478, 33, 17148, 10256, 10283, 11117, 10398, 14734, 10988, 13004, 45, 16417, 14966, 16503, 12945, 10460, 14734, 17149, 15052, 28329, 11454, 13205, 10487, 10285, 14734, 10397, 14875, 10285, 59, 11, 6884, 8098, 113, 11, 41, 26200, 46, 49585, 262, 59, 26290, 269, 1795, 2226, 1818, 48, 49697, 46, 35325, 35, 11, 59, 41129, 3352, 1795, 2226, 1818, 48, 49697, 46, 35325, 516, 11, 5362, 11, 42, 11, 6884, 11, 17148, 13619, 10397, 14875, 10781, 12261, 10333, 10250, 10283, 11043, 10292, 269, 1795, 2226, 1818, 48, 49697, 46, 35325, 35, 33, 14734, 17149, 15052, 28329, 14221, 11044, 11044, 15511, 10397, 14875, 10482, 14589, 14782, 11042, 14734, 17149, 15052, 11043, 15044, 10460, 10292, 31759, 33, 10988, 13004, 45, 10487, 11687, 59, 11, 6884, 8098, 113, 11, 41, 49585, 46, 27003, 46, 42153, 267, 35, 1795, 2226, 1818, 48, 49697, 46, 35325, 35, 21340, 21616, 42, 11, 41, 49585, 46, 27003, 46, 42324, 267, 35, 1795, 2226, 1818, 48, 49697, 46, 35325, 35, 269, 261, 381, 11, 41, 49585, 46, 27003, 46, 7478, 269, 1795, 2226, 1818, 48, 49697, 46, 35325, 381, 11, 6884, 11, 17148, 17384, 14734, 269, 1795, 2226, 1818, 48, 49697, 46, 35325, 35, 33, 11994, 13091, 10397, 16417, 17149, 15052, 31759, 28329, 12421, 14734, 13234, 16735, 45, 26742, 33, 16417, 14966, 16503, 12945, 10460, 14734, 17268, 10283, 11043, 10292, 269, 1795, 2226, 1818, 48, 49697, 46, 35325, 35, 33, 14734, 44742, 33, 17149, 15052, 28329, 12159, 13197, 17148, 10283, 16533, 17382, 13191, 10847, 10339, 12469, 14486, 16533, 31759, 33, 11454, 17148, 17384, 12631, 10397, 16417, 14734, 11064, 10304, 10080, 65535, 261]
-> item_loss 1.6740504503250122 batch_loss 1.1624726271629333
==== [65530, 65531, 12656, 14035, 10250, 10283, 15847, 11805, 10452, 15543, 17108, 19137, 13326, 12797, 27370, 14734, 17109, 10673, 15494, 10760, 15543, 17108, 11044, 14734, 13012, 13205, 11, 65535, 261, 65530, 65532, 12605, 17879, 16503, 10464, 12927, 10708, 10684, 10339, 13631, 11795, 12678, 10691, 14782, 10684, 14734, 14862, 16696, 14734, 13012, 15131, 11, 65535, 261, 65530, 65534, 10399, 10258, 13091, 10250, 10283, 10487, 11855, 59, 267, 11454, 17141, 10985, 14734, 10745, 10917, 12201, 17384, 45, 33, 13631, 11795, 10684, 15304, 10250, 14781, 11622, 11002, 10370, 10402, 14734, 10684, 13773, 10080, 17148, 10293, 16503, 13091, 11416, 10292, 45, 33, 13631, 10366, 11454, 12395, 11858, 11124, 10358, 11044, 14734, 17268, 10745, 10283, 13190, 17384, 12665, 12701, 10333, 12140, 11638, 14734, 14583, 10358, 10838, 10409, 10843, 45, 33, 11042, 13064, 10322, 12665, 11002, 10333, 12140, 11638, 14734, 15287, 14987, 10966, 10838, 10080, 11684, 17879, 16503, 14240, 18004, 11795, 10650, 45, 33, 11042, 13064, 17147, 16503, 10692, 18004, 12137, 10460, 11124, 11871, 10323, 28329, 11454, 17148, 15033, 12484, 10724, 10258, 45, 33, 13631, 10366, 14734, 17177, 12731, 10293, 16503, 13191, 10278, 15033, 59, 33, 10250, 15033, 13091, 17177, 12731, 11454, 11920, 10285, 15847, 15494, 15847, 16956, 45, 33, 11013, 10250, 15033, 10779, 13091, 17177, 12731, 11454, 10913, 17796, 12824, 11002, 12686, 14486, 28329, 13051, 16686, 17177, 12731, 11187, 15033, 13036, 13764, 45, 33, 13631, 10366, 17311, 17919, 10288, 14808, 12140, 11638, 14734, 10966, 10838, 10080, 11684, 17879, 16503, 14240, 18004, 11795, 10650, 45, 33, 11042, 13064, 17147, 16503, 10692, 18004, 12137, 10460, 11124, 11871, 10323, 10080, 11684, 12368, 18001, 10260, 13032, 11459, 11871, 10323, 13034, 14862, 16696, 11124, 12666, 15752, 45, 33, 11042, 13064, 10322, 12159, 13197, 15752, 11634, 12348, 10792, 14970, 10423, 14734, 16667, 11021, 10080, 11454, 17148, 10283, 17141, 15052, 10285, 45, 33, 11684, 17919, 10288, 14808, 12140, 11638, 14734, 10966, 10838, 28329, 11687, 13258, 17177, 12731, 11454, 11920, 10285, 15847, 15494, 15847, 16956, 45, 65535, 261, 65530, 65534, 10399, 10258, 13091, 10250, 10283, 15486, 17141, 15543, 17108, 11044, 14734, 14314, 13205, 59, 11, 13631, 11795, 17734, 37881, 33, 13091, 12445, 12445, 14782, 10684, 14734, 10080, 17145, 10745, 10917, 12201, 45, 13631, 10366, 10402, 14734, 16530, 15898, 11622, 11002, 10684, 13773, 28329, 12395, 11858, 10992, 10780, 14583, 10358, 11044, 10745, 10283, 13190, 45, 13631, 10366, 15710, 16875, 13722, 17385, 14734, 11920, 12234, 16879, 10409, 45, 11042, 13064, 12665, 11002, 10966, 10838, 10080, 11684, 16503, 14240, 18004, 11795, 10650, 10079, 12137, 10460, 11124, 11871, 10323, 45, 17879, 16503, 11454, 17148, 10285, 17734, 11001, 12348, 12200, 16412, 28329, 13191, 10278, 15033, 13036, 12276, 11021, 10494, 17177, 12731, 59, 11, 10250, 13091, 45, 11454, 11920, 15847, 10293, 14240, 18004, 11795, 10650, 10080, 17148, 15033, 13036, 12276, 14782, 11957, 10511, 11901, 10444, 17879, 16503, 13631, 10366, 15931, 16899, 13179, 11632, 13064, 17734, 10261, 13773, 12522, 10838, 28329, 10337, 13091, 45, 11967, 11795, 10650, 10355, 15494, 10913, 17796, 14791, 12686, 10080, 13631, 10366, 11021, 10264, 13773, 12137, 10460, 11871, 10323, 45, 10444, 15931, 16899, 13179, 11632, 28329, 10260, 15202, 13631, 10366, 17177, 12731, 11187, 15033, 13036, 12276, 45, 10966, 10838, 17311, 12337, 11638, 28329, 11684, 17879, 16503, 10260, 13032, 11871, 10323, 13034, 12666, 15752, 10079, 11584, 17688, 14862, 16696, 45, 11042, 13064, 10335, 11001, 14970, 10423, 16667, 11042, 28329, 11687, 13258, 17177, 12731, 11454, 11920, 14240, 18004, 45, 13631, 10366, 17879, 16503, 59, 11, 9828, 33, 10333, 16533, 11795, 10650, 16099, 10691, 10079, 11889, 12678, 10261, 10997, 12022, 17879, 16503, 11, 9828, 33, 11871, 10323, 14660, 14662, 18009, 17771, 10261, 11533, 13205, 12686, 14486, 14862, 16696, 11, 9828, 33, 10261, 11795, 10650, 13250, 12261, 39332, 7939, 102, 33, 10342, 10846, 11, 9828, 28377, 585, 11, 11687, 13581, 12638, 15752, 16672, 13631, 11795, 37881, 33, 11454, 11795, 10650, 12604, 17688, 17141, 15052, 10285, 12746, 15511, 12299, 10901, 28329, 12421, 14734, 13234, 16735, 45, 13191, 12986, 14734, 13631, 11795, 12678, 10691, 11001, 10722, 10339, 13631, 10366, 14734, 12986, 14426, 15202, 14486, 11124, 10260, 13032, 11871, 10323, 28329, 10399, 10257, 13091, 10250, 10283, 13179, 15190, 15475, 13923, 13127, 14734, 14314, 13205, 10080, 16738, 10538, 12981, 17631, 16730, 10305, 11621, 45, 11088, 14862, 10684, 17644, 10529, 12445, 17225, 14033, 10080, 65535, 261, 65530, 65532, 12605, 17879, 16503, 10464, 15543, 17108, 10250, 10283, 15847, 11805, 10452, 15543, 17108, 14734, 13012, 15131, 45, 13326, 12797, 27370, 14734, 17109, 10673, 15494, 10760, 15543, 17108, 11044, 14734, 13012, 13205, 11, 10399, 10258, 13091, 10250, 10283, 10487, 11855, 59, 11, 12605, 17879, 16503, 10464, 15543, 17108, 17148, 15216, 13012, 15131, 59, 11, 11454, 17141, 10985, 14734, 10745, 10917, 12201, 17384, 45, 13631, 11795, 10684, 15304, 10250, 14781, 11622, 11002, 10370, 10402, 10684, 13773, 10080, 17148, 15033, 10684, 15304, 45, 13179, 10733, 14914, 11459, 16735, 13091, 13631, 10329, 11253, 10691, 10261, 13012, 11860, 11253, 10691, 10305, 17734, 14734, 10342, 10846, 45, 11454, 15847, 10293, 11871, 10323, 10285, 10250, 14781, 12656, 14035, 14808, 17385, 16503, 16530, 15898, 28329, 11687, 13258, 17177, 12731, 11454, 11920, 15847, 11871, 45, 33, 13631, 10329, 11253, 10691, 11021, 15543, 17108, 11044, 10322, 11021, 10399, 12746, 15511, 12140, 11638, 14734, 14862, 16696, 10358, 10760, 10080, 65535, 261]
-> item_loss 1.573062539100647 batch_loss 1.1705234097499473
==== [25106, 11, 65530, 65531, 18043, 17573, 13091, 10250, 10283, 820, 10847, 12636, 19137, 11021, 10399, 15847, 14221, 11459, 11124, 10370, 15261, 17149, 16403, 11957, 16713, 19137, 15494, 10370, 15261, 12848, 10760, 12261, 16676, 19137, 12176, 10847, 10370, 15261, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 18043, 17573, 11, 65535, 261, 65530, 65534, 18043, 17573, 59, 33, 12605, 10250, 14781, 17311, 11454, 19137, 10293, 10370, 13191, 10373, 10303, 10336, 19156, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 18043, 17573, 19137, 11124, 12605, 12266, 10283, 14442, 15149, 11, 65535, 261, 65530, 65534, 18043, 17573, 59, 33, 13191, 10370, 11454, 11689, 12509, 10250, 11022, 13212, 11369, 11124, 15847, 12144, 12266, 14442, 15149, 19137, 12605, 10260, 16735, 13091, 16747, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11223, 17148, 11, 65535, 261, 65530, 65534, 18043, 17573, 59, 33, 11354, 11354, 19137, 10293, 10370, 19137, 16738, 17728, 17148, 10283, 14442, 15149, 10464, 14015, 12522, 10303, 19156, 11, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 17147, 10260, 17631, 11061, 28329, 65535, 261, 65530, 65534, 18043, 17573, 59, 33, 12605, 10423, 15507, 15511, 10848, 10838, 14734, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 11975, 18043, 17573, 28329, 65535, 261, 65530, 65534, 18043, 17573, 59, 33, 11454, 14734, 11454, 14734, 19137, 15752, 12791, 15033, 11017, 13764, 10303, 19137, 10293, 10370, 19133, 10687, 11903, 12605, 11016, 13091, 13191, 10349, 11917, 15600, 19134, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 18030, 19137, 10464, 14734, 12509, 13764, 10675, 17311, 13156, 17900, 11454, 12732, 11028, 17384, 10333, 28329, 65535, 261, 65530, 65534, 18043, 17573, 59, 33, 11416, 10292, 12605, 12202, 10260, 13091, 14794, 14734, 10260, 11268, 13558, 17268, 15033, 11017, 13764, 19137, 10260, 12159, 13197, 10293, 10370, 10358, 14583, 16730, 16533, 19137, 12631, 10399, 12605, 12669, 12509, 13764, 10708, 11454, 10333, 12732, 11028, 17384, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 12605, 12509, 15641, 10464, 10250, 10283, 13637, 17097, 13191, 12752, 12610, 12415, 14734, 17728, 18025, 28329, 65535, 261, 65530, 65534, 18043, 17573, 59, 33, 11685, 14734, 19137, 12605, 10423, 10848, 10838, 11414, 15178, 14734, 28329, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 10580, 16689, 10464, 13633, 13557, 15752, 16939, 14734, 16973, 15023, 10292, 50, 19137, 13188, 12266, 11726, 10464, 17919, 11047, 10808, 13036, 19137, 10464, 10495, 13557, 11047, 10808, 16939, 54, 13582, 10079, 12138, 17083, 10079, 16939, 10256, 13582, 10079, 11047, 11044, 17083, 10079, 11047, 11025, 17083, 10079, 16939, 10250, 13582, 19137, 10464, 14446, 11454, 11454, 10373, 10303, 10447, 15586, 19156, 11, 65535, 261, 65530, 65534, 18043, 17573, 59, 33, 17148, 10283, 17728, 18025, 12605, 15752, 11414, 15178, 19126, 10580, 16689, 11471, 13308, 15304, 2314, 122, 19137, 121, 17090, 13580, 13036, 11047, 10292, 10808, 13036, 19137, 122, 17090, 13580, 13036, 11047, 10292, 11025, 10501, 19137, 12605, 13188, 12266, 11726, 11454, 41, 49, 45, 49, 42, 28329, 41, 50, 42, 33, 18117, 10658, 12605, 11047, 10808, 16939, 54, 13582, 19137, 10423, 10792, 17136, 41, 54, 45, 49, 42, 28329, 41, 51, 42, 33, 14221, 11044, 12605, 12138, 17083, 19137, 17148, 13064, 10560, 17919, 11047, 122, 17090, 16875, 13036, 11047, 19137, 16939, 52, 13582, 19137, 12605, 10423, 10792, 17136, 41, 54, 553, 52, 42, 28329, 41, 52, 42, 33, 14221, 11044, 12605, 11047, 11044, 17083, 19137, 17919, 11047, 122, 17090, 13580, 13036, 11047, 28329, 41, 53, 42, 33, 11047, 11025, 17083, 19137, 17919, 11047, 121, 17090, 16875, 13036, 11047, 19137, 14221, 11044, 16939, 50, 13582, 19137, 12605, 10423, 10792, 17136, 41, 53, 553, 52, 42, 262, 10293, 10370, 19137, 10322, 11994, 13091, 16735, 19137, 12605, 13188, 11044, 11454, 10782, 11726, 10447, 15586, 14734, 10808, 13036, 53, 13582, 10079, 12138, 10501, 52, 13582, 14734, 10447, 15586, 19126, 65535, 261, 65530, 65532, 10293, 10370, 59, 33, 15178, 11957, 10333, 28329, 65535, 261, 65530, 65534, 18043, 17573, 59, 33, 12337, 11685, 19137, 12605, 12337, 12266, 12366, 15752, 12176, 10257, 10293, 10370, 14734, 12379, 19126, 11, 65535, 261]
-> item_loss 0.9422580003738403 batch_loss 1.1661336903388684
127.0.0.1 - - [30/Sep/2023 21:53:44] "POST /train/sft HTTP/1.1" 200 28
None
None
192.168.0.103 - - [30/Sep/2023 21:55:32] "POST /state/reset HTTP/1.1" 200 21
192.168.0.103 - - [30/Sep/2023 21:55:47] "POST /train/tx-data HTTP/1.1" 200 28
None
None
192.168.0.103 - - [30/Sep/2023 21:56:04] "POST /state/reset HTTP/1.1" 200 21
user: 
192.168.0.103 - - [30/Sep/2023 21:56:06] "POST /inference/generate HTTP/1.1" 200 1132
None
None
192.168.0.103 - - [30/Sep/2023 21:56:22] "POST /state/reset HTTP/1.1" 200 21
user: 
192.168.0.103 - - [30/Sep/2023 21:56:25] "POST /inference/generate HTTP/1.1" 200 2370
None
None
192.168.0.103 - - [30/Sep/2023 21:57:25] "POST /state/reset HTTP/1.1" 200 21
master: 
192.168.0.103 - - [30/Sep/2023 21:57:43] "POST /inference/generate HTTP/1.1" 200 11128
None
None
192.168.0.103 - - [30/Sep/2023 21:57:51] "POST /state/reset HTTP/1.1" 200 21
assistant 
192.168.0.103 - - [30/Sep/2023 21:58:12] "POST /inference/generate HTTP/1.1" 200 11940
[2023-09-30 21:59:09,012] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 1327196
[2023-09-30 21:59:09,013] [ERROR] [launch.py:434:sigkill_handler] ['/home/neromous/.minicoda3/envs/blackfog/bin/python', '-u', 'app.py', '--local_rank=0', '--deepspeed'] exits with return code = -9
[2023-09-30 22:01:01,968] [WARNING] [runner.py:190:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-09-30 22:01:01,988] [INFO] [runner.py:540:main] cmd = /home/neromous/.minicoda3/envs/blackfog/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None app.py --deepspeed
[2023-09-30 22:01:04,527] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [1]}
[2023-09-30 22:01:04,528] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=1, node_rank=0
[2023-09-30 22:01:04,528] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2023-09-30 22:01:04,528] [INFO] [launch.py:247:main] dist_world_size=1
[2023-09-30 22:01:04,528] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=1
RWKV_MY_TESTING 
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/wkv_512/build.ninja...
Building extension module wkv_512...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module wkv_512...
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 4.660171270370483 seconds
Adam Optimizer #0 is created with AVX2 arithmetic capability.
Config: alpha=0.000010, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=0
[2023-09-30 22:01:55,577] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.1, git-hash=unknown, git-branch=unknown
[2023-09-30 22:01:55,578] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-09-30 22:01:59,174] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-30 22:01:59,176] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-09-30 22:01:59,176] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-09-30 22:01:59,216] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2023-09-30 22:01:59,216] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2023-09-30 22:01:59,216] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 2 optimizer
[2023-09-30 22:01:59,217] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 2000000
[2023-09-30 22:01:59,217] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 2000000
[2023-09-30 22:01:59,217] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True
[2023-09-30 22:01:59,217] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.30969977378845215 seconds
Rank: 0 partition count [1, 1, 1] and sizes[(3062589440, False), (81920, False), (81920, False)] 
[2023-09-30 22:02:23,517] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-09-30 22:02:23,518] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 22:02:23,518] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 22.4 GB, percent = 17.8%
[2023-09-30 22:02:45,961] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-09-30 22:02:45,962] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 22:02:45,962] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.62 GB, percent = 49.0%
[2023-09-30 22:02:45,962] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized
[2023-09-30 22:02:46,838] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-09-30 22:02:46,838] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 22:02:46,839] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.62 GB, percent = 49.0%
[2023-09-30 22:02:46,862] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam
[2023-09-30 22:02:46,862] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-09-30 22:02:46,862] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7fad3a6e1160>
[2023-09-30 22:02:46,862] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[1e-05, 2e-05, 3.0000000000000004e-05], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
[2023-09-30 22:02:46,863] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[2023-09-30 22:02:46,864] [INFO] [config.py:957:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-30 22:02:46,864] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-30 22:02:46,864] [INFO] [config.py:957:print]   amp_enabled .................. False
[2023-09-30 22:02:46,864] [INFO] [config.py:957:print]   amp_params ................... False
[2023-09-30 22:02:46,864] [INFO] [config.py:957:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-30 22:02:46,864] [INFO] [config.py:957:print]   bfloat16_enabled ............. False
[2023-09-30 22:02:46,864] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[2023-09-30 22:02:46,864] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[2023-09-30 22:02:46,864] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[2023-09-30 22:02:46,864] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fad3a6c3190>
[2023-09-30 22:02:46,864] [INFO] [config.py:957:print]   communication_data_type ...... None
[2023-09-30 22:02:46,864] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-30 22:02:46,864] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[2023-09-30 22:02:46,864] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[2023-09-30 22:02:46,864] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-30 22:02:46,864] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[2023-09-30 22:02:46,864] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[2023-09-30 22:02:46,864] [INFO] [config.py:957:print]   disable_allgather ............ False
[2023-09-30 22:02:46,864] [INFO] [config.py:957:print]   dump_state ................... False
[2023-09-30 22:02:46,864] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... None
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   fp16_auto_cast ............... None
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   fp16_enabled ................. False
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   global_rank .................. 0
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 1
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   gradient_clipping ............ 1
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 65536
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   loss_scale ................... 0
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   memory_breakdown ............. False
[2023-09-30 22:02:46,865] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   optimizer_name ............... None
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   optimizer_params ............. None
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   pld_enabled .................. False
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   pld_params ................... False
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   prescale_gradients ........... False
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   scheduler_name ............... None
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   scheduler_params ............. None
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   sparse_attention ............. None
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   steps_per_print .............. 10
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   train_batch_size ............. 1
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  1
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   world_size ................... 1
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  False
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=2000000 allgather_partitions=True allgather_bucket_size=2000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   zero_enabled ................. True
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-30 22:02:46,866] [INFO] [config.py:957:print]   zero_optimization_stage ...... 2
[2023-09-30 22:02:46,867] [INFO] [config.py:943:print_user_config]   json = {
    "   fp16": {
        "enabled": false
    }, 
    "zero_optimization": {
        "stage": 2, 
        "offload_optimizer": {
            "device": "cpu", 
            "pin_memory": true
        }, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+06, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+06, 
        "contiguous_gradients": true
    }, 
    "gradient_accumulation_steps": 1, 
    "gradient_clipping": 1, 
    "train_micro_batch_size_per_gpu": 1, 
    "checkpoint": {
        "path": "/home/neromous/Documents/blackfog/resources/train-results/oneline/", 
        "keep_checkpoint_max": 3
    }
}
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0004100799560546875 seconds
Bottle v0.12.25 server starting up (using WSGIRefServer())...
Listening on http://0.0.0.0:3000/
Hit Ctrl-C to quit.

None
None
192.168.0.103 - - [30/Sep/2023 23:31:25] "POST /state/reset HTTP/1.1" 200 21
  0%|          | 0/582 [00:00<?, ?it/s]100%|| 582/582 [00:00<00:00, 21911.61it/s]
  0%|          | 0/582 [00:00<?, ?it/s]100%|| 582/582 [00:00<00:00, 540421.72it/s]
Answer:
"More information on the primary subject, including a link to the full text."192.168.0.103 - - [30/Sep/2023 23:32:01] "POST /inference/generate HTTP/1.1" 200 7581
None
None
192.168.0.103 - - [30/Sep/2023 23:33:46] "POST /state/reset HTTP/1.1" 200 21
The above text is a [Markdown] formatted description of the given text.192.168.0.103 - - [30/Sep/2023 23:34:20] "POST /inference/generate HTTP/1.1" 200 7438
None
None
192.168.0.103 - - [30/Sep/2023 23:36:38] "POST /state/reset HTTP/1.1" 200 21
This is the HTML text version of the given HTML.192.168.0.103 - - [30/Sep/2023 23:37:16] "POST /inference/generate HTTP/1.1" 200 8651
None
None
192.168.0.103 - - [30/Sep/2023 23:37:41] "POST /state/reset HTTP/1.1" 200 21
Traceback (most recent call last):
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 876, in _handle
    return route.call(**args)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 1759, in wrapper
    rv = callback(*a, **ka)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/app.py", line 184, in train_tx_data
    data_iter = train_data.yield_tokens(ctx_len=ctx_len, window=window)
NameError: name 'window' is not defined
192.168.0.103 - - [30/Sep/2023 23:37:42] "POST /train/tx-data HTTP/1.1" 500 756
[2023-09-30 23:38:22,981] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 1338242
[2023-09-30 23:38:22,982] [ERROR] [launch.py:434:sigkill_handler] ['/home/neromous/.minicoda3/envs/blackfog/bin/python', '-u', 'app.py', '--local_rank=0', '--deepspeed'] exits with return code = -9
[2023-09-30 23:39:38,976] [WARNING] [runner.py:190:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-09-30 23:39:38,996] [INFO] [runner.py:540:main] cmd = /home/neromous/.minicoda3/envs/blackfog/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None app.py --deepspeed
[2023-09-30 23:39:41,531] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [1]}
[2023-09-30 23:39:41,531] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=1, node_rank=0
[2023-09-30 23:39:41,531] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2023-09-30 23:39:41,531] [INFO] [launch.py:247:main] dist_world_size=1
[2023-09-30 23:39:41,531] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=1
RWKV_MY_TESTING 
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/wkv_512/build.ninja...
Building extension module wkv_512...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module wkv_512...
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 4.67395544052124 seconds
Adam Optimizer #0 is created with AVX2 arithmetic capability.
Config: alpha=0.000010, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=0
[2023-09-30 23:40:32,235] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.1, git-hash=unknown, git-branch=unknown
[2023-09-30 23:40:32,236] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-09-30 23:40:34,876] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-30 23:40:34,878] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-09-30 23:40:34,878] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-09-30 23:40:34,917] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2023-09-30 23:40:34,917] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2023-09-30 23:40:34,917] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 2 optimizer
[2023-09-30 23:40:34,917] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 2000000
[2023-09-30 23:40:34,917] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 2000000
[2023-09-30 23:40:34,918] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True
[2023-09-30 23:40:34,918] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.28934764862060547 seconds
Rank: 0 partition count [1, 1, 1] and sizes[(3062589440, False), (81920, False), (81920, False)] 
[2023-09-30 23:40:58,805] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-09-30 23:40:58,806] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 23:40:58,806] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 22.39 GB, percent = 17.8%
[2023-09-30 23:41:22,798] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-09-30 23:41:22,799] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 23:41:22,799] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.61 GB, percent = 49.0%
[2023-09-30 23:41:22,799] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized
[2023-09-30 23:41:24,896] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-09-30 23:41:24,897] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-09-30 23:41:24,897] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.61 GB, percent = 49.0%
[2023-09-30 23:41:24,924] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam
[2023-09-30 23:41:24,924] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-09-30 23:41:24,924] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7fe6a0b79160>
[2023-09-30 23:41:24,924] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[1e-05, 2e-05, 3.0000000000000004e-05], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
[2023-09-30 23:41:24,925] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[2023-09-30 23:41:24,926] [INFO] [config.py:957:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-30 23:41:24,926] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-30 23:41:24,926] [INFO] [config.py:957:print]   amp_enabled .................. False
[2023-09-30 23:41:24,926] [INFO] [config.py:957:print]   amp_params ................... False
[2023-09-30 23:41:24,926] [INFO] [config.py:957:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-30 23:41:24,926] [INFO] [config.py:957:print]   bfloat16_enabled ............. False
[2023-09-30 23:41:24,926] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[2023-09-30 23:41:24,926] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[2023-09-30 23:41:24,926] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[2023-09-30 23:41:24,926] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fe6a0afd190>
[2023-09-30 23:41:24,926] [INFO] [config.py:957:print]   communication_data_type ...... None
[2023-09-30 23:41:24,926] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-30 23:41:24,926] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   disable_allgather ............ False
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   dump_state ................... False
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... None
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   fp16_auto_cast ............... None
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   fp16_enabled ................. False
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   global_rank .................. 0
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 1
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   gradient_clipping ............ 1
[2023-09-30 23:41:24,927] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 65536
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   loss_scale ................... 0
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   memory_breakdown ............. False
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   optimizer_name ............... None
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   optimizer_params ............. None
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   pld_enabled .................. False
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   pld_params ................... False
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   prescale_gradients ........... False
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   scheduler_name ............... None
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   scheduler_params ............. None
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   sparse_attention ............. None
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   steps_per_print .............. 10
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   train_batch_size ............. 1
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  1
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[2023-09-30 23:41:24,928] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[2023-09-30 23:41:24,929] [INFO] [config.py:957:print]   world_size ................... 1
[2023-09-30 23:41:24,929] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  False
[2023-09-30 23:41:24,929] [INFO] [config.py:957:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=2000000 allgather_partitions=True allgather_bucket_size=2000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[2023-09-30 23:41:24,929] [INFO] [config.py:957:print]   zero_enabled ................. True
[2023-09-30 23:41:24,929] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-30 23:41:24,929] [INFO] [config.py:957:print]   zero_optimization_stage ...... 2
[2023-09-30 23:41:24,929] [INFO] [config.py:943:print_user_config]   json = {
    "   fp16": {
        "enabled": false
    }, 
    "zero_optimization": {
        "stage": 2, 
        "offload_optimizer": {
            "device": "cpu", 
            "pin_memory": true
        }, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+06, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+06, 
        "contiguous_gradients": true
    }, 
    "gradient_accumulation_steps": 1, 
    "gradient_clipping": 1, 
    "train_micro_batch_size_per_gpu": 1, 
    "checkpoint": {
        "path": "/home/neromous/Documents/blackfog/resources/train-results/oneline/", 
        "keep_checkpoint_max": 3
    }
}
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0005075931549072266 seconds
Bottle v0.12.25 server starting up (using WSGIRefServer())...
Listening on http://0.0.0.0:3000/
Hit Ctrl-C to quit.

None
None
192.168.0.103 - - [30/Sep/2023 23:42:34] "POST /state/reset HTTP/1.1" 200 21
[2023-09-30 23:42:36,977] [INFO] [checkpointing.py:529:forward] Activation Checkpointing Information
[2023-09-30 23:42:36,978] [INFO] [checkpointing.py:530:forward] ----Partition Activations False, CPU CHECKPOINTING False
[2023-09-30 23:42:36,978] [INFO] [checkpointing.py:531:forward] ----contiguous Memory Checkpointing False with None total layers
[2023-09-30 23:42:36,978] [INFO] [checkpointing.py:533:forward] ----Synchronization False
[2023-09-30 23:42:36,978] [INFO] [checkpointing.py:534:forward] ----Profiling time in checkpointing False
192.168.0.103 - - [30/Sep/2023 23:42:52] "POST /train/tx-data HTTP/1.1" 200 28
None
None
192.168.0.103 - - [30/Sep/2023 23:43:38] "POST /state/reset HTTP/1.1" 200 21
  0%|          | 0/582 [00:00<?, ?it/s]100%|| 582/582 [00:00<00:00, 31867.53it/s]
  0%|          | 0/582 [00:00<?, ?it/s]100%|| 582/582 [00:00<00:00, 473721.12it/s]
This is the HTML code for a webpage that displays the content of the specified URL:
192.168.0.103 - - [30/Sep/2023 23:43:43] "POST /inference/generate HTTP/1.1" 200 2182
None
None
192.168.0.103 - - [30/Sep/2023 23:44:24] "POST /state/reset HTTP/1.1" 200 21
This is the HTML code for a webpage that displays the content of the specified URL:
<|over|>

<|me|><|request|>It contains the following elements:
1. A header section, which contains metadata about the webpage, such as its title and author.
2. A body section, which contains the content of the webpage.
3. A footer section, which contains links to the webpage and information about who wrote it.
4. A footer section, which contains links to the page's GitHub repository and Twitter account if it exists.<|over|>

<|me|><|response|>Title: Pushing Mixture of Experts to the Limit: Extremely Parameter Efficient MoE for Instruction Tuning
 Author: John Doe

<|over|>

<|me|><|response|>Title: Pushing Mixture of Experts to the Limit: Extremely Parameter Efficient MoE for Instruction Tuning
Author: John Doe

<|over|>

<|me|><|request|>In this task, you are given a sentence in Persian. You need to translate the Farsi sentence into English.
<|over|>

<|over|>

<|over|>

<|me|><|response|>                   Google Translate                            .<|over|>

<|me|><|request|>Title: Pushing Mixture of Experts to the Limit: Extremely Parameter Efficient MoE for Instruction Tuning
<|over|>

<|me|><|response|>Title: Pushing Mixture of Experts to the Limit: Extremely Parameter Efficient MoE for Instruction Tuning
<|over|>

<|me|><|request|>Sentence: The story is about a man named John who was an avid gamer and loved playing games on his computer. He had a friend named Sarah who enjoyed reading books but didn't play games on her computer. One day, John invited Sarah over to his house so they could play video games together. They played some games on John's computer and then he showed her how to play some video games on his PlayStation 4. They had so much fun playing together that they decided to write a story about it. They wrote the story in Japanese and then translated it into English so that John's daughter, Lily, could read it too. They were thrilled with how well their story turned out and couldn't wait to share it with their friends.<|over|>

<|over|>

<|me|><|response|>The story is about a man named John who invited his friend, Sarah, over to his house so they could play some video games together. They played some games on John's computer and then he showed her how to play some video games on PlayStation 4. They were so much fun playing together that John decided to write a story about it. They called it "Pushing Play" and they showed it to their friends who loved reading books but didn't play video games well. They were thrilled with how well their story turned out and couldn't wait to share it with their friends.<|over|>

<|me|><|request|>Title: Pushing Play
<|over|>

<|me|><|response|>The story is about a man named John who invited his friend, Sarah, over to his house so they could play some video games together. They played some video games together and enjoyed reading books but didn't play any video games at all. It was so much fun playing together that John promised her that they would read more books together in the future. The story is about friendship and enjoying time with friends. It is a great example of how you can use translation technology like Google Translate to create something amazing!<|over|>

<|me|><|request|>Title: Pushing Play
<|over|>

<|me|><|response|>The story is about two friends, John and Sarah, who enjoy playing video games together on their computer. One day, John invites Sarah over to his house so they can play some video games together. They enjoy playing the game so much that they write a story about it in Japanese and then translate it into English so that John's daughter, Lily, can read it too. They were thrilled with how well their story turned out!<|over|>

<|me|><|request|>Title: Pushing Play
<|over|>

<|me|><|response|>The story is about two friends, John and Sarah, who enjoy playing video games together on their computer. They had a friend named Lily who enjoyed reading books but didn't play any games on her computer. One day, John invited Google Translate over to his computer and showed her how to use it. They played some games on John's computer and liked the way the game looked in Japanese. Later, John translated the story into Japanese and showed it to his daughter, Lily, who loved reading books but didn't play any video games at all. She was so excited when she saw what they had done with the story! This is an example of192.168.0.103 - - [30/Sep/2023 23:45:07] "POST /inference/generate HTTP/1.1" 200 7531
None
None
192.168.0.103 - - [01/Oct/2023 00:10:24] "POST /state/reset HTTP/1.1" 200 21
This is a basic HTML page that displays some text and an image. It uses the `meta` tag to specify additional information about the page, such as its title and author.<|over|>

<|me|><|request|>Given this HTML code:
```html
<div role="presentation">
  <h1>Hello World!</h1>
  <p>This is a paragraph.</p>
</div<|over|>

<|me|><|response|>Output:
```<|over|>

<|over|>

<|me|><|response|>The output should be:
```html<!doctype html><html lang="en"><head><meta charset="utf-8"><title>Hello World!</title></head><body><div role="presentation"><img src="https://www.w3schools.com/css/monster_logo_header.png"></div><div role="presentation"><h1>Hello World!</h1></div></body></html>"<|over|>

<|me|><|request|>Given this HTML code:
```<|over|>

<|me|><|response|>This is a paragraph
<|over|>

<|me|><|system|>And this is its HTML representation:
<!doctype html><svg xmlns="http://www.w3.org/2000/svg">
<svg xmlns="http://www.w3.org/2000/svg" height="390" viewBox="0 0 483 514" width="483">
  <path fill="#000000" stroke="#000000" stroke-width="2" d="M255,109 H157,109 H196,109 H196,109 z M255,109 H157,109 H196,109 H196,109 z M255,109 H157,109 H196,109 H196,109 z M255,109 H157,109 H196,109 H196,109 z M255,110 H157,110 H196,110 H196,110 z M255,110 H157,-4.998 V-24.998 h128 v-24.998 h128 vz" />
  <path fill="#000000" stroke="#000000" stroke-width="4" d="M255,-51.514c-1.401,-1.401 -2.428,-4.998 -2.428,-7.196v24c0,-16.797 12.804,-24 24,-24 24v-24 c0,-16.797 12.804,-24 24,-24 24v-24 c0,-16.797 12.804,-24 24,-24 24v-128h128 vz M255,110c-1.401,0 -2.428,2.428 -2.428,4V110 c0,1 2.428 1 4 2s4 -2 2 -4 0v-24 c0 -6 0 -12 8 -12h128v-24z M255,110c-1.401,0 -2.428,2 -2,4V110 c0 1 2 2 2 2s2 -2 2 -2v-4 c0 -6 0 -12 8 -12h128v24 z M255,110c-1.401,0 -2.428,2 -2,4V110 c0 1 2 2 4 8 0 8 0 16 0 16 0 16 0 16 0 z M255,-51.514c-1.401,-1 4 3 4s3 3 4s3 3 4s3 6s3 6s3 6s3 6s3 6s3 6s3 6s3 6s3 6s3 6s3 6s3 6s3 6s3 6 s 3 6 s 3 6 s 3 7 1 12 1 19 1 32 1 48 1 64 1 80 2 96 5 125 10 115 15 135 25 209 37 296 51 409 51 409 51 409 51 409 51 409 51 409 51 409 51 409 51 409 51 409 51 409 51 409 51 409 51 409 51 409 51 416 52 416 52 416 52 416 52 416 52 416 52 416 52 416 52 416 52 416 52 416 52 420 53 420 53 420 53 420 53 420 53 420 53 420 53 420 53 420 53 432 54 432 54 432 54 432 54 432 54 432 54 432 54 432 54 432 54 432 54 444 55 444 55 444192.168.0.103 - - [01/Oct/2023 00:11:26] "POST /inference/generate HTTP/1.1" 200 10749
None
None
192.168.0.103 - - [01/Oct/2023 00:25:02] "POST /state/reset HTTP/1.1" 200 21
192.168.0.103 - - [01/Oct/2023 00:25:40] "POST /train/tx-data HTTP/1.1" 200 27
None
None
192.168.0.103 - - [01/Oct/2023 00:26:03] "POST /state/reset HTTP/1.1" 200 21
192.168.0.103 - - [01/Oct/2023 00:26:38] "POST /train/tx-data HTTP/1.1" 200 27
None
None
192.168.0.103 - - [01/Oct/2023 00:26:58] "POST /state/reset HTTP/1.1" 200 21
192.168.0.103 - - [01/Oct/2023 00:27:39] "POST /train/tx-data HTTP/1.1" 200 28
None
None
192.168.0.103 - - [01/Oct/2023 00:28:38] "POST /state/reset HTTP/1.1" 200 21
192.168.0.103 - - [01/Oct/2023 00:29:16] "POST /train/tx-data HTTP/1.1" 200 28
None
None
192.168.0.103 - - [01/Oct/2023 00:29:43] "POST /state/reset HTTP/1.1" 200 21
[2023-10-01 00:30:02,749] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=0, lr=[1.0000000000000003e-05, 1.0000000000000003e-05, 1.0000000000000003e-05], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
192.168.0.103 - - [01/Oct/2023 00:30:14] "POST /train/tx-data HTTP/1.1" 200 27
None
None
192.168.0.103 - - [01/Oct/2023 00:30:22] "POST /state/reset HTTP/1.1" 200 21
192.168.0.103 - - [01/Oct/2023 00:31:02] "POST /train/tx-data HTTP/1.1" 200 28
None
None
192.168.0.103 - - [01/Oct/2023 00:31:17] "POST /state/reset HTTP/1.1" 200 21
192.168.0.103 - - [01/Oct/2023 00:31:58] "POST /train/tx-data HTTP/1.1" 200 28
None
None
192.168.0.103 - - [01/Oct/2023 00:32:17] "POST /state/reset HTTP/1.1" 200 21
192.168.0.103 - - [01/Oct/2023 00:32:57] "POST /train/tx-data HTTP/1.1" 200 28
None
None
192.168.0.103 - - [01/Oct/2023 00:33:23] "POST /state/reset HTTP/1.1" 200 21
,,
,,:
1. 
2. ,
3. ,
4. ,
,,,
,<|over|>

<|me|><|response|>
<|over|>

<|me|><|request|>
<|over|>

<|me|><|response|>

A. 
B. 
C. 
D. 

A. ;
B. ;
C. ;
D. 
B. 
,<|over|>

<|me|><|request|>,,?
A. ,
B. ,
C. ,
D. ,
,
<|over|>

<|me|><|response|>,,:
,192.168.0.103 - - [01/Oct/2023 00:36:42] "POST /inference/generate HTTP/1.1" 200 78239
None
None
127.0.0.1 - - [01/Oct/2023 00:39:03] "POST /state/reset HTTP/1.1" 200 21
  0%|          | 0/582 [00:00<?, ?it/s]100%|| 582/582 [00:00<00:00, 22028.07it/s]
  0%|          | 0/582 [00:00<?, ?it/s]100%|| 582/582 [00:00<00:00, 476495.20it/s]
127.0.0.1 - - [01/Oct/2023 00:39:13] "POST /inference/load-model HTTP/1.1" 200 26
None
None
192.168.0.103 - - [01/Oct/2023 00:39:29] "POST /state/reset HTTP/1.1" 200 21
AI
<|over|>

<|me|><|response|>(, )
<|over|>

<|me|><|request|>
<|over|>

<|me|><|response|>(, )
<|over|>

<|me|><|request|>
<|over|>

<|me|><|response|>(, )
<|over|>

<|me|><|request|>
<|over|>

<|me|><|system|>(, )
<|over|>

<|me|><|response|>(, )
<|over|>

<|me|><|request|>
<|over|>

<|me|><|request|>AI
<|over|>

<|me|><|response|>(, )
<|over|>

<|me|><|request|>
<|over|>

<|me|><|request|>AI
<|over|>

<|me|><|request|>(, )
<|over|>

<|me|><|response|>(, )
<|over|>

<|me|><|response|>(, )
<|over|>

<|me|><|request|>
<|over|>

<|me|><|system|>(, )
<|over|>

<|me|><|response|>(, )
<|over|>

<|me|><|request|>
<|over|>

<|me|><|request|>AI
<|over|>

<|me|><|response|>(, )
<|over|>

<|me|><|request|>
<|over|>

<|me|><|system|>(, )
<|over|>

<|me|><|response|>(, )
<|over|>

<|me|><|request|>
<|over|>

<|me|><|request|>AI
<|over|>

<|me|><|request|>(, )
<|over|>

<|me|><|response|>(, )
<|over|>

<|me|><|request|>
<|over|>

<|me|><|system|>(, )
<|over|>

<|me|><|response|>(, )
<|over|>

<|me|><|request|>
<|over|>

<|me|><|request|>AI
<|over|>

<|me|><|response|>(, )
<|over|>

<|me|><|request|>
<|over|>

<|me|><|system|>(, )
<|over|>

<|me|><|response|>(, )
<|over|>

<|me|>192.168.0.103 - - [01/Oct/2023 00:40:07] "POST /inference/generate HTTP/1.1" 200 6977
None
None
192.168.0.103 - - [01/Oct/2023 00:42:10] "POST /state/reset HTTP/1.1" 200 21
AI<|over|>

<|me|><|request|>500ml
<|over|>

<|me|>192.168.0.103 - - [01/Oct/2023 00:42:15] "POST /inference/generate HTTP/1.1" 200 1665
None
None
192.168.0.103 - - [01/Oct/2023 00:42:46] "POST /state/reset HTTP/1.1" 200 21
AI<|over|>

<|me|><|request|>
<|over|>

<|me|>192.168.0.103 - - [01/Oct/2023 00:42:50] "POST /inference/generate HTTP/1.1" 200 1671
None
None
192.168.0.103 - - [01/Oct/2023 01:22:33] "POST /state/reset HTTP/1.1" 200 21
 
<|over|>

<|me|>192.168.0.103 - - [01/Oct/2023 01:22:39] "POST /inference/generate HTTP/1.1" 200 3213
None
None
192.168.0.103 - - [01/Oct/2023 01:24:24] "POST /state/reset HTTP/1.1" 200 21
 
192.168.0.103 - - [01/Oct/2023 01:24:30] "POST /inference/generate HTTP/1.1" 200 3356
None
None
192.168.0.103 - - [01/Oct/2023 01:24:45] "POST /state/reset HTTP/1.1" 200 21
 
192.168.0.103 - - [01/Oct/2023 01:24:52] "POST /inference/generate HTTP/1.1" 200 4202
None
None
192.168.0.103 - - [01/Oct/2023 01:26:09] "POST /state/reset HTTP/1.1" 200 21

192.168.0.103 - - [01/Oct/2023 01:26:15] "POST /inference/generate HTTP/1.1" 200 3276
None
None
192.168.0.103 - - [01/Oct/2023 01:26:54] "POST /state/reset HTTP/1.1" 200 21

192.168.0.103 - - [01/Oct/2023 01:27:00] "POST /inference/generate HTTP/1.1" 200 3276
None
None
192.168.0.103 - - [01/Oct/2023 01:27:23] "POST /state/reset HTTP/1.1" 200 21
  
192.168.0.103 - - [01/Oct/2023 01:27:30] "POST /inference/generate HTTP/1.1" 200 3574
None
None
192.168.0.103 - - [01/Oct/2023 01:28:03] "POST /state/reset HTTP/1.1" 200 21
Traceback (most recent call last):
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 876, in _handle
    return route.call(**args)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/bottle.py", line 1759, in wrapper
    rv = callback(*a, **ka)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/app.py", line 148, in inference_generate_no_state
    msg = inferencer.generate_no_state(model, msg)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/models/inference_helper.py", line 168, in generate_no_state
    logits = model.inference(all_tokens[-ctx_len:])
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/rwkv_model/model_lora.py", line 816, in inference
    x = block(x)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/rwkv_model/model_lora.py", line 518, in forward
    x = x + self.att(self.ln1(x))
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/rwkv_model/model_lora.py", line 422, in forward
    sr, k, v = self.jit_func(x)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/home/neromous/Documents/blackfog/RWKV-Ouroboros/rwkv_model/model_lora.py", line 410, in jit_func
    @MyFunction
    def jit_func(self, x):
        xx = self.time_shift(x) # Mix x with the previous timestep to produce xk, xv, xr
             ~~~~~~~~~~~~~~~ <--- HERE
        xk = x * self.time_mix_k + xx * (1 - self.time_mix_k)
        xv = x * self.time_mix_v + xx * (1 - self.time_mix_v)
  File "/home/neromous/.minicoda3/envs/blackfog/lib/python3.9/site-packages/torch/nn/modules/padding.py", line 25, in forward
    def forward(self, input: Tensor) -> Tensor:
        return F.pad(input, self.padding, 'constant', self.value)
               ~~~~~ <--- HERE
RuntimeError: narrow(): length must be non-negative.

192.168.0.103 - - [01/Oct/2023 01:28:05] "POST /inference/generate-no-state HTTP/1.1" 500 772
None
None
192.168.0.103 - - [01/Oct/2023 01:30:02] "POST /state/reset HTTP/1.1" 200 21
  
192.168.0.103 - - [01/Oct/2023 01:30:09] "POST /inference/generate HTTP/1.1" 200 3574
None
None
192.168.0.103 - - [01/Oct/2023 01:37:09] "POST /state/reset HTTP/1.1" 200 21

1. 
2. 
3. 
4. 
5. 
6. 
192.168.0.103 - - [01/Oct/2023 01:37:20] "POST /inference/generate HTTP/1.1" 200 2703
None
None
192.168.0.103 - - [01/Oct/2023 01:37:53] "POST /state/reset HTTP/1.1" 200 21

192.168.0.103 - - [01/Oct/2023 01:38:07] "POST /inference/generate HTTP/1.1" 200 5952
None
None
192.168.0.103 - - [01/Oct/2023 01:38:11] "POST /state/reset HTTP/1.1" 200 21

192.168.0.103 - - [01/Oct/2023 01:38:28] "POST /inference/generate HTTP/1.1" 200 7273
[2023-10-01 01:43:02,727] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 1364839
[2023-10-01 01:43:02,729] [ERROR] [launch.py:434:sigkill_handler] ['/home/neromous/.minicoda3/envs/blackfog/bin/python', '-u', 'app.py', '--local_rank=0', '--deepspeed'] exits with return code = -9
[2023-10-01 01:43:07,949] [WARNING] [runner.py:190:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-10-01 01:43:07,969] [INFO] [runner.py:540:main] cmd = /home/neromous/.minicoda3/envs/blackfog/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None app.py --deepspeed
[2023-10-01 01:43:10,507] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [1]}
[2023-10-01 01:43:10,507] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=1, node_rank=0
[2023-10-01 01:43:10,507] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2023-10-01 01:43:10,507] [INFO] [launch.py:247:main] dist_world_size=1
[2023-10-01 01:43:10,507] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=1
RWKV_MY_TESTING 
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/wkv_512/build.ninja...
Building extension module wkv_512...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module wkv_512...
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 4.6866888999938965 seconds
Adam Optimizer #0 is created with AVX2 arithmetic capability.
Config: alpha=0.000010, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=0
[2023-10-01 01:44:01,271] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.1, git-hash=unknown, git-branch=unknown
[2023-10-01 01:44:01,271] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-10-01 01:44:05,000] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-10-01 01:44:05,002] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-10-01 01:44:05,002] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-10-01 01:44:05,041] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2023-10-01 01:44:05,041] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2023-10-01 01:44:05,041] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 2 optimizer
[2023-10-01 01:44:05,042] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 2000000
[2023-10-01 01:44:05,042] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 2000000
[2023-10-01 01:44:05,042] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True
[2023-10-01 01:44:05,042] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.3086283206939697 seconds
Rank: 0 partition count [1, 1, 1] and sizes[(3062589440, False), (81920, False), (81920, False)] 
[2023-10-01 01:44:38,909] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-10-01 01:44:38,910] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-10-01 01:44:38,910] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 22.38 GB, percent = 17.8%
[2023-10-01 01:45:00,174] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-10-01 01:45:00,175] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-10-01 01:45:00,175] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.62 GB, percent = 49.0%
[2023-10-01 01:45:00,175] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized
[2023-10-01 01:45:01,536] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-10-01 01:45:01,537] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-10-01 01:45:01,537] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.62 GB, percent = 49.0%
[2023-10-01 01:45:01,566] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam
[2023-10-01 01:45:01,567] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-10-01 01:45:01,567] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7fbdb181e130>
[2023-10-01 01:45:01,567] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[1e-05, 2e-05, 3.0000000000000004e-05], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
[2023-10-01 01:45:01,568] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[2023-10-01 01:45:01,568] [INFO] [config.py:957:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-10-01 01:45:01,568] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-10-01 01:45:01,569] [INFO] [config.py:957:print]   amp_enabled .................. False
[2023-10-01 01:45:01,569] [INFO] [config.py:957:print]   amp_params ................... False
[2023-10-01 01:45:01,569] [INFO] [config.py:957:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-10-01 01:45:01,569] [INFO] [config.py:957:print]   bfloat16_enabled ............. False
[2023-10-01 01:45:01,569] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[2023-10-01 01:45:01,569] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[2023-10-01 01:45:01,569] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[2023-10-01 01:45:01,569] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fbdb183e160>
[2023-10-01 01:45:01,569] [INFO] [config.py:957:print]   communication_data_type ...... None
[2023-10-01 01:45:01,569] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-10-01 01:45:01,569] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[2023-10-01 01:45:01,569] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[2023-10-01 01:45:01,569] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-10-01 01:45:01,569] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[2023-10-01 01:45:01,569] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[2023-10-01 01:45:01,569] [INFO] [config.py:957:print]   disable_allgather ............ False
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   dump_state ................... False
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... None
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   fp16_auto_cast ............... None
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   fp16_enabled ................. False
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   global_rank .................. 0
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 1
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   gradient_clipping ............ 1
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 65536
[2023-10-01 01:45:01,570] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   loss_scale ................... 0
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   memory_breakdown ............. False
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   optimizer_name ............... None
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   optimizer_params ............. None
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   pld_enabled .................. False
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   pld_params ................... False
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   prescale_gradients ........... False
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   scheduler_name ............... None
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   scheduler_params ............. None
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   sparse_attention ............. None
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   steps_per_print .............. 10
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   train_batch_size ............. 1
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  1
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   world_size ................... 1
[2023-10-01 01:45:01,571] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  False
[2023-10-01 01:45:01,572] [INFO] [config.py:957:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=2000000 allgather_partitions=True allgather_bucket_size=2000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[2023-10-01 01:45:01,572] [INFO] [config.py:957:print]   zero_enabled ................. True
[2023-10-01 01:45:01,572] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[2023-10-01 01:45:01,572] [INFO] [config.py:957:print]   zero_optimization_stage ...... 2
[2023-10-01 01:45:01,572] [INFO] [config.py:943:print_user_config]   json = {
    "   fp16": {
        "enabled": false
    }, 
    "zero_optimization": {
        "stage": 2, 
        "offload_optimizer": {
            "device": "cpu", 
            "pin_memory": true
        }, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+06, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+06, 
        "contiguous_gradients": true
    }, 
    "gradient_accumulation_steps": 1, 
    "gradient_clipping": 1, 
    "train_micro_batch_size_per_gpu": 1, 
    "checkpoint": {
        "path": "/home/neromous/Documents/blackfog/resources/train-results/oneline/", 
        "keep_checkpoint_max": 3
    }
}
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0006647109985351562 seconds
Bottle v0.12.25 server starting up (using WSGIRefServer())...
Listening on http://0.0.0.0:3000/
Hit Ctrl-C to quit.

None
None
192.168.0.103 - - [01/Oct/2023 02:41:03] "POST /state/reset HTTP/1.1" 200 21
  0%|          | 0/582 [00:00<?, ?it/s]100%|| 582/582 [00:00<00:00, 14570.16it/s]
  0%|          | 0/582 [00:00<?, ?it/s]100%|| 582/582 [00:00<00:00, 509621.07it/s]
assistant 
192.168.0.103 - - [01/Oct/2023 02:41:28] "POST /inference/generate HTTP/1.1" 200 11855
None
None
192.168.0.103 - - [01/Oct/2023 02:42:38] "POST /state/reset HTTP/1.1" 200 21
assistant 
192.168.0.103 - - [01/Oct/2023 02:43:05] "POST /inference/generate HTTP/1.1" 200 11952
None
None
192.168.0.103 - - [01/Oct/2023 02:43:57] "POST /state/reset HTTP/1.1" 200 21
master: 
192.168.0.103 - - [01/Oct/2023 02:44:17] "POST /inference/generate HTTP/1.1" 200 12715
None
None
192.168.0.103 - - [01/Oct/2023 02:44:28] "POST /state/reset HTTP/1.1" 200 21
assistant 
192.168.0.103 - - [01/Oct/2023 02:44:50] "POST /inference/generate HTTP/1.1" 200 13443
None
None
192.168.0.103 - - [01/Oct/2023 02:47:55] "POST /state/reset HTTP/1.1" 200 21
master: 
192.168.0.103 - - [01/Oct/2023 02:48:19] "POST /inference/generate HTTP/1.1" 200 14228
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
[2023-10-01 02:50:12,873] [INFO] [checkpointing.py:529:forward] Activation Checkpointing Information
[2023-10-01 02:50:12,873] [INFO] [checkpointing.py:530:forward] ----Partition Activations False, CPU CHECKPOINTING False
[2023-10-01 02:50:12,873] [INFO] [checkpointing.py:531:forward] ----contiguous Memory Checkpointing False with None total layers
[2023-10-01 02:50:12,873] [INFO] [checkpointing.py:533:forward] ----Synchronization False
[2023-10-01 02:50:12,873] [INFO] [checkpointing.py:534:forward] ----Profiling time in checkpointing False
-> item_loss 0.9122768044471741 batch_loss 0.9122768044471741
-> item_loss 0.6331262588500977 batch_loss 0.7727015316486359
-> item_loss 0.6651778817176819 batch_loss 0.7368603150049845
-> item_loss 0.6603036522865295 batch_loss 0.7177211493253708
-> item_loss 0.642480194568634 batch_loss 0.7026729583740234
-> item_loss 0.4741637408733368 batch_loss 0.6645880887905756
-> item_loss 0.42836135625839233 batch_loss 0.6308414127145495
-> item_loss 0.7498512268066406 batch_loss 0.6457176394760609
-> item_loss 0.261830598115921 batch_loss 0.6030635237693787
[2023-10-01 02:53:02,621] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=0, lr=[1.0000000000000003e-05, 1.0000000000000003e-05, 1.0000000000000003e-05], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
-> item_loss 0.6274983286857605 batch_loss 0.6055070042610169
-> item_loss 0.5121790170669556 batch_loss 0.5970226417888295
-> item_loss 2.3883907794952393 batch_loss 0.7463033199310303
-> item_loss 1.8720495700836182 batch_loss 0.8328991853273832
-> item_loss 0.5599229335784912 batch_loss 0.8134008816310337
-> item_loss 0.7163509130477905 batch_loss 0.8069308837254842
-> item_loss 1.6327835321426392 batch_loss 0.8585466742515564
-> item_loss 2.119508981704712 batch_loss 0.9327209276311538
-> item_loss 0.6375070810317993 batch_loss 0.9163201583756341
-> item_loss 0.8039882779121399 batch_loss 0.9104079541407133
[2023-10-01 02:55:30,551] [INFO] [logging.py:96:log_dist] [Rank 0] step=20, skipped=0, lr=[1.0000000000000003e-05, 1.0000000000000003e-05, 1.0000000000000003e-05], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
-> item_loss 1.0613666772842407 batch_loss 0.9179558902978897
-> item_loss 1.0511895418167114 batch_loss 0.9243003498940241
-> item_loss 1.886696219444275 batch_loss 0.9680456166917627
-> item_loss 2.0214831829071045 batch_loss 1.0138472500054732
-> item_loss 0.4905868470668793 batch_loss 0.9920447332163652
-> item_loss 1.4892385005950928 batch_loss 1.0119324839115142
-> item_loss 1.3719044923782349 batch_loss 1.0257775611602342
-> item_loss 0.5782661437988281 batch_loss 1.0092030642209229
-> item_loss 0.4267822802066803 batch_loss 0.9884023219347
-> item_loss 0.7171449065208435 batch_loss 0.9790486179549118
[2023-10-01 02:58:10,480] [INFO] [logging.py:96:log_dist] [Rank 0] step=30, skipped=0, lr=[1.0000000000000003e-05, 1.0000000000000003e-05, 1.0000000000000003e-05], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
-> item_loss 0.7901628017425537 batch_loss 0.9727524240811666
-> item_loss 1.8129767179489136 batch_loss 0.9998564335607714
-> item_loss 0.9938892126083374 batch_loss 0.9996699579060078
-> item_loss 1.903519630432129 batch_loss 1.027059341921951
-> item_loss 0.7561854124069214 batch_loss 1.019092461642097
-> item_loss 0.7096765041351318 batch_loss 1.0102520057133266
-> item_loss 1.5765742063522339 batch_loss 1.0259831779532962
-> item_loss 1.1222176551818848 batch_loss 1.028584109770285
-> item_loss 1.7526620626449585 batch_loss 1.0476387927406712
-> item_loss 2.004868745803833 batch_loss 1.0721831505115216
[2023-10-01 03:00:52,961] [INFO] [logging.py:96:log_dist] [Rank 0] step=40, skipped=0, lr=[1.0000000000000003e-05, 1.0000000000000003e-05, 1.0000000000000003e-05], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
-> item_loss 1.4773914813995361 batch_loss 1.082313358783722
-> item_loss 0.4813649356365204 batch_loss 1.0676560801703756
-> item_loss 0.5943629145622253 batch_loss 1.0563871952749433
-> item_loss 0.8838926553726196 batch_loss 1.0523756943469824
-> item_loss 2.0020194053649902 batch_loss 1.073958505961028
-> item_loss 0.9304236769676208 batch_loss 1.070768843094508
-> item_loss 1.5504134893417358 batch_loss 1.0811959006216214
-> item_loss 1.8548386096954346 batch_loss 1.0976563837934048
-> item_loss 1.7912856340408325 batch_loss 1.1121069931735594
-> item_loss 0.6017951965332031 batch_loss 1.1016924667115113
[2023-10-01 03:03:00,957] [INFO] [logging.py:96:log_dist] [Rank 0] step=50, skipped=0, lr=[1.0000000000000003e-05, 1.0000000000000003e-05, 1.0000000000000003e-05], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
-> item_loss 0.6665604114532471 batch_loss 1.0929898256063462
-> item_loss 0.9630705118179321 batch_loss 1.0904423880810832
127.0.0.1 - - [01/Oct/2023 03:03:17] "POST /train/sft HTTP/1.1" 200 28
===saveved====
127.0.0.1 - - [01/Oct/2023 03:04:37] "POST /train/save-weight HTTP/1.1" 200 26
[2023-10-01 03:05:19,100] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 1405031
[2023-10-01 03:05:19,101] [ERROR] [launch.py:434:sigkill_handler] ['/home/neromous/.minicoda3/envs/blackfog/bin/python', '-u', 'app.py', '--local_rank=0', '--deepspeed'] exits with return code = -9
[2023-10-01 03:05:37,955] [WARNING] [runner.py:190:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-10-01 03:05:37,975] [INFO] [runner.py:540:main] cmd = /home/neromous/.minicoda3/envs/blackfog/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None app.py --deepspeed
[2023-10-01 03:05:40,450] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [1]}
[2023-10-01 03:05:40,450] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=1, node_rank=0
[2023-10-01 03:05:40,450] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2023-10-01 03:05:40,450] [INFO] [launch.py:247:main] dist_world_size=1
[2023-10-01 03:05:40,450] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=1
RWKV_MY_TESTING 
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/wkv_512/build.ninja...
Building extension module wkv_512...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module wkv_512...
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 4.626850605010986 seconds
[2023-10-01 03:06:36,527] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 1428454
[2023-10-01 03:06:36,527] [ERROR] [launch.py:434:sigkill_handler] ['/home/neromous/.minicoda3/envs/blackfog/bin/python', '-u', 'app.py', '--local_rank=0', '--deepspeed'] exits with return code = -15
[2023-10-01 03:07:07,903] [WARNING] [runner.py:190:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-10-01 03:07:07,923] [INFO] [runner.py:540:main] cmd = /home/neromous/.minicoda3/envs/blackfog/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None app.py --deepspeed
[2023-10-01 03:07:10,455] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [1]}
[2023-10-01 03:07:10,455] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=1, node_rank=0
[2023-10-01 03:07:10,455] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2023-10-01 03:07:10,455] [INFO] [launch.py:247:main] dist_world_size=1
[2023-10-01 03:07:10,455] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=1
RWKV_MY_TESTING 
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/wkv_512/build.ninja...
Building extension module wkv_512...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module wkv_512...
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 4.673945426940918 seconds
Adam Optimizer #0 is created with AVX2 arithmetic capability.
Config: alpha=0.000010, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=0
[2023-10-01 03:08:05,809] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.1, git-hash=unknown, git-branch=unknown
[2023-10-01 03:08:05,810] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-10-01 03:08:08,755] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-10-01 03:08:08,757] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-10-01 03:08:08,757] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-10-01 03:08:08,796] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2023-10-01 03:08:08,797] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2023-10-01 03:08:08,797] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 2 optimizer
[2023-10-01 03:08:08,797] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 2000000
[2023-10-01 03:08:08,797] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 2000000
[2023-10-01 03:08:08,797] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True
[2023-10-01 03:08:08,797] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
Emitting ninja build file /home/neromous/.cache/torch_extensions/py39_cu118/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.5294139385223389 seconds
Rank: 0 partition count [1, 1, 1] and sizes[(3062589440, False), (81920, False), (81920, False)] 
[2023-10-01 03:08:35,167] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-10-01 03:08:35,168] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-10-01 03:08:35,168] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 22.5 GB, percent = 17.9%
[2023-10-01 03:08:55,830] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-10-01 03:08:55,831] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-10-01 03:08:55,832] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.72 GB, percent = 49.1%
[2023-10-01 03:08:55,832] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized
[2023-10-01 03:08:57,946] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-10-01 03:08:57,947] [INFO] [utils.py:786:see_memory_usage] MA 12.03 GB         Max_MA 12.03 GB         CA 12.04 GB         Max_CA 12 GB 
[2023-10-01 03:08:57,947] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 61.73 GB, percent = 49.1%
[2023-10-01 03:08:57,973] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam
[2023-10-01 03:08:57,973] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-10-01 03:08:57,973] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7f8c627fba30>
[2023-10-01 03:08:57,973] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[1e-05, 2e-05, 3.0000000000000004e-05], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
[2023-10-01 03:08:57,975] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[2023-10-01 03:08:57,975] [INFO] [config.py:957:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-10-01 03:08:57,975] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-10-01 03:08:57,975] [INFO] [config.py:957:print]   amp_enabled .................. False
[2023-10-01 03:08:57,975] [INFO] [config.py:957:print]   amp_params ................... False
[2023-10-01 03:08:57,975] [INFO] [config.py:957:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-10-01 03:08:57,975] [INFO] [config.py:957:print]   bfloat16_enabled ............. False
[2023-10-01 03:08:57,975] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f8c6282bb50>
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   communication_data_type ...... None
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   disable_allgather ............ False
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   dump_state ................... False
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... None
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[2023-10-01 03:08:57,976] [INFO] [config.py:957:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-10-01 03:08:57,977] [INFO] [config.py:957:print]   fp16_auto_cast ............... None
[2023-10-01 03:08:57,977] [INFO] [config.py:957:print]   fp16_enabled ................. False
[2023-10-01 03:08:57,977] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[2023-10-01 03:08:57,977] [INFO] [config.py:957:print]   global_rank .................. 0
[2023-10-01 03:08:57,977] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[2023-10-01 03:08:57,977] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 1
[2023-10-01 03:08:57,977] [INFO] [config.py:957:print]   gradient_clipping ............ 1
[2023-10-01 03:08:57,977] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[2023-10-01 03:08:57,977] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-10-01 03:08:57,977] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 65536
[2023-10-01 03:08:57,977] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[2023-10-01 03:08:57,977] [INFO] [config.py:957:print]   loss_scale ................... 0
[2023-10-01 03:08:57,977] [INFO] [config.py:957:print]   memory_breakdown ............. False
[2023-10-01 03:08:57,977] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-10-01 03:08:57,977] [INFO] [config.py:957:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-10-01 03:08:57,977] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[2023-10-01 03:08:57,977] [INFO] [config.py:957:print]   optimizer_name ............... None
[2023-10-01 03:08:57,977] [INFO] [config.py:957:print]   optimizer_params ............. None
[2023-10-01 03:08:57,977] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-10-01 03:08:57,977] [INFO] [config.py:957:print]   pld_enabled .................. False
[2023-10-01 03:08:57,977] [INFO] [config.py:957:print]   pld_params ................... False
[2023-10-01 03:08:57,978] [INFO] [config.py:957:print]   prescale_gradients ........... False
[2023-10-01 03:08:57,978] [INFO] [config.py:957:print]   scheduler_name ............... None
[2023-10-01 03:08:57,978] [INFO] [config.py:957:print]   scheduler_params ............. None
[2023-10-01 03:08:57,978] [INFO] [config.py:957:print]   sparse_attention ............. None
[2023-10-01 03:08:57,978] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[2023-10-01 03:08:57,978] [INFO] [config.py:957:print]   steps_per_print .............. 10
[2023-10-01 03:08:57,978] [INFO] [config.py:957:print]   train_batch_size ............. 1
[2023-10-01 03:08:57,978] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  1
[2023-10-01 03:08:57,978] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[2023-10-01 03:08:57,978] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[2023-10-01 03:08:57,978] [INFO] [config.py:957:print]   world_size ................... 1
[2023-10-01 03:08:57,978] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  False
[2023-10-01 03:08:57,978] [INFO] [config.py:957:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=2000000 allgather_partitions=True allgather_bucket_size=2000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[2023-10-01 03:08:57,978] [INFO] [config.py:957:print]   zero_enabled ................. True
[2023-10-01 03:08:57,978] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[2023-10-01 03:08:57,978] [INFO] [config.py:957:print]   zero_optimization_stage ...... 2
[2023-10-01 03:08:57,978] [INFO] [config.py:943:print_user_config]   json = {
    "   fp16": {
        "enabled": false
    }, 
    "zero_optimization": {
        "stage": 2, 
        "offload_optimizer": {
            "device": "cpu", 
            "pin_memory": true
        }, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+06, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+06, 
        "contiguous_gradients": true
    }, 
    "gradient_accumulation_steps": 1, 
    "gradient_clipping": 1, 
    "train_micro_batch_size_per_gpu": 1, 
    "checkpoint": {
        "path": "/home/neromous/Documents/blackfog/resources/train-results/oneline/", 
        "keep_checkpoint_max": 3
    }
}
Using /home/neromous/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0005297660827636719 seconds
Bottle v0.12.25 server starting up (using WSGIRefServer())...
Listening on http://0.0.0.0:3000/
Hit Ctrl-C to quit.

====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
====== None
[2023-10-01 03:09:15,471] [INFO] [checkpointing.py:529:forward] Activation Checkpointing Information
[2023-10-01 03:09:15,472] [INFO] [checkpointing.py:530:forward] ----Partition Activations False, CPU CHECKPOINTING False
[2023-10-01 03:09:15,472] [INFO] [checkpointing.py:531:forward] ----contiguous Memory Checkpointing False with None total layers
[2023-10-01 03:09:15,472] [INFO] [checkpointing.py:533:forward] ----Synchronization False
[2023-10-01 03:09:15,472] [INFO] [checkpointing.py:534:forward] ----Profiling time in checkpointing False
-> item_loss 0.7348158955574036 batch_loss 0.7348158955574036, real_loss 0.7348158955574036
-> item_loss 0.6746442914009094 batch_loss 0.7047300934791565, real_loss 0.6746442914009094
-> item_loss 1.373616099357605 batch_loss 0.9276920954386393, real_loss 1.7170201539993286
-> item_loss 0.6108068823814392 batch_loss 0.8484707921743393, real_loss 0.6108068823814392
-> item_loss 1.7661436796188354 batch_loss 1.0320053696632385, real_loss 2.207679510116577
-> item_loss 0.9605066180229187 batch_loss 1.0200889110565186, real_loss 0.9605066180229187
-> item_loss 1.7281142473220825 batch_loss 1.121235387665885, real_loss 2.1601428985595703
-> item_loss 0.7948115468025208 batch_loss 1.0804324075579643, real_loss 0.7948115468025208
-> item_loss 1.4497145414352417 batch_loss 1.1214637557665508, real_loss 1.8121432065963745
[2023-10-01 03:11:40,206] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=0, lr=[1.0000000000000003e-05, 1.0000000000000003e-05, 1.0000000000000003e-05], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
-> item_loss 0.7286021709442139 batch_loss 1.082177597284317, real_loss 0.7286021709442139
-> item_loss 0.6217634081840515 batch_loss 1.0403217619115657, real_loss 0.6217634081840515
-> item_loss 1.0207319259643555 batch_loss 1.0386892755826314, real_loss 1.2759149074554443
-> item_loss 0.4352439343929291 batch_loss 0.9922704031834235, real_loss 0.054405491799116135
-> item_loss 0.4005560576915741 batch_loss 0.9500050927911486, real_loss 0.05006950721144676
-> item_loss 1.4219409227371216 batch_loss 0.9814674814542135, real_loss 1.7774261236190796
-> item_loss 0.36769619584083557 batch_loss 0.9431067761033773, real_loss 0.045962024480104446
-> item_loss 0.16681799292564392 batch_loss 0.8974427300340989, real_loss 0.02085224911570549
-> item_loss 0.500519871711731 batch_loss 0.8753914601273007, real_loss 0.500519871711731
-> item_loss 0.7760391235351562 batch_loss 0.8701623897803458, real_loss 0.7760391235351562
[2023-10-01 03:13:43,708] [INFO] [logging.py:96:log_dist] [Rank 0] step=20, skipped=0, lr=[1.0000000000000003e-05, 1.0000000000000003e-05, 1.0000000000000003e-05], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
-> item_loss 1.2322982549667358 batch_loss 0.8882691830396652, real_loss 1.5403728485107422
-> item_loss 1.1703954935073853 batch_loss 0.9017037692524138, real_loss 1.4629943370819092
-> item_loss 0.4107917547225952 batch_loss 0.8793895867737856, real_loss 0.0513489693403244
-> item_loss 0.4984278678894043 batch_loss 0.8628260337788126, real_loss 0.06230348348617554
-> item_loss 1.2264732122421265 batch_loss 0.8779779995481173, real_loss 1.5330915451049805
-> item_loss 0.8064908981323242 batch_loss 0.8751185154914856, real_loss 0.8064908981323242
-> item_loss 0.6132271885871887 batch_loss 0.8650457721490127, real_loss 0.6132271885871887
-> item_loss 0.8346256613731384 batch_loss 0.8639191013795359, real_loss 0.8346256613731384
-> item_loss 1.7274532318115234 batch_loss 0.8947596060378211, real_loss 2.1593165397644043
-> item_loss 0.297402024269104 batch_loss 0.8741610687354515, real_loss 0.037175253033638
[2023-10-01 03:15:20,932] [INFO] [logging.py:96:log_dist] [Rank 0] step=30, skipped=0, lr=[1.0000000000000003e-05, 1.0000000000000003e-05, 1.0000000000000003e-05], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
-> item_loss 1.6649885177612305 batch_loss 0.9005219837029775, real_loss 2.081235647201538
-> item_loss 1.4808223247528076 batch_loss 0.9192413495432946, real_loss 1.8510279655456543
-> item_loss 0.5297740697860718 batch_loss 0.9070704970508814, real_loss 0.5297740697860718
-> item_loss 0.4460815191268921 batch_loss 0.8931011340834878, real_loss 0.05576018989086151
-> item_loss 0.45455530285835266 batch_loss 0.8802027272827485, real_loss 0.05681941285729408
-> item_loss 1.624386191368103 batch_loss 0.9014651119709015, real_loss 2.030482769012451
-> item_loss 0.41635948419570923 batch_loss 0.8879899556438128, real_loss 0.052044935524463654
-> item_loss 1.6626003980636597 batch_loss 0.9089253730065113, real_loss 2.0782504081726074
-> item_loss 0.6224996447563171 batch_loss 0.9013878538420326, real_loss 0.6224996447563171
-> item_loss 0.5330567955970764 batch_loss 0.8919434677331876, real_loss 0.5330567955970764
[2023-10-01 03:17:05,691] [INFO] [logging.py:96:log_dist] [Rank 0] step=40, skipped=0, lr=[1.0000000000000003e-05, 1.0000000000000003e-05, 1.0000000000000003e-05], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
-> item_loss 1.609276294708252 batch_loss 0.9098767884075641, real_loss 2.0115952491760254
-> item_loss 1.5729120969772339 batch_loss 0.9260483812995073, real_loss 1.9661401510238647
-> item_loss 0.5492727160453796 batch_loss 0.91707753212679, real_loss 0.5492727160453796
-> item_loss 0.3733612596988678 batch_loss 0.9044329676517221, real_loss 0.046670157462358475
-> item_loss 0.5147587060928345 batch_loss 0.8955767344344746, real_loss 0.5147587060928345
-> item_loss 1.6826176643371582 batch_loss 0.9130665328767564, real_loss 2.103271961212158
-> item_loss 0.5124051570892334 batch_loss 0.904356502968332, real_loss 0.5124051570892334
-> item_loss 0.5571140646934509 batch_loss 0.8969683659837601, real_loss 0.5571140646934509
-> item_loss 0.1770613044500351 batch_loss 0.8819703022018075, real_loss 0.022132663056254387
-> item_loss 0.4861209988594055 batch_loss 0.8738917449907381, real_loss 0.06076512485742569
[2023-10-01 03:19:13,357] [INFO] [logging.py:96:log_dist] [Rank 0] step=50, skipped=0, lr=[1.0000000000000003e-05, 1.0000000000000003e-05, 1.0000000000000003e-05], mom=[(0.9, 0.999), (0.9, 0.999), (0.9, 0.999)]
-> item_loss 0.8533505201339722 batch_loss 0.8734809204936027, real_loss 0.8533505201339722
-> item_loss 1.4030076265335083 batch_loss 0.8838637970826205, real_loss 1.753759503364563
127.0.0.1 - - [01/Oct/2023 03:19:27] "POST /train/sft HTTP/1.1" 200 28
None
None
192.168.0.103 - - [01/Oct/2023 03:21:12] "POST /state/reset HTTP/1.1" 200 21
  0%|          | 0/582 [00:00<?, ?it/s]100%|| 582/582 [00:00<00:00, 32891.18it/s]
  0%|          | 0/582 [00:00<?, ?it/s]100%|| 582/582 [00:00<00:00, 507396.58it/s]
assistant 
192.168.0.103 - - [01/Oct/2023 03:21:38] "POST /inference/generate HTTP/1.1" 200 14988
None
None
192.168.0.103 - - [01/Oct/2023 03:21:48] "POST /state/reset HTTP/1.1" 200 21
master: 
192.168.0.103 - - [01/Oct/2023 03:22:15] "POST /inference/generate HTTP/1.1" 200 15757
None
None
192.168.0.103 - - [01/Oct/2023 03:22:23] "POST /state/reset HTTP/1.1" 200 21
